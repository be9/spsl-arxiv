url;title;authors;abstract;subject
https://arxiv.org/abs/1601.00367;Benders Decomposition for the Design of a Hub and Shuttle Public Transit  System; Arthur Maheo,  Philip Kilby,  Pascal Van Hentenryck;  The BusPlus project aims at improving the off-peak hours public transit service in Canberra, Australia. To address the difficulty of covering a large geographic area, BusPlus proposes a hub and shuttle model consisting of a combination of a few high-frequency bus routes between key hubs and a large number of shuttles that bring passengers from their origin to the closest hub and take them from their last bus stop to their destination. This paper focuses on the design of bus network and proposes an efficient solving method to this multimodal network design problem based on the Benders decomposition method. Starting from a MIP formulation of the problem, the paper presents a Benders decomposition approach using dedicated solution techniques for solving independent sub-problems, Pareto optimal cuts, cut bundling, and core point update. Computational results on real-world data from Canberra's public transit system justify the design choices and show that the approach outperforms the MIP formulation by two orders of magnitude. Moreover, the results show that the hub and shuttle model may decrease transit time by a factor of 2, while staying within the costs of the existing transit system. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.00529;Programming in logic without logic programming; Robert Kowalski,  Fariba Sadri;  In previous work, we proposed a logic-based framework in which computation is the execution of actions in an attempt to make reactive rules of the form if antecedent then consequent true in a canonical model of a logic program determined by an initial state, sequence of events, and the resulting sequence of subsequent states. In this model-theoretic semantics, reactive rules are the driving force, and logic programs play only a supporting role. In the canonical model, states, actions and other events are represented with timestamps. But in the operational semantics, for the sake of efficiency, timestamps are omitted and only the current state is maintained. State transitions are performed reactively by executing actions to make the consequents of rules true whenever the antecedents become true. This operational semantics is sound, but incomplete. It cannot make reactive rules true by preventing their antecedents from becoming true, or by proactively making their consequents true before their antecedents become true. In this paper, we characterize the notion of reactive model, and prove that the operational semantics can generate all and only such models. In order to focus on the main issues, we omit the logic programming component of the framework. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.00626;Scalable Models for Computing Hierarchies in Information Networks; Baoxu Shi,  Tim Weninger;"  Information hierarchies are organizational structures that often used to organize and present large and complex information as well as provide a mechanism for effective human navigation. Fortunately, many statistical and computational models exist that automatically generate hierarchies; however, the existing approaches do not consider linkages in information {\em networks} that are increasingly common in real-world scenarios. Current approaches also tend to present topics as an abstract probably distribution over words, etc rather than as tangible nodes from the original network. Furthermore, the statistical techniques present in many previous works are not yet capable of processing data at Web-scale. In this paper we present the Hierarchical Document Topic Model (HDTM), which uses a distributed vertex-programming process to calculate a nonparametric Bayesian generative model. Experiments on three medium size data sets and the entire Wikipedia dataset show that HDTM can infer accurate hierarchies even over large information networks. ";"Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Learning (cs.LG)"
https://arxiv.org/abs/1601.00669;Artwork creation by a cognitive architecture integrating computational  creativity and dual process approaches; Agnese Augello,  Ignazio Infantino,  Antonio Lieto,  Giovanni Pilato,  Riccardo Rizzo,  Filippo Vella;  The paper proposes a novel cognitive architecture (CA) for computational creativity based on the Psi model and on the mechanisms inspired by dual process theories of reasoning and rationality. In recent years, many cognitive models have focused on dual process theories to better describe and implement complex cognitive skills in artificial agents, but creativity has been approached only at a descriptive level. In previous works we have described various modules of the cognitive architecture that allows a robot to execute creative paintings. By means of dual process theories we refine some relevant mechanisms to obtain artworks, and in particular we explain details about the resolution level of the CA dealing with different strategies of access to the Long Term Memory (LTM) and managing the interaction between S1 and S2 processes of the dual process theory. The creative process involves both divergent and convergent processes in either implicit or explicit manner. This leads to four activities (exploratory, reflective, tacit, and analytic) that, triggered by urges and motivations, generate creative acts. These creative acts exploit both the LTM and the WM in order to make novel substitutions to a perceived image by properly mixing parts of pictures coming from different domains. The paper highlights the role of the interaction between S1 and S2 processes, modulated by the resolution level, which focuses the attention of the creative agent by broadening or narrowing the exploration of novel solutions, or even drawing the solution from a set of already made associations. An example of artificial painter is described in some experimentations by using a robotic platform. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.00816;Open challenges in understanding development and evolution of speech  forms: The roles of embodied self-organization, motivation and active  exploration; Pierre-Yves Oudeyer (Flowers);  This article discusses open scientific challenges for understanding development and evolution of speech forms, as a commentary to Moulin-Frier et al. (Moulin-Frier et al., 2015). Based on the analysis of mathematical models of the origins of speech forms, with a focus on their assumptions , we study the fundamental question of how speech can be formed out of non--speech, at both developmental and evolutionary scales. In particular, we emphasize the importance of embodied self-organization , as well as the role of mechanisms of motivation and active curiosity-driven exploration in speech formation. Finally , we discuss an evolutionary-developmental perspective of the origins of speech. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Learning (cs.LG)"
https://arxiv.org/abs/1601.00901;Joint learning of ontology and semantic parser from text; Janez Starc,  Dunja Mladenić;  Semantic parsing methods are used for capturing and representing semantic meaning of text. Meaning representation capturing all the concepts in the text may not always be available or may not be sufficiently complete. Ontologies provide a structured and reasoning-capable way to model the content of a collection of texts. In this work, we present a novel approach to joint learning of ontology and semantic parser from text. The method is based on semi-automatic induction of a context-free grammar from semantically annotated text. The grammar parses the text into semantic trees. Both, the grammar and the semantic trees are used to learn the ontology on several levels -- classes, instances, taxonomic and non-taxonomic relations. The approach was evaluated on the first sentences of Wikipedia pages describing people. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1601.01297;Angrier Birds: Bayesian reinforcement learning; Imanol Arrieta Ibarra,  Bernardo Ramos,  Lars Roemheld;  We train a reinforcement learner to play a simplified version of the game Angry Birds. The learner is provided with a game state in a manner similar to the output that could be produced by computer vision algorithms. We improve on the efficiency of regular {\epsilon}-greedy Q-Learning with linear function approximation through more systematic exploration in Randomized Least Squares Value Iteration (RLSVI), an algorithm that samples its policy from a posterior distribution on optimal policies. With larger state-action spaces, efficient exploration becomes increasingly important, as evidenced by the faster learning in RLSVI. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1601.01492;Complexity of Shift Bribery in Committee Elections; Robert Bredereck,  Piotr Faliszewski,  Rolf Niedermeier,  Nimrod Talmon;  We study the (parameterized) complexity of SHIFT BRIBERY for multiwinner voting rules. We focus on SNTV, Bloc, k-Borda, and Chamberlin-Courant, as well as on approximate variants of Chamberlin-Courant, since the original rule is NP-hard to compute. We show that SHIFT BRIBERY tends to be significantly harder in the multiwinner setting than in the single-winner one by showing settings where SHIFT BRIBERY is easy in the single-winner cases, but is hard (and hard to approximate) in the multiwinner ones. Moreover, we show that the non-monotonicity of those rules which are based on approximation algorithms for the Chamberlin-Courant rule sometimes affects the complexity of SHIFT BRIBERY. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)"
https://arxiv.org/abs/1601.01614;Toward Organic Computing Approach for Cybernetic Responsive Environment; Duhart Clément,  Bertelle Cyrille;  The developpment of the Internet of Things (IoT) concept revives Responsive Environments (RE) technologies. Nowadays, the idea of a permanent connection between physical and digital world is technologically possible. The capillar Internet relates to the Internet extension into daily appliances such as they become actors of Internet like any hu-man. The parallel development of Machine-to-Machine communications and Arti cial Intelligence (AI) technics start a new area of cybernetic. This paper presents an approach for Cybernetic Organism (Cyborg) for RE based on Organic Computing (OC). In such approach, each appli-ance is a part of an autonomic system in order to control a physical environment. The underlying idea is that such systems must have self-x properties in order to adapt their behavior to external disturbances with a high-degree of autonomy. ;"Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1601.01635;Fuzzy Object-Oriented Dynamic Networks. I; D. A. Terletskyi,  A. I. Provotar;  The concepts of fuzzy objects and their classes are described that make it possible to structurally represent knowledge about fuzzy and partially-defined objects and their classes. Operations over such objects and classes are also proposed that make it possible to obtain sets and new classes of fuzzy objects and also to model variations in object structures under the influence of external factors. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.01675;Ensemble Methods of Classification for Power Systems Security Assessment; Alexei Zhukov,  Victor Kurbatsky,  Nikita Tomin,  Denis Sidorov,  Daniil Panasetsky,  Aoife Foley;  One of the most promising approaches for complex technical systems analysis employs ensemble methods of classification. Ensemble methods enable to build a reliable decision rules for feature space classification in the presence of many possible states of the system. In this paper, novel techniques based on decision trees are used for evaluation of the reliability of the regime of electric power systems. We proposed hybrid approach based on random forests models and boosting models. Such techniques can be applied to predict the interaction of increasing renewable power, storage devices and swiching of smart loads from intelligent domestic appliances, heaters and air-conditioning units and electric vehicles with grid for enhanced decision making. The ensemble classification methods were tested on the modified 118-bus IEEE power system showing that proposed technique can be employed to examine whether the power system is secured under steady-state operating conditions. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1601.01920;Towards Semantic Integration of Heterogeneous Sensor Data with  Indigenous Knowledge for Drought Forecasting; Adeyinka K. Akanbi,  Muthoni Masinde;  In the Internet of Things (IoT) domain, various heterogeneous ubiquitous devices would be able to connect and communicate with each other seamlessly, irrespective of the domain. Semantic representation of data through detailed standardized annotation has shown to improve the integration of the interconnected heterogeneous devices. However, the semantic representation of these heterogeneous data sources for environmental monitoring systems is not yet well supported. To achieve the maximum benefits of IoT for drought forecasting, a dedicated semantic middleware solution is required. This research proposes a middleware that semantically represents and integrates heterogeneous data sources with indigenous knowledge based on a unified ontology for an accurate IoT-based drought early warning system (DEWS). ;"Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI); Software Engineering (cs.SE)"
https://arxiv.org/abs/1601.02433;Git4Voc: Git-based Versioning for Collaborative Vocabulary Development; Lavdim Halilaj,  Irlán Grangel-González,  Gökhan Coskun,  Sören Auer;  Collaborative vocabulary development in the context of data integration is the process of finding consensus between the experts of the different systems and domains. The complexity of this process is increased with the number of involved people, the variety of the systems to be integrated and the dynamics of their domain. In this paper we advocate that the realization of a powerful version control system is the heart of the problem. Driven by this idea and the success of Git in the context of software development, we investigate the applicability of Git for collaborative vocabulary development. Even though vocabulary development and software development have much more similarities than differences there are still important differences. These need to be considered within the development of a successful versioning and collaboration system for vocabulary development. Therefore, this paper starts by presenting the challenges we were faced with during the creation of vocabularies collaboratively and discusses its distinction to software development. Based on these insights we propose Git4Voc which comprises guidelines how Git can be adopted to vocabulary development. Finally, we demonstrate how Git hooks can be implemented to go beyond the plain functionality of Git by realizing vocabulary-specific features like syntactic validation and semantic diffs. ;"Artificial Intelligence (cs.AI); Databases (cs.DB); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1601.02745;Basic Reasoning with Tensor Product Representations; Paul Smolensky,  Moontae Lee,  Xiaodong He,  Wen-tau Yih,  Jianfeng Gao,  Li Deng;"  In this paper we present the initial development of a general theory for mapping inference in predicate logic to computation over Tensor Product Representations (TPRs; Smolensky (1990), Smolensky & Legendre (2006)). After an initial brief synopsis of TPRs (Section 0), we begin with particular examples of inference with TPRs in the 'bAbI' question-answering task of Weston et al. (2015) (Section 1). We then present a simplification of the general analysis that suffices for the bAbI task (Section 2). Finally, we lay out the general treatment of inference over TPRs (Section 3). We also show the simplification in Section 2 derives the inference methods described in Lee et al. (2016); this shows how the simple methods of Lee et al. (2016) can be formally extended to more general reasoning tasks. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.02865;Essence' Description; Peter Nightingale,  Andrea Rendl;  A description of the Essence' language as used by the tool Savile Row. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.03065;An Application of the Generalized Rectangular Fuzzy Model to Critical  Thinking Assessment; Igor Ya. Subbotin,  Michael Gr. Voskoglou;  The authors apply the Generalized Rectangular Model to assessing critical thinking skills and its relations with their language competency. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.03411;Analysis of Algorithms and Partial Algorithms; Andrew MacFie;  We present an alternative methodology for the analysis of algorithms, based on the concept of expected discounted reward. This methodology naturally handles algorithms that do not always terminate, so it can (theoretically) be used with partial algorithms for undecidable problems, such as those found in artificial general intelligence (AGI) and automated theorem proving. We mention an approach to self-improving AGI enabled by this methodology. Aug 2017 addendum: This article was originally written with multiple audiences in mind. It is really best put in the following terms. Goertzel, Hutter, Legg, and others have developed a definition of an intelligence score for a general abstract agent: expected lifetime reward in a random environment. AIXI is generally the optimal agent according to this score, but there may be reasons to analyze other agents and compare score values. If we want to use this definition of intelligence in practice, perhaps we can start by analyzing some simple agents. Common algorithms can be thought of as simple agents (environment is input, reward is based on running time) so we take the goal of applying the agent intelligence score to algorithms. That is, we want to find, what are the IQ scores of algorithms? We can do some very simple analysis, but the real answer is that even for simple algorithms, the intelligence score is too difficult to work with in practice. ;"Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1601.03785;A Method for Image Reduction Based on a Generalization of Ordered  Weighted Averaging Functions; A. Diego S. Farias,  Valdigleis S. Costa,  Luiz Ranyer A. Lopes,  Benjamín Bedregal,  Regivan Santiago;  In this paper we propose a special type of aggregation function which generalizes the notion of Ordered Weighted Averaging Function - OWA. The resulting functions are called Dynamic Ordered Weighted Averaging Functions --- DYOWAs. This generalization will be developed in such way that the weight vectors are variables depending on the input vector. Particularly, this operators generalize the aggregation functions: Minimum, Maximum, Arithmetic Mean, Median, etc, which are extensively used in image processing. In this field of research two problems are considered: The determination of methods to reduce images and the construction of techniques which provide noise reduction. The operators described here are able to be used in both cases. In terms of image reduction we apply the methodology provided by Patermain et al. We use the noise reduction operators obtained here to treat the images obtained in the first part of the paper, thus obtaining images with better quality. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.04105;Learning the Semantics of Structured Data Sources; Mohsen Taheriyan,  Craig A. Knoblock,  Pedro Szekely,  Jose Luis Ambite;  Information sources such as relational databases, spreadsheets, XML, JSON, and Web APIs contain a tremendous amount of structured data that can be leveraged to build and augment knowledge graphs. However, they rarely provide a semantic model to describe their contents. Semantic models of data sources represent the implicit meaning of the data by specifying the concepts and the relationships within the data. Such models are the key ingredients to automatically publish the data into knowledge graphs. Manually modeling the semantics of data sources requires significant effort and expertise, and although desirable, building these models automatically is a challenging problem. Most of the related work focuses on semantic annotation of the data fields (source attributes). However, constructing a semantic model that explicitly describes the relationships between the attributes in addition to their semantic types is critical. We present a novel approach that exploits the knowledge from a domain ontology and the semantic models of previously modeled sources to automatically learn a rich semantic model for a new source. This model represents the semantics of the new source in terms of the concepts and relationships defined by the domain ontology. Given some sample data from the new source, we leverage the knowledge in the domain ontology and the known semantic models to construct a weighted graph that represents the space of plausible semantic models for the new source. Then, we compute the top k candidate semantic models and suggest to the user a ranked list of the semantic models for the new source. The approach takes into account user corrections to learn more accurate semantic models on future data sources. Our evaluation shows that our method generates expressive semantic models for data sources and services with minimal user input. ... ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.04574;SimpleDS: A Simple Deep Reinforcement Learning Dialogue System; Heriberto Cuayáhuitl;  This paper presents 'SimpleDS', a simple and publicly available dialogue system trained with deep reinforcement learning. In contrast to previous reinforcement learning dialogue systems, this system avoids manual feature engineering by performing action selection directly from raw text of the last system and (noisy) user responses. Our initial results, in the restaurant domain, show that it is indeed possible to induce reasonable dialogue behaviour with an approach that aims for high levels of automation in dialogue control for intelligent interactive agents. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.04667;Proactive Message Passing on Memory Factor Networks; Patrick Eschenfeldt,  Dan Schmidt,  Stark Draper,  Jonathan Yedidia;"  We introduce a new type of graphical model that we call a ""memory factor network"" (MFN). We show how to use MFNs to model the structure inherent in many types of data sets. We also introduce an associated message-passing style algorithm called ""proactive message passing""' (PMP) that performs inference on MFNs. PMP comes with convergence guarantees and is efficient in comparison to competing algorithms such as variants of belief propagation. We specialize MFNs and PMP to a number of distinct types of data (discrete, continuous, labelled) and inference problems (interpolation, hypothesis testing), provide examples, and discuss approaches for efficient implementation. ";"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1601.05893;GeoTextTagger: High-Precision Location Tagging of Textual Documents  using a Natural Language Processing Approach; Shawn Brunsting,  Hans De Sterck,  Remco Dolman,  Teun van Sprundel;  Location tagging, also known as geotagging or geolocation, is the process of assigning geographical coordinates to input data. In this paper we present an algorithm for location tagging of textual documents. Our approach makes use of previous work in natural language processing by using a state-of-the-art part-of-speech tagger and named entity recognizer to find blocks of text which may refer to locations. A knowledge base (OpenStreatMap) is then used to find a list of possible locations for each block. Finally, one location is chosen for each block by assigning distance-based scores to each location and repeatedly selecting the location and block with the best score. We tested our geolocation algorithm with Wikipedia articles about topics with a well-defined geographical location that are geotagged by the articles' authors, where classification approaches have achieved median errors as low as 11 km, with attainable accuracy limited by the class size. Our approach achieved a 10th percentile error of 490 metres and median error of 54 kilometres on the Wikipedia dataset we used. When considering the five location tags with the greatest scores, 50% of articles were assigned at least one tag within 8.5 kilometres of the article's author-assigned true location. We also tested our approach on Twitter messages that are tagged with the location from which the message was sent. Twitter texts are challenging because they are short and unstructured and often do not contain words referring to the location they were sent from, but we obtain potentially useful results. We explain how we use the Spark framework for data analytics to collect and process our test data. In general, classification-based approaches for location tagging may be reaching their upper accuracy limit, but our precision-focused approach has high accuracy for some texts and shows significant potential for improvement overall. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Databases (cs.DB); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1601.05977;The Singularity Controversy, Part I: Lessons Learned and Open Questions:  Conclusions from the Battle on the Legitimacy of the Debate; Amnon H. Eden;  This report seeks to inform policy makers on the nature and the merit of the arguments for and against the concerns associated with a potential technological singularity. Part I describes the lessons learned from our investigation of the subject, separating the argu-ments of merit from the fallacies and misconceptions that confuse the debate and undermine its rational resolution. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY)"
https://arxiv.org/abs/1601.06069;Coalition-based Planning of Military Operations: Adversarial Reasoning  Algorithms in an Integrated Decision Aid; Larry Ground,  Alexander Kott,  Ray Budd;  Use of knowledge-based planning tools can help alleviate the challenges of planning a complex operation by a coalition of diverse parties in an adversarial environment. We explore these challenges and potential contributions of knowledge-based tools using as an example the CADET system, a knowledge-based tool capable of producing automatically (or with human guidance) battle plans with realistic degree of detail and complexity. In ongoing experiments, it compared favorably with human planners. Interleaved planning, scheduling, routing, attrition and consumption processes comprise the computational approach of this tool. From the coalition operations perspective, such tools offer an important aid in rapid synchronization of assets and actions of heterogeneous assets belonging to multiple organizations, potentially with distinct doctrine and rules of engagement. In this paper, we discuss the functionality of the tool, provide a brief overview of the technical approach and experimental results, and outline the potential value of such tools. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.06108;Decision Aids for Adversarial Planning in Military Operations:  Algorithms, Tools, and Turing-test-like Experimental Validation; Alexander Kott,  Ray Budd,  Larry Ground,  Lakshmi Rebbapragada,  John Langston;  Use of intelligent decision aids can help alleviate the challenges of planning complex operations. We describe integrated algorithms, and a tool capable of translating a high-level concept for a tactical military operation into a fully detailed, actionable plan, producing automatically (or with human guidance) plans with realistic degree of detail and of human-like quality. Tight interleaving of several algorithms -- planning, adversary estimates, scheduling, routing, attrition and consumption estimates -- comprise the computational approach of this tool. Although originally developed for Army large-unit operations, the technology is generic and also applies to a number of other domains, particularly in critical situations requiring detailed planning within a constrained period of time. In this paper, we focus particularly on the engineering tradeoffs in the design of the tool. In an experimental evaluation, reminiscent of the Turing test, the tool's performance compared favorably with human planners. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.06180;On the Latent Variable Interpretation in Sum-Product Networks; Robert Peharz,  Robert Gens,  Franz Pernkopf,  Pedro Domingos;  One of the central themes in Sum-Product networks (SPNs) is the interpretation of sum nodes as marginalized latent variables (LVs). This interpretation yields an increased syntactic or semantic structure, allows the application of the EM algorithm and to efficiently perform MPE inference. In literature, the LV interpretation was justified by explicitly introducing the indicator variables corresponding to the LVs' states. However, as pointed out in this paper, this approach is in conflict with the completeness condition in SPNs and does not fully specify the probabilistic model. We propose a remedy for this problem by modifying the original approach for introducing the LVs, which we call SPN augmentation. We discuss conditional independencies in augmented SPNs, formally establish the probabilistic interpretation of the sum-weights and give an interpretation of augmented SPNs as Bayesian networks. Based on these results, we find a sound derivation of the EM algorithm for SPNs. Furthermore, the Viterbi-style algorithm for MPE proposed in literature was never proven to be correct. We show that this is indeed a correct algorithm, when applied to selective SPNs, and in particular when applied to augmented SPNs. Our theoretical results are confirmed in experiments on synthetic data and 103 real-world datasets. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1601.06245;Artificial Persuasion in Pedagogical Games; Zhiwei Zeng;  A Persuasive Teachable Agent (PTA) is a special type of Teachable Agent which incorporates a persuasion theory in order to provide persuasive and more personalized feedback to the student. By employing the persuasion techniques, the PTA seeks to maintain the student in a high motivation and high ability state in which he or she has higher cognitive ability and his or her changes in attitudes are more persistent. However, the existing model of the PTA still has a few limitations. Firstly, the existing PTA model focuses on modelling the PTA's ability to persuade, while does not model its ability to be taught by the student and to practice the knowledge it has learnt. Secondly, the quantitative model for computational processes in the PTA has low reusability. Thirdly, there is still a gap between theoretical models and practical implementation of the PTA. To address these three limitations, this book proposes an improved agent model which follows a goal-oriented approach and models the PTA in its totality by integrating the Persuasion Reasoning of the PTA with the Teachability Reasoning and the Practicability Reasoning. The project also proposes a more abstract and generalized quantitative model for the computations in the PTA. With higher level of abstraction, the reusability of the quantitative model is also improved. New system architecture is introduced to bridge the gap between theoretical models and implementation of the PTA. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY)"
https://arxiv.org/abs/1601.06569;Towards Resolving Unidentifiability in Inverse Reinforcement Learning; Kareem Amin,  Satinder Singh;  We consider a setting for Inverse Reinforcement Learning (IRL) where the learner is extended with the ability to actively select multiple environments, observing an agent's behavior on each environment. We first demonstrate that if the learner can experiment with any transition dynamics on some fixed set of states and actions, then there exists an algorithm that reconstructs the agent's reward function to the fullest extent theoretically possible, and that requires only a small (logarithmic) number of experiments. We contrast this result to what is known about IRL in single fixed environments, namely that the true reward function is fundamentally unidentifiable. We then extend this setting to the more realistic case where the learner may not select any transition dynamic, but rather is restricted to some fixed set of environments that it may try. We connect the problem of maximizing the information derived from experiments to submodular function maximization and demonstrate that a greedy algorithm is near optimal (up to logarithmic factors). Finally, we empirically validate our algorithm on an environment inspired by behavioral psychology. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.06610;Generalizing Prototype Theory: A Formal Quantum Framework; Diederik Aerts,  Jan Broekaert,  Liane Gabora,  Sandro Sozzo;  Theories of natural language and concepts have been unable to model the flexibility, creativity, context-dependence, and emergence, exhibited by words, concepts and their combinations. The mathematical formalism of quantum theory has instead been successful in capturing these phenomena such as graded membership, situational meaning, composition of categories, and also more complex decision making situations, which cannot be modeled in traditional probabilistic approaches. We show how a formal quantum approach to concepts and their combinations can provide a powerful extension of prototype theory. We explain how prototypes can interfere in conceptual combinations as a consequence of their contextual interactions, and provide an illustration of this using an intuitive wave-like diagram. This quantum-conceptual approach gives new life to original prototype theory, without however making it a privileged concept theory, as we explain at the end of our paper. ;"Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)"
https://arxiv.org/abs/1601.06732;Concept Generation in Language Evolution; Martha Lewis,  Jonathan Lawry;  This thesis investigates the generation of new concepts from combinations of existing concepts as a language evolves. We give a method for combining concepts, and will be investigating the utility of composite concepts in language evolution and thence the utility of concept generation. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)"
https://arxiv.org/abs/1601.06738;A Label Semantics Approach to Linguistic Hedges; Martha Lewis,  Jonathan Lawry;  We introduce a model for the linguistic hedges `very' and `quite' within the label semantics framework, and combined with the prototype and conceptual spaces theories of concepts. The proposed model emerges naturally from the representational framework we use and as such, has a clear semantic grounding. We give generalisations of these hedge models and show that they can be composed with themselves and with other functions, going on to examine their behaviour in the limit of composition. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1601.06755;The Utility of Hedged Assertions in the Emergence of Shared Categorical  Labels; Martha Lewis,  Jonathan Lawry;  We investigate the emergence of shared concepts in a community of language users using a multi-agent simulation. We extend results showing that negated assertions are of use in developing shared categories, to include assertions modified by linguistic hedges. Results show that using hedged assertions positively affects the emergence of shared categories in two distinct ways. Firstly, using contraction hedges like `very' gives better convergence over time. Secondly, using expansion hedges such as `quite' reduces concept overlap. However, both these improvements come at a cost of slower speed of development. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)"
https://arxiv.org/abs/1601.06763;Emerging Dimension Weights in a Conceptual Spaces Model of Concept  Combination; Martha Lewis,  Jonathan Lawry;  We investigate the generation of new concepts from combinations of properties as an artificial language develops. To do so, we have developed a new framework for conjunctive concept combination. This framework gives a semantic grounding to the weighted sum approach to concept combination seen in the literature. We implement the framework in a multi-agent simulation of language evolution and show that shared combination weights emerge. The expected value and the variance of these weights across agents may be predicted from the distribution of elements in the conceptual space, as determined by the underlying environment, together with the rate at which agents adopt others' concepts. When this rate is smaller, the agents are able to converge to weights with lower variance. However, the time taken to converge to a steady state distribution of weights is longer. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)"
https://arxiv.org/abs/1601.06862;A Survey on Artificial Intelligence and Data Mining for MOOCs; Simon Fauvel,  Han Yu;  Massive Open Online Courses (MOOCs) have gained tremendous popularity in the last few years. Thanks to MOOCs, millions of learners from all over the world have taken thousands of high-quality courses for free. Putting together an excellent MOOC ecosystem is a multidisciplinary endeavour that requires contributions from many different fields. Artificial intelligence (AI) and data mining (DM) are two such fields that have played a significant role in making MOOCs what they are today. By exploiting the vast amount of data generated by learners engaging in MOOCs, DM improves our understanding of the MOOC ecosystem and enables MOOC practitioners to deliver better courses. Similarly, AI, supported by DM, can greatly improve student experience and learning outcomes. In this survey paper, we first review the state-of-the-art artificial intelligence and data mining research applied to MOOCs, emphasising the use of AI and DM tools and techniques to improve student engagement, learning outcomes, and our understanding of the MOOC ecosystem. We then offer an overview of key trends and important research to carry out in the fields of AI and DM so that MOOCs can reach their full potential. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY)"
https://arxiv.org/abs/1601.06923;Identification and classification of TCM syndrome types among patients  with vascular mild cognitive impairment using latent tree analysis; Chen Fu,  Nevin L. Zhang,  Bao Xin Chen,  Zhou Rong Chen,  Xiang Lan Jin,  Rong Juan Guo,  Zhi Gang Chen,  Yun Ling Zhang;  Objective: To treat patients with vascular mild cognitive impairment (VMCI) using TCM, it is necessary to classify the patients into TCM syndrome types and to apply different treatments to different types. We investigate how to properly carry out the classification using a novel data-driven method known as latent tree analysis. Method: A cross-sectional survey on VMCI was carried out in several regions in northern China from 2008 to 2011, which resulted in a data set that involves 803 patients and 93 symptoms. Latent tree analysis was performed on the data to reveal symptom co-occurrence patterns, and the patients were partitioned into clusters in multiple ways based on the patterns. The patient clusters were matched up with syndrome types, and population statistics of the clusters are used to quantify the syndrome types and to establish classification rules. Results: Eight syndrome types are identified: Qi Deficiency, Qi Stagnation, Blood Deficiency, Blood Stasis, Phlegm-Dampness, Fire-Heat, Yang Deficiency, and Yin Deficiency. The prevalence and symptom occurrence characteristics of each syndrome type are determined. Quantitative classification rules are established for determining whether a patient belongs to each of the syndrome types. Conclusions: A solution for the TCM syndrome classification problem associated with VMCI is established based on the latent tree analysis of unlabeled symptom survey data. The results can be used as a reference in clinic practice to improve the quality of syndrome differentiation and to reduce diagnosis variances across physicians. They can also be used for patient selection in research projects aimed at finding biomarkers for the syndrome types and in randomized control trials aimed at determining the efficacy of TCM treatments of VMCI. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.07065;Intelligent Conversational Bot for Massive Online Open Courses (MOOCs); Ser Ling Lim,  Ong Sing Goh;  Massive Online Open Courses (MOOCs) which were introduced in 2008 has since drawn attention around the world for both its advantages as well as criticism on its drawbacks. One of the issues in MOOCs which is the lack of interactivity with the instructor has brought conversational bot into the picture to fill in this gap. In this study, a prototype of MOOCs conversational bot, MOOC-bot is being developed and integrated into MOOCs website to respond to the learner inquiries using text or speech input. MOOC-bot is using the popular Artificial Intelligence Markup Language (AIML) to develop its knowledge base, leverage from AIML capability to deliver appropriate responses and can be quickly adapted to new knowledge domains. The system architecture of MOOC-bot consists of knowledge base along with AIML interpreter, chat interface, MOOCs website and Web Speech API to provide speech recognition and speech synthesis capability. The initial MOOC-bot prototype has the general knowledge from the past Loebner Prize winner - ALICE, frequent asked questions, and a content offered by Universiti Teknikal Malaysia Melaka (UTeM). The evaluation of MOOC-bot based on the past competition questions from Chatterbox Challenge (CBC) and Loebner Prize has shown that it was able to provide correct answers most of the time during the test and demonstrated the capability to prolong the conversation. The advantages of MOOC-bot such as able to provide 24-hour service that can serve different time zones, able to have knowledge in multiple domains, and can be shared by multiple sites simultaneously have outweighed its existing limitations. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.07224;Bachelor's thesis on generative probabilistic programming (in Russian  language, June 2014); Yura N Perov;  This Bachelor's thesis, written in Russian, is devoted to a relatively new direction in the field of machine learning and artificial intelligence, namely probabilistic programming. The thesis gives a brief overview to the already existing probabilistic programming languages: Church, Venture, and Anglican. It also describes the results of the first experiments on the automatic induction of probabilistic programs. The thesis was submitted, in June 2014, in partial fulfilment of the requirements for the degree of Bachelor of Science in Mathematics in the Department of Mathematics and Computer Science, Siberian Federal University, Krasnoyarsk, Russia. The work, which is described in this thesis, has been performing in 2012-2014 in the Massachusetts Institute of Technology and in the University of Oxford by the colleagues of the author and by himself. ;"Artificial Intelligence (cs.AI); Programming Languages (cs.PL)"
https://arxiv.org/abs/1601.07409;Multi-Object Reasoning with Constrained Goal Models; Chi Mai Nguyen,  Roberto Sebastiani,  Paolo Giorgini,  John Mylopoulos;"  Goal models have been widely used in Computer Science to represent software requirements, business objectives, and design qualities. Existing goal modelling techniques, however, have shown limitations of expressiveness and/or tractability in coping with complex real-world problems. In this work, we exploit advances in automated reasoning technologies, notably Satisfiability and Optimization Modulo Theories (SMT/OMT), and we propose and formalize: (i) an extended modelling language for goals, namely the Constrained Goal Model (CGM), which makes explicit the notion of goal refinement and of domain assumption, allows for expressing preferences between goals and refinements, and allows for associating numerical attributes to goals and refinements for defining constraints and optimization goals over multiple objective functions, refinements and their numerical attributes; (ii) a novel set of automated reasoning functionalities over CGMs, allowing for automatically generating suitable refinements of input CGMs, under user-specified assumptions and constraints, that also maximize preferences and optimize given objective functions. We have implemented these modelling and reasoning functionalities in a tool, named CGM-Tool, using the OMT solver OptiMathSAT as automated reasoning backend. Moreover, we have conducted an experimental evaluation on large CGMs to support the claim that our proposal scales well for goal models with thousands of elements. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.07483;Learning and Tuning Meta-heuristics in Plan Space Planning; Shashank Shekhar,  Deepak Khemani;  In recent years, the planning community has observed that techniques for learning heuristic functions have yielded improvements in performance. One approach is to use offline learning to learn predictive models from existing heuristics in a domain dependent manner. These learned models are deployed as new heuristic functions. The learned models can in turn be tuned online using a domain independent error correction approach to further enhance their informativeness. The online tuning approach is domain independent but instance specific, and contributes to improved performance for individual instances as planning proceeds. Consequently it is more effective in larger problems. In this paper, we mention two approaches applicable in Partial Order Causal Link (POCL) Planning that is also known as Plan Space Planning. First, we endeavor to enhance the performance of a POCL planner by giving an algorithm for supervised learning. Second, we then discuss an online error minimization approach in POCL framework to minimize the step-error associated with the offline learned models thus enhancing their informativeness. Our evaluation shows that the learning approaches scale up the performance of the planner over standard benchmarks, specially for larger problems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1601.07596;Efficient Hill-Climber for Multi-Objective Pseudo-Boolean Optimization; Francisco Chicano,  Darrell Whitley,  Renato Tinos;  Local search algorithms and iterated local search algorithms are a basic technique. Local search can be a stand along search methods, but it can also be hybridized with evolutionary algorithms. Recently, it has been shown that it is possible to identify improving moves in Hamming neighborhoods for k-bounded pseudo-Boolean optimization problems in constant time. This means that local search does not need to enumerate neighborhoods to find improving moves. It also means that evolutionary algorithms do not need to use random mutation as a operator, except perhaps as a way to escape local optima. In this paper, we show how improving moves can be identified in constant time for multiobjective problems that are expressed as k-bounded pseudo-Boolean functions. In particular, multiobjective forms of NK Landscapes and Mk Landscapes are considered. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1601.07929;Probabilistic Models for Computerized Adaptive Testing: Experiments; Martin Plajner,  Jiří Vomlel;  This paper follows previous research we have already performed in the area of Bayesian networks models for CAT. We present models using Item Response Theory (IRT - standard CAT method), Bayesian networks, and neural networks. We conducted simulated CAT tests on empirical data. Results of these tests are presented for each model separately and compared. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.00165;Using Social Networks to Aid Homeless Shelters: Dynamic Influence  Maximization under Uncertainty - An Extended Version; Amulya Yadav,  Hau Chan,  Albert Jiang,  Haifeng Xu,  Eric Rice,  Milind Tambe;"  This paper presents HEALER, a software agent that recommends sequential intervention plans for use by homeless shelters, who organize these interventions to raise awareness about HIV among homeless youth. HEALER's sequential plans (built using knowledge of social networks of homeless youth) choose intervention participants strategically to maximize influence spread, while reasoning about uncertainties in the network. While previous work presents influence maximizing techniques to choose intervention participants, they do not address three real-world issues: (i) they completely fail to scale up to real-world sizes; (ii) they do not handle deviations in execution of intervention plans; (iii) constructing real-world social networks is an expensive process. HEALER handles these issues via four major contributions: (i) HEALER casts this influence maximization problem as a POMDP and solves it using a novel planner which scales up to previously unsolvable real-world sizes; (ii) HEALER allows shelter officials to modify its recommendations, and updates its future plans in a deviation-tolerant manner; (iii) HEALER constructs social networks of homeless youth at low cost, using a Facebook application. Finally, (iv) we show hardness results for the problem that HEALER solves. HEALER will be deployed in the real world in early Spring 2016 and is currently undergoing testing at a homeless shelter. ";"Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Social and Information Networks (cs.SI)"
https://arxiv.org/abs/1602.00198;Discussion on Mechanical Learning and Learning Machine; Chuyu Xiong;  Mechanical learning is a computing system that is based on a set of simple and fixed rules, and can learn from incoming data. A learning machine is a system that realizes mechanical learning. Importantly, we emphasis that it is based on a set of simple and fixed rules, contrasting to often called machine learning that is sophisticated software based on very complicated mathematical theory, and often needs human intervene for software fine tune and manual adjustments. Here, we discuss some basic facts and principles of such system, and try to lay down a framework for further study. We propose 2 directions to approach mechanical learning, just like Church-Turing pair: one is trying to realize a learning machine, another is trying to well describe the mechanical learning. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.00269;Numerical Atrribute Extraction from Clinical Texts; Sarath P R,  Sunil Mandhan,  Yoshiki Niwa;"  This paper describes about information extraction system, which is an extension of the system developed by team Hitachi for ""Disease/Disorder Template filling"" task organized by ShARe/CLEF eHealth Evolution Lab 2014. In this extension module we focus on extraction of numerical attributes and values from discharge summary records and associating correct relation between attributes and values. We solve the problem in two steps. First step is extraction of numerical attributes and values, which is developed as a Named Entity Recognition (NER) model using Stanford NLP libraries. Second step is correctly associating the attributes to values, which is developed as a relation extraction module in Apache cTAKES framework. We integrated Stanford NER model as cTAKES pipeline component and used in relation extraction module. Conditional Random Field (CRF) algorithm is used for NER and Support Vector Machines (SVM) for relation extraction. For attribute value relation extraction, we observe 95% accuracy using NER alone and combined accuracy of 87% with NER and SVM. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.00515;Marvin: Semantic annotation using multiple knowledge sources; Nikola Milosevic;  People are producing more written material then anytime in the history. The increase is so high that professionals from the various fields are no more able to cope with this amount of publications. Text mining tools can offer tools to help them and one of the tools that can aid information retrieval and information extraction is semantic text annotation. In this report we present Marvin, a text annotator written in Java, which can be used as a command line tool and as a Java library. Marvin is able to annotate text using multiple sources, including WordNet, MetaMap, DBPedia and thesauri represented as SKOS. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1602.00753;Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects; Hessam Bagherinezhad,  Hannaneh Hajishirzi,  Yejin Choi,  Ali Farhadi;  Human vision greatly benefits from the information about sizes of objects. The role of size in several visual reasoning tasks has been thoroughly explored in human perception and cognition. However, the impact of the information about sizes of objects is yet to be determined in AI. We postulate that this is mainly attributed to the lack of a comprehensive repository of size information. In this paper, we introduce a method to automatically infer object sizes, leveraging visual and textual information from web. By maximizing the joint likelihood of textual and visual observations, our method learns reliable relative size estimates, with no explicit human supervision. We introduce the relative size dataset and show that our method outperforms competitive textual and visual baselines in reasoning about size comparisons. ;"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1602.01059;A Comparative Study of Ranking-based Semantics for Abstract  Argumentation; Elise Bonzon (LIPADE),  Jérôme Delobelle (CRIL),  Sébastien Konieczny (CRIL),  Nicolas Maudet (LIP6);  Argumentation is a process of evaluating and comparing a set of arguments. A way to compare them consists in using a ranking-based semantics which rank-order arguments from the most to the least acceptable ones. Recently, a number of such semantics have been proposed independently, often associated with some desirable properties. However, there is no comparative study which takes a broader perspective. This is what we propose in this work. We provide a general comparison of all these semantics with respect to the proposed properties. That allows to underline the differences of behavior between the existing semantics. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.01208;Spatial Concept Acquisition for a Mobile Robot that Integrates  Self-Localization and Unsupervised Word Discovery from Spoken Sentences; Akira Taniguchi,  Tadahiro Taniguchi,  Tetsunari Inamura;  In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Further, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)"
https://arxiv.org/abs/1602.01398;Finding the different patterns in buildings data using bag of words  representation with clustering; Usman Habib,  Gerhard Zucker;  The understanding of the buildings operation has become a challenging task due to the large amount of data recorded in energy efficient buildings. Still, today the experts use visual tools for analyzing the data. In order to make the task realistic, a method has been proposed in this paper to automatically detect the different patterns in buildings. The K Means clustering is used to automatically identify the ON (operational) cycles of the chiller. In the next step the ON cycles are transformed to symbolic representation by using Symbolic Aggregate Approximation (SAX) method. Then the SAX symbols are converted to bag of words representation for hierarchical clustering. Moreover, the proposed technique is applied to real life data of adsorption chiller. Additionally, the results from the proposed method and dynamic time warping (DTW) approach are also discussed and compared. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.01585;Ups and Downs: Modeling the Visual Evolution of Fashion Trends with  One-Class Collaborative Filtering; Ruining He,  Julian McAuley;  Building a successful recommender system depends on understanding both the dimensions of people's preferences as well as their dynamics. In certain domains, such as fashion, modeling such preferences can be incredibly difficult, due to the need to simultaneously model the visual appearance of products as well as their evolution over time. The subtle semantics and non-linear dynamics of fashion evolution raise unique challenges especially considering the sparsity and large scale of the underlying datasets. In this paper we build novel models for the One-Class Collaborative Filtering setting, where our goal is to estimate users' fashion-aware personalized ranking functions based on their past feedback. To uncover the complex and evolving visual factors that people consider when evaluating products, our method combines high-level visual features extracted from a deep convolutional neural network, users' past feedback, as well as evolving trends within the community. Experimentally we evaluate our method on two large real-world datasets from Amazon.com, where we show it to outperform state-of-the-art personalized ranking measures, and also use it to visualize the high-level fashion trends across the 11-year span of our dataset. ;"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1602.01628;Fuzzy Object-Oriented Dynamic Networks. II; D. A. Terletskyi,  A. I. Provotar;  This article generalizes object-oriented dynamic networks to the fuzzy case, which allows one to represent knowledge on objects and classes of objects that are fuzzy by nature and also to model their changes in time. Within the framework of the approach described, a mechanism is proposed that makes it possible to acquire new knowledge on the basis of basic knowledge and considerably differs from well-known methods used in existing models of knowledge representation. The approach is illustrated by an example of construction of a concrete fuzzy object-oriented dynamic network. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.01718;Formal Verification of Autonomous Vehicle Platooning; Maryam Kamali,  Louise A. Dennis,  Owen McAree,  Michael Fisher,  Sandor M. Veres;"  The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the new autonomous behaviors of the vehicles in these platoons must be certified. An appropriate representation for vehicle platooning is as a multi-agent system in which each agent captures the ""autonomous decisions"" carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the agent code does not scale to the full system and as the global verification technique does not capture the essential verification of autonomous behavior, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles. ";"Artificial Intelligence (cs.AI); Software Engineering (cs.SE)"
https://arxiv.org/abs/1602.01971;Wayfinding and cognitive maps for pedestrian models; Erik Andresen,  David Haensel,  Mohcine Chraibi,  Armin Seyfried;  Usually, routing models in pedestrian dynamics assume that agents have fulfilled and global knowledge about the building's structure. However, they neglect the fact that pedestrians possess no or only parts of information about their position relative to final exits and possible routes leading to them. To get a more realistic description we introduce the systematics of gathering and using spatial knowledge. A new wayfinding model for pedestrian dynamics is proposed. The model defines for every pedestrian an individual knowledge representation implying inaccuracies and uncertainties. In addition, knowledge-driven search strategies are introduced. The presented concept is tested on a fictive example scenario. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.02086;Region Based Approximation for High Dimensional Bayesian Network Models; Peng Lin,  Martin Neil,  Norman Fenton;  Performing efficient inference on Bayesian Networks (BNs), with large numbers of densely connected variables is challenging. With exact inference methods, such as the Junction Tree algorithm, clustering complexity can grow exponentially with the number of nodes and so computation becomes intractable. This paper presents a general purpose approximate inference algorithm called Triplet Region Construction (TRC) that reduces the clustering complexity for factorized models from worst case exponential to polynomial. We employ graph factorization to reduce connection complexity and produce clusters of limited size. Unlike MCMC algorithms TRC is guaranteed to converge and we present experiments that show that TRC achieves accurate results when compared with exact solutions. ;"Artificial Intelligence (cs.AI); Information Theory (cs.IT)"
https://arxiv.org/abs/1602.02089;Harmonic Grammar in a DisCo Model of Meaning; Martha Lewis,  Bob Coecke;  The model of cognition developed in (Smolensky and Legendre, 2006) seeks to unify two levels of description of the cognitive process: the connectionist and the symbolic. The theory developed brings together these two levels into the Integrated Connectionist/Symbolic Cognitive architecture (ICS). Clark and Pulman (2007) draw a parallel with semantics where meaning may be modelled on both distributional and symbolic levels, developed by Coecke et al, 2010 into the Distributional Compositional (DisCo) model of meaning. In the current work, we revisit Smolensky and Legendre (S&L)'s model. We describe the DisCo framework, summarise the key ideas in S&L's architecture, and describe how their description of harmony as a graded measure of grammaticality may be applied in the DisCo model. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1602.02169;Probabilistic Extension to the Concurrent Constraint Factor Oracle Model  for Music Improvisation; Mauricio Toro;"  We can program a Real-Time (RT) music improvisation system in C++ without a formal semantic or we can model it with process calculi such as the Non-deterministic Timed Concurrent Constraint (ntcc) calculus. ""A Concurrent Constraints Factor Oracle (FO) model for Music Improvisation"" (Ccfomi) is an improvisation model specified on ntcc. Since Ccfomi improvises non-deterministically, there is no control on choices and therefore little control over the sequence variation during the improvisation. To avoid this, we extended Ccfomi using the Probabilistic Non-deterministic Timed Concurrent Constraint calculus. Our extension to Ccfomi does not change the time and space complexity of building the FO, thus making our extension compatible with RT. However, there was not a ntcc interpreter capable of RT to execute Ccfomi. We developed Ntccrt --a RT capable interpreter for ntcc-- and we executed Ccfomi on Ntccrt. In the future, we plan to extend Ntccrt to execute our extension to Ccfomi. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.02261;End-to-End Goal-Driven Web Navigation; Rodrigo Nogueira,  Kyunghyun Cho;  We propose a goal-driven web navigation as a benchmark task for evaluating an agent with abilities to understand natural language and plan on partially observed environments. In this challenging task, an agent navigates through a website, which is represented as a graph consisting of web pages as nodes and hyperlinks as directed edges, to find a web page in which a query appears. The agent is required to have sophisticated high-level reasoning based on natural languages and efficient sequential decision-making capability to succeed. We release a software tool, called WebNav, that automatically transforms a website into this goal-driven web navigation task, and as an example, we make WikiNav, a dataset constructed from the English Wikipedia. We extensively evaluate different variants of neural net based artificial agents on WikiNav and observe that the proposed goal-driven web navigation well reflects the advances in models, making it a suitable benchmark for evaluating future progress. Furthermore, we extend the WikiNav with question-answer pairs from Jeopardy! and test the proposed agent based on recurrent neural networks against strong inverted index based search engines. The artificial agents trained on WikiNav outperforms the engined based approaches, demonstrating the capability of the proposed goal-driven navigation as a good proxy for measuring the progress in real-world tasks such as focused crawling and question-answering. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.02617;Adaptive imputation of missing values for incomplete pattern  classification; Zhun-Ga Liu,  Quan Pan,  Jean Dezert (Palaiseau),  Arnaud Martin (DRUID);  In classification of incomplete pattern, the missing values can either play a crucial role in the class determination, or have only little influence (or eventually none) on the classification results according to the context. We propose a credal classification method for incomplete pattern with adaptive imputation of missing values based on belief function theory. At first, we try to classify the object (incomplete pattern) based only on the available attribute values. As underlying principle, we assume that the missing information is not crucial for the classification if a specific class for the object can be found using only the available information. In this case, the object is committed to this particular class. However, if the object cannot be classified without ambiguity, it means that the missing values play a main role for achieving an accurate classification. In this case, the missing values will be imputed based on the K-nearest neighbor (K-NN) and self-organizing map (SOM) techniques, and the edited pattern with the imputation is then classified. The (original or edited) pattern is respectively classified according to each training class, and the classification results represented by basic belief assignments are fused with proper combination rules for making the credal classification. The object is allowed to belong with different masses of belief to the specific classes and meta-classes (which are particular disjunctions of several single classes). The credal classification captures well the uncertainty and imprecision of classification, and reduces effectively the rate of misclassifications thanks to the introduction of meta-classes. The effectiveness of the proposed method with respect to other classical methods is demonstrated based on several experiments using artificial and real data sets. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.02672;Learning to Communicate to Solve Riddles with Deep Distributed Recurrent  Q-Networks; Jakob N. Foerster,  Yannis M. Assael,  Nando de Freitas,  Shimon Whiteson;  We propose deep distributed recurrent Q-networks (DDRQN), which enable teams of agents to learn to solve communication-based coordination tasks. In these tasks, the agents are not given any pre-designed communication protocol. Therefore, in order to successfully communicate, they must first automatically develop and agree upon their own communication protocol. We present empirical results on two multi-agent learning problems based on well-known riddles, demonstrating that DDRQN can successfully solve such tasks and discover elegant communication protocols to do so. To our knowledge, this is the first time deep reinforcement learning has succeeded in learning communication protocols. In addition, we present ablation experiments that confirm that each of the main components of the DDRQN architecture are critical to its success. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1602.02867;Value Iteration Networks; Aviv Tamar,  Yi Wu,  Garrett Thomas,  Sergey Levine,  Pieter Abbeel;  We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.03203;Time Resource Networks; Szymon Sidor,  Peng Yu,  Cheng Fang,  Brian Williams;  The problem of scheduling under resource constraints is widely applicable. One prominent example is power management, in which we have a limited continuous supply of power but must schedule a number of power-consuming tasks. Such problems feature tightly coupled continuous resource constraints and continuous temporal constraints. We address such problems by introducing the Time Resource Network (TRN), an encoding for resource-constrained scheduling problems. The definition allows temporal specifications using a general family of representations derived from the Simple Temporal network, including the Simple Temporal Network with Uncertainty, and the probabilistic Simple Temporal Network (Fang et al. (2014)). We propose two algorithms for determining the consistency of a TRN: one based on Mixed Integer Programing and the other one based on Constraint Programming, which we evaluate on scheduling problems with Simple Temporal Constraints and Probabilistic Temporal Constraints. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.03291;Feature Based Task Recommendation in Crowdsourcing with Implicit  Observations; Habibur Rahman,  Lucas Joppa,  Senjuti Basu Roy;  Existing research in crowdsourcing has investigated how to recommend tasks to workers based on which task the workers have already completed, referred to as {\em implicit feedback}. We, on the other hand, investigate the task recommendation problem, where we leverage both implicit feedback and explicit features of the task. We assume that we are given a set of workers, a set of tasks, interactions (such as the number of times a worker has completed a particular task), and the presence of explicit features of each task (such as, task location). We intend to recommend tasks to the workers by exploiting the implicit interactions, and the presence or absence of explicit features in the tasks. We formalize the problem as an optimization problem, propose two alternative problem formulations and respective solutions that exploit implicit feedback, explicit features, as well as similarity between the tasks. We compare the efficacy of our proposed solutions against multiple state-of-the-art techniques using two large scale real world datasets. ;"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1602.03506;Research Priorities for Robust and Beneficial Artificial Intelligence; Stuart Russell (Berkeley),  Daniel Dewey (FHI),  Max Tegmark (MIT);  Success in the quest for artificial intelligence has the potential to bring unprecedented benefits to humanity, and it is therefore worthwhile to investigate how to maximize these benefits while avoiding potential pitfalls. This article gives numerous examples (which should by no means be construed as an exhaustive list) of such worthwhile research aimed at ensuring that AI remains robust and beneficial. ;"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.03779;Network of Bandits insure Privacy of end-users; Raphaël Féraud;  In order to distribute the best arm identification task as close as possible to the user's devices, on the edge of the Radio Access Network, we propose a new problem setting, where distributed players collaborate to find the best arm. This architecture guarantees privacy to end-users since no events are stored. The only thing that can be observed by an adversary through the core network is aggregated information across users. We provide a first algorithm, Distributed Median Elimination, which is optimal in term of number of transmitted bits and near optimal in term of speed-up factor with respect to an optimal algorithm run independently on each player. In practice, this first algorithm cannot handle the trade-off between the communication cost and the speed-up factor, and requires some knowledge about the distribution of players. Extended Distributed Median Elimination overcomes these limitations, by playing in parallel different instances of Distributed Median Elimination and selecting the best one. Experiments illustrate and complete the analysis. According to the analysis, in comparison to Median Elimination performed on each player, the proposed algorithm shows significant practical improvements. ;"Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Learning (cs.LG)"
https://arxiv.org/abs/1602.03924;Modeling Human Ad Hoc Coordination; Peter M. Krafft,  Chris L. Baker,  Alex Pentland,  Joshua B. Tenenbaum;  Whether in groups of humans or groups of computer agents, collaboration is most effective between individuals who have the ability to coordinate on a joint strategy for collective action. However, in general a rational actor will only intend to coordinate if that actor believes the other group members have the same intention. This circular dependence makes rational coordination difficult in uncertain environments if communication between actors is unreliable and no prior agreements have been made. An important normative question with regard to coordination in these ad hoc settings is therefore how one can come to believe that other actors will coordinate, and with regard to systems involving humans, an important empirical question is how humans arrive at these expectations. We introduce an exact algorithm for computing the infinitely recursive hierarchy of graded beliefs required for rational coordination in uncertain environments, and we introduce a novel mechanism for multiagent coordination that uses it. Our algorithm is valid in any environment with a finite state space, and extensions to certain countably infinite state spaces are likely possible. We test our mechanism for multiagent coordination as a model for human decisions in a simple coordination game using existing experimental data. We then explore via simulations whether modeling humans in this way may improve human-agent collaboration. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)"
https://arxiv.org/abs/1602.03963;Detection of Cooperative Interactions in Logistic Regression Models; Easton Li Xu,  Xiaoning Qian,  Tie Liu,  Shuguang Cui;  An important problem in the field of bioinformatics is to identify interactive effects among profiled variables for outcome prediction. In this paper, a logistic regression model with pairwise interactions among a set of binary covariates is considered. Modeling the structure of the interactions by a graph, our goal is to recover the interaction graph from independently identically distributed (i.i.d.) samples of the covariates and the outcome. When viewed as a feature selection problem, a simple quantity called influence is proposed as a measure of the marginal effects of the interaction terms on the outcome. For the case when the underlying interaction graph is known to be acyclic, it is shown that a simple algorithm that is based on a maximum-weight spanning tree with respect to the plug-in estimates of the influences not only has strong theoretical performance guarantees, but can also outperform generic feature selection algorithms for recovering the interaction graph from i.i.d. samples of the covariates and the outcome. Our results can also be extended to the model that includes both individual effects and pairwise interactions via the help of an auxiliary covariate. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.04019;Energetics of the brain and AI; Anders Sandberg;  Does the energy requirements for the human brain give energy constraints that give reason to doubt the feasibility of artificial intelligence? This report will review some relevant estimates of brain bioenergetics and analyze some of the methods of estimating brain emulation energy requirements. Turning to AI, there are reasons to believe the energy requirements for de novo AI to have little correlation with brain (emulation) energy requirements since cost could depend merely of the cost of processing higher-level representations rather than billions of neural firings. Unless one thinks the human way of thinking is the most optimal or most easily implementable way of achieving software intelligence, we should expect de novo AI to make use of different, potentially very compressed and fast, processes. ;"Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)"
https://arxiv.org/abs/1602.04032;A Truthful Mechanism with Biparameter Learning for Online Crowdsourcing; Satyanath Bhat,  Divya Padmanabhan,  Shweta Jain,  Y Narahari;  We study a problem of allocating divisible jobs, arriving online, to workers in a crowdsourcing setting which involves learning two parameters of strategically behaving workers. Each job is split into a certain number of tasks that are then allocated to workers. Each arriving job has to be completed within a deadline and each task has to be completed satisfying an upper bound on probability of failure. The job population is homogeneous while the workers are heterogeneous in terms of costs, completion times, and times to failure. The job completion time and time to failure of each worker are stochastic with fixed but unknown means. The requester is faced with the challenge of learning two separate parameters of each (strategically behaving) worker simultaneously, namely, the mean job completion time and the mean time to failure. The time to failure of a worker depends on the duration of the task handled by the worker. Assuming non-strategic workers to start with, we solve this biparameter learning problem by applying the Robust UCB algorithm. Then, we non-trivially extend this algorithm to the setting where the workers are strategic about their costs. Our proposed mechanism is dominant strategy incentive compatible and ex-post individually rational with asymptotically optimal regret performance. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1602.04257;Identifying Diabetic Patients with High Risk of Readmission; Malladihalli S Bhuvan,  Ankit Kumar,  Adil Zafar,  Vinith Kishore;  Hospital readmissions are expensive and reflect the inadequacies in healthcare system. In the United States alone, treatment of readmitted diabetic patients exceeds 250 million dollars per year. Early identification of patients facing a high risk of readmission can enable healthcare providers to to conduct additional investigations and possibly prevent future readmissions. This not only improves the quality of care but also reduces the medical expenses on readmission. Machine learning methods have been leveraged on public health data to build a system for identifying diabetic patients facing a high risk of future readmission. Number of inpatient visits, discharge disposition and admission type were identified as strong predictors of readmission. Further, it was found that the number of laboratory tests and discharge disposition together predict whether the patient will be readmitted shortly after being discharged from the hospital (i.e. <30 days) or after a longer period of time (i.e. >30 days). These insights can help healthcare providers to improve inpatient diabetic care. Finally, the cost analysis suggests that \$252.76 million can be saved across 98,053 diabetic patient encounters by incorporating the proposed cost sensitive analysis model. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY)"
https://arxiv.org/abs/1602.04259;A Minimalistic Approach to Sum-Product Network Learning for Real  Applications; Viktoriya Krakovna,  Moshe Looks;  Sum-Product Networks (SPNs) are a class of expressive yet tractable hierarchical graphical models. LearnSPN is a structure learning algorithm for SPNs that uses hierarchical co-clustering to simultaneously identifying similar entities and similar features. The original LearnSPN algorithm assumes that all the variables are discrete and there is no missing data. We introduce a practical, simplified version of LearnSPN, MiniSPN, that runs faster and can handle missing data and heterogeneous features common in real applications. We demonstrate the performance of MiniSPN on standard benchmark datasets and on two datasets from Google's Knowledge Graph exhibiting high missingness rates and a mix of discrete and continuous features. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.04290;Designing Intelligent Instruments; Kevin H. Knuth,  Philip M. Erner,  Scott Frasso;  Remote science operations require automated systems that can both act and react with minimal human intervention. One such vision is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, decides which new measurements to take. This innovation implements experimental design and unites it with data analysis in such a way that it completes the cycle of learning. This cycle is the basis of the Scientific Method. The three basic steps of this cycle are hypothesis generation, inquiry, and inference. Hypothesis generation is implemented by artificially supplying the instrument with a parameterized set of possible hypotheses that might be used to describe the physical system. The act of inquiry is handled by an inquiry engine that relies on Bayesian adaptive exploration where the optimal experiment is chosen as the one which maximizes the expected information gain. The inference engine is implemented using the nested sampling algorithm, which provides the inquiry engine with a set of posterior samples from which the expected information gain can be estimated. With these computational structures in place, the instrument will refine its hypotheses, and repeat the learning cycle by taking measurements until the system under study is described within a pre-specified tolerance. We will demonstrate our first attempts toward achieving this goal with an intelligent instrument constructed using the LEGO MINDSTORMS NXT robotics platform. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1602.04358;Machine olfaction using time scattering of sensor multiresolution graphs; Leonid Gugel,  Yoel Shkolnisky,  Shai Dekel;  In this paper we construct a learning architecture for high dimensional time series sampled by sensor arrangements. Using a redundant wavelet decomposition on a graph constructed over the sensor locations, our algorithm is able to construct discriminative features that exploit the mutual information between the sensors. The algorithm then applies scattering networks to the time series graphs to create the feature space. We demonstrate our method on a machine olfaction problem, where one needs to classify the gas type and the location where it originates from data sampled by an array of sensors. Our experimental results clearly demonstrate that our method outperforms classical machine learning techniques used in previous studies. ;"Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.04376;BPCMont: Business Process Change Management Ontology; Muhammad Fahad;  Change management for evolving collaborative business process development is crucial when the business logic, transections and workflow change due to changes in business strategies or organizational and technical environment. During the change implementation, business processes are analyzed and improved ensuring that they capture the proposed change and they do not contain any undesired functionalities or change side-effects. This paper presents Business Process Change Management approach for the efficient and effective implementation of change in the business process. The key technology behind our approach is our proposed Business Process Change Management Ontology (BPCMont) which is the main contribution of this paper. BPCMont, as a formalized change specification, helps to revert BP into a consistent state in case of system crash, intermediate conflicting stage or unauthorized change done, aid in change traceability in the new and old versions of business processes, change effects can be seen and estimated effectively, ease for Stakeholders to validate and verify change implementation, etc. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.04435;Random Forest Based Approach for Concept Drift Handling; A. Zhukov,  D. Sidorov,  A. Foley;"  Concept drift has potential in smart grid analysis because the socio-economic behaviour of consumers is not governed by the laws of physics. Likewise there are also applications in wind power forecasting. In this paper we present decision tree ensemble classification method based on the Random Forest algorithm for concept drift. The weighted majority voting ensemble aggregation rule is employed based on the ideas of Accuracy Weighted Ensemble (AWE) method. Base learner weight in our case is computed for each sample evaluation using base learners accuracy and intrinsic proximity measure of Random Forest. Our algorithm exploits both temporal weighting of samples and ensemble pruning as a forgetting strategy. We present results of empirical comparison of our method with original random forest with incorporated ""replace-the-looser"" forgetting andother state-of-the-art concept-drfit classifiers like AWE2. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Statistics Theory (math.ST)"
https://arxiv.org/abs/1602.04473;Large-Scale Reasoning with OWL; Michael Ruster;  With the growth of the Semantic Web in size and importance, more and more knowledge is stored in machine-readable formats such as the Web Ontology Language OWL. This paper outlines common approaches for efficient reasoning on large-scale data consisting of billions ($10^9$) of triples. Therefore, OWL and its sublanguages, as well as forward and backward chaining techniques are presented. The WebPIE reasoner is discussed in detail as an example for forward chaining using MapReduce for materialisation. Moreover, the QueryPIE reasoner is presented as a backward chaining/hybrid approach which uses query rewriting. Furthermore, an overview on other reasoners is given such as OWLIM and TrOWL. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1602.04498;Extending Consequence-Based Reasoning to SRIQ; Andrew Bate,  Boris Motik,  Bernardo Cuenca Grau,  František Simančík,  Ian Horrocks;  Consequence-based calculi are a family of reasoning algorithms for description logics (DLs), and they combine hypertableau and resolution in a way that often achieves excellent performance in practice. Up to now, however, they were proposed for either Horn DLs (which do not support disjunction), or for DLs without counting quantifiers. In this paper we present a novel consequence-based calculus for SRIQ---a rich DL that supports both features. This extension is non-trivial since the intermediate consequences that need to be derived during reasoning cannot be captured using DLs themselves. The results of our preliminary performance evaluation suggest the feasibility of our approach in practice. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.04613;Towards reducing the multidimensionality of OLAP cubes using the  Evolutionary Algorithms and Factor Analysis Methods; Sami Naouali,  Semeh Ben Salem;  Data Warehouses are structures with large amount of data collected from heterogeneous sources to be used in a decision support system. Data Warehouses analysis identifies hidden patterns initially unexpected which analysis requires great memory and computation cost. Data reduction methods were proposed to make this analysis easier. In this paper, we present a hybrid approach based on Genetic Algorithms (GA) as Evolutionary Algorithms and the Multiple Correspondence Analysis (MCA) as Analysis Factor Methods to conduct this reduction. Our approach identifies reduced subset of dimensions from the initial subset p where p'<p where it is proposed to find the profile fact that is the closest to reference. GAs identify the possible subsets and the Khi formula of the ACM evaluates the quality of each subset. The study is based on a distance measurement between the reference and n facts profile extracted from the Warehouses. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.04875;POMDP-lite for Robust Robot Planning under Uncertainty; Min Chen,  Emilio Frazzoli,  David Hsu,  Wee Sun Lee;  The partially observable Markov decision process (POMDP) provides a principled general model for planning under uncertainty. However, solving a general POMDP is computationally intractable in the worst case. This paper introduces POMDP-lite, a subclass of POMDPs in which the hidden state variables are constant or only change deterministically. We show that a POMDP-lite is equivalent to a set of fully observable Markov decision processes indexed by a hidden parameter and is useful for modeling a variety of interesting robotic tasks. We develop a simple model-based Bayesian reinforcement learning algorithm to solve POMDP-lite models. The algorithm performs well on large-scale POMDP-lite models with up to $10^{20}$ states and outperforms the state-of-the-art general-purpose POMDP algorithms. We further show that the algorithm is near-Bayesian-optimal under suitable conditions. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.04936;Reinforcement Learning approach for Real Time Strategy Games Battle city  and S3; Harshit Sethy,  Amit Patel;  In this paper we proposed reinforcement learning algorithms with the generalized reward function. In our proposed method we use Q-learning and SARSA algorithms with generalised reward function to train the reinforcement learning agent. We evaluated the performance of our proposed algorithms on two real-time strategy games called BattleCity and S3. There are two main advantages of having such an approach as compared to other works in RTS. (1) We can ignore the concept of a simulator which is often game specific and is usually hard coded in any type of RTS games (2) our system can learn from interaction with any opponents and quickly change the strategy according to the opponents and do not need any human traces as used in previous works. Keywords : Reinforcement learning, Machine learning, Real time strategy, Artificial intelligence. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1602.04951;Q($λ$) with Off-Policy Corrections; Anna Harutyunyan,  Marc G. Bellemare,  Tom Stepleton,  Remi Munos;  We propose and analyze an alternate approach to off-policy multi-step temporal difference learning, in which off-policy returns are corrected with the current Q-function in terms of rewards, rather than with the target policy in terms of transition probabilities. We prove that such approximate corrections are sufficient for off-policy convergence both in policy evaluation and control, provided certain conditions. These conditions relate the distance between the target and behavior policies, the eligibility trace parameter and the discount factor, and formalize an underlying tradeoff in off-policy TD($\lambda$). We illustrate this theoretical relationship empirically on a continuous-state control task. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.05404;11 x 11 Domineering is Solved: The first player wins; Jos W.H.M. Uiterwijk;  We have developed a program called MUDoS (Maastricht University Domineering Solver) that solves Domineering positions in a very efficient way. This enables the solution of known positions so far (up to the 10 x 10 board) much quicker (measured in number of investigated nodes). More importantly, it enables the solution of the 11 x 11 Domineering board, a board up till now far out of reach of previous Domineering solvers. The solution needed the investigation of 259,689,994,008 nodes, using almost half a year of computation time on a single simple desktop computer. The results show that under optimal play the first player wins the 11 x 11 Domineering game, irrespective if Vertical or Horizontal starts the game. In addition, several other boards hitherto unsolved were solved. Using the convention that Vertical starts, the 8 x 15, 11 x 9, 12 x 8, 12 x 15, 14 x 8, and 17 x 6 boards are all won by Vertical, whereas the 6 x 17, 8 x 12, 9 x 11, and 11 x 10 boards are all won by Horizontal. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.00423;Quantifying the vanishing gradient and long distance dependency problem  in recursive neural networks and recursive LSTMs; Phong Le,  Willem Zuidema;  Recursive neural networks (RNN) and their recently proposed extension recursive long short term memory networks (RLSTM) are models that compute representations for sentences, by recursively combining word embeddings according to an externally provided parse tree. Both models thus, unlike recurrent networks, explicitly make use of the hierarchical structure of a sentence. In this paper, we demonstrate that RNNs nevertheless suffer from the vanishing gradient and long distance dependency problem, and that RLSTMs greatly improve over RNN's on these problems. We present an artificial learning task that allows us to quantify the severity of these problems for both models. We further show that a ratio of gradients (at the root node and a focal leaf node) is highly indicative of the success of backpropagation at optimizing the relevant weights low in the tree. This paper thus provides an explanation for existing, superior results of RLSTMs on tasks such as sentiment analysis, and suggests that the benefits of including hierarchical structure and of including LSTM-style gating are complementary. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1603.00772;Filter based Taxonomy Modification for Improving Hierarchical  Classification; Azad Naik,  Huzefa Rangwala;"  Hierarchical Classification (HC) is a supervised learning problem where unlabeled instances are classified into a taxonomy of classes. Several methods that utilize the hierarchical structure have been developed to improve the HC performance. However, in most cases apriori defined hierarchical structure by domain experts is inconsistent; as a consequence performance improvement is not noticeable in comparison to flat classification methods. We propose a scalable data-driven filter based rewiring approach to modify an expert-defined hierarchy. Experimental comparisons of top-down HC with our modified hierarchy, on a wide range of datasets shows classification performance improvement over the baseline hierarchy (i:e:, defined by expert), clustered hierarchy and flattening based hierarchy modification approaches. In comparison to existing rewiring approaches, our developed method (rewHier) is computationally efficient, enabling it to scale to datasets with large numbers of classes, instances and features. We also show that our modified hierarchy leads to improved classification performance for classes with few training samples in comparison to flat and state-of-the-art HC approaches. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.01182;Network Unfolding Map by Edge Dynamics Modeling; Filipe Alves Neto Verri,  Paulo Roberto Urio,  Liang Zhao;"  The emergence of collective dynamics in neural networks is a mechanism of the animal and human brain for information processing. In this paper, we develop a computational technique of distributed processing elements, which are called particles. We observe the collective dynamics of particles in a complex network for transductive inference on semi-supervised learning problems. Three actions govern the particles' dynamics: walking, absorption, and generation. Labeled vertices generate new particles that compete against rival particles for edge domination. Active particles randomly walk in the network until they are absorbed by either a rival vertex or an edge currently dominated by rival particles. The result from the model simulation consists of sets of edges sorted by the label dominance. Each set tends to form a connected subnetwork to represent a data class. Although the intrinsic dynamics of the model is a stochastic one, we prove there exists a deterministic version with largely reduced computational complexity; specifically, with subquadratic growth. Furthermore, the edge domination process corresponds to an unfolding map. Intuitively, edges ""stretch"" and ""shrink"" according to edge dynamics. Consequently, such effect summarizes the relevant relationships between vertices and uncovered data classes. The proposed model captures important details of connectivity patterns over the edge dynamics evolution, which contrasts with previous approaches focused on vertex dynamics. Computer simulations reveal that our model can identify nonlinear features in both real and artificial data, including boundaries between distinct classes and the overlapping structure of data. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.01228;GeoGebra Tools with Proof Capabilities; Zoltán Kovács,  Csilla Sólyom-Gecse;  We report about significant enhancements of the complex algebraic geometry theorem proving subsystem in GeoGebra for automated proofs in Euclidean geometry, concerning the extension of numerous GeoGebra tools with proof capabilities. As a result, a number of elementary theorems can be proven by using GeoGebra's intuitive user interface on various computer architectures including native Java and web based systems with JavaScript. We also provide a test suite for benchmarking our results with 200 test cases. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.01312;Learning Physical Intuition of Block Towers by Example; Adam Lerer,  Sam Gross,  Rob Fergus;  Wooden blocks are a common toy for infants, allowing them to develop motor skills and gain intuition about the physical behavior of the world. In this paper, we explore the ability of deep feed-forward models to learn such intuitive physics. Using a 3D game engine, we create small towers of wooden blocks whose stability is randomized and render them collapsing (or remaining upright). This data allows us to train large convolutional network models which can accurately predict the outcome, as well as estimating the block trajectories. The models are also able to generalize in two important ways: (i) to new physical scenarios, e.g. towers with an additional block and (ii) to images of real wooden blocks, where it obtains a performance comparable to human subjects. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.01488;A knowledge representation meta-model for rule-based modelling of  signalling networks; Adrien Basso-Blandin (LIP, ENS Lyon),  Walter Fontana (Harvard Medical School),  Russ Harmer (CNRS & LIP, ENS Lyon);  The study of cellular signalling pathways and their deregulation in disease states, such as cancer, is a large and extremely complex task. Indeed, these systems involve many parts and processes but are studied piecewise and their literatures and data are consequently fragmented, distributed and sometimes--at least apparently--inconsistent. This makes it extremely difficult to build significant explanatory models with the result that effects in these systems that are brought about by many interacting factors are poorly understood. The rule-based approach to modelling has shown some promise for the representation of the highly combinatorial systems typically found in signalling where many of the proteins are composed of multiple binding domains, capable of simultaneous interactions, and/or peptide motifs controlled by post-translational modifications. However, the rule-based approach requires highly detailed information about the precise conditions for each and every interaction which is rarely available from any one single source. Rather, these conditions must be painstakingly inferred and curated, by hand, from information contained in many papers--each of which contains only part of the story. In this paper, we introduce a graph-based meta-model, attuned to the representation of cellular signalling networks, which aims to ease this massive cognitive burden on the rule-based curation process. This meta-model is a generalization of that used by Kappa and BNGL which allows for the flexible representation of knowledge at various levels of granularity. In particular, it allows us to deal with information which has either too little, or too much, detail with respect to the strict rule-based meta-model. Our approach provides a basis for the gradual aggregation of fragmented biological knowledge extracted from the literature into an instance of the meta-model from which we can define an automated translation into executable Kappa programs. ;"Artificial Intelligence (cs.AI); Molecular Networks (q-bio.MN)"
https://arxiv.org/abs/1603.01581;Causal inference for cloud computing; Philipp Geiger,  Lucian Carata,  Bernhard Schoelkopf;"  Cloud computing involves complex technical and economical systems and interactions. This brings about various challenges, two of which are: (1) debugging and control of computing systems, based on heterogeneous data, and (2) prediction of performance and price of ""spot"" resources, allocated via auctions. In this paper, we first establish two theoretical results on approximate causal inference. We then use the first one, approximate counterfactuals, along with established causal methodology, to outline a general framework to address (1). To address (2), we show how the second one, approximate integration of causal knowledge, can in principle provide a tool for cloud clients to trade off privacy against predictability of cloud costs. We report experiments on simulated and real data. ";"Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)"
https://arxiv.org/abs/1603.01722;A Linked Data Scalability Challenge: Concept Reuse Leads to Semantic  Decay; Paolo Pareti,  Ewan Klein,  Adam Barker;  The increasing amount of available Linked Data resources is laying the foundations for more advanced Semantic Web applications. One of their main limitations, however, remains the general low level of data quality. In this paper we focus on a measure of quality which is negatively affected by the increase of the available resources. We propose a measure of semantic richness of Linked Data concepts and we demonstrate our hypothesis that the more a concept is reused, the less semantically rich it becomes. This is a significant scalability issue, as one of the core aspects of Linked Data is the propagation of semantic information on the Web by reusing common terms. We prove our hypothesis with respect to our measure of semantic richness and we validate our model empirically. Finally, we suggest possible future directions to address this scalability problem. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.01840;Hierarchical Decision Making In Electricity Grid Management; Gal Dalal,  Elad Gilboa,  Shie Mannor;  The power grid is a complex and vital system that necessitates careful reliability management. Managing the grid is a difficult problem with multiple time scales of decision making and stochastic behavior due to renewable energy generations, variable demand and unplanned outages. Solving this problem in the face of uncertainty requires a new methodology with tractable algorithms. In this work, we introduce a new model for hierarchical decision making in complex systems. We apply reinforcement learning (RL) methods to learn a proxy, i.e., a level of abstraction, for real-time power grid reliability. We devise an algorithm that alternates between slow time-scale policy improvement, and fast time-scale value function approximation. We compare our results to prevailing heuristics, and show the strength of our method. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Applications (stat.AP)"
https://arxiv.org/abs/1603.02041;Learning Shared Representations in Multi-task Reinforcement Learning; Diana Borsa,  Thore Graepel,  John Shawe-Taylor;  We investigate a paradigm in multi-task reinforcement learning (MT-RL) in which an agent is placed in an environment and needs to learn to perform a series of tasks, within this space. Since the environment does not change, there is potentially a lot of common ground amongst tasks and learning to solve them individually seems extremely wasteful. In this paper, we explicitly model and learn this shared structure as it arises in the state-action value space. We will show how one can jointly learn optimal value-functions by modifying the popular Value-Iteration and Policy-Iteration procedures to accommodate this shared representation assumption and leverage the power of multi-task supervised learning. Finally, we demonstrate that the proposed model and training procedures, are able to infer good value functions, even under low samples regimes. In addition to data efficiency, we will show in our analysis, that learning abstractions of the state space jointly across tasks leads to more robust, transferable representations with the potential for better generalization. this shared representation assumption and leverage the power of multi-task supervised learning. Finally, we demonstrate that the proposed model and training procedures, are able to infer good value functions, even under low samples regimes. In addition to data efficiency, we will show in our analysis, that learning abstractions of the state space jointly across tasks leads to more robust, transferable representations with the potential for better generalization. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1603.02208;An Online Mechanism for Ridesharing in Autonomous Mobility-on-Demand  Systems; Wen Shen,  Cristina V. Lopes,  Jacob W. Crandall;  With proper management, Autonomous Mobility-on-Demand (AMoD) systems have great potential to satisfy the transport demands of urban populations by providing safe, convenient, and affordable ridesharing services. Meanwhile, such systems can substantially decrease private car ownership and use, and thus significantly reduce traffic congestion, energy consumption, and carbon emissions. To achieve this objective, an AMoD system requires private information about the demand from passengers. However, due to self-interestedness, passengers are unlikely to cooperate with the service providers in this regard. Therefore, an online mechanism is desirable if it incentivizes passengers to truthfully report their actual demand. For the purpose of promoting ridesharing, we hereby introduce a posted-price, integrated online ridesharing mechanism (IORS) that satisfies desirable properties such as ex-post incentive compatibility, individual rationality, and budget-balance. Numerical results indicate the competitiveness of IORS compared with two benchmarks, namely the optimal assignment and an offline, auction-based mechanism. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)"
https://arxiv.org/abs/1603.02738;Learning to Blend Computer Game Levels; Matthew Guzdial,  Mark Riedl;  We present an approach to generate novel computer game levels that blend different game concepts in an unsupervised fashion. Our primary contribution is an analogical reasoning process to construct blends between level design models learned from gameplay videos. The models represent probabilistic relationships between elements in the game. An analogical reasoning process maps features between two models to produce blended models that can then generate new level chunks. As a proof-of-concept we train our system on the classic platformer game Super Mario Bros. due to its highly-regarded and well understood level design. We evaluate the extent to which the models represent stylistic level design knowledge and demonstrate the ability of our system to explain levels that were blended by human expert designers. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.03181;Inferring Fine-grained Details on User Activities and Home Location from  Social Media: Detecting Drinking-While-Tweeting Patterns in Communities; Nabil Hossain,  Tianran Hu,  Roghayeh Feizi,  Ann Marie White,  Jiebo Luo,  Henry Kautz;  Nearly all previous work on geo-locating latent states and activities from social media confounds general discussions about activities, self-reports of users participating in those activities at times in the past or future, and self-reports made at the immediate time and place the activity occurs. Activities, such as alcohol consumption, may occur at different places and types of places, and it is important not only to detect the local regions where these activities occur, but also to analyze the degree of participation in them by local residents. In this paper, we develop new machine learning based methods for fine-grained localization of activities and home locations from Twitter data. We apply these methods to discover and compare alcohol consumption patterns in a large urban area, New York City, and a more suburban and rural area, Monroe County. We find positive correlations between the rate of alcohol consumption reported among a community's Twitter users and the density of alcohol outlets, demonstrating that the degree of correlation varies significantly between urban and suburban areas. While our experiments are focused on alcohol use, our methods for locating homes and distinguishing temporally-specific self-reports are applicable to a broad range of behaviors and latent states. ;"Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)"
https://arxiv.org/abs/1603.03267;Hierarchical Linearly-Solvable Markov Decision Problems; Anders Jonsson,  Vicenç Gómez;  We present a hierarchical reinforcement learning framework that formulates each task in the hierarchy as a special type of Markov decision process for which the Bellman equation is linear and has analytical solution. Problems of this type, called linearly-solvable MDPs (LMDPs) have interesting properties that can be exploited in a hierarchical setting, such as efficient learning of the optimal value function or task compositionality. The proposed hierarchical approach can also be seen as a novel alternative to solving LMDPs with large state spaces. We derive a hierarchical version of the so-called Z-learning algorithm that learns different tasks simultaneously and show empirically that it significantly outperforms the state-of-the-art learning methods in two classical hierarchical reinforcement learning domains: the taxi domain and an autonomous guided vehicle task. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.03511;A Set Theoretic Approach for Knowledge Representation: the  Representation Part; Yi Zhou;  In this paper, we propose a set theoretic approach for knowledge representation. While the syntax of an application domain is captured by set theoretic constructs including individuals, concepts and operators, knowledge is formalized by equality assertions. We first present a primitive form that uses minimal assumed knowledge and constructs. Then, assuming naive set theory, we extend it by definitions, which are special kinds of knowledge. Interestingly, we show that the primitive form is expressive enough to define logic operators, not only propositional connectives but also quantifiers. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.03515;Near-Optimal Active Learning of Halfspaces via Query Synthesis in the  Noisy Setting; Lin Chen,  Hamed Hassani,  Amin Karbasi;  In this paper, we consider the problem of actively learning a linear classifier through query synthesis where the learner can construct artificial queries in order to estimate the true decision boundaries. This problem has recently gained a lot of interest in automated science and adversarial reverse engineering for which only heuristic algorithms are known. In such applications, queries can be constructed de novo to elicit information (e.g., automated science) or to evade detection with minimal cost (e.g., adversarial reverse engineering). We develop a general framework, called dimension coupling (DC), that 1) reduces a d-dimensional learning problem to d-1 low dimensional sub-problems, 2) solves each sub-problem efficiently, 3) appropriately aggregates the results and outputs a linear classifier, and 4) provides a theoretical guarantee for all possible schemes of aggregation. The proposed method is proved resilient to noise. We show that the DC framework avoids the curse of dimensionality: its computational complexity scales linearly with the dimension. Moreover, we show that the query complexity of DC is near optimal (within a constant factor of the optimum algorithm). To further support our theoretical analysis, we compare the performance of DC with the existing work. We observe that DC consistently outperforms the prior arts in terms of query complexity while often running orders of magnitude faster. ;"Artificial Intelligence (cs.AI); Information Theory (cs.IT); Learning (cs.LG)"
https://arxiv.org/abs/1603.03518;High-dimensional Black-box Optimization via Divide and Approximate  Conquer; Peng Yang,  Ke Tang,  Xin Yao;  Divide and Conquer (DC) is conceptually well suited to high-dimensional optimization by decomposing a problem into multiple small-scale sub-problems. However, appealing performance can be seldom observed when the sub-problems are interdependent. This paper suggests that the major difficulty of tackling interdependent sub-problems lies in the precise evaluation of a partial solution (to a sub-problem), which can be overwhelmingly costly and thus makes sub-problems non-trivial to conquer. Thus, we propose an approximation approach, named Divide and Approximate Conquer (DAC), which reduces the cost of partial solution evaluation from exponential time to polynomial time. Meanwhile, the convergence to the global optimum (of the original problem) is still guaranteed. The effectiveness of DAC is demonstrated empirically on two sets of non-separable high-dimensional problems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.03729;Penta and Hexa Valued Representation of Neutrosophic Information; Vasile Patrascu;  Starting from the primary representation of neutrosophic information, namely the degree of truth, degree of indeterminacy and degree of falsity, we define a nuanced representation in a penta valued fuzzy space, described by the index of truth, index of falsity, index of ignorance, index of contradiction and index of hesitation. Also, it was constructed an associated penta valued logic and then using this logic, it was defined for the proposed penta valued structure the following operators: union, intersection, negation, complement and dual. Then, the penta valued representation is extended to a hexa valued one, adding the sixth component, namely the index of ambiguity. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.03814;Solving MaxSAT by Successive Calls to a SAT Solver; Mohamed El Halaby;  The Maximum Satisfiability (MaxSAT) problem is the problem of finding a truth assignment that maximizes the number of satisfied clauses of a given Boolean formula in Conjunctive Normal Form (CNF). Many exact solvers for MaxSAT have been developed during recent years, and many of them were presented in the well-known SAT conference. Algorithms for MaxSAT generally fall into two categories: (1) branch and bound algorithms and (2) algorithms that use successive calls to a SAT solver (SAT- based), which this paper in on. In practical problems, SAT-based algorithms have been shown to be more efficient. This paper provides an experimental investigation to compare the performance of recent SAT-based and branch and bound algorithms on the benchmarks of the MaxSAT Evaluations. ;"Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1603.03884;Grounding Recursive Aggregates: Preliminary Report; Martin Gebser,  Roland Kaminski,  Torsten Schaub;  Problem solving in Answer Set Programming consists of two steps, a first grounding phase, systematically replacing all variables by terms, and a second solving phase computing the stable models of the obtained ground program. An intricate part of both phases is the treatment of aggregates, which are popular language constructs that allow for expressing properties over sets. In this paper, we elaborate upon the treatment of aggregates during grounding in Gringo series 4. Consequently, our approach is applicable to grounding based on semi-naive database evaluation techniques. In particular, we provide a series of algorithms detailing the treatment of recursive aggregates and illustrate this by a running example. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1603.04110;Geometry of Interest (GOI): Spatio-Temporal Destination Extraction and  Partitioning in GPS Trajectory Data; Seyed Morteza Mousavi,  Aaron Harwood,  Shanika Karunasekera,  Mojtaba Maghrebi;"  Nowadays large amounts of GPS trajectory data is being continuously collected by GPS-enabled devices such as vehicles navigation systems and mobile phones. GPS trajectory data is useful for applications such as traffic management, location forecasting, and itinerary planning. Such applications often need to extract the time-stamped Sequence of Visited Locations (SVLs) of the mobile objects. The nearest neighbor query (NNQ) is the most applied method for labeling the visited locations based on the IDs of the POIs in the process of SVL generation. NNQ in some scenarios is not accurate enough. To improve the quality of the extracted SVLs, instead of using NNQ, we label the visited locations as the IDs of the POIs which geometrically intersect with the GPS observations. Intersection operator requires the accurate geometry of the points of interest which we refer to them as the Geometries of Interest (GOIs). In some application domains (e.g. movement trajectories of animals), adequate information about the POIs and their GOIs may not be available a priori, or they may not be publicly accessible and, therefore, they need to be derived from GPS trajectory data. In this paper we propose a novel method for estimating the POIs and their GOIs, which consists of three phases: (i) extracting the geometries of the stay regions; (ii) constructing the geometry of destination regions based on the extracted stay regions; and (iii) constructing the GOIs based on the geometries of the destination regions. Using the geometric similarity to known GOIs as the major evaluation criterion, the experiments we performed using long-term GPS trajectory data show that our method outperforms the existing approaches. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.04119;Exploratory Gradient Boosting for Reinforcement Learning in Complex  Domains; David Abel,  Alekh Agarwal,  Fernando Diaz,  Akshay Krishnamurthy,  Robert E. Schapire;  High-dimensional observations and complex real-world dynamics present major challenges in reinforcement learning for both function approximation and exploration. We address both of these challenges with two complementary techniques: First, we develop a gradient-boosting style, non-parametric function approximator for learning on $Q$-function residuals. And second, we propose an exploration strategy inspired by the principles of state abstraction and information acquisition under uncertainty. We demonstrate the empirical effectiveness of these techniques, first, as a preliminary check, on two standard tasks (Blackjack and $n$-Chain), and then on two much larger and more realistic tasks with high-dimensional observation spaces. Specifically, we introduce two benchmarks built within the game Minecraft where the observations are pixel arrays of the agent's visual field. A combination of our two algorithmic techniques performs competitively on the standard reinforcement-learning tasks while consistently and substantially outperforming baselines on the two tasks with high-dimensional observation spaces. The new function approximator, exploration strategy, and evaluation benchmarks are each of independent interest in the pursuit of reinforcement-learning methods that scale to real-world domains. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1603.04402;Controlling Search in Very large Commonsense Knowledge Bases: A Machine  Learning Approach; Abhishek Sharma,  Michael Witbrock,  Keith Goolsbey;  Very large commonsense knowledge bases (KBs) often have thousands to millions of axioms, of which relatively few are relevant for answering any given query. A large number of irrelevant axioms can easily overwhelm resolution-based theorem provers. Therefore, methods that help the reasoner identify useful inference paths form an essential part of large-scale reasoning systems. In this paper, we describe two ordering heuristics for optimization of reasoning in such systems. First, we discuss how decision trees can be used to select inference steps that are more likely to succeed. Second, we identify a small set of problem instance features that suffice to guide searches away from intractable regions of the search space. We show the efficacy of these techniques via experiments on thousands of queries from the Cyc KB. Results show that these methods lead to an order of magnitude reduction in inference time. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.04586;Optimal Sensing via Multi-armed Bandit Relaxations in Mixed  Observability Domains; Mikko Lauri,  Risto Ritala;  Sequential decision making under uncertainty is studied in a mixed observability domain. The goal is to maximize the amount of information obtained on a partially observable stochastic process under constraints imposed by a fully observable internal state. An upper bound for the optimal value function is derived by relaxing constraints. We identify conditions under which the relaxed problem is a multi-armed bandit whose optimal policy is easily computable. The upper bound is applied to prune the search space in the original problem, and the effect on solution quality is assessed via simulation experiments. Empirical results show effective pruning of the search space in a target monitoring domain. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (cs.SY)"
https://arxiv.org/abs/1603.05314;Hardware Acceleration for Boolean Satisfiability Solver by Applying  Belief Propagation Algorithm; Te-Hsuan Chen,  Ju-Yi Lu;  Boolean satisfiability (SAT) has an extensive application domain in computer science, especially in electronic design automation applications. Circuit synthesis, optimization, and verification problems can be solved by transforming original problems to SAT problems. However, the SAT problem is known as NP-complete, which means there is no efficient method to solve it. Therefore, an efficient SAT solver to enhance the performance is always desired. We propose a hardware acceleration method for SAT problems. By surveying the properties of SAT problems and the decoding of low-density parity-check (LDPC) codes, a special class of error-correcting codes, we discover that both of them are constraint satisfaction problems. The belief propagation algorithm has been successfully applied to the decoding of LDPC, and the corresponding decoder hardware designs are extensively studied. Therefore, we proposed a belief propagation based algorithm to solve SAT problems. With this algorithm, the SAT solver can be accelerated by hardware. A software simulator is implemented to verify the proposed algorithm and the performance improvement is estimated. Our experiment results show that time complexity does not increase with the size of SAT problems and the proposed method can achieve at least 30x speedup compared to MiniSat. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1603.06125;The Computational Power of Dynamic Bayesian Networks; Joshua Brulé;  This paper considers the computational power of constant size, dynamic Bayesian networks. Although discrete dynamic Bayesian networks are no more powerful than hidden Markov models, dynamic Bayesian networks with continuous random variables and discrete children of continuous parents are capable of performing Turing-complete computation. With modified versions of existing algorithms for belief propagation, such a simulation can be carried out in real time. This result suggests that dynamic Bayesian networks may be more powerful than previously considered. Relationships to causal models and recurrent neural networks are also discussed. ;"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1603.06141;Evolving Shepherding Behavior with Genetic Programming Algorithms; Joshua Brulé,  Kevin Engel,  Nick Fung,  Isaac Julien;  We apply genetic programming techniques to the `shepherding' problem, in which a group of one type of animal (sheep dogs) attempts to control the movements of a second group of animals (sheep) obeying flocking behavior. Our genetic programming algorithm evolves an expression tree that governs the movements of each dog. The operands of the tree are hand-selected features of the simulation environment that may allow the dogs to herd the sheep effectively. The algorithm uses tournament-style selection, crossover reproduction, and a point mutation. We find that the evolved solutions generalize well and outperform a (naive) human-designed algorithm. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1603.06459;Characterization of neighborhood behaviours in a multi-neighborhood  local search algorithm; Nguyen Thi Thanh Dang,  Patrick De Causmaecker;  We consider a multi-neighborhood local search algorithm with a large number of possible neighborhoods. Each neighborhood is accompanied by a weight value which represents the probability of being chosen at each iteration. These weights are fixed before the algorithm runs, and are considered as parameters of the algorithm. Given a set of instances, off-line tuning of the algorithm's parameters can be done by automated algorithm configuration tools (e.g., SMAC). However, the large number of neighborhoods can make the tuning expensive and difficult even when the number of parameters has been reduced by some intuition. In this work, we propose a systematic method to characterize each neighborhood's behaviours, representing them as a feature vector, and using cluster analysis to form similar groups of neighborhoods. The novelty of our characterization method is the ability of reflecting changes of behaviours according to hardness of different solution quality regions. We show that using neighborhood clusters instead of individual neighborhoods helps to reduce the parameter configuration space without misleading the search of the tuning procedure. Moreover, this method is problem-independent and potentially can be applied in similar contexts. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.06485;A System for Probabilistic Linking of Thesauri and Classification  Systems; Lisa Posch,  Philipp Schaer,  Arnim Bleier,  Markus Strohmaier;  This paper presents a system which creates and visualizes probabilistic semantic links between concepts in a thesaurus and classes in a classification system. For creating the links, we build on the Polylingual Labeled Topic Model (PLL-TM). PLL-TM identifies probable thesaurus descriptors for each class in the classification system by using information from the natural language text of documents, their assigned thesaurus descriptors and their designated classes. The links are then presented to users of the system in an interactive visualization, providing them with an automatically generated overview of the relations between the thesaurus and the classification system. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Digital Libraries (cs.DL)"
https://arxiv.org/abs/1603.07029;Comparing Human and Automated Evaluation of Open-Ended Student Responses  to Questions of Evolution; Michael J Wiser,  Louise S Mead,  James J Smith,  Robert T Pennock;  Written responses can provide a wealth of data in understanding student reasoning on a topic. Yet they are time- and labor-intensive to score, requiring many instructors to forego them except as limited parts of summative assessments at the end of a unit or course. Recent developments in Machine Learning (ML) have produced computational methods of scoring written responses for the presence or absence of specific concepts. Here, we compare the scores from one particular ML program -- EvoGrader -- to human scoring of responses to structurally- and content-similar questions that are distinct from the ones the program was trained on. We find that there is substantial inter-rater reliability between the human and ML scoring. However, sufficient systematic differences remain between the human and ML scoring that we advise only using the ML scoring for formative, rather than summative, assessment of student reasoning. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.07051;Cosolver2B: An Efficient Local Search Heuristic for the Travelling Thief  Problem; Mohamed El Yafrani,  Belaïd Ahiod;  Real-world problems are very difficult to optimize. However, many researchers have been solving benchmark problems that have been extensively investigated for the last decades even if they have very few direct applications. The Traveling Thief Problem (TTP) is a NP-hard optimization problem that aims to provide a more realistic model. TTP targets particularly routing problem under packing/loading constraints which can be found in supply chain management and transportation. In this paper, TTP is presented and formulated mathematically. A combined local search algorithm is proposed and compared with Random Local Search (RLS) and Evolutionary Algorithm (EA). The obtained results are quite promising since new better solutions were found. ;"Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1603.07417;Load Disaggregation Based on Aided Linear Integer Programming; Md. Zulfiquar Ali Bhotto,  Stephen Makonin,  Ivan V. Bajic;  Load disaggregation based on aided linear integer programming (ALIP) is proposed. We start with a conventional linear integer programming (IP) based disaggregation and enhance it in several ways. The enhancements include additional constraints, correction based on a state diagram, median filtering, and linear programming-based refinement. With the aid of these enhancements, the performance of IP-based disaggregation is significantly improved. The proposed ALIP system relies only on the instantaneous load samples instead of waveform signatures, and hence does not crucially depend on high sampling frequency. Experimental results show that the proposed ALIP system performs better than the conventional IP-based load disaggregation system. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.07704;Probabilistic Reasoning via Deep Learning: Neural Association Models; Quan Liu,  Hui Jiang,  Andrew Evdokimov,  Zhen-Hua Ling,  Xiaodan Zhu,  Si Wei,  Yu Hu;  In this paper, we propose a new deep learning approach, called neural association model (NAM), for probabilistic reasoning in artificial intelligence. We propose to use neural networks to model association between any two events in a domain. Neural networks take one event as input and compute a conditional probability of the other event to model how likely these two events are to be associated. The actual meaning of the conditional probabilities varies between applications and depends on how the models are trained. In this work, as two case studies, we have investigated two NAM structures, namely deep neural networks (DNN) and relation-modulated neural nets (RMNN), on several probabilistic reasoning tasks in AI, including recognizing textual entailment, triple classification in multi-relational knowledge bases and commonsense reasoning. Experimental results on several popular datasets derived from WordNet, FreeBase and ConceptNet have all demonstrated that both DNNs and RMNNs perform equally well and they can significantly outperform the conventional methods available for these reasoning tasks. Moreover, compared with DNNs, RMNNs are superior in knowledge transfer, where a pre-trained model can be quickly extended to an unseen relation after observing only a few training samples. To further prove the effectiveness of the proposed models, in this work, we have applied NAMs to solving challenging Winograd Schema (WS) problems. Experiments conducted on a set of WS problems prove that the proposed models have the potential for commonsense reasoning. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1603.08253;Negative Learning Rates and P-Learning; Devon Merrill;  We present a method of training a differentiable function approximator for a regression task using negative examples. We effect this training using negative learning rates. We also show how this method can be used to perform direct policy learning in a reinforcement learning setting. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1603.08262;Towards Machine Intelligence; Kamil Rocki;  There exists a theory of a single general-purpose learning algorithm which could explain the principles of its operation. This theory assumes that the brain has some initial rough architecture, a small library of simple innate circuits which are prewired at birth and proposes that all significant mental algorithms can be learned. Given current understanding and observations, this paper reviews and lists the ingredients of such an algorithm from both architectural and functional perspectives. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1603.08714;Properties of ABA+ for Non-Monotonic Reasoning: Errata; Kristijonas Cyras;  This technical report provides errata of [K. Cyras, F. Toni, Properties of ABA+ for Non-Monotonic Reasoning, in: 16th International Workshop on Non-Monotonic Reasoning (NMR), Cape Town, South Africa, 2016 pp. 25-34.] Propositions 19, 20, 22, Corollary 23 and (partially) Proposition 24 from Section 6 (Non-Monotonic Reasoning Properties) in that paper are withdrawn as unproven, and thus assumed to be false, while additional results are provided. The rest of the paper in question stands unchanged. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.08776;COCO: The Experimental Procedure; Nikolaus Hansen (Inria),  Tea Tusar (Inria),  Olaf Mersmann,  Anne Auger (Inria),  Dimo Brockhoff (Inria);  We present a budget-free experimental setup and procedure for benchmarking numericaloptimization algorithms in a black-box scenario. This procedure can be applied with the COCO benchmarking platform. We describe initialization of and input to the algorithm and touch upon therelevance of termination and restarts. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1603.08785;COCO: A Platform for Comparing Continuous Optimizers in a Black-Box  Setting; Nikolaus Hansen (TAO),  Anne Auger (TAO),  Olaf Mersmann,  Tea Tusar (DOLPHIN),  Dimo Brockhoff (DOLPHIN);  COCO is a platform for Comparing Continuous Optimizers in a black-box setting. It aims at automatizing the tedious and repetitive task of benchmarking numerical optimization algorithms to the greatest possible extent. We present the rationals behind the development of the platform as a general proposition for a guideline towards better benchmarking. We detail underlying fundamental concepts of COCO such as its definition of a problem, the idea of instances, the relevance of target values, and runtime as central performance measure. Finally, we give a quick overview of the basic code structure and the available test suites. ;"Artificial Intelligence (cs.AI); Numerical Analysis (cs.NA); Machine Learning (stat.ML)"
https://arxiv.org/abs/1603.08789;Using Enthymemes to Fill the Gap between Logical Argumentation and  Revision of Abstract Argumentation Frameworks; Jean-Guy Mailly;"  In this paper, we present a preliminary work on an approach to fill the gap between logic-based argumentation and the numerous approaches to tackle the dynamics of abstract argumentation frameworks. Our idea is that, even when arguments and attacks are defined by means of a logical belief base, there may be some uncertainty about how accurate is the content of an argument, and so the presence (or absence) of attacks concerning it. We use enthymemes to illustrate this notion of uncertainty of arguments and attacks. Indeed, as argued in the literature, real arguments are often enthymemes instead of completely specified deductive arguments. This means that some parts of the pair (support, claim) may be missing because they are supposed to belong to some ""common knowledge"", and then should be deduced by the agent which receives the enthymeme. But the perception that agents have of the common knowledge may be wrong, and then a first agent may state an enthymeme that her opponent is not able to decode in an accurate way. It is likely that the decoding of the enthymeme by the agent leads to mistaken attacks between this new argument and the existing ones. In this case, the agent can receive some information about attacks or arguments acceptance statuses which disagree with her argumentation framework. We exemplify a way to incorporate this new piece of information by means of existing works on the dynamics of abstract argumentation frameworks. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1603.08869;Algorithms for Batch Hierarchical Reinforcement Learning; Tiancheng Zhao,  Mohammad Gowayyed;  Hierarchical Reinforcement Learning (HRL) exploits temporal abstraction to solve large Markov Decision Processes (MDP) and provide transferable subtask policies. In this paper, we introduce an off-policy HRL algorithm: Hierarchical Q-value Iteration (HQI). We show that it is possible to effectively learn recursive optimal policies for any valid hierarchical decomposition of the original MDP, given a fixed dataset collected from a flat stochastic behavioral policy. We first formally prove the convergence of the algorithm for tabular MDP. Then our experiments on the Taxi domain show that HQI converges faster than a flat Q-value Iteration and enjoys easy state abstraction. Also, we demonstrate that our algorithm is able to learn optimal policies for different hierarchical structures from the same fixed dataset, which enables model comparison without recollecting data. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.0074;Topological characterizations to three types of covering approximation  operators; Aiping Huang,  William Zhu;  Covering-based rough set theory is a useful tool to deal with inexact, uncertain or vague knowledge in information systems. Topology, one of the most important subjects in mathematics, provides mathematical tools and interesting topics in studying information systems and rough sets. In this paper, we present the topological characterizations to three types of covering approximation operators. First, we study the properties of topology induced by the sixth type of covering lower approximation operator. Second, some topological characterizations to the covering lower approximation operator to be an interior operator are established. We find that the topologies induced by this operator and by the sixth type of covering lower approximation operator are the same. Third, we study the conditions which make the first type of covering upper approximation operator be a closure operator, and find that the topology induced by the operator is the same as the topology induced by the fifth type of covering upper approximation operator. Forth, the conditions of the second type of covering upper approximation operator to be a closure operator and the properties of topology induced by it are established. Finally, these three topologies space are compared. In a word, topology provides a useful method to study the covering-based rough sets. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.0075;Geometric lattice structure of covering-based rough sets through  matroids; Aiping Huang,  William Zhu;  Covering-based rough set theory is a useful tool to deal with inexact, uncertain or vague knowledge in information systems. Geometric lattice has widely used in diverse fields, especially search algorithm design which plays important role in covering reductions. In this paper, we construct four geometric lattice structures of covering-based rough sets through matroids, and compare their relationships. First, a geometric lattice structure of covering-based rough sets is established through the transversal matroid induced by the covering, and its characteristics including atoms, modular elements and modular pairs are studied. We also construct a one-to-one correspondence between this type of geometric lattices and transversal matroids in the context of covering-based rough sets. Second, sufficient and necessary conditions for three types of covering upper approximation operators to be closure operators of matroids are presented. We exhibit three types of matroids through closure axioms, and then obtain three geometric lattice structures of covering-based rough sets. Third, these four geometric lattice structures are compared. Some core concepts such as reducible elements in covering-based rough sets are investigated with geometric lattices. In a word, this work points out an interesting view, namely geometric lattice, to study covering-based rough sets. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.0077;Optimistic Agents are Asymptotically Optimal; Peter Sunehag,  Marcus Hutter;  We use optimism to introduce generic asymptotically optimal reinforcement learning agents. They achieve, with an arbitrary finite or compact class of environments, asymptotically optimal behavior. Furthermore, in the finite deterministic case we provide finite error bounds. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1210.0091;Test-cost-sensitive attribute reduction of data with normal distribution  measurement errors; Hong Zhao,  Fan Min,  William Zhu;"  The measurement error with normal distribution is universal in applications. Generally, smaller measurement error requires better instrument and higher test cost. In decision making based on attribute values of objects, we shall select an attribute subset with appropriate measurement error to minimize the total test cost. Recently, error-range-based covering rough set with uniform distribution error was proposed to investigate this issue. However, the measurement errors satisfy normal distribution instead of uniform distribution which is rather simple for most applications. In this paper, we introduce normal distribution measurement errors to covering-based rough set model, and deal with test-cost-sensitive attribute reduction problem in this new model. The major contributions of this paper are four-fold. First, we build a new data model based on normal distribution measurement errors. With the new data model, the error range is an ellipse in a two-dimension space. Second, the covering-based rough set with normal distribution measurement errors is constructed through the ""3-sigma"" rule. Third, the test-cost-sensitive attribute reduction problem is redefined on this covering-based rough set. Fourth, a heuristic algorithm is proposed to deal with this problem. The algorithm is tested on ten UCI (University of California - Irvine) datasets. The experimental results show that the algorithm is more effective and efficient than the existing one. This study is a step toward realistic applications of cost-sensitive learning. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.0167;Exhaustive Search-based Model for Hybrid Sensor Network; A.A. Waskita,  H. Suhartanto,  Z. Akbar,  L.T. Handoko;  A new model for a cluster of hybrid sensors network with multi sub-clusters is proposed. The model is in particular relevant to the early warning system in a large scale monitoring system in, for example, a nuclear power plant. It mainly addresses to a safety critical system which requires real-time processes with high accuracy. The mathematical model is based on the extended conventional search algorithm with certain interactions among the nearest neighborhood of sensors. It is argued that the model could realize a highly accurate decision support system with less number of parameters. A case of one dimensional interaction function is discussed, and a simple algorithm for the model is also given. ;"Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)"
https://arxiv.org/abs/1210.0772;Relationship between the second type of covering-based rough set and  matroid via closure operator; Yanfang Liu,  William Zhu;  Recently, in order to broad the application and theoretical areas of rough sets and matroids, some authors have combined them from many different viewpoints, such as circuits, rank function, spanning sets and so on. In this paper, we connect the second type of covering-based rough sets and matroids from the view of closure operators. On one hand, we establish a closure system through the fixed point family of the second type of covering lower approximation operator, and then construct a closure operator. For a covering of a universe, the closure operator is a closure one of a matroid if and only if the reduct of the covering is a partition of the universe. On the other hand, we investigate the sufficient and necessary condition that the second type of covering upper approximation operation is a closure one of a matroid. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.0794;A Semantic Approach for Automatic Structuring and Analysis of Software  Process Patterns; Nahla Jlaiel,  Khouloud Madhbouh,  Mohamed Ben Ahmed;  The main contribution of this paper, is to propose a novel semantic approach based on a Natural Language Processing technique in order to ensure a semantic unification of unstructured process patterns which are expressed not only in different formats but also, in different forms. This approach is implemented using the GATE text engineering framework and then evaluated leading up to high-quality results motivating us to continue in this direction. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1210.0887;The Definition of AI in Terms of Multi Agent Systems; Dimiter Dobrev;"  The questions which we will consider here are ""What is AI?"" and ""How can we make AI?"". Here we will present the definition of AI in terms of multi-agent systems. This means that here you will not find a new answer to the question ""What is AI?"", but an old answer in a new form. This new form of the definition of AI is of interest for the theory of multi-agent systems because it gives us better understanding of this theory. More important is that this work will help us answer the second question. We want to make a program which is capable of constructing a model of its environment. Every multi-agent model is equivalent to a single-agent model but multi-agent models are more natural and accordingly more easily discoverable. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.1568;A Definition of Artificial Intelligence; Dimiter Dobrev;  In this paper we offer a formal definition of Artificial Intelligence and this directly gives us an algorithm for construction of this object. Really, this algorithm is useless due to the combinatory explosion. The main innovation in our definition is that it does not include the knowledge as a part of the intelligence. So according to our definition a newly born baby also is an Intellect. Here we differs with Turing's definition which suggests that an Intellect is a person with knowledge gained through the years. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.1649;Conflict-driven ASP Solving with External Sources; Thomas Eiter,  Michael Fink,  Thomas Krennwallner,  Christoph Redl;  Answer Set Programming (ASP) is a well-known problem solving approach based on nonmonotonic logic programs and efficient solvers. To enable access to external information, HEX-programs extend programs with external atoms, which allow for a bidirectional communication between the logic program and external sources of computation (e.g., description logic reasoners and Web resources). Current solvers evaluate HEX-programs by a translation to ASP itself, in which values of external atoms are guessed and verified after the ordinary answer set computation. This elegant approach does not scale with the number of external accesses in general, in particular in presence of nondeterminism (which is instrumental for ASP). In this paper, we present a novel, native algorithm for evaluating HEX-programs which uses learning techniques. In particular, we extend conflict-driven ASP solving techniques, which prevent the solver from running into the same conflict again, from ordinary to HEX-programs. We show how to gain additional knowledge from external source evaluations and how to use it in a conflict-driven algorithm. We first target the uninformed case, i.e., when we have no extra information on external sources, and then extend our approach to the case where additional meta-information is available. Experiments show that learning from external sources can significantly decrease both the runtime and the number of considered candidate compatible sets. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.1753;Intelligent Search Heuristics for Cost Based Scheduling; Murphy Choy,  Michelle Cheong;  Nurse scheduling is a difficult optimization problem with multiple constraints. There is extensive research in the literature solving the problem using meta-heuristics approaches. In this paper, we will investigate an intelligent search heuristics that handles cost based scheduling problem. The heuristics demonstrated superior performances compared to the original algorithms used to solve the problems described in Li et. Al. (2003) and Ozkarahan (1989) in terms of time needed to establish a feasible solution. Both problems can be formulated as a cost problem. The search heuristic consists of several phrases of search and input based on the cost of each assignment and how the assignment will interact with the cost of the resources. ;"Artificial Intelligence (cs.AI); Optimization and Control (math.OC)"
https://arxiv.org/abs/1210.1785;Relative Expressiveness of Defeasible Logics; Michael Maher;  We address the relative expressiveness of defeasible logics in the framework DL. Relative expressiveness is formulated as the ability to simulate the reasoning of one logic within another logic. We show that such simulations must be modular, in the sense that they also work if applied only to part of a theory, in order to achieve a useful notion of relative expressiveness. We present simulations showing that logics in DL with and without the capability of team defeat are equally expressive. We also show that logics that handle ambiguity differently -- ambiguity blocking versus ambiguity propagating -- have distinct expressiveness, with neither able to simulate the other under a different formulation of expressiveness. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1210.1791;An efficient algorithm for estimating state sequences in imprecise  hidden Markov models; Jasper De Bock,  Gert de Cooman;  We present an efficient exact algorithm for estimating state sequences from outputs (or observations) in imprecise hidden Markov models (iHMM), where both the uncertainty linking one state to the next, and that linking a state to its output, are represented using coherent lower previsions. The notion of independence we associate with the credal network representing the iHMM is that of epistemic irrelevance. We consider as best estimates for state sequences the (Walley--Sen) maximal sequences for the posterior joint state model conditioned on the observed output sequence, associated with a gain function that is the indicator of the state sequence. This corresponds to (and generalises) finding the state sequence with the highest posterior probability in HMMs with precise transition and output probabilities (pHMMs). We argue that the computational complexity is at worst quadratic in the length of the Markov chain, cubic in the number of states, and essentially linear in the number of maximal state sequences. For binary iHMMs, we investigate experimentally how the number of maximal state sequences depends on the model parameters. We also present a simple toy application in optical character recognition, demonstrating that our algorithm can be used to robustify the inferences made by precise probability models. ;"Artificial Intelligence (cs.AI); Probability (math.PR)"
https://arxiv.org/abs/1210.1931;D-FLAT: Declarative Problem Solving Using Tree Decompositions and  Answer-Set Programming; Bernhard Bliem,  Michael Morak,  Stefan Woltran;  In this work, we propose Answer-Set Programming (ASP) as a tool for rapid prototyping of dynamic programming algorithms based on tree decompositions. In fact, many such algorithms have been designed, but only a few of them found their way into implementation. The main obstacle is the lack of easy-to-use systems which (i) take care of building a tree decomposition and (ii) provide an interface for declarative specifications of dynamic programming algorithms. In this paper, we present D-FLAT, a novel tool that relieves the user of having to handle all the technical details concerned with parsing, tree decomposition, the handling of data structures, etc. Instead, it is only the dynamic programming algorithm itself which has to be specified in the ASP language. D-FLAT employs an ASP solver in order to compute the local solutions in the dynamic programming algorithm. In the paper, we give a few examples illustrating the use of D-FLAT and describe the main features of the system. Moreover, we report experiments which show that ASP-based D-FLAT encodings for some problems outperform monolithic ASP encodings on instances of small treewidth. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1210.2316;Disjunctive Datalog with Existential Quantifiers: Semantics,  Decidability, and Complexity Issues; Mario Alviano,  Wolfgang Faber,  Nicola Leone,  Marco Manna;  Datalog is one of the best-known rule-based languages, and extensions of it are used in a wide context of applications. An important Datalog extension is Disjunctive Datalog, which significantly increases the expressivity of the basic language. Disjunctive Datalog is useful in a wide range of applications, ranging from Databases (e.g., Data Integration) to Artificial Intelligence (e.g., diagnosis and planning under incomplete knowledge). However, in recent years an important shortcoming of Datalog-based languages became evident, e.g. in the context of data-integration (consistent query-answering, ontology-based data access) and Semantic Web applications: The language does not permit any generation of and reasoning with unnamed individuals in an obvious way. In general, it is weak in supporting many cases of existential quantification. To overcome this problem, Datalogex has recently been proposed, which extends traditional Datalog by existential quantification in rule heads. In this work, we propose a natural extension of Disjunctive Datalog and Datalogex, called Datalogexor, which allows both disjunctions and existential quantification in rule heads and is therefore an attractive language for knowledge representation and reasoning, especially in domains where ontology-based reasoning is needed. We formally define syntax and semantics of the language Datalogexor, and provide a notion of instantiation, which we prove to be adequate for Datalogexor. A main issue of Datalogex and hence also of Datalogexor is that decidability is no longer guaranteed for typical reasoning tasks. In order to address this issue, we identify many decidable fragments of the language, which extend, in a natural way, analog classes defined in the non-disjunctive case. Moreover, we carry out an in-depth complexity analysis, deriving interesting results which range from Logarithmic Space to Exponential Time. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1210.2715;AI in arbitrary world; Dimiter Dobrev;  In order to build AI we have to create a program which copes well in an arbitrary world. In this paper we will restrict our attention on one concrete world, which represents the game Tick-Tack-Toe. This world is a very simple one but it is sufficiently complicated for our task because most people cannot manage with it. The main difficulty in this world is that the player cannot see the entire internal state of the world so he has to build a model in order to understand the world. The model which we will offer will consist of final automata and first order formulas. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.2984;Learning Onto-Relational Rules with Inductive Logic Programming; Francesca A. Lisi;  Rules complement and extend ontologies on the Semantic Web. We refer to these rules as onto-relational since they combine DL-based ontology languages and Knowledge Representation formalisms supporting the relational data model within the tradition of Logic Programming and Deductive Databases. Rule authoring is a very demanding Knowledge Engineering task which can be automated though partially by applying Machine Learning algorithms. In this chapter we show how Inductive Logic Programming (ILP), born at the intersection of Machine Learning and Logic Programming and considered as a major approach to Relational Learning, can be adapted to Onto-Relational Learning. For the sake of illustration, we provide details of a specific Onto-Relational Learning solution to the problem of learning rule-based definitions of DL concepts and roles with ILP. ;"Artificial Intelligence (cs.AI); Databases (cs.DB); Learning (cs.LG); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1210.3241;Distributional Framework for Emergent Knowledge Acquisition and its  Application to Automated Document Annotation; Vit Novacek;  The paper introduces a framework for representation and acquisition of knowledge emerging from large samples of textual data. We utilise a tensor-based, distributional representation of simple statements extracted from text, and show how one can use the representation to infer emergent knowledge patterns from the textual data in an unsupervised manner. Examples of the patterns we investigate in the paper are implicit term relationships or conjunctive IF-THEN rules. To evaluate the practical relevance of our approach, we apply it to annotation of life science articles with terms from MeSH (a controlled biomedical vocabulary and thesaurus). ;"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1210.3375;An Agent-based framework for cooperation in Supply Chain; Benaissa Ezzeddine,  Benabdelhafid Abdellatif,  Benaissa Mounir;"  Supply Chain coordination has become a critical success factor for Supply Chain management (SCM) and effectively improving the performance of organizations in various industries. Companies are increasingly located at the intersection of one or more corporate networks which are designated by ""Supply Chain"". Managing this chain is mainly based on an 'information sharing' and redeployment activities between the various links that comprise it. Several attempts have been made by industrialists and researchers to educate policymakers about the gains to be made by the implementation of cooperative relationships. The approach presented in this paper here is among the works that aim to propose solutions related to information systems distributed Supply Chains to enable the different actors of the chain to improve their performance. We propose in particular solutions that focus on cooperation between actors in the Supply Chain. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.3946;Local optima networks and the performance of iterated local search; Fabio Daolio (ISI),  Sébastien Verel (INRIA Lille - Nord Europe),  Gabriela Ochoa,  Marco Tomassini (ISI);  Local Optima Networks (LONs) have been recently proposed as an alternative model of combinatorial fitness landscapes. The model compresses the information given by the whole search space into a smaller mathematical object that is the graph having as vertices the local optima and as edges the possible weighted transitions between them. A new set of metrics can be derived from this model that capture the distribution and connectivity of the local optima in the underlying configuration space. This paper departs from the descriptive analysis of local optima networks, and actively studies the correlation between network features and the performance of a local search heuristic. The NK family of landscapes and the Iterated Local Search metaheuristic are considered. With a statistically-sound approach based on multiple linear regression, it is shown that some LONs' features strongly influence and can even partly predict the performance of a heuristic search algorithm. This study validates the expressive power of LONs as a model of combinatorial fitness landscapes. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4021;Local Optima Networks, Landscape Autocorrelation and Heuristic Search  Performance; Francisco Chicano,  Fabio Daolio (ISI),  Gabriela Ochoa,  Sébastien Verel (INRIA Lille - Nord Europe),  Marco Tomassini (ISI),  Enrique Alba;  Recent developments in fitness landscape analysis include the study of Local Optima Networks (LON) and applications of the Elementary Landscapes theory. This paper represents a first step at combining these two tools to explore their ability to forecast the performance of search algorithms. We base our analysis on the Quadratic Assignment Problem (QAP) and conduct a large statistical study over 600 generated instances of different types. Our results reveal interesting links between the network measures, the autocorrelation measures and the performance of heuristic search algorithms. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1210.4840;Lifted Relax, Compensate and then Recover: From Approximate to Exact  Lifted Probabilistic Inference; Guy Van den Broeck,  Arthur Choi,  Adnan Darwiche;  We propose an approach to lifted approximate inference for first-order probabilistic models, such as Markov logic networks. It is based on performing exact lifted inference in a simplified first-order model, which is found by relaxing first-order constraints, and then compensating for the relaxation. These simplified models can be incrementally improved by carefully recovering constraints that have been relaxed, also at the first-order level. This leads to a spectrum of approximations, with lifted belief propagation on one end, and exact lifted inference on the other. We discuss how relaxation, compensation, and recovery can be performed, all at the firstorder level, and show empirically that our approach substantially improves on the approximations of both propositional solvers and lifted belief propagation. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4841;An Efficient Message-Passing Algorithm for the M-Best MAP Problem; Dhruv Batra;  Much effort has been directed at algorithms for obtaining the highest probability configuration in a probabilistic random field model known as the maximum a posteriori (MAP) inference problem. In many situations, one could benefit from having not just a single solution, but the top M most probable solutions known as the M-Best MAP problem. In this paper, we propose an efficient message-passing based algorithm for solving the M-Best MAP problem. Specifically, our algorithm solves the recently proposed Linear Programming (LP) formulation of M-Best MAP [7], while being orders of magnitude faster than a generic LP-solver. Our approach relies on studying a particular partial Lagrangian relaxation of the M-Best MAP LP which exposes a natural combinatorial structure of the problem that we exploit. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1210.4842;Causal Inference by Surrogate Experiments: z-Identifiability; Elias Bareinboim,  Judea Pearl;"  We address the problem of estimating the effect of intervening on a set of variables X from experiments on a different set, Z, that is more accessible to manipulation. This problem, which we call z-identifiability, reduces to ordinary identifiability when Z = empty and, like the latter, can be given syntactic characterization using the do-calculus [Pearl, 1995; 2000]. We provide a graphical necessary and sufficient condition for z-identifiability for arbitrary sets X,Z, and Y (the outcomes). We further develop a complete algorithm for computing the causal effect of X on Y using information provided by experiments on Z. Finally, we use our results to prove completeness of do-calculus relative to z-identifiability, a result that does not follow from completeness relative to ordinary identifiability. ";"Artificial Intelligence (cs.AI); Methodology (stat.ME)"
https://arxiv.org/abs/1210.4845;Exploiting Uniform Assignments in First-Order MPE; Udi Apsel,  Ronen I. Brafman;  The MPE (Most Probable Explanation) query plays an important role in probabilistic inference. MPE solution algorithms for probabilistic relational models essentially adapt existing belief assessment method, replacing summation with maximization. But the rich structure and symmetries captured by relational models together with the properties of the maximization operator offer an opportunity for additional simplification with potentially significant computational ramifications. Specifically, these models often have groups of variables that define symmetric distributions over some population of formulas. The maximizing choice for different elements of this group is the same. If we can realize this ahead of time, we can significantly reduce the size of the model by eliminating a potentially significant portion of random variables. This paper defines the notion of uniformly assigned and partially uniformly assigned sets of variables, shows how one can recognize these sets efficiently, and how the model can be greatly simplified once we recognize them, with little computational effort. We demonstrate the effectiveness of these ideas empirically on a number of models. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4852;The Do-Calculus Revisited; Judea Pearl;  The do-calculus was developed in 1995 to facilitate the identification of causal effects in non-parametric models. The completeness proofs of [Huang and Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of [Tian and Shpitser, 2010] have laid this identification problem to rest. Recent explorations unveil the usefulness of the do-calculus in three additional areas: mediation analysis [Pearl, 2012], transportability [Pearl and Bareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the task of fusing empirical results from several diverse studies, conducted on heterogeneous populations and under different conditions, so as to synthesize an estimate of a causal relation in some target environment, potentially different from those under study. The talk surveys these results with emphasis on the challenges posed by meta-synthesis. For background material, see this http URL ;"Artificial Intelligence (cs.AI); Methodology (stat.ME)"
https://arxiv.org/abs/1210.4857;Generalized Belief Propagation on Tree Robust Structured Region Graphs; Andrew E. Gelfand,  Max Welling;"  This paper provides some new guidance in the construction of region graphs for Generalized Belief Propagation (GBP). We connect the problem of choosing the outer regions of a LoopStructured Region Graph (SRG) to that of finding a fundamental cycle basis of the corresponding Markov network. We also define a new class of tree-robust Loop-SRG for which GBP on any induced (spanning) tree of the Markov network, obtained by setting to zero the off-tree interactions, is exact. This class of SRG is then mapped to an equivalent class of tree-robust cycle bases on the Markov network. We show that a treerobust cycle basis can be identified by proving that for every subset of cycles, the graph obtained from the edges that participate in a single cycle only, is multiply connected. Using this we identify two classes of tree-robust cycle bases: planar cycle bases and ""star"" cycle bases. In experiments we show that tree-robustness can be successfully exploited as a design principle to improve the accuracy and convergence of GBP. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4861;Uniform Solution Sampling Using a Constraint Solver As an Oracle; Stefano Ermon,  Carla P. Gomes,  Bart Selman;  We consider the problem of sampling from solutions defined by a set of hard constraints on a combinatorial space. We propose a new sampling technique that, while enforcing a uniform exploration of the search space, leverages the reasoning power of a systematic constraint solver in a black-box scheme. We present a series of challenging domains, such as energy barriers and highly asymmetric spaces, that reveal the difficulties introduced by hard constraints. We demonstrate that standard approaches such as Simulated Annealing and Gibbs Sampling are greatly affected, while our new technique can overcome many of these difficulties. Finally, we show that our sampling scheme naturally defines a new approximate model counting technique, which we empirically show to be very accurate on a range of benchmark problems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4865;Scaling Up Decentralized MDPs Through Heuristic Search; Jilles S. Dibangoye,  Christopher Amato,  Arnoud Doniec;  Decentralized partially observable Markov decision processes (Dec-POMDPs) are rich models for cooperative decision-making under uncertainty, but are often intractable to solve optimally (NEXP-complete). The transition and observation independent Dec-MDP is a general subclass that has been shown to have complexity in NP, but optimal algorithms for this subclass are still inefficient in practice. In this paper, we first provide an updated proof that an optimal policy does not depend on the histories of the agents, but only the local observations. We then present a new algorithm based on heuristic search that is able to expand search nodes by using constraint optimization. We show experimental results comparing our approach with the state-of-the-art DecMDP and Dec-POMDP solvers. These results show a reduction in computation time and an increase in scalability by multiple orders of magnitude in a number of benchmarks. ;"Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)"
https://arxiv.org/abs/1210.4866;A Bayesian Approach to Constraint Based Causal Inference; Tom Claassen,  Tom Heskes;  We target the problem of accuracy and robustness in causal inference from finite data sets. Some state-of-the-art algorithms produce clear output complete with solid theoretical guarantees but are susceptible to propagating erroneous decisions, while others are very adept at handling and representing uncertainty, but need to rely on undesirable assumptions. Our aim is to combine the inherent robustness of the Bayesian approach with the theoretical strength and clarity of constraint-based methods. We use a Bayesian score to obtain probability estimates on the input statements used in a constraint-based procedure. These are subsequently processed in decreasing order of reliability, letting more reliable decisions take precedence in case of con icts, until a single output model is obtained. Tests show that a basic implementation of the resulting Bayesian Constraint-based Causal Discovery (BCCD) algorithm already outperforms established procedures such as FCI and Conservative PC. It can also indicate which causal decisions in the output have high reliability and which do not. ;"Artificial Intelligence (cs.AI); Methodology (stat.ME)"
https://arxiv.org/abs/1210.4870;Crowdsourcing Control: Moving Beyond Multiple Choice; Christopher H. Lin,  Mausam,  Daniel Weld;  To ensure quality results from crowdsourced tasks, requesters often aggregate worker responses and use one of a plethora of strategies to infer the correct answer from the set of noisy responses. However, all current models assume prior knowledge of all possible outcomes of the task. While not an unreasonable assumption for tasks that can be posited as multiple-choice questions (e.g. n-ary classification), we observe that many tasks do not naturally fit this paradigm, but instead demand a free-response formulation where the outcome space is of infinite size (e.g. audio transcription). We model such tasks with a novel probabilistic graphical model, and design and implement LazySusan, a decision-theoretic controller that dynamically requests responses as necessary in order to infer answers to these tasks. We also design an EM algorithm to jointly learn the parameters of our model while inferring the correct answers to multiple tasks at a time. Live experiments on Amazon Mechanical Turk demonstrate the superiority of LazySusan at solving SAT Math questions, eliminating 83.2% of the error and achieving greater net utility compared to the state-ofthe-art strategy, majority-voting. We also show in live experiments that our EM algorithm outperforms majority-voting on a visualization task that we design. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1210.4874;Dynamic Stochastic Orienteering Problems for Risk-Aware Applications; Hoong Chuin Lau,  William Yeoh,  Pradeep Varakantham,  Duc Thien Nguyen,  Huaxing Chen;"  Orienteering problems (OPs) are a variant of the well-known prize-collecting traveling salesman problem, where the salesman needs to choose a subset of cities to visit within a given deadline. OPs and their extensions with stochastic travel times (SOPs) have been used to model vehicle routing problems and tourist trip design problems. However, they suffer from two limitations travel times between cities are assumed to be time independent and the route provided is independent of the risk preference (with respect to violating the deadline) of the user. To address these issues, we make the following contributions: We introduce (1) a dynamic SOP (DSOP) model, which is an extension of SOPs with dynamic (time-dependent) travel times; (2) a risk-sensitive criterion to allow for different risk preferences; and (3) a local search algorithm to solve DSOPs with this risk-sensitive criterion. We evaluated our algorithms on a real-world dataset for a theme park navigation problem as well as synthetic datasets employed in the literature. ";"Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1210.4875;A Theory of Goal-Oriented MDPs with Dead Ends; Andrey Kolobov,  Mausam,  Daniel Weld;  Stochastic Shortest Path (SSP) MDPs is a problem class widely studied in AI, especially in probabilistic planning. They describe a wide range of scenarios but make the restrictive assumption that the goal is reachable from any state, i.e., that dead-end states do not exist. Because of this, SSPs are unable to model various scenarios that may have catastrophic events (e.g., an airplane possibly crashing if it flies into a storm). Even though MDP algorithms have been used for solving problems with dead ends, a principled theory of SSP extensions that would allow dead ends, including theoretically sound algorithms for solving such MDPs, has been lacking. In this paper, we propose three new MDP classes that admit dead ends under increasingly weaker assumptions. We present Value Iteration-based as well as the more efficient heuristic search algorithms for optimally solving each class, and explore theoretical relationships between these classes. We also conduct a preliminary empirical study comparing the performance of our algorithms on different MDP classes, especially on scenarios with unavoidable dead ends. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4878;Join-graph based cost-shifting schemes; Alexander T. Ihler,  Natalia Flerova,  Rina Dechter,  Lars Otten;"  We develop several algorithms taking advantage of two common approaches for bounding MPE queries in graphical models: minibucket elimination and message-passing updates for linear programming relaxations. Both methods are quite similar, and offer useful perspectives for the other; our hybrid approaches attempt to balance the advantages of each. We demonstrate the power of our hybrid algorithms through extensive empirical evaluation. Most notably, a Branch and Bound search guided by the heuristic function calculated by one of our new algorithms has recently won first place in the PASCAL2 inference challenge. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4880;Inferring Strategies from Limited Reconnaissance in Real-time Strategy  Games; Jesse Hostetler,  Ethan W. Dereszynski,  Thomas G. Dietterich,  Alan Fern;  In typical real-time strategy (RTS) games, enemy units are visible only when they are within sight range of a friendly unit. Knowledge of an opponent's disposition is limited to what can be observed through scouting. Information is costly, since units dedicated to scouting are unavailable for other purposes, and the enemy will resist scouting attempts. It is important to infer as much as possible about the opponent's current and future strategy from the available observations. We present a dynamic Bayes net model of strategies in the RTS game Starcraft that combines a generative model of how strategies relate to observable quantities with a principled framework for incorporating evidence gained via scouting. We demonstrate the model's ability to infer unobserved aspects of the game from realistic observations. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Learning (cs.LG)"
https://arxiv.org/abs/1210.4882;A Maximum Likelihood Approach For Selecting Sets of Alternatives; Ariel D. Procaccia,  Sashank J. Reddi,  Nisarg Shah;  We consider the problem of selecting a subset of alternatives given noisy evaluations of the relative strength of different alternatives. We wish to select a k-subset (for a given k) that provides a maximum likelihood estimate for one of several objectives, e.g., containing the strongest alternative. Although this problem is NP-hard, we show that when the noise level is sufficiently high, intuitive methods provide the optimal solution. We thus generalize classical results about singling out one alternative and identifying the hidden ranking of alternatives by strength. Extensive experiments show that our methods perform well in practical settings. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4885;A Case Study in Complexity Estimation: Towards Parallel Branch-and-Bound  over Graphical Models; Lars Otten,  Rina Dechter;  We study the problem of complexity estimation in the context of parallelizing an advanced Branch and Bound-type algorithm over graphical models. The algorithm's pruning power makes load balancing, one crucial element of every distributed system, very challenging. We propose using a statistical regression model to identify and tackle disproportionally complex parallel subproblems, the cause of load imbalance, ahead of time. The proposed model is evaluated and analyzed on various levels and shown to yield robust predictions. We then demonstrate its effectiveness for load balancing in practice. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4890;The Complexity of Approximately Solving Influence Diagrams; Denis D. Maua,  Cassio Polpo de Campos,  Marco Zaffalon;  Influence diagrams allow for intuitive and yet precise description of complex situations involving decision making under uncertainty. Unfortunately, most of the problems described by influence diagrams are hard to solve. In this paper we discuss the complexity of approximately solving influence diagrams. We do not assume no-forgetting or regularity, which makes the class of problems we address very broad. Remarkably, we show that when both the tree-width and the cardinality of the variables are bounded the problem admits a fully polynomial-time approximation scheme. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4894;Heuristic Ranking in Tightly Coupled Probabilistic Description Logics; Thomas Lukasiewicz,  Maria Vanina Martinez,  Giorgio Orsi,  Gerardo I. Simari;  The Semantic Web effort has steadily been gaining traction in the recent years. In particular,Web search companies are recently realizing that their products need to evolve towards having richer semantic search capabilities. Description logics (DLs) have been adopted as the formal underpinnings for Semantic Web languages used in describing ontologies. Reasoning under uncertainty has recently taken a leading role in this arena, given the nature of data found on theWeb. In this paper, we present a probabilistic extension of the DL EL++ (which underlies the OWL2 EL profile) using Markov logic networks (MLNs) as probabilistic semantics. This extension is tightly coupled, meaning that probabilistic annotations in formulas can refer to objects in the ontology. We show that, even though the tightly coupled nature of our language means that many basic operations are data-intractable, we can leverage a sublanguage of MLNs that allows to rank the atomic consequences of an ontology relative to their probability values (called ranking queries) even when these values are not fully computed. We present an anytime algorithm to answer ranking queries, and provide an upper bound on the error that it incurs, as well as a criterion to decide when results are guaranteed to be correct. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1210.4897;Belief Propagation for Structured Decision Making; Qiang Liu,  Alexander T. Ihler;  Variational inference algorithms such as belief propagation have had tremendous impact on our ability to learn and use graphical models, and give many insights for developing or understanding exact and approximate inference. However, variational approaches have not been widely adoped for decision making in graphical models, often formulated through influence diagrams and including both centralized and decentralized (or multi-agent) decisions. In this work, we present a general variational framework for solving structured cooperative decision-making problems, use it to propose several belief propagation-like algorithms, and analyze them both theoretically and empirically. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4900;Probability and Asset Updating using Bayesian Networks for Combinatorial  Prediction Markets; Wei Sun,  Robin Hanson,  Kathryn Blackmond Laskey,  Charles Twardy;  A market-maker-based prediction market lets forecasters aggregate information by editing a consensus probability distribution either directly or by trading securities that pay off contingent on an event of interest. Combinatorial prediction markets allow trading on any event that can be specified as a combination of a base set of events. However, explicitly representing the full joint distribution is infeasible for markets with more than a few base events. A factored representation such as a Bayesian network (BN) can achieve tractable computation for problems with many related variables. Standard BN inference algorithms, such as the junction tree algorithm, can be used to update a representation of the entire joint distribution given a change to any local conditional probability. However, in order to let traders reuse assets from prior trades while never allowing assets to become negative, a BN based prediction market also needs to update a representation of each user's assets and find the conditional state in which a user has minimum assets. Users also find it useful to see their expected assets given an edit outcome. We show how to generalize the junction tree algorithm to perform all these computations. ;"Artificial Intelligence (cs.AI); Trading and Market Microstructure (q-fin.TR)"
https://arxiv.org/abs/1210.4906;Efficient MRF Energy Minimization via Adaptive Diminishing Smoothing; Bogdan Savchynskyy,  Stefan Schmidt,  Joerg Kappes,  Christoph Schnoerr;  We consider the linear programming relaxation of an energy minimization problem for Markov Random Fields. The dual objective of this problem can be treated as a concave and unconstrained, but non-smooth function. The idea of smoothing the objective prior to optimization was recently proposed in a series of papers. Some of them suggested the idea to decrease the amount of smoothing (so called temperature) while getting closer to the optimum. However, no theoretical substantiation was provided. We propose an adaptive smoothing diminishing algorithm based on the duality gap between relaxed primal and dual objectives and demonstrate the efficiency of our approach with a smoothed version of Sequential Tree-Reweighted Message Passing (TRW-S) algorithm. The strategy is applicable to other algorithms as well, avoids adhoc tuning of the smoothing during iterations, and provably guarantees convergence to the optimum. ;"Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1210.4907;From imprecise probability assessments to conditional probabilities with  quasi additive classes of conditioning events; Giuseppe Sanfilippo;  In this paper, starting from a generalized coherent (i.e. avoiding uniform loss) intervalvalued probability assessment on a finite family of conditional events, we construct conditional probabilities with quasi additive classes of conditioning events which are consistent with the given initial assessment. Quasi additivity assures coherence for the obtained conditional probabilities. In order to reach our goal we define a finite sequence of conditional probabilities by exploiting some theoretical results on g-coherence. In particular, we use solutions of a finite sequence of linear systems. ;"Artificial Intelligence (cs.AI); Probability (math.PR)"
https://arxiv.org/abs/1210.4910;New Advances and Theoretical Insights into EDML; Khaled S. Refaat,  Arthur Choi,  Adnan Darwiche;  EDML is a recently proposed algorithm for learning MAP parameters in Bayesian networks. In this paper, we present a number of new advances and insights on the EDML algorithm. First, we provide the multivalued extension of EDML, originally proposed for Bayesian networks over binary variables. Next, we identify a simplified characterization of EDML that further implies a simple fixed-point algorithm for the convex optimization problem that underlies it. This characterization further reveals a connection between EDML and EM: a fixed point of EDML is a fixed point of EM, and vice versa. We thus identify also a new characterization of EM fixed points, but in the semantics of EDML. Finally, we propose a hybrid EDML/EM algorithm that takes advantage of the improved empirical convergence behavior of EDML, while maintaining the monotonic improvement property of EM. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1210.4911;Multi-objective Influence Diagrams; Radu Marinescu,  Abdul Razak,  Nic Wilson;  We describe multi-objective influence diagrams, based on a set of p objectives, where utility values are vectors in Rp, and are typically only partially ordered. These can still be solved by a variable elimination algorithm, leading to a set of maximal values of expected utility. If the Pareto ordering is used this set can often be prohibitively large. We consider approximate representations of the Pareto set based on e-coverings, allowing much larger problems to be solved. In addition, we define a method for incorporating user tradeoffs, which also greatly improves the efficiency. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4912;FHHOP: A Factored Hybrid Heuristic Online Planning Algorithm for Large  POMDPs; Zhongzhang Zhang,  Xiaoping Chen;"  Planning in partially observable Markov decision processes (POMDPs) remains a challenging topic in the artificial intelligence community, in spite of recent impressive progress in approximation techniques. Previous research has indicated that online planning approaches are promising in handling large-scale POMDP domains efficiently as they make decisions ""on demand"" instead of proactively for the entire state space. We present a Factored Hybrid Heuristic Online Planning (FHHOP) algorithm for large POMDPs. FHHOP gets its power by combining a novel hybrid heuristic search strategy with a recently developed factored state representation. On several benchmark problems, FHHOP substantially outperformed state-of-the-art online heuristic search approaches in terms of both scalability and quality. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.4913;An Improved Admissible Heuristic for Learning Optimal Bayesian Networks; Changhe Yuan,  Brandon Malone;  Recently two search algorithms, A* and breadth-first branch and bound (BFBnB), were developed based on a simple admissible heuristic for learning Bayesian network structures that optimize a scoring function. The heuristic represents a relaxation of the learning problem such that each variable chooses optimal parents independently. As a result, the heuristic may contain many directed cycles and result in a loose bound. This paper introduces an improved admissible heuristic that tries to avoid directed cycles within small groups of variables. A sparse representation is also introduced to store only the unique optimal parent choices. Empirical results show that the new techniques significantly improved the efficiency and scalability of A* and BFBnB on most of datasets tested in this paper. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1210.4916;A Cluster-Cumulant Expansion at the Fixed Points of Belief Propagation; Max Welling,  Andrew E. Gelfand,  Alexander T. Ihler;"  We introduce a new cluster-cumulant expansion (CCE) based on the fixed points of iterative belief propagation (IBP). This expansion is similar in spirit to the loop-series (LS) recently introduced in [1]. However, in contrast to the latter, the CCE enjoys the following important qualities: 1) it is defined for arbitrary state spaces 2) it is easily extended to fixed points of generalized belief propagation (GBP), 3) disconnected groups of variables will not contribute to the CCE and 4) the accuracy of the expansion empirically improves upon that of the LS. The CCE is based on the same M\""obius transform as the Kikuchi approximation, but unlike GBP does not require storing the beliefs of the GBP-clusters nor does it suffer from convergence issues during belief updating. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.5222;Module Theorem for The General Theory of Stable Models; Joseph Babb,  Joohyung Lee;  The module theorem by Janhunen et al. demonstrates how to provide a modular structure in answer set programming, where each module has a well-defined input/output interface which can be used to establish the compositionality of answer sets. The theorem is useful in the analysis of answer set programs, and is a basis of incremental grounding and reactive answer set programming. We extend the module theorem to the general theory of stable models by Ferraris et al. The generalization applies to non-ground logic programs allowing useful constructs in answer set programming, such as choice rules, the count aggregate, and nested expressions. Our extension is based on relating the module theorem to the symmetric splitting theorem by Ferraris et al. Based on this result, we reformulate and extend the theory of incremental answer set computation to a more general class of programs. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1210.5670;Typed Answer Set Programming and Inverse Lambda Algorithms; Chitta Baral,  Juraj Dzifcak,  Marcos A. Gonzalez,  Aaron Gottesman;"  Our broader goal is to automatically translate English sentences into formulas in appropriate knowledge representation languages as a step towards understanding and thus answering questions with respect to English text. Our focus in this paper is on the language of Answer Set Programming (ASP). Our approach to translate sentences to ASP rules is inspired by Montague's use of lambda calculus formulas as meaning of words and phrases. With ASP as the target language the meaning of words and phrases are ASP-lambda formulas. In an earlier work we illustrated our approach by manually developing a dictionary of words and their ASP-lambda formulas. However such an approach is not scalable. In this paper our focus is on two algorithms that allow one to construct ASP-lambda formulas in an inverse manner. In particular the two algorithms take as input two lambda-calculus expressions G and H and compute a lambda-calculus expression F such that F with input as G, denoted by F@G, is equal to H; and similarly G@F = H. We present correctness and complexity results about these algorithms. To do that we develop the notion of typed ASP-lambda calculus theories and their orders and use it in developing the completeness results. (To appear in Theory and Practice of Logic Programming.) ";"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)"
https://arxiv.org/abs/1210.6128;Improved Local Search in Artificial Bee Colony using Golden Section  Search; Tarun Kumar Sharma,  Millie Pant,  V.P.Singh;  Artificial bee colony (ABC), an optimization algorithm is a recent addition to the family of population based search algorithm. ABC has taken its inspiration from the collective intelligent foraging behavior of honey bees. In this study we have incorporated golden section search mechanism in the structure of basic ABC to improve the global convergence and prevent to stick on a local solution. The proposed variant is termed as ILS-ABC. Comparative numerical results with the state-of-art algorithms show the performance of the proposal when applied to the set of unconstrained engineering design problems. The simulated results show that the proposed variant can be successfully applied to solve real life problems. ;"Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)"
https://arxiv.org/abs/1210.6209;Characteristic of partition-circuit matroid through approximation number; Yanfang Liu,  William Zhu;  Rough set theory is a useful tool to deal with uncertain, granular and incomplete knowledge in information systems. And it is based on equivalence relations or partitions. Matroid theory is a structure that generalizes linear independence in vector spaces, and has a variety of applications in many fields. In this paper, we propose a new type of matroids, namely, partition-circuit matroids, which are induced by partitions. Firstly, a partition satisfies circuit axioms in matroid theory, then it can induce a matroid which is called a partition-circuit matroid. A partition and an equivalence relation on the same universe are one-to-one corresponding, then some characteristics of partition-circuit matroids are studied through rough sets. Secondly, similar to the upper approximation number which is proposed by Wang and Zhu, we define the lower approximation number. Some characteristics of partition-circuit matroids and the dual matroids of them are investigated through the lower approximation number and the upper approximation number. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.6275;Ambiente de Planejamento Ipê; João Eugenio Marynowski;  In this work we investigate the systems that implements algorithms for the planning problem in Artificial Intelligence, called planners, with especial attention to the planners based on the plan graph. We analyze the problem of comparing the performance of the different algorithms and we propose an environment for the development and analysis of planners. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.6415;Lex-Partitioning: A New Option for BDD Search; Stefan Edelkamp,  Peter Kissmann,  Álvaro Torralba;  For the exploration of large state spaces, symbolic search using binary decision diagrams (BDDs) can save huge amounts of memory and computation time. State sets are represented and modified by accessing and manipulating their characteristic functions. BDD partitioning is used to compute the image as the disjunction of smaller subimages. In this paper, we propose a novel BDD partitioning option. The partitioning is lexicographical in the binary representation of the states contained in the set that is represented by a BDD and uniform with respect to the number of states represented. The motivation of controlling the state set sizes in the partitioning is to eventually bridge the gap between explicit and symbolic search. Let n be the size of the binary state vector. We propose an O(n) ranking and unranking scheme that supports negated edges and operates on top of precomputed satcount values. For the uniform split of a BDD, we then use unranking to provide paths along which we partition the BDDs. In a shared BDD representation the efforts are O(n). The algorithms are fully integrated in the CUDD library and evaluated in strongly solving general game playing benchmarks. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.6855;Asynchronous Decentralized Algorithm for Space-Time Cooperative  Pathfinding; Michal Čáp,  Peter Novák,  Jiří Vokřínek,  Michal Pěchouček;  Cooperative pathfinding is a multi-agent path planning problem where a group of vehicles searches for a corresponding set of non-conflicting space-time trajectories. Many of the practical methods for centralized solving of cooperative pathfinding problems are based on the prioritized planning strategy. However, in some domains (e.g., multi-robot teams of unmanned aerial vehicles, autonomous underwater vehicles, or unmanned ground vehicles) a decentralized approach may be more desirable than a centralized one due to communication limitations imposed by the domain and/or privacy concerns. In this paper we present an asynchronous decentralized variant of prioritized planning ADPP and its interruptible version IADPP. The algorithm exploits the inherent parallelism of distributed systems and allows for a speed up of the computation process. Unlike the synchronized planning approaches, the algorithm allows an agent to react to updates about other agents' paths immediately and invoke its local spatio-temporal path planner to find the best trajectory, as response to the other agents' choices. We provide a proof of correctness of the algorithms and experimentally evaluate them on synthetic domains. ;"Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Robotics (cs.RO)"
https://arxiv.org/abs/1210.7002;A Biomimetic Approach Based on Immune Systems for Classification of  Unstructured Data; Mohamed Hamou,  Abdelmalek Amine,  Ahmed Chaouki Lokbani;  In this paper we present the results of unstructured data clustering in this case a textual data from Reuters 21578 corpus with a new biomimetic approach using immune system. Before experimenting our immune system, we digitalized textual data by the n-grams approach. The novelty lies on hybridization of n-grams and immune systems for clustering. The experimental results show that the recommended ideas are promising and prove that this method can solve the text clustering problem. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.7154;Get my pizza right: Repairing missing is-a relations in ALC ontologies  (extended version); Patrick Lambrix,  Zlatan Dragisic,  Valentina Ivanova;  With the increased use of ontologies in semantically-enabled applications, the issue of debugging defects in ontologies has become increasingly important. These defects can lead to wrong or incomplete results for the applications. Debugging consists of the phases of detection and repairing. In this paper we focus on the repairing phase of a particular kind of defects, i.e. the missing relations in the is-a hierarchy. Previous work has dealt with the case of taxonomies. In this work we extend the scope to deal with ALC ontologies that can be represented using acyclic terminologies. We present algorithms and discuss a system. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.7959;Algorithm Selection for Combinatorial Search Problems: A Survey; Lars Kotthoff;  The Algorithm Selection Problem is concerned with selecting the best algorithm to solve a given problem on a case-by-case basis. It has become especially relevant in the last decade, as researchers are increasingly investigating how to identify the most suitable existing algorithm for solving a problem instead of developing new algorithms. This survey presents an overview of this work focusing on the contributions made in the area of combinatorial search problems, where Algorithm Selection techniques have achieved significant performance improvements. We unify and organise the vast literature according to criteria that determine Algorithm Selection systems in practice. The comprehensive classification of approaches identifies and analyses the different directions from which Algorithm Selection has been approached. This paper contrasts and compares different methods for solving the problem as well as ways of using these solutions. It closes by identifying directions of current and future research. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1210.8385;First Experiments with PowerPlay; Rupesh Kumar Srivastava,  Bas R. Steunebrink,  Jürgen Schmidhuber;  Like a scientist or a playing child, PowerPlay not only learns new skills to solve given problems, but also invents new interesting problems by itself. By design, it continually comes up with the fastest to find, initially novel, but eventually solvable tasks. It also continually simplifies or compresses or speeds up solutions to previous tasks. Here we describe first experiments with PowerPlay. A self-delimiting recurrent neural network SLIM RNN is used as a general computational problem solving architecture. Its connection weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. Our PowerPlay-driven SLIM RNN learns to become an increasingly general solver of self-invented problems, continually adding new problem solving procedures to its growing skill repertoire. Extending a recent conference paper, we identify interesting, emerging, developmental stages of our open-ended system. We also show how it automatically self-modularizes, frequently re-using code for previously invented skills, always trying to invent novel tasks that can be quickly validated because they do not require too many weight changes affecting too many previous tasks. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1210.8442;Linear-Nonlinear-Poisson Neuron Networks Perform Bayesian Inference On  Boltzmann Machines; Louis Yuanlong Shao;  One conjecture in both deep learning and classical connectionist viewpoint is that the biological brain implements certain kinds of deep networks as its back-end. However, to our knowledge, a detailed correspondence has not yet been set up, which is important if we want to bridge between neuroscience and machine learning. Recent researches emphasized the biological plausibility of Linear-Nonlinear-Poisson (LNP) neuron model. We show that with neurally plausible settings, the whole network is capable of representing any Boltzmann machine and performing a semi-stochastic Bayesian inference algorithm lying between Gibbs sampling and variational inference. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)"
https://arxiv.org/abs/1212.0229;Simplification and integration in computing and cognition: the SP theory  and the multiple alignment concept; James Gerard Wolff;  The main purpose of this article is to describe potential benefits and applications of the SP theory, a unique attempt to simplify and integrate ideas across artificial intelligence, mainstream computing and human cognition, with information compression as a unifying theme. The theory, including a concept of multiple alignment, combines conceptual simplicity with descriptive and explanatory power in several areas including representation of knowledge, natural language processing, pattern recognition, several kinds of reasoning, the storage and retrieval of information, planning and problem solving, unsupervised learning, information compression, and human perception and cognition. In the SP machine -- an expression of the SP theory which is currently realised in the form of computer models -- there is potential for an overall simplification of computing systems, including software. As a theory with a broad base of support, the SP theory promises useful insights in many areas and the integration of structures and functions, both within a given area and amongst different areas. There are potential benefits in natural language processing (with potential for the understanding and translation of natural languages), the need for a versatile intelligence in autonomous robots, computer vision, intelligent databases, maintaining multiple versions of documents or web pages, software engineering, criminal investigations, the management of big data and gaining benefits from it, the semantic web, medical diagnosis, the detection of computer viruses, the economical transmission of data, and data fusion. Further development of these ideas would be facilitated by the creation of a high-parallel, web-based, open-source version of the SP machine, with a good user interface. This would provide a means for researchers to explore what can be done with the system and to refine it. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1212.0582;Compositional Stochastic Modeling and Probabilistic Programming; Eric Mjolsness;  Probabilistic programming is related to a compositional approach to stochastic modeling by switching from discrete to continuous time dynamics. In continuous time, an operator-algebra semantics is available in which processes proceeding in parallel (and possibly interacting) have summed time-evolution operators. From this foundation, algorithms for simulation, inference and model reduction may be systematically derived. The useful consequences are potentially far-reaching in computational science, machine learning and beyond. Hybrid compositional stochastic modeling/probabilistic programming approaches may also be possible. ;"Artificial Intelligence (cs.AI); Programming Languages (cs.PL)"
https://arxiv.org/abs/1212.0692;An Empirical Evaluation of Portfolios Approaches for solving CSPs; Roberto Amadini,  Maurizio Gabbrielli,  Jacopo Mauro;  Recent research in areas such as SAT solving and Integer Linear Programming has shown that the performances of a single arbitrarily efficient solver can be significantly outperformed by a portfolio of possibly slower on-average solvers. We report an empirical evaluation and comparison of portfolio approaches applied to Constraint Satisfaction Problems (CSPs). We compared models developed on top of off-the-shelf machine learning algorithms with respect to approaches used in the SAT field and adapted for CSPs, considering different portfolio sizes and using as evaluation metrics the number of solved problems and the time taken to solve them. Results indicate that the best SAT approaches have top performances also in the CSP field and are slightly more competitive than simple models built on top of classification algorithms. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1212.0750;Problem Solving and Computational Thinking in a Learning Environment; Michael Gr. Voskoglou,  Sheryl Buckley;  Computational thinking is a new problem soling method named for its extensive use of computer science techniques. It synthesizes critical thinking and existing knowledge and applies them in solving complex technological problems. The term was coined by J. Wing, but the relationship between computational and critical thinking, the two modes of thiking in solving problems, has not been yet learly established. This paper aims at shedding some light into this relationship. We also present two classroom experiments performed recently at the Graduate Technological Educational Institute of Patras in Greece. The results of these experiments give a strong indication that the use of computers as a tool for problem solving enchances the students' abilities in solving real world problems involving mathematical modelling. This is also crossed by earlier findings of other researchers for the problem solving process in general (not only for mathematical problems). ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.0768;An ontology-based approach to relax traffic regulation for autonomous  vehicle assistance; Philippe Morignot (INRIA Rocquencourt),  Fawzi Nashashibi (INRIA Rocquencourt);"  Traffic regulation must be respected by all vehicles, either human- or computer- driven. However, extreme traffic situations might exhibit practical cases in which a vehicle should safely and reasonably relax traffic regulation, e.g., in order not to be indefinitely blocked and to keep circulating. In this paper, we propose a high-level representation of an automated vehicle, other vehicles and their environment, which can assist drivers in taking such ""illegal"" but practical relaxation decisions. This high-level representation (an ontology) includes topological knowledge and inference rules, in order to compute the next high-level motion an automated vehicle should take, as assistance to a driver. Results on practical cases are presented. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.0967;Compiling Relational Database Schemata into Probabilistic Graphical  Models; Sameer Singh,  Thore Graepel;  Instead of requiring a domain expert to specify the probabilistic dependencies of the data, in this work we present an approach that uses the relational DB schema to automatically construct a Bayesian graphical model for a database. This resulting model contains customized distributions for columns, latent variables that cluster the data, and factors that reflect and represent the foreign key links. Experiments demonstrate the accuracy of the model and the scalability of inference on synthetic and real-world data. ;"Artificial Intelligence (cs.AI); Databases (cs.DB); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1212.1143;Multiscale Markov Decision Problems: Compression, Solution, and Transfer  Learning; Jake Bouvrie,  Mauro Maggioni;  Many problems in sequential decision making and stochastic control often have natural multiscale structure: sub-tasks are assembled together to accomplish complex goals. Systematically inferring and leveraging hierarchical structure, particularly beyond a single level of abstraction, has remained a longstanding challenge. We describe a fast multiscale procedure for repeatedly compressing, or homogenizing, Markov decision processes (MDPs), wherein a hierarchy of sub-problems at different scales is automatically determined. Coarsened MDPs are themselves independent, deterministic MDPs, and may be solved using existing algorithms. The multiscale representation delivered by this procedure decouples sub-tasks from each other and can lead to substantial improvements in convergence rates both locally within sub-problems and globally across sub-problems, yielding significant computational savings. A second fundamental aspect of this work is that these multiscale decompositions yield new transfer opportunities across different problems, where solutions of sub-tasks at different levels of the hierarchy may be amenable to transfer to new problems. Localized transfer of policies and potential operators at arbitrary scales is emphasized. Finally, we demonstrate compression and transfer in a collection of illustrative domains, including examples involving discrete and continuous statespaces. ;"Artificial Intelligence (cs.AI); Systems and Control (cs.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)"
https://arxiv.org/abs/1212.1570;A simple method for decision making in robocup soccer simulation 3d  environment; Khashayar Niki Maleki,  Mohammad Hadi Valipour,  Sadegh Mokari,  Roohollah Yeylaghi Ashrafi,  Mohammad Reza Jamali,  Caro Lucas;  In this paper new hierarchical hybrid fuzzy-crisp methods for decision making and action selection of an agent in soccer simulation 3D environment are presented. First, the skills of an agent are introduced, implemented and classified in two layers, the basicskills and the highlevel skills. In the second layer, a twophase mechanism for decision making is introduced. In phase one, some useful methods are implemented which check the agent's situation for performing required skills. In the next phase, the team str ategy, team for mation, agent's role and the agent's positioning system are introduced. A fuzzy logical approach is employed to recognize the team strategy and further more to tell the player the best position to move. At last, we comprised our implemented algor ithm in the Robocup Soccer Simulation 3D environment and results showed th eefficiency of the introduced methodology. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1212.2005;The Dynamic Controllability of Conditional STNs with Uncertainty; Luke Hunsberger,  Roberto Posenato,  Carlo Combi;  Recent attempts to automate business processes and medical-treatment processes have uncovered the need for a formal framework that can accommodate not only temporal constraints, but also observations and actions with uncontrollable durations. To meet this need, this paper defines a Conditional Simple Temporal Network with Uncertainty (CSTNU) that combines the simple temporal constraints from a Simple Temporal Network (STN) with the conditional nodes from a Conditional Simple Temporal Problem (CSTP) and the contingent links from a Simple Temporal Network with Uncertainty (STNU). A notion of dynamic controllability for a CSTNU is defined that generalizes the dynamic consistency of a CTP and the dynamic controllability of an STNU. The paper also presents some sound constraint-propagation rules for dynamic controllability that are expected to form the backbone of a dynamic-controllability-checking algorithm for CSTNUs. ;"Artificial Intelligence (cs.AI); Systems and Control (cs.SY)"
https://arxiv.org/abs/1212.2056;Soft Constraint Logic Programming for Electric Vehicle Travel  Optimization; Giacoma Valentina Monreale,  Ugo Montanari,  Nicklas Hoch;  Soft Constraint Logic Programming is a natural and flexible declarative programming formalism, which allows to model and solve real-life problems involving constraints of different types. In this paper, after providing a slightly more general and elegant presentation of the framework, we show how we can apply it to the e-mobility problem of coordinating electric vehicles in order to overcome both energetic and temporal constraints and so to reduce their running cost. In particular, we focus on the journey optimization sub-problem, considering sequences of trips from a user's appointment to another one. Solutions provide the best alternatives in terms of time and energy consumption, including route sequences and possible charging events. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2444;On revising fuzzy belief bases; Richard Booth,  Eva Richter;  We look at the problem of revising fuzzy belief bases, i.e., belief base revision in which both formulas in the base as well as revision-input formulas can come attached with varying truth-degrees. Working within a very general framework for fuzzy logic which is able to capture a variety of types of inference under uncertainty, such as truth-functional fuzzy logics and certain types of probabilistic inference, we show how the idea of rational change from 'crisp' base revision, as embodied by the idea of partial meet revision, can be faithfully extended to revising fuzzy belief bases. We present and axiomatise an operation of partial meet fuzzy revision and illustrate how the operation works in several important special instances of the framework. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2445;Upgrading Ambiguous Signs in QPNs; Janneke H. Bolt,  Silja Renooij,  Linda C. van der Gaag;  WA qualitative probabilistic network models the probabilistic relationships between its variables by means of signs. Non-monotonic influences have associated an ambiguous sign. These ambiguous signs typically lead to uninformative results upon inference. A non-monotonic influence can, however, be associated with a, more informative, sign that indicates its effect in the current state of the network. To capture this effect, we introduce the concept of situational sign. Furthermore, if the network converts to a state in which all variables that provoke the non-monotonicity have been observed, a non-monotonic influence reduces to a monotonic influence. We study the persistence and propagation of situational signs upon inference and give a method to establish the sign of a reduced influence. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2446;Parametric Dependability Analysis through Probabilistic Horn Abduction; Andrea Bobbio,  Stefania Montani,  Luigi Portinale;"  Dependability modeling and evaluation is aimed at investigating that a system performs its function correctly in time. A usual way to achieve a high reliability, is to design redundant systems that contain several replicas of the same subsystem or component. State space methods for dependability analysis may suffer of the state space explosion problem in such a kind of situation. Combinatorial models, on the other hand, require the simplified assumption of statistical independence; however, in case of redundant systems, this does not guarantee a reduced number of modeled elements. In order to provide a more compact system representation, parametric system modeling has been investigated in the literature, in such a way that a set of replicas of a given subsystem is parameterized so that only one representative instance is explicitly included. While modeling aspects can be suitably addressed by these approaches, analytical tools working on parametric characterizations are often more difficult to be defined and the standard approach is to 'unfold' the parametric model, in order to exploit standard analysis algorithms working at the unfolded 'ground' level. Moreover, parameterized combinatorial methods still require the statistical independence assumption. In the present paper we consider the formalism of Parametric Fault Tree (PFT) and we show how it can be related to Probabilistic Horn Abduction (PHA). Since PHA is a framework where both modeling and analysis can be performed in a restricted first-order language, we aim at showing that converting a PFT into a PHA knowledge base will allow an approach to dependability analysis directly exploiting parametric representation. We will show that classical qualitative and quantitative dependability measures can be characterized within PHA. Furthermore, additional modeling aspects (such as noisy gates and local dependencies) as well as additional reliability measures (such as posterior probability analysis) can be naturally addressed by this conversion. A simple example of a multi-processor system with several replicated units is used to illustrate the approach. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2448;On Triangulating Dynamic Graphical Models; Jeff A. Bilmes,  Chris Bartels;  This paper introduces new methodology to triangulate dynamic Bayesian networks (DBNs) and dynamic graphical models (DGMs). While most methods to triangulate such networks use some form of constrained elimination scheme based on properties of the underlying directed graph, we find it useful to view triangulation and elimination using properties only of the resulting undirected graph, obtained after the moralization step. We first briefly introduce the Graphical model toolkit (GMTK) and its notion of dynamic graphical models, one that slightly extends the standard notion of a DBN. We next introduce the 'boundary algorithm', a method to find the best boundary between partitions in a dynamic model. We find that using this algorithm, the notions of forward- and backward-interface become moot - namely, the size and fill-in of the best forward- and backward- interface are identical. Moreover, we observe that finding a good partition boundary allows for constrained elimination orders (and therefore graph triangulations) that are not possible using standard slice-by-slice constrained eliminations. More interestingly, with certain boundaries it is possible to obtain constrained elimination schemes that lie outside the space of possible triangulations using only unconstrained elimination. Lastly, we report triangulation results on invented graphs, standard DBNs from the literature, novel DBNs used in speech recognition research systems, and also random graphs. Using a number of different triangulation quality measures (max clique size, state-space, etc.), we find that with our boundary algorithm the triangulation quality can dramatically improve. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2449;An Empirical Study of w-Cutset Sampling for Bayesian Networks; Bozhena Bidyuk,  Rina Dechter;  The paper studies empirically the time-space trade-off between sampling and inference in a sl cutset sampling algorithm. The algorithm samples over a subset of nodes in a Bayesian network and applies exact inference over the rest. Consequently, while the size of the sampling space decreases, requiring less samples for convergence, the time for generating each single sample increases. The w-cutset sampling selects a sampling set such that the induced-width of the network when the sampling set is observed is bounded by w, thus requiring inference whose complexity is exponential in w. In this paper, we investigate performance of w-cutset sampling over a range of w values and measure the accuracy of w-cutset sampling as a function of w. Our experiments demonstrate that the cutset sampling idea is quite powerful showing that an optimal balance between inference and sampling benefits substantially from restricting the cutset size, even at the cost of more complex inference. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2450;A possibilistic handling of partially ordered information; Salem Benferhat,  Sylvain Lagrue,  Odile Papini;  In a standard possibilistic logic, prioritized information are encoded by means of weighted knowledge base. This paper proposes an extension of possibilistic logic for dealing with partially ordered information. We Show that all basic notions of standard possibilitic logic (sumbsumption, syntactic and semantic inference, etc.) have natural couterparts when dealing with partially ordered information. We also propose an algorithm which computes possibilistic conclusions of a partial knowledge base of a partially ordered knowlege base. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2452;Value Elimination: Bayesian Inference via Backtracking Search; Fahiem Bacchus,  Shannon Dalmao,  Toniann Pitassi;"  Backtracking search is a powerful algorithmic paradigm that can be used to solve many problems. It is in a certain sense the dual of variable elimination; but on many problems, e.g., SAT, it is vastly superior to variable elimination in practice. Motivated by this we investigate the application of backtracking search to the problem of Bayesian inference (Bayes). We show that natural generalizations of known techniques allow backtracking search to achieve performance guarantees similar to standard algorithms for Bayes, and that there exist problems on which backtracking can in fact do much better. We also demonstrate that these ideas can be applied to implement a Bayesian inference engine whose performance is competitive with standard algorithms. Since backtracking search can very naturally take advantage of context specific structure, the potential exists for performance superior to standard algorithms on many problems. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2455;New Advances in Inference by Recursive Conditioning; David Allen,  Adnan Darwiche;  Recursive Conditioning (RC) was introduced recently as the first any-space algorithm for inference in Bayesian networks which can trade time for space by varying the size of its cache at the increment needed to store a floating point number. Under full caching, RC has an asymptotic time and space complexity which is comparable to mainstream algorithms based on variable elimination and clustering (exponential in the network treewidth and linear in its size). We show two main results about RC in this paper. First, we show that its actual space requirements under full caching are much more modest than those needed by mainstream methods and study the implications of this finding. Second, we show that RC can effectively deal with determinism in Bayesian networks by employing standard logical techniques, such as unit resolution, allowing a significant reduction in its time requirements in certain cases. We illustrate our results using a number of benchmark networks, including the very challenging ones that arise in genetic linkage analysis. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2456;Incremental Compilation of Bayesian networks; Julia M. Flores,  Jose A. Gamez,  Kristian G. Olesen;"  Most methods of exact probability propagation in Bayesian networks do not carry out the inference directly over the network, but over a secondary structure known as a junction tree or a join tree (JT). The process of obtaining a JT is usually termed {sl compilation}. As compilation is usually viewed as a whole process; each time the network is modified, a new compilation process has to be carried out. The possibility of reusing an already existing JT, in order to obtain the new one regarding only the modifications in the network has received only little attention in the literature. In this paper we present a method for incremental compilation of a Bayesian network, following the classical scheme in which triangulation plays the key role. In order to perform incremental compilation we propose to recompile only those parts of the JT which can have been affected by the networks modifications. To do so, we exploit the technique OF maximal prime subgraph decomposition in determining the minimal subgraph(s) that have to be recompiled, and thereby the minimal subtree(s) of the JT that should be replaced by new subtree(s).We focus on structural modifications : addition and deletion of links and variables. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2457;Structure-Based Causes and Explanations in the Independent Choice Logic; Alberto Finzi,  Thomas Lukasiewicz;  This paper is directed towards combining Pearl's structural-model approach to causal reasoning with high-level formalisms for reasoning about actions. More precisely, we present a combination of Pearl's structural-model approach with Poole's independent choice logic. We show how probabilistic theories in the independent choice logic can be mapped to probabilistic causal models. This mapping provides the independent choice logic with appealing concepts of causality and explanation from the structural-model approach. We illustrate this along Halpern and Pearl's sophisticated notions of actual cause, explanation, and partial explanation. This mapping also adds first-order modeling capabilities and explicit actions to the structural-model approach. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2458;Inference in Polytrees with Sets of Probabilities; Jose Carlos Ferreira da Rocha,  Fabio Gagliardi Cozman,  Cassio Polpo de Campos;"  Inferences in directed acyclic graphs associated with probability sets and probability intervals are NP-hard, even for polytrees. In this paper we focus on such inferences, and propose: 1) a substantial improvement on Tessems A / R algorithm FOR polytrees WITH probability intervals; 2) a new algorithm FOR direction - based local search(IN sets OF probability) that improves ON existing methods; 3) a collection OF branch - AND - bound algorithms that combine the previous techniques.The first two techniques lead TO approximate solutions, WHILE branch - AND - bound procedures can produce either exact OR approximate solutions.We report ON dramatic improvements ON existing techniques FOR inference WITH probability sets AND intervals, IN SOME cases reducing the computational effort BY many orders OF magnitude. ";"Artificial Intelligence (cs.AI); Computation (stat.CO)"
https://arxiv.org/abs/1212.2459;Symbolic Generalization for On-line Planning; Zhengzhu Feng,  Eric A. Hansen,  Shlomo Zilberstein;  Symbolic representations have been used successfully in off-line planning algorithms for Markov decision processes. We show that they can also improve the performance of on-line planners. In addition to reducing computation time, symbolic generalization can reduce the amount of costly real-world interactions required for convergence. We introduce Symbolic Real-Time Dynamic Programming (or sRTDP), an extension of RTDP. After each step of on-line interaction with an environment, sRTDP uses symbolic model-checking techniques to generalizes its experience by updating a group of states rather than a single state. We examine two heuristic approaches to dynamic grouping of states and show that they accelerate the planning process significantly in terms of both CPU time and the number of steps of interaction with the environment. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2461;Probabilistic Reasoning about Actions in Nonmonotonic Causal Theories; Thomas Eiter,  Thomas Lukasiewicz;  We present the language {m P}{cal C}+ for probabilistic reasoning about actions, which is a generalization of the action language {cal C}+ that allows to deal with probabilistic as well as nondeterministic effects of actions. We define a formal semantics of {m P}{cal C}+ in terms of probabilistic transitions between sets of states. Using a concept of a history and its belief state, we then show how several important problems in reasoning about actions can be concisely formulated in our formalism. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2463;A Simple Insight into Iterative Belief Propagation's Success; Rina Dechter,  Robert Mateescu;  In Non - ergodic belief networks the posterior belief OF many queries given evidence may become zero.The paper shows that WHEN belief propagation IS applied iteratively OVER arbitrary networks(the so called, iterative OR loopy belief propagation(IBP)) it IS identical TO an arc - consistency algorithm relative TO zero - belief queries(namely assessing zero posterior probabilities). This implies that zero - belief conclusions derived BY belief propagation converge AND are sound.More importantly it suggests that the inference power OF IBP IS AS strong AND AS weak, AS that OF arc - consistency.This allows the synthesis OF belief networks FOR which belief propagation IS useless ON one hand, AND focuses the investigation OF classes OF belief network FOR which belief propagation may be zero - complete.Finally, ALL the above conclusions apply also TO Generalized belief propagation algorithms that extend loopy belief propagation AND allow a crisper understanding OF their power. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2464;A Robust Independence Test for Constraint-Based Learning of Causal  Structure; Denver Dash,  Marek J. Druzdzel;  Constraint-based (CB) learning is a formalism for learning a causal network with a database D by performing a series of conditional-independence tests to infer structural information. This paper considers a new test of independence that combines ideas from Bayesian learning, Bayesian network inference, and classical hypothesis testing to produce a more reliable and robust test. The new test can be calculated in the same asymptotic time and space required for the standard tests such as the chi-squared test, but it allows the specification of a prior distribution over parameters and can be used when the database is incomplete. We prove that the test is correct, and we demonstrate empirically that, when used with a CB causal discovery algorithm with noninformative priors, it recovers structural features more reliably and it produces networks with smaller KL-Divergence, especially as the number of nodes increases or the number of records decreases. Another benefit is the dramatic reduction in the probability that a CB algorithm will stall during the search, providing a remedy for an annoying problem plaguing CB learning when the database is small. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1212.2465;Loopy Belief Propagation as a Basis for Communication in Sensor Networks; Christopher Crick,  Avi Pfeffer;"  Sensor networks are an exciting new kind of computer system. Consisting of a large number of tiny, cheap computational devices physically distributed in an environment, they gather and process data about the environment in real time. One of the central questions in sensor networks is what to do with the data, i.e., how to reason with it and how to communicate it. This paper argues that the lessons of the UAI community, in particular that one should produce and communicate beliefs rather than raw sensor values, are highly relevant to sensor networks. We contend that loopy belief propagation is particularly well suited to communicating beliefs in sensor networks, due to its compact implementation and distributed nature. We investigate the ability of loopy belief propagation to function under the stressful conditions likely to prevail in sensor networks. Our experiments show that it performs well and degrades gracefully. It converges to appropriate beliefs even in highly asynchronous settings where some nodes communicate far less frequently than others; it continues to function if some nodes fail to participate in the propagation process; and it can track changes in the environment that occur while beliefs are propagating. As a result, we believe that sensor networks present an important application opportunity for UAI. ";"Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1212.2469;Using the structure of d-connecting paths as a qualitative measure of  the strength of dependence; Sanjay Chaudhari,  Thomas S. Richardson;  Pearls concept OF a d - connecting path IS one OF the foundations OF the modern theory OF graphical models : the absence OF a d - connecting path IN a DAG indicates that conditional independence will hold IN ANY distribution factorising according TO that graph. IN this paper we show that IN singly - connected Gaussian DAGs it IS possible TO USE the form OF a d - connection TO obtain qualitative information about the strength OF conditional dependence.More precisely, the squared partial correlations BETWEEN two given variables, conditioned ON different subsets may be partially ordered BY examining the relationship BETWEEN the d - connecting path AND the SET OF variables conditioned upon. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2473;A Linear Belief Function Approach to Portfolio Evaluation; Liping Liu,  Catherine Shenoy,  Prakash P. Shenoy;"  By elaborating on the notion of linear belief functions (Dempster 1990; Liu 1996), we propose an elementary approach to knowledge representation for expert systems using linear belief functions. We show how to use basic matrices to represent market information and financial knowledge, including complete ignorance, statistical observations, subjective speculations, distributional assumptions, linear relations, and empirical asset pricing models. We then appeal to Dempster's rule of combination to integrate the knowledge for assessing an overall belief of portfolio performance, and updating the belief by incorporating additional information. We use an example of three gold stocks to illustrate the approach. ";"Artificial Intelligence (cs.AI); Statistical Finance (q-fin.ST)"
https://arxiv.org/abs/1212.2476;Approximate Decomposition: A Method for Bounding and Estimating  Probabilistic and Deterministic Queries; David Ephraim Larkin;"  In this paper, we introduce a method for approximating the solution to inference and optimization tasks in uncertain and deterministic reasoning. Such tasks are in general intractable for exact algorithms because of the large number of dependency relationships in their structure. Our method effectively maps such a dense problem to a sparser one which is in some sense ""closest"". Exact methods can be run on the sparser problem to derive bounds on the original answer, which can be quite sharp. We present empirical results demonstrating that our method works well on the tasks of belief inference and finding the probability of the most probable explanation in belief networks, and finding the cost of the solution that violates the smallest number of constraints in constraint satisfaction problems. On one large CPCS network, for example, we were able to calculate upper and lower bounds on the conditional probability of a variable, given evidence, that were almost identical in the average case. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2481;Monte-Carlo optimizations for resource allocation problems in stochastic  network systems; Milos Hauskrecht,  Tomas Singliar;  Real-world distributed systems and networks are often unreliable and subject to random failures of its components. Such a stochastic behavior affects adversely the complexity of optimization tasks performed routinely upon such systems, in particular, various resource allocation tasks. In this work we investigate and develop Monte Carlo solutions for a class of two-stage optimization problems in stochastic networks in which the expected value of resource allocations before and after stochastic failures needs to be optimized. The limitation of these problems is that their exact solutions are exponential in the number of unreliable network components: thus, exact methods do not scale-up well to large networks often seen in practice. We first prove that Monte Carlo optimization methods can overcome the exponential bottleneck of exact methods. Next we support our theoretical findings on resource allocation experiments and show a very good scale-up potential of the new methods to large stochastic networks. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2482;Implementation and Comparison of Solution Methods for Decision Processes  with Non-Markovian Rewards; Charles Gretton,  David Price,  Sylvie Thiebaux;"  This paper examines a number of solution methods for decision processes with non-Markovian rewards (NMRDPs). They all exploit a temporal logic specification of the reward function to automatically translate the NMRDP into an equivalent Markov decision process (MDP) amenable to well-known MDP solution methods. They differ however in the representation of the target MDP and the class of MDP solution methods to which they are suited. As a result, they adopt different temporal logics and different translations. Unfortunately, no implementation of these methods nor experimental let alone comparative results have ever been reported. This paper is the first step towards filling this gap. We describe an integrated system for solving NMRDPs which implements these methods and several variants under a common interface; we use it to compare the various approaches and identify the problem features favoring one over the other. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2484;Decision Making with Partially Consonant Belief Functions; Phan H. Giang,  Prakash P. Shenoy;  This paper studies decision making for Walley's partially consonant belief functions (pcb). In a pcb, the set of foci are partitioned. Within each partition, the foci are nested. The pcb class includes probability functions and possibility functions as extreme cases. Unlike earlier proposals for a decision theory with belief functions, we employ an axiomatic approach. We adopt an axiom system similar in spirit to von Neumann - Morgenstern's linear utility theory for a preference relation on pcb lotteries. We prove a representation theorem for this relation. Utility for a pcb lottery is a combination of linear utility for probabilistic lottery and binary utility for possibilistic lottery. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2485;Phase Transition of Tractability in Constraint Satisfaction and Bayesian  Network Inference; Yong Gao;  There has been great interest in identifying tractable subclasses of NP complete problems and designing efficient algorithms for these tractable classes. Constraint satisfaction and Bayesian network inference are two examples of such problems that are of great importance in AI and algorithms. In this paper we study, under the frameworks of random constraint satisfaction problems and random Bayesian networks, a typical tractable subclass characterized by the treewidth of the problems. We show that the property of having a bounded treewidth for CSPs and Bayesian network inference problem has a phase transition that occurs while the underlying structures of problems are still sparse. This implies that algorithms making use of treewidth based structural knowledge only work efficiently in a limited range of random instance. ;"Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1212.2486;Extending Factor Graphs so as to Unify Directed and Undirected Graphical  Models; Brendan J. Frey;  The two most popular types of graphical model are directed models (Bayesian networks) and undirected models (Markov random fields, or MRFs). Directed and undirected models offer complementary properties in model construction, expressing conditional independencies, expressing arbitrary factorizations of joint distributions, and formulating message-passing inference algorithms. We show that the strengths of these two representations can be combined in a single type of graphical model called a 'factor graph'. Every Bayesian network or MRF can be easily converted to a factor graph that expresses the same conditional independencies, expresses the same factorization of the joint distribution, and can be used for probabilistic inference through application of a single, simple message-passing algorithm. In contrast to chain graphs, where message-passing is implemented on a hypergraph, message-passing can be directly implemented on the factor graph. We describe a modified 'Bayes-ball' algorithm for establishing conditional independence in factor graphs, and we show that factor graphs form a strict superset of Bayesian networks and MRFs. In particular, we give an example of a commonly-used 'mixture of experts' model fragment, whose independencies cannot be represented in a Bayesian network or an MRF, but can be represented in a factor graph. We finish by giving examples of real-world problems that are not well suited to representation in Bayesian networks and MRFs, but are well-suited to representation in factor graphs. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2493;Decentralized Sensor Fusion With Distributed Particle Filters; Matthew Rosencrantz,  Geoffrey Gordon,  Sebastian Thrun;  This paper presents a scalable Bayesian technique for decentralized state estimation from multiple platforms in dynamic environments. As has long been recognized, centralized architectures impose severe scaling limitations for distributed systems due to the enormous communication overheads. We propose a strictly decentralized approach in which only nearby platforms exchange information. They do so through an interactive communication protocol aimed at maximizing information flow. Our approach is evaluated in the context of a distributed surveillance scenario that arises in a robotic system for playing the game of laser tag. Our results, both from simulation and using physical robots, illustrate an unprecedented scaling capability to large teams of vehicles. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1212.2496;An Axiomatic Approach to Robustness in Search Problems with Multiple  Scenarios; Patrice Perny,  Olivier Spanjaard;  This paper is devoted to the search of robust solutions in state space graphs when costs depend on scenarios. We first present axiomatic requirements for preference compatibility with the intuitive idea of robustness.This leads us to propose the Lorenz dominance rule as a basis for robustness analysis. Then, after presenting complexity results about the determination of robust solutions, we propose a new sophistication of A* specially designed to determine the set of robust paths in a state space graph. The behavior of the algorithm is illustrated on a small example. Finally, an axiomatic justification of the refinement of robustness by an OWA criterion is provided. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2497;Solving MAP Exactly using Systematic Search; James D. Park,  Adnan Darwiche;"  MAP is the problem of finding a most probable instantiation of a set of variables in a Bayesian network given some evidence. Unlike computing posterior probabilities, or MPE (a special case of MAP), the time and space complexity of structural solutions for MAP are not only exponential in the network treewidth, but in a larger parameter known as the ""constrained"" treewidth. In practice, this means that computing MAP can be orders of magnitude more expensive than computing posterior probabilities or MPE. This paper introduces a new, simple upper bound on the probability of a MAP solution, which admits a tradeoff between the bound quality and the time needed to compute it. The bound is shown to be generally much tighter than those of other methods of comparable complexity. We use this proposed upper bound to develop a branch-and-bound search algorithm for solving MAP exactly. Experimental results demonstrate that the search algorithm is able to solve many problems that are far beyond the reach of any structure-based method for MAP. For example, we show that the proposed algorithm can compute MAP exactly and efficiently for some networks whose constrained treewidth is more than 40. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2499;Marginalizing Out Future Passengers in Group Elevator Control; Daniel N. Nikovski,  Matthew Brand;  Group elevator scheduling is an NP-hard sequential decision-making problem with unbounded state spaces and substantial uncertainty. Decision-theoretic reasoning plays a surprisingly limited role in fielded systems. A new opportunity for probabilistic methods has opened with the recent discovery of a tractable solution for the expected waiting times of all passengers in the building, marginalized over all possible passenger itineraries. Though commercially competitive, this solution does not contemplate future passengers. Yet in up-peak traffic, the effects of future passengers arriving at the lobby and entering elevator cars can dominate all waiting times. We develop a probabilistic model of how these arrivals affect the behavior of elevator cars at the lobby, and demonstrate how this model can be used to very significantly reduce the average waiting time of all passengers. ;"Artificial Intelligence (cs.AI); Systems and Control (cs.SY)"
https://arxiv.org/abs/1212.2501;Dealing with uncertainty in fuzzy inductive reasoning methodology; Francisco Mugica,  Angela Nebot,  Pilar Gomez;  The aim of this research is to develop a reasoning under uncertainty strategy in the context of the Fuzzy Inductive Reasoning (FIR) methodology. FIR emerged from the General Systems Problem Solving developed by G. Klir. It is a data driven methodology based on systems behavior rather than on structural knowledge. It is a very useful tool for both the modeling and the prediction of those systems for which no previous structural knowledge is available. FIR reasoning is based on pattern rules synthesized from the available data. The size of the pattern rule base can be very large making the prediction process quite difficult. In order to reduce the size of the pattern rule base, it is possible to automatically extract classical Sugeno fuzzy rules starting from the set of pattern rules. The Sugeno rule base preserves pattern rules knowledge as much as possible. In this process some information is lost but robustness is considerably increased. In the forecasting process either the pattern rule base or the Sugeno fuzzy rule base can be used. The first option is desirable when the computational resources make it possible to deal with the overall pattern rule base or when the extracted fuzzy rules are not accurate enough due to uncertainty associated to the original data. In the second option, the prediction process is done by means of the classical Sugeno inference system. If the amount of uncertainty associated to the data is small, the predictions obtained using the Sugeno fuzzy rule base will be very accurate. In this paper a mixed pattern/fuzzy rules strategy is proposed to deal with uncertainty in such a way that the best of both perspectives is used. Areas in the data space with a higher level of uncertainty are identified by means of the so-called error models. The prediction process in these areas makes use of a mixed pattern/fuzzy rules scheme, whereas areas identified with a lower level of uncertainty only use the Sugeno fuzzy rule base. The proposed strategy is applied to a real biomedical system, i.e., the central nervous system control of the cardiovascular system. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2502;Optimal Limited Contingency Planning; Nicolas Meuleau,  David Smith;  For a given problem, the optimal Markov policy can be considerred as a conditional or contingent plan containing a (potentially large) number of branches. Unfortunately, there are applications where it is desirable to strictly limit the number of decision points and branches in a plan. For example, it may be that plans must later undergo more detailed simulation to verify correctness and safety, or that they must be simple enough to be understood and analyzed by humans. As a result, it may be necessary to limit consideration to plans with only a small number of branches. This raises the question of how one goes about finding optimal plans containing only a limited number of branches. In this paper, we present an any-time algorithm for optimal k-contingency planning (OKP). It is the first optimal algorithm for limited contingency planning that is not an explicit enumeration of possible contingent plans. By modelling the problem as a Partially Observable Markov Decision Process, it implements the Bellman optimality principle and prunes the solution space. We present experimental results of applying this algorithm to some simple test cases. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2503;Practically Perfect; Christopher Meek,  David Maxwell Chickering;"  The property of perfectness plays an important role in the theory of Bayesian networks. First, the existence of perfect distributions for arbitrary sets of variables and directed acyclic graphs implies that various methods for reading independence from the structure of the graph (e.g., Pearl, 1988; Lauritzen, Dawid, Larsen & Leimer, 1990) are complete. Second, the asymptotic reliability of various search methods is guaranteed under the assumption that the generating distribution is perfect (e.g., Spirtes, Glymour & Scheines, 2000; Chickering & Meek, 2002). We provide a lower-bound on the probability of sampling a non-perfect distribution when using a fixed number of bits to represent the parameters of the Bayesian network. This bound approaches zero exponentially fast as one increases the number of bits used to represent the parameters. This result implies that perfect distributions with fixed-length representations exist. We also provide a lower-bound on the number of bits needed to guarantee that a distribution sampled from a uniform Dirichlet distribution is perfect with probability greater than 1/2. This result is useful for constructing randomized reductions for hardness proofs. ";"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1212.2505;Systematic vs. Non-systematic Algorithms for Solving the MPE Task; Radu Marinescu,  Kalev Kask,  Rina Dechter;  The paper continues the study of partitioning based inference of heuristics for search in the context of solving the Most Probable Explanation task in Bayesian Networks. We compare two systematic Branch and Bound search algorithms, BBBT (for which the heuristic information is constructed during search and allows dynamic variable/value ordering) and its predecessor BBMB (for which the heuristic information is pre-compiled), against a number of popular local search algorithms for the MPE problem. We show empirically that, when viewed as approximation schemes, BBBT/BBMB are superior to all of these best known SLS algorithms, especially when the domain sizes increase beyond 2. This is in contrast with the performance of SLS vs. systematic search on CSP/SAT problems, where SLS often significantly outperforms systematic algorithms. As far as we know, BBBT/BBMB are currently the best performing algorithms for solving the MPE task. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2506;Strong Faithfulness and Uniform Consistency in Causal Inference; Jiji Zhang,  Peter L. Spirtes;  A fundamental question in causal inference is whether it is possible to reliably infer manipulation effects from observational data. There are a variety of senses of asymptotic reliability in the statistical literature, among which the most commonly discussed frequentist notions are pointwise consistency and uniform consistency. Uniform consistency is in general preferred to pointwise consistency because the former allows us to control the worst case error bounds with a finite sample size. In the sense of pointwise consistency, several reliable causal inference algorithms have been established under the Markov and Faithfulness assumptions [Pearl 2000, Spirtes et al. 2001]. In the sense of uniform consistency, however, reliable causal inference is impossible under the two assumptions when time order is unknown and/or latent confounders are present [Robins et al. 2000]. In this paper we present two natural generalizations of the Faithfulness assumption in the context of structural equation models, under which we show that the typical algorithms in the literature (in some cases with modifications) are uniformly consistent even when the time order is unknown. We also discuss the situation where latent confounders may be present and the sense in which the Faithfulness assumption is a limiting case of the stronger assumptions. ;"Artificial Intelligence (cs.AI); Methodology (stat.ME)"
https://arxiv.org/abs/1212.2507;An Importance Sampling Algorithm Based on Evidence Pre-propagation; Changhe Yuan,  Marek J. Druzdzel;  Precision achieved by stochastic sampling algorithms for Bayesian networks typically deteriorates in face of extremely unlikely evidence. To address this problem, we propose the Evidence Pre-propagation Importance Sampling algorithm (EPIS-BN), an importance sampling algorithm that computes an approximate importance function by the heuristic methods: loopy belief Propagation and e-cutoff. We tested the performance of e-cutoff on three large real Bayesian networks: ANDES, CPCS, and PATHFINDER. We observed that on each of these networks the EPIS-BN algorithm gives us a considerable improvement over the current state of the art algorithm, the AIS-BN algorithm. In addition, it avoids the costly learning stage of the AIS-BN algorithm. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2515;The Revisiting Problem in Mobile Robot Map Building: A Hierarchical  Bayesian Approach; Benjamin Stewart,  Jonathan Ko,  Dieter Fox,  Kurt Konolige;"  We present an application of hierarchical Bayesian estimation to robot map building. The revisiting problem occurs when a robot has to decide whether it is seeing a previously-built portion of a map, or is exploring new territory. This is a difficult decision problem, requiring the probability of being outside of the current known map. To estimate this probability, we model the structure of a ""typical"" environment as a hidden Markov model that generates sequences of views observed by a robot navigating through the environment. A Dirichlet prior over structural models is learned from previously explored environments. Whenever a robot explores a new environment, the posterior over the model is estimated by Dirichlet hyperparameters. Our approach is implemented and tested in the context of multi-robot map merging, a particularly difficult instance of the revisiting problem. Experiments with robot data show that the technique yields strong improvements over alternative methods. ";"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1212.2518;Efficient Inference in Large Discrete Domains; Rita Sharma,  David L Poole;  In this paper we examine the problem of inference in Bayesian Networks with discrete random variables that have very large or even unbounded domains. For example, in a domain where we are trying to identify a person, we may have variables that have as domains, the set of all names, the set of all postal codes, or the set of all credit card numbers. We cannot just have big tables of the conditional probabilities, but need compact representations. We provide an inference algorithm, based on variable elimination, for belief networks containing both large domain and normal discrete random variables. We use intensional (i.e., in terms of procedures) and extensional (in terms of listing the elements) representations of conditional probabilities and of the intermediate factors. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2519;CLP(BN): Constraint Logic Programming for Probabilistic Knowledge; Vitor Santos Costa,  David Page,  Maleeha Qazi,  James Cussens;  We present CLP(BN), a novel approach that aims at expressing Bayesian networks through the constraint logic programming framework. Arguably, an important limitation of traditional Bayesian networks is that they are propositional, and thus cannot represent relations between multiple similar objects in multiple contexts. Several researchers have thus proposed first-order languages to describe such networks. Namely, one very successful example of this approach are the Probabilistic Relational Models (PRMs), that combine Bayesian networks with relational database technology. The key difficulty that we had to address when designing CLP(cal{BN}) is that logic based representations use ground terms to denote objects. With probabilitic data, we need to be able to uniquely represent an object whose value we are not sure about. We use {sl Skolem functions} as unique new symbols that uniquely represent objects with unknown value. The semantics of CLP(cal{BN}) programs then naturally follow from the general framework of constraint logic programming, as applied to a specific domain where we have probabilistic data. This paper introduces and defines CLP(cal{BN}), and it describes an implementation and initial experiments. The paper also shows how CLP(cal{BN}) relates to Probabilistic Relational Models (PRMs), Ngo and Haddawys Probabilistic Logic Programs, AND Kersting AND De Raedts Bayesian Logic Programs. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2614;A Study on Fuzzy Systems; Michael Gr. Voskoglou;  We use princiles of fuzzy logic to develop a general model representing several processes in a system's operation characterized by a degree of vagueness and/or uncertainy. Further, we introduce three altenative measures of a fuzzy system's effectiveness connected to the above model. An applcation is also developed for the Mathematical Modelling process illustrating our results. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2657;Study: Symmetry breaking for ASP; Anna Ryabokon;"  In their nature configuration problems are combinatorial (optimization) problems. In order to find a configuration a solver has to instantiate a number of components of a some type and each of these components can be used in a relation defined for a type. Therefore, many solutions of a configuration problem have symmetric ones which can be obtained by replacing some component of a solution by another one of the same type. These symmetric solutions decrease performance of optimization algorithms because of two reasons: a) they satisfy all requirements and cannot be pruned out from the search space; and b) existence of symmetric optimal solutions does not allow to prove the optimum in a feasible time. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2671;Performance Analysis of ANFIS in short term Wind Speed Prediction; Ernesto Cortés Pérez,  Ignacio Algredo-Badillo,  Víctor Hugo García Rodríguez;  Results are presented on the performance of Adaptive Neuro-Fuzzy Inference system (ANFIS) for wind velocity forecasts in the Isthmus of Tehuantepec region in the state of Oaxaca, Mexico. The data bank was provided by the meteorological station located at the University of Isthmus, Tehuantepec campus, and this data bank covers the period from 2008 to 2011. Three data models were constructed to carry out 16, 24 and 48 hours forecasts using the following variables: wind velocity, temperature, barometric pressure, and date. The performance measure for the three models is the mean standard error (MSE). In this work, performance analysis in short-term prediction is presented, because it is essential in order to define an adequate wind speed model for eolian parks, where a right planning provide economic benefits. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2791;Understanding (dis)similarity measures; Lluís A. Belanche;  Intuitively, the concept of similarity is the notion to measure an inexact matching between two entities of the same reference set. The notions of similarity and its close relative dissimilarity are widely used in many fields of Artificial Intelligence. Yet they have many different and often partial definitions or properties, usually restricted to one field of application and thus incompatible with other uses. This paper contributes to the design and understanding of similarity and dissimilarity measures for Artificial Intelligence. A formal dual definition for each concept is proposed, joined with a set of fundamental properties. The behavior of the properties under several transformations is studied and revealed as an important matter to bear in mind. We also develop several practical examples that work out the proposed approach. ;"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1212.2857;ConArg: a Tool to Solve (Weighted) Abstract Argumentation Frameworks  with (Soft) Constraints; Stefano Bistarelli,  Francesco Santini;"  ConArg is a Constraint Programming-based tool that can be used to model and solve different problems related to Abstract Argumentation Frameworks (AFs). To implement this tool we have used JaCoP, a Java library that provides the user with a Finite Domain Constraint Programming paradigm. ConArg is able to randomly generate networks with small-world properties in order to find conflict-free, admissible, complete, stable grounded, preferred, semi-stable, stage and ideal extensions on such interaction graphs. We present the main features of ConArg and we report the performance in time, showing also a comparison with ASPARTIX [1], a similar tool using Answer Set Programming. The use of techniques for constraint solving can tackle the complexity of the problems presented in [2]. Moreover we suggest semiring-based soft constraints as a mean to parametrically represent and solve Weighted Argumentation Frameworks: different kinds of preference levels related to attacks, e.g., a score representing a ""fuzziness"", a ""cost"" or a probability, can be represented by choosing different instantiation of the semiring algebraic structure. The basic idea is to provide a common computational and quantitative framework. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.2902;Modeling in OWL 2 without Restrictions; Michael Schneider,  Sebastian Rudolph,  Geoff Sutcliffe;  The Semantic Web ontology language OWL 2 DL comes with a variety of language features that enable sophisticated and practically useful modeling. However, the use of these features has been severely restricted in order to retain decidability of the language. For example, OWL 2 DL does not allow a property to be both transitive and asymmetric, which would be desirable, e.g., for representing an ancestor relation. In this paper, we argue that the so-called global restrictions of OWL 2 DL preclude many useful forms of modeling, by providing a catalog of basic modeling patterns that would be available in OWL 2 DL if the global restrictions were discarded. We then report on the results of evaluating several state-of-the-art OWL 2 DL reasoners on problems that use combinations of features in a way that the global restrictions are violated. The systems turn out to rely heavily on the global restrictions and are thus largely incapable of coping with the modeling patterns. Next we show how off-the-shelf first-order logic theorem proving technology can be used to perform reasoning in the OWL 2 direct semantics, the semantics that underlies OWL 2 DL, but without requiring the global restrictions. Applying a naive proof-of-concept implementation of this approach to the test problems was successful in all cases. Based on our observations, we make suggestions for future lines of research on expressive description logic-style OWL reasoning. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.3618;Machine Learning in Proof General: Interfacing Interfaces; Ekaterina Komendantskaya (School of Computing, University of Dundee),  Jónathan Heras (School of Computing, University of Dundee),  Gudmund Grov (School of Mathematical and Computer Sciences, Heriot-Watt University);  We present ML4PG - a machine learning extension for Proof General. It allows users to gather proof statistics related to shapes of goals, sequences of applied tactics, and proof tree structures from the libraries of interactive higher-order proofs written in Coq and SSReflect. The gathered data is clustered using the state-of-the-art machine learning algorithms available in MATLAB and Weka. ML4PG provides automated interfacing between Proof General and MATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints in the process of interactive proof development. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1212.3817;Probability Bracket Notation: Markov State Chain Projector, Hidden  Markov Models and Dynamic Bayesian Networks; Xing M. Wang;  After a brief discussion of Markov Evolution Formula (MEF) expressed in Probability Bracket Notation (PBN), its close relation with the joint probability distribution (JPD) of Visible Markov Models (VMM) is demonstrated by introducing Markov State Chain Projector (MSCP). The state basis and the observed basis are defined in the Sequential Event Space (SES) of Hidden Markov Models (HMM). The JPD of HMM is derived by using basis transformation in SES. The Viterbi algorithm is revisited and applied to the famous Weather HMM example, whose node graph and inference results are displayed by using software package Elvira. In the end, the formulas of VMM, HMM and some factorial HMM (FHMM) are expressed in PBN as instances of dynamic Bayesian Networks (DBN). ;"Artificial Intelligence (cs.AI); Probability (math.PR)"
https://arxiv.org/abs/1212.3996;Increasing Air Traffic: What is the Problem?; Areski Hadjaz,  Gaétan Marceau (INRIA Saclay - Ile de France),  Pierre Savéant (TRT),  Marc Schoenauer (INRIA Saclay - Ile de France, MSR - INRIA);  Nowadays, huge efforts are made to modernize the air traffic management systems to cope with uncertainty, complexity and sub-optimality. An answer is to enhance the information sharing between the stakeholders. This paper introduces a framework that bridges the gap between air traffic management and air traffic control on the one hand, and bridges the gap between the ground, the approach and the en-route centers on the other hand. An original system is presented, that has three essential components: the trajectory models, the optimization process, and the monitoring process. The uncertainty of the trajectory is modeled with a Bayesian Network, where the nodes are associated to two types of random variables: the time of overflight on metering points of the airspace, and the traveling time of the routes linking these points. The resulting Bayesian Network covers the complete airspace, and Monte- Carlo simulations are done to estimate the probabilities of sector congestion and delays. On top of this trajectory model, an optimization process minimizes these probabilities by tuning the parameters of the Bayesian trajectory model related to overflight times on metering points. The last component is the monitoring process, that continuously updates the situation of the airspace, modifying the trajectories uncertainties according to actual positions of aircraft. After each update, a new optimal set of overflight times is computed, and can be communicated to the controllers as clearances for the aircraft pilots. The paper presents a formal specification of this global optimization problem, whose underlying rationale was derived with the help of air traffic controllers at Thales Air Systems. ;"Artificial Intelligence (cs.AI); Systems and Control (cs.SY)"
https://arxiv.org/abs/1212.3998;Online Learning for Ground Trajectory Prediction; Areski Hadjaz,  Gaétan Marceau (INRIA Saclay - Ile de France),  Pierre Savéant (TRT),  Marc Schoenauer (INRIA Saclay - Ile de France, MSR - INRIA);  This paper presents a model based on an hybrid system to numerically simulate the climbing phase of an aircraft. This model is then used within a trajectory prediction tool. Finally, the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimization algorithm is used to tune five selected parameters, and thus improve the accuracy of the model. Incorporated within a trajectory prediction tool, this model can be used to derive the order of magnitude of the prediction error over time, and thus the domain of validity of the trajectory prediction. A first validation experiment of the proposed model is based on the errors along time for a one-time trajectory prediction at the take off of the flight with respect to the default values of the theoretical BADA model. This experiment, assuming complete information, also shows the limit of the model. A second experiment part presents an on-line trajectory prediction, in which the prediction is continuously updated based on the current aircraft position. This approach raises several issues, for which improvements of the basic model are proposed, and the resulting trajectory prediction tool shows statistically significantly more accurate results than those of the default model. ;"Artificial Intelligence (cs.AI); Systems and Control (cs.SY)"
https://arxiv.org/abs/1212.4799;Towards common-sense reasoning via conditional simulation: legacies of  Turing in Artificial Intelligence; Cameron E. Freer,  Daniel M. Roy,  Joshua B. Tenenbaum;  The problem of replicating the flexibility of human common-sense reasoning has captured the imagination of computer scientists since the early days of Alan Turing's foundational work on computation and the philosophy of artificial intelligence. In the intervening years, the idea of cognition as computation has emerged as a fundamental tenet of Artificial Intelligence (AI) and cognitive science. But what kind of computation is cognition? We describe a computational formalism centered around a probabilistic Turing machine called QUERY, which captures the operation of probabilistic conditioning via conditional simulation. Through several examples and analyses, we demonstrate how the QUERY abstraction can be used to cast common-sense reasoning as probabilistic inference in a statistical model of our observations and the uncertain structure of the world that generated that experience. This formulation is a recent synthesis of several research programs in AI and cognitive science, but it also represents a surprising convergence of several of Turing's pioneering insights in AI, the foundations of computation, and statistics. ;"Artificial Intelligence (cs.AI); Logic (math.LO); Machine Learning (stat.ML)"
https://arxiv.org/abs/1212.5276;Multi-Objective AI Planning: Evaluating DAE-YAHSP on a Tunable Benchmark; Mostepha Redouane Khouadjia (INRIA Saclay - Ile de France),  Marc Schoenauer (INRIA Saclay - Ile de France, LRI),  Vincent Vidal (DCSD),  Johann Dréo (TRT),  Pierre Savéant (TRT);  All standard AI planners to-date can only handle a single objective, and the only way for them to take into account multiple objectives is by aggregation of the objectives. Furthermore, and in deep contrast with the single objective case, there exists no benchmark problems on which to test the algorithms for multi-objective planning. Divide and Evolve (DAE) is an evolutionary planner that won the (single-objective) deterministic temporal satisficing track in the last International Planning Competition. Even though it uses intensively the classical (and hence single-objective) planner YAHSP, it is possible to turn DAE-YAHSP into a multi-objective evolutionary planner. A tunable benchmark suite for multi-objective planning is first proposed, and the performances of several variants of multi-objective DAE-YAHSP are compared on different instances of this benchmark, hopefully paving the road to further multi-objective competitions in AI planning. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.5776;Improving problem solving by exploiting the concept of symmetry; M. A. El-Dosuky,  M. Z. Rashad,  T. T. Hamza,  A.H. EL-Bassiouny;"  We investigate the concept of symmetry and its role in problem solving. This paper first defines precisely the elements that constitute a ""problem"" and its ""solution,"" and gives several examples to illustrate these definitions. Given precise definitions of problems, it is relatively straightforward to construct a search process for finding solutions. Finally this paper attempts to exploit the concept of symmetry in improving problem solving. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.6207;Irrespective Priority-Based Regular Properties of High-Intensity Virtual  Environments; Kirill A. Sorudeykin;  We have a lot of relation to the encoding and the Theory of Information, when considering thinking. This is a natural process and, at once, the complex thing we investigate. This always was a challenge - to understand how our mind works, and we are trying to find some universal models for this. A lot of ways have been considered so far, but we are looking for Something, we seek for approaches. And the goal is to find a consistent, noncontradictory view, which should at once be enough flexible in any dimensions to allow to represent various kinds of processes and environments, matters of different nature and diverse objects. Developing of such a model is the destination of this article. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.6216;Generating Motion Patterns Using Evolutionary Computation in Digital  Soccer; Masoud Amoozgar,  Daniel Khashabi,  Milad Heydarian,  Mohammad Nokhbeh,  Saeed Bagheri Shouraki;  Dribbling an opponent player in digital soccer environment is an important practical problem in motion planning. It has special complexities which can be generalized to most important problems in other similar Multi Agent Systems. In this paper, we propose a hybrid computational geometry and evolutionary computation approach for generating motion trajectories to avoid a mobile obstacle. In this case an opponent agent is not only an obstacle but also one who tries to harden dribbling procedure. One characteristic of this approach is reducing process cost of online stage by transferring it to offline stage which causes increment in agents' performance. This approach breaks the problem into two offline and online stages. During offline stage the goal is to find desired trajectory using evolutionary computation and saving it as a trajectory plan. A trajectory plan consists of nodes which approximate information of each trajectory plan. In online stage, a linear interpolation along with Delaunay triangulation in xy-plan is applied to trajectory plan to retrieve desired action. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1212.6519;Dialectics of Knowledge Representation in a Granular Rough Set Theory; A. Mani;  The concepts of rough and definite objects are relatively more determinate than those of granules and granulation in general rough set theory (RST) [1]. Representation of rough objects can however depend on the dialectical relation between granulation and definiteness. In this research, we make this exact in the context of RST over proto-transitive approximation spaces. This approach can be directly extended to many other types of RST. These are used for formulating an extended concept of knowledge interpretation (KI)(relative the situation for classical RST) and the problem of knowledge representation (KR) is solved. These will be of direct interest in granular KR in RST as developed by the present author [2] and of rough objects in general. In [3], these have already been used for five different semantics by the present author. This is an extended version of [4] with key examples and more results. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1212.6521;A Frequency-Domain Encoding for Neuroevolution; Jan Koutník,  Juergen Schmidhuber,  Faustino Gomez;"  Neuroevolution has yet to scale up to complex reinforcement learning tasks that require large networks. Networks with many inputs (e.g. raw video) imply a very high dimensional search space if encoded directly. Indirect methods use a more compact genotype representation that is transformed into networks of potentially arbitrary size. In this paper, we present an indirect method where networks are encoded by a set of Fourier coefficients which are transformed into network weight matrices via an inverse Fourier-type transform. Because there often exist network solutions whose weight matrices contain regularity (i.e. adjacent weights are correlated), the number of coefficients required to represent these networks in the frequency domain is much smaller than the number of weights (in the same way that natural images can be compressed by ignore high-frequency components). This ""compressed"" encoding is compared to the direct approach where search is conducted in the weight space on the high-dimensional octopus arm task. The results show that representing networks in the frequency domain can reduce the search-space dimensionality by as much as two orders of magnitude, both accelerating convergence and yielding more general solutions. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1212.6527;Discovering Basic Emotion Sets via Semantic Clustering on a Twitter  Corpus; Eugene Yuta Bann;  A plethora of words are used to describe the spectrum of human emotions, but how many emotions are there really, and how do they interact? Over the past few decades, several theories of emotion have been proposed, each based around the existence of a set of 'basic emotions', and each supported by an extensive variety of research including studies in facial expression, ethology, neurology and physiology. Here we present research based on a theory that people transmit their understanding of emotions through the language they use surrounding emotion keywords. Using a labelled corpus of over 21,000 tweets, six of the basic emotion sets proposed in existing literature were analysed using Latent Semantic Clustering (LSC), evaluating the distinctiveness of the semantic meaning attached to the emotional label. We hypothesise that the more distinct the language is used to express a certain emotion, then the more distinct the perception (including proprioception) of that emotion is, and thus more 'basic'. This allows us to select the dimensions best representing the entire spectrum of emotion. We find that Ekman's set, arguably the most frequently used for classifying emotions, is in fact the most semantically distinct overall. Next, taking all analysed (that is, previously proposed) emotion terms into account, we determine the optimal semantically irreducible basic emotion set using an iterative LSC algorithm. Our newly-derived set (Accepting, Ashamed, Contempt, Interested, Joyful, Pleased, Sleepy, Stressed) generates a 6.1% increase in distinctiveness over Ekman's set (Angry, Disgusted, Joyful, Sad, Scared). We also demonstrate how using LSC data can help visualise emotions. We introduce the concept of an Emotion Profile and briefly analyse compound emotions both visually and mathematically. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1212.6550;Alternating Directions Dual Decomposition; Andre F. T. Martins,  Mario A. T. Figueiredo,  Pedro M. Q. Aguiar,  Noah A. Smith,  Eric P. Xing;  We propose AD3, a new algorithm for approximate maximum a posteriori (MAP) inference on factor graphs based on the alternating directions method of multipliers. Like dual decomposition algorithms, AD3 uses worker nodes to iteratively solve local subproblems and a controller node to combine these local solutions into a global update. The key characteristic of AD3 is that each local subproblem has a quadratic regularizer, leading to a faster consensus than subgradient-based dual decomposition, both theoretically and in practice. We provide closed-form solutions for these AD3 subproblems for binary pairwise factors and factors imposing first-order logic constraints. For arbitrary factors (large or combinatorial), we introduce an active set method which requires only an oracle for computing a local MAP configuration, making AD3 applicable to a wide range of problems. Experiments on synthetic and realworld problems show that AD3 compares favorably with the state-of-the-art. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00287;STRIPS Planning in Infinite Domains; Caelan Reed Garrett,  Tomás Lozano-Pérez,  Leslie Pack Kaelbling;  Many robotic planning applications involve continuous actions with highly non-linear constraints, which cannot be modeled using modern planners that construct a propositional representation. We introduce STRIPStream: an extension of the STRIPS language which can model these domains by supporting the specification of blackbox generators to handle complex constraints. The outputs of these generators interact with actions through possibly infinite streams of objects and static predicates. We provide two algorithms which both reduce STRIPStream problems to a sequence of finite-domain planning problems. The representation and algorithms are entirely domain independent. We demonstrate our framework on simple illustrative domains, and then on a high-dimensional, continuous robotic task and motion planning domain. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00349;An affective computational model for machine consciousness; Rohitash Chandra;  In the past, several models of consciousness have become popular and have led to the development of models for machine consciousness with varying degrees of success and challenges for simulation and implementations. Moreover, affective computing attributes that involve emotions, behavior and personality have not been the focus of models of consciousness as they lacked motivation for deployment in software applications and robots. The affective attributes are important factors for the future of machine consciousness with the rise of technologies that can assist humans. Personality and affection hence can give an additional flavor for the computational model of consciousness in humanoid robotics. Recent advances in areas of machine learning with a focus on deep learning can further help in developing aspects of machine consciousness in areas that can better replicate human sensory perceptions such as speech recognition and vision. With such advancements, one encounters further challenges in developing models that can synchronize different aspects of affective computing. In this paper, we review some existing models of consciousnesses and present an affective computational model that would enable the human touch and feel for robotic systems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00464;Conceptual Spaces for Cognitive Architectures: A Lingua Franca for  Different Levels of Representation; Antonio Lieto,  Antonio Chella,  Marcello Frixione;"  During the last decades, many cognitive architectures (CAs) have been realized adopting different assumptions about the organization and the representation of their knowledge level. Some of them (e.g. SOAR [Laird (2012)]) adopt a classical symbolic approach, some (e.g. LEABRA [O'Reilly and Munakata (2000)]) are based on a purely connectionist model, while others (e.g. CLARION [Sun (2006)] adopt a hybrid approach combining connectionist and symbolic representational levels. Additionally, some attempts (e.g. biSOAR) trying to extend the representational capacities of CAs by integrating diagrammatical representations and reasoning are also available [Kurup and Chandrasekaran (2007)]. In this paper we propose a reflection on the role that Conceptual Spaces, a framework developed by Peter G\""ardenfors [G\""ardenfors (2000)] more than fifteen years ago, can play in the current development of the Knowledge Level in Cognitive Systems and Architectures. In particular, we claim that Conceptual Spaces offer a lingua franca that allows to unify and generalize many aspects of the symbolic, sub-symbolic and diagrammatic approaches (by overcoming some of their typical problems) and to integrate them on a common ground. In doing so we extend and detail some of the arguments explored by G\""ardenfors [G\""ardenfors (1997)] for defending the need of a conceptual, intermediate, representation level between the symbolic and the sub-symbolic one. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00642;Finding Risk-Averse Shortest Path with Time-dependent Stochastic Costs; Dajian Li,  Paul Weng,  Orkun Karabasoglu;  In this paper, we tackle the problem of risk-averse route planning in a transportation network with time-dependent and stochastic costs. To solve this problem, we propose an adaptation of the A* algorithm that accommodates any risk measure or decision criterion that is monotonic with first-order stochastic dominance. We also present a case study of our algorithm on the Manhattan, NYC, transportation network. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00646;From Preference-Based to Multiobjective Sequential Decision-Making; Paul Weng;  In this paper, we present a link between preference-based and multiobjective sequential decision-making. While transforming a multiobjective problem to a preference-based one is quite natural, the other direction is a bit less obvious. We present how this transformation (from preference-based to multiobjective) can be done under the classic condition that preferences over histories can be represented by additively decomposable utilities and that the decision criterion to evaluate policies in a state is based on expectation. This link yields a new source of multiobjective sequential decision-making problems (i.e., when reward values are unknown) and justifies the use of solving methods developed in one setting in the other one. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00696;A pre-semantics for counterfactual conditionals and similar logics; Karl Schlechta (LIF);  The elegant Stalnaker/Lewis semantics for counterfactual conditonals works with distances between models. But human beings certainly have no tables of models and distances in their head. We begin here an investigation using a more realistic picture, based on findings in neuroscience. We call it a pre-semantics, as its meaning is not a description of the world, but of the brain, whose structure is (partly) determined by the world it reasons about. In the final section, we reconsider the components, and postulate that there are no atomic pictures, we can always look inside. ;"Artificial Intelligence (cs.AI); Logic (math.LO)"
https://arxiv.org/abs/1701.00833;Fuzzy finite element model updating using metaheuristic optimization  algorithms; I. Boulkaibet,  T. Marwala,  M.I. Friswell,  H. Haddad Khodaparast,  S. Adhikari;  In this paper, a non-probabilistic method based on fuzzy logic is used to update finite element models (FEMs). Model updating techniques use the measured data to improve the accuracy of numerical models of structures. However, the measured data are contaminated with experimental noise and the models are inaccurate due to randomness in the parameters. This kind of aleatory uncertainty is irreducible, and may decrease the accuracy of the finite element model updating process. However, uncertainty quantification methods can be used to identify the uncertainty in the updating parameters. In this paper, the uncertainties associated with the modal parameters are defined as fuzzy membership functions, while the model updating procedure is defined as an optimization problem at each {\alpha}-cut level. To determine the membership functions of the updated parameters, an objective function is defined and minimized using two metaheuristic optimization algorithms: ant colony optimization (ACO) and particle swarm optimization (PSO). A structural example is used to investigate the accuracy of the fuzzy model updating strategy using the PSO and ACO algorithms. Furthermore, the results obtained by the fuzzy finite element model updating are compared with the Bayesian model updating results. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00867;A K-fold Method for Baseline Estimation in Policy Gradient Algorithms; Nithyanand Kota,  Abhishek Mishra,  Sunil Srinivasa, Xi (Peter) Chen,  Pieter Abbeel;  The high variance issue in unbiased policy-gradient methods such as VPG and REINFORCE is typically mitigated by adding a baseline. However, the baseline fitting itself suffers from the underfitting or the overfitting problem. In this paper, we develop a K-fold method for baseline estimation in policy gradient algorithms. The parameter K is the baseline estimation hyperparameter that can adjust the bias-variance trade-off in the baseline estimates. We demonstrate the usefulness of our approach via two state-of-the-art policy gradient algorithms on three MuJoCo locomotive control tasks. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.00877;On the Usability of Probably Approximately Correct Implication Bases; Daniel Borchmann,  Tom Hanika,  Sergei Obiedkov;  We revisit the notion of probably approximately correct implication bases from the literature and present a first formulation in the language of formal concept analysis, with the goal to investigate whether such bases represent a suitable substitute for exact implication bases in practical use-cases. To this end, we quantitatively examine the behavior of probably approximately correct implication bases on artificial and real-world data sets and compare their precision and recall with respect to their corresponding exact implication bases. Using a small example, we also provide qualitative insight that implications from probably approximately correct bases can still represent meaningful knowledge from a given data set. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1701.01048;Stochastic Planning and Lifted Inference; Roni Khardon,  Scott Sanner;  Lifted probabilistic inference (Poole, 2003) and symbolic dynamic programming for lifted stochastic planning (Boutilier et al, 2001) were introduced around the same time as algorithmic efforts to use abstraction in stochastic systems. Over the years, these ideas evolved into two distinct lines of research, each supported by a rich literature. Lifted probabilistic inference focused on efficient arithmetic operations on template-based graphical models under a finite domain assumption while symbolic dynamic programming focused on supporting sequential decision-making in rich quantified logical action models and on open domain reasoning. Given their common motivation but different focal points, both lines of research have yielded highly complementary innovations. In this chapter, we aim to help close the gap between these two research areas by providing an overview of lifted stochastic planning from the perspective of probabilistic inference, showing strong connections to other chapters in this book. This also allows us to define Generalized Lifted Inference as a paradigm that unifies these areas and elucidates open problems for future research that can benefit both lifted inference and stochastic planning. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.01302;Toward negotiable reinforcement learning: shifting priorities in Pareto  optimal sequential decision-making; Andrew Critch;"  Existing multi-objective reinforcement learning (MORL) algorithms do not account for objectives that arise from players with differing beliefs. Concretely, consider two players with different beliefs and utility functions who may cooperate to build a machine that takes actions on their behalf. A representation is needed for how much the machine's policy will prioritize each player's interests over time. Assuming the players have reached common knowledge of their situation, this paper derives a recursion that any Pareto optimal policy must satisfy. Two qualitative observations can be made from the recursion: the machine must (1) use each player's own beliefs in evaluating how well an action will serve that player's utility function, and (2) shift the relative priority it assigns to each player's expected utilities over time, by a factor proportional to how well that player's beliefs predict the machine's inputs. Observation (2) represents a substantial divergence from na\""{i}ve linear utility aggregation (as in Harsanyi's utilitarian theorem, and existing MORL algorithms), which is shown here to be inadequate for Pareto optimal sequential decision-making on behalf of players with different beliefs. ";"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Learning (cs.LG)"
https://arxiv.org/abs/1701.01487;Designing a Safe Autonomous Artificial Intelligence Agent based on Human  Self-Regulation; Mark Muraven;  There is a growing focus on how to design safe artificial intelligent (AI) agents. As systems become more complex, poorly specified goals or control mechanisms may cause AI agents to engage in unwanted and harmful outcomes. Thus it is necessary to design AI agents that follow initial programming intentions as the program grows in complexity. How to specify these initial intentions has also been an obstacle to designing safe AI agents. Finally, there is a need for the AI agent to have redundant safety mechanisms to ensure that any programming errors do not cascade into major problems. Humans are autonomous intelligent agents that have avoided these problems and the present manuscript argues that by understanding human self-regulation and goal setting, we may be better able to design safe AI agents. Some general principles of human self-regulation are outlined and specific guidance for AI design is given. ;"Artificial Intelligence (cs.AI); Systems and Control (cs.SY)"
https://arxiv.org/abs/1701.01497;Learning local trajectories for high precision robotic tasks :  application to KUKA LBR iiwa Cartesian positioning; Joris Guerin,  Olivier Gibaru,  Eric Nyiri,  Stephane Thiery;  To ease the development of robot learning in industry, two conditions need to be fulfilled. Manipulators must be able to learn high accuracy and precision tasks while being safe for workers in the factory. In this paper, we extend previously submitted work which consists in rapid learning of local high accuracy behaviors. By exploration and regression, linear and quadratic models are learnt for respectively the dynamics and cost function. Iterative Linear Quadratic Gaussian Regulator combined with cost quadratic regression can converge rapidly in the final stages towards high accuracy behavior as the cost function is modelled quite precisely. In this paper, both a different cost function and a second order improvement method are implemented within this framework. We also propose an analysis of the algorithm parameters through simulation for a positioning task. Finally, an experimental validation on a KUKA LBR iiwa robot is carried out. This collaborative robot manipulator can be easily programmed into safety mode, which makes it qualified for the second industry constraint stated above. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Robotics (cs.RO)"
https://arxiv.org/abs/1701.01724;DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker; Matej Moravčík,  Martin Schmid,  Neil Burch,  Viliam Lisý,  Dustin Morrill,  Nolan Bard,  Trevor Davis,  Kevin Waugh,  Michael Johanson,  Michael Bowling;  Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker is the quintessential game of imperfect information, and a longstanding challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated with statistical significance professional poker players in heads-up no-limit Texas hold'em. The approach is theoretically sound and is shown to produce more difficult to exploit strategies than prior approaches. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.02163;Just an Update on PMING Distance for Web-based Semantic Similarity in  Artificial Intelligence and Data Mining; Valentina Franzoni;  One of the main problems that emerges in the classic approach to semantics is the difficulty in acquisition and maintenance of ontologies and semantic annotations. On the other hand, the Internet explosion and the massive diffusion of mobile smart devices lead to the creation of a worldwide system, which information is daily checked and fueled by the contribution of millions of users who interacts in a collaborative way. Search engines, continually exploring the Web, are a natural source of information on which to base a modern approach to semantic annotation. A promising idea is that it is possible to generalize the semantic similarity, under the assumption that semantically similar terms behave similarly, and define collaborative proximity measures based on the indexing information returned by search engines. The PMING Distance is a proximity measure used in data mining and information retrieval, which collaborative information express the degree of relationship between two terms, using only the number of documents returned as result for a query on a search engine. In this work, the PMINIG Distance is updated, providing a novel formal algebraic definition, which corrects previous works. The novel point of view underlines the features of the PMING to be a locally normalized linear combination of the Pointwise Mutual Information and Normalized Google Distance. The analyzed measure dynamically reflects the collaborative change made on the web resources. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Probability (math.PR)"
https://arxiv.org/abs/1701.02388;Stoic Ethics for Artificial Agents; Gabriel Murray;  We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I. systems. This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories. We relate ethical A.I. to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect. More generally, we put forward an ethical view of A.I. that focuses more on internal states of the artificial agent rather than on external actions of the agent. We provide examples relating to near-term A.I. systems as well as hypothetical superintelligent agents. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.02543;Predicting Citywide Crowd Flows Using Deep Spatio-Temporal Residual  Networks; Junbo Zhang,  Yu Zheng,  Dekang Qi,  Ruiyuan Li,  Xiuwen Yi,  Tianrui Li;  Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, including spatial dependencies (nearby and distant), temporal dependencies (closeness, period, trend), and external conditions (e.g., weather and events). We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast two types of crowd flows (i.e. inflow and outflow) in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We have developed a real-time system based on Microsoft Azure Cloud, called UrbanFlow, providing the crowd flow monitoring and forecasting in Guiyang City of China. In addition, we present an extensive experimental evaluation using two types of crowd flows in Beijing and New York City (NYC), where ST-ResNet outperforms nine well-known baselines. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.02545;IoFClime: The fuzzy logic and the Internet of Things to control indoor  temperature regarding the outdoor ambient conditions; Daniel Meana-Llorián,  Cristian González García,  B. Cristina Pelayo G-Bustelo,  Juan Manuel Cueva Lovelle,  Nestor Garcia-Fernandez;  The Internet of Things is arriving to our homes or cities through fields already known like Smart Homes, Smart Cities, or Smart Towns. The monitoring of environmental conditions of cities can help to adapt the indoor locations of the cities in order to be more comfortable for people who stay there. A way to improve the indoor conditions is an efficient temperature control, however, it depends on many factors like the different combinations of outdoor temperature and humidity. Therefore, adjusting the indoor temperature is not setting a value according to other value. There are many more factors to take into consideration, hence the traditional logic based in binary states cannot be used. Many problems cannot be solved with a set of binary solutions and we need a new way of development. Fuzzy logic is able to interpret many states, more than two states, giving to computers the capacity to react in a similar way to people. In this paper we will propose a new approach to control the temperature using the Internet of Things together its platforms and fuzzy logic regarding not only the indoor temperature but also the outdoor temperature and humidity in order to save energy and to set a more comfortable environment for their users. Finally, we will conclude that the fuzzy approach allows us to achieve an energy saving around 40% and thus, save money. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03000;A Framework for Knowledge Management and Automated Reasoning Applied on  Intelligent Transport Systems; Aneta Vulgarakis Feljan,  Athanasios Karapantelakis,  Leonid Mokrushin,  Hongxin Liang,  Rafia Inam,  Elena Fersman,  Carlos R.B. Azevedo,  Klaus Raizer,  Ricardo S. Souza;  Cyber-Physical Systems in general, and Intelligent Transport Systems (ITS) in particular use heterogeneous data sources combined with problem solving expertise in order to make critical decisions that may lead to some form of actions e.g., driver notifications, change of traffic light signals and braking to prevent an accident. Currently, a major part of the decision process is done by human domain experts, which is time-consuming, tedious and error-prone. Additionally, due to the intrinsic nature of knowledge possession this decision process cannot be easily replicated or reused. Therefore, there is a need for automating the reasoning processes by providing computational systems a formal representation of the domain knowledge and a set of methods to process that knowledge. In this paper, we propose a knowledge model that can be used to express both declarative knowledge about the systems' components, their relations and their current state, as well as procedural knowledge representing possible system behavior. In addition, we introduce a framework for knowledge management and automated reasoning (KMARF). The idea behind KMARF is to automatically select an appropriate problem solver based on formalized reasoning expertise in the knowledge base, and convert a problem definition to the corresponding format. This approach automates reasoning, thus reducing operational costs, and enables reusability of knowledge and methods across different domains. We illustrate the approach on a transportation planning use case. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03037;Towards Smart Proof Search for Isabelle; Yutaka Nagashima;  Despite the recent progress in automatic theorem provers, proof engineers are still suffering from the lack of powerful proof automation. In this position paper we first report our proof strategy language based on a meta-tool approach. Then, we propose an AI-based approach to drastically improve proof automation for Isabelle, while identifying three major challenges we plan to address for this objective. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03322;From First-Order Logic to Assertional Logic; Yi Zhou;  First-Order Logic (FOL) is widely regarded as one of the most important foundations for knowledge representation. Nevertheless, in this paper, we argue that FOL has several critical issues for this purpose. Instead, we propose an alternative called assertional logic, in which all syntactic objects are categorized as set theoretic constructs including individuals, concepts and operators, and all kinds of knowledge are formalized by equality assertions. We first present a primitive form of assertional logic that uses minimal assumed knowledge and constructs. Then, we show how to extend it by definitions, which are special kinds of knowledge, i.e., assertions. We argue that assertional logic, although simpler, is more expressive and extensible than FOL. As a case study, we show how assertional logic can be used to unify logic and probability, and more building blocks in AI. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03500;A Savage-Like Axiomatization for Nonstandard Expected Utility; Grant Molnar;"  Since Leonard Savage's epoch-making ""Foundations of Statistics,"" Subjective Expected Utility Theory has been the presumptive model for decision-making. Savage provided an act-based axiomatization of standard expected utility theory. In this article, we provide a Savage-like axiomatization of nonstandard expected utility theory. It corresponds to a weakening of Savage's $6^{th}$ axiom. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03571;Fuzzy Clustering Data Given in the Ordinal Scale; Zhengbing Hu,  Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Viktoriia O. Samitova;  A fuzzy clustering algorithm for multidimensional data is proposed in this article. The data is described by vectors whose components are linguistic variables defined in an ordinal scale. The obtained results confirm the efficiency of the proposed approach. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03714;On the links between argumentation-based reasoning and nonmonotonic  reasoning; Zimi Li,  Nir Oren,  Simon Parsons;  In this paper we investigate the links between instantiated argumentation systems and the axioms for non-monotonic reasoning described in [9] with the aim of characterising the nature of argument based reasoning. In doing so, we consider two possible interpretations of the consequence relation, and describe which axioms are met by ASPIC+ under each of these interpretations. We then consider the links between these axioms and the rationality postulates. Our results indicate that argument based reasoning as characterised by ASPIC+ is - according to the axioms of [9] - non-cumulative and non-monotonic, and therefore weaker than the weakest non-monotonic reasoning systems they considered possible. This weakness underpins ASPIC+'s success in modelling other reasoning systems, and we conclude by considering the relationship between ASPIC+ and other weak logical systems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03866;Long Timescale Credit Assignment in NeuralNetworks with External Memory; Steven Stenberg Hansen;  Credit assignment in traditional recurrent neural networks usually involves back-propagating through a long chain of tied weight matrices. The length of this chain scales linearly with the number of time-steps as the same network is run at each time-step. This creates many problems, such as vanishing gradients, that have been well studied. In contrast, a NNEM's architecture recurrent activity doesn't involve a long chain of activity (though some architectures such as the NTM do utilize a traditional recurrent architecture as a controller). Rather, the externally stored embedding vectors are used at each time-step, but no messages are passed from previous time-steps. This means that vanishing gradients aren't a problem, as all of the necessary gradient paths are short. However, these paths are extremely numerous (one per embedding vector in memory) and reused for a very long time (until it leaves the memory). Thus, the forward-pass information of each memory must be stored for the entire duration of the memory. This is problematic as this additional storage far surpasses that of the actual memories, to the extent that large memories on infeasible to back-propagate through in high dimensional settings. One way to get around the need to hold onto forward-pass information is to recalculate the forward-pass whenever gradient information is available. However, if the observations are too large to store in the domain of interest, direct reinstatement of a forward pass cannot occur. Instead, we rely on a learned autoencoder to reinstate the observation, and then use the embedding network to recalculate the forward-pass. Since the recalculated embedding vector is unlikely to perfectly match the one stored in memory, we try out 2 approximations to utilize error gradient w.r.t. the vector in memory. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1701.03868;Minimally Naturalistic Artificial Intelligence; Steven Stenberg Hansen;"  The rapid advancement of machine learning techniques has re-energized research into general artificial intelligence. While the idea of domain-agnostic meta-learning is appealing, this emerging field must come to terms with its relationship to human cognition and the statistics and structure of the tasks humans perform. The position of this article is that only by aligning our agents' abilities and environments with those of humans do we stand a chance at developing general artificial intelligence (GAI). A broad reading of the famous 'No Free Lunch' theorem is that there is no universally optimal inductive bias or, equivalently, bias-free learning is impossible. This follows from the fact that there are an infinite number of ways to extrapolate data, any of which might be the one used by the data generating environment; an inductive bias prefers some of these extrapolations to others, which lowers performance in environments using these adversarial extrapolations. We may posit that the optimal GAI is the one that maximally exploits the statistics of its environment to create its inductive bias; accepting the fact that this agent is guaranteed to be extremely sub-optimal for some alternative environments. This trade-off appears benign when thinking about the environment as being the physical universe, as performance on any fictive universe is obviously irrelevant. But, we should expect a sharper inductive bias if we further constrain our environment. Indeed, we implicitly do so by defining GAI in terms of accomplishing that humans consider useful. One common version of this is need the for 'common-sense reasoning', which implicitly appeals to the statistics of physical universe as perceived by humans. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.03937;Hedera: Scalable Indexing and Exploring Entities in Wikipedia Revision  History; Tuan Tran,  Tu Ngoc Nguyen;  Much of work in semantic web relying on Wikipedia as the main source of knowledge often work on static snapshots of the dataset. The full history of Wikipedia revisions, while contains much more useful information, is still difficult to access due to its exceptional volume. To enable further research on this collection, we developed a tool, named Hedera, that efficiently extracts semantic information from Wikipedia revision history datasets. Hedera exploits Map-Reduce paradigm to achieve rapid extraction, it is able to handle one entire Wikipedia articles revision history within a day in a medium-scale cluster, and supports flexible data structures for various kinds of semantic web study. ;"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1701.04569;Multiobjective Optimization of Solar Powered Irrigation System with  Fuzzy Type-2 Noise Modelling; T.Ganesan,  P.Vasant,  I.Elamvazuthi;  Optimization is becoming a crucial element in industrial applications involving sustainable alternative energy systems. During the design of such systems, the engineer/decision maker would often encounter noise factors (e.g. solar insolation and ambient temperature fluctuations) when their system interacts with the environment. In this chapter, the sizing and design optimization of the solar powered irrigation system was considered. This problem is multivariate, noisy, nonlinear and multiobjective. This design problem was tackled by first using the Fuzzy Type II approach to model the noise factors. Consequently, the Bacterial Foraging Algorithm (BFA) (in the context of a weighted sum framework) was employed to solve this multiobjective fuzzy design problem. This method was then used to construct the approximate Pareto frontier as well as to identify the best solution option in a fuzzy setting. Comprehensive analyses and discussions were performed on the generated numerical results with respect to the implemented solution methods. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.04645;Une mesure d'expertise pour le crowdsourcing; Hosna Ouni (IRISA, DRUID),  Arnaud Martin (IRISA, UR1, DRUID),  Laetitia Gros,  Mouloud Kharoune (IRISA, DRUID),  Zoltan Miklos (IRISA, DRUID);"  Crowdsourcing, a major economic issue, is the fact that the firm outsources internal task to the crowd. It is a form of digital subcontracting for the general public. The evaluation of the participants work quality is a major issue in crowdsourcing. Indeed, contributions must be controlled to ensure the effectiveness and relevance of the campaign. We are particularly interested in small, fast and not automatable tasks. Several methods have been proposed to solve this problem, but they are applicable when the ""golden truth"" is not always known. This work has the particularity to propose a method for calculating the degree of expertise in the presence of gold data in crowdsourcing. This method is based on the belief function theory and proposes a structuring of data using graphs. The proposed approach will be assessed and applied to the data. ";"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1701.04663;Intrinsically Motivated Acquisition of Modular Slow Features for  Humanoids in Continuous and Non-Stationary Environments; Varun Raj Kompella,  Laurenz Wiskott;"  A compact information-rich representation of the environment, also called a feature abstraction, can simplify a robot's task of mapping its raw sensory inputs to useful action sequences. However, in environments that are non-stationary and only partially observable, a single abstraction is probably not sufficient to encode most variations. Therefore, learning multiple sets of spatially or temporally local, modular abstractions of the inputs would be beneficial. How can a robot learn these local abstractions without a teacher? More specifically, how can it decide from where and when to start learning a new abstraction? A recently proposed algorithm called Curious Dr. MISFA addresses this problem. The algorithm is based on two underlying learning principles called artificial curiosity and slowness. The former is used to make the robot self-motivated to explore by rewarding itself whenever it makes progress learning an abstraction; the later is used to update the abstraction by extracting slowly varying components from raw sensory inputs. Curious Dr. MISFA's application is, however, limited to discrete domains constrained by a pre-defined state space and has design limitations that make it unstable in certain situations. This paper presents a significant improvement that is applicable to continuous environments, is computationally less expensive, simpler to use with fewer hyper parameters, and stable in certain non-stationary environments. We demonstrate the efficacy and stability of our method in a vision-based robot simulator. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.04895;Unknowable Manipulators: Social Network Curator Algorithms; Samuel Albanie,  Hillary Shakespeare,  Tom Gunter;  For a social networking service to acquire and retain users, it must find ways to keep them engaged. By accurately gauging their preferences, it is able to serve them with the subset of available content that maximises revenue for the site. Without the constraints of an appropriate regulatory framework, we argue that a sufficiently sophisticated curator algorithm tasked with performing this process may choose to explore curation strategies that are detrimental to users. In particular, we suggest that such an algorithm is capable of learning to manipulate its users, for several qualitative reasons: 1. Access to vast quantities of user data combined with ongoing breakthroughs in the field of machine learning are leading to powerful but uninterpretable strategies for decision making at scale. 2. The availability of an effective feedback mechanism for assessing the short and long term user responses to curation strategies. 3. Techniques from reinforcement learning have allowed machines to learn automated and highly successful strategies at an abstract level, often resulting in non-intuitive yet nonetheless highly appropriate action selection. In this work, we consider the form that these strategies for user manipulation might take and scrutinise the role that regulation should play in the design of such systems. ;"Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1701.05059;Ontology based system to guide internship assignment process; Abir M 'Baya (DISP),  Jannik Laval (DISP),  Nejib Moalla (DISP),  Yacine Ouzrout (DISP),  Abdelaziz Bouras;  Internship assignment is a complicated process for universities since it is necessary to take into account a multiplicity of variables to establish a compromise between companies' requirements and student competencies acquired during the university training. These variables build up a complex relations map that requires the formulation of an exhaustive and rigorous conceptual scheme. In this research a domain ontological model is presented as support to the student's decision making for opportunities of University studies level of the University Lumiere Lyon 2 (ULL) education system. The ontology is designed and created using methodological approach offering the possibility of improving the progressive creation, capture and knowledge articulation. In this paper, we draw a balance taking the demands of the companies across the capabilities of the students. This will be done through the establishment of an ontological model of an educational learners' profile and the internship postings which are written in a free text and using uncontrolled vocabulary. Furthermore, we outline the process of semantic matching which improves the quality of query results. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.05130;On the Performance of Network Parallel Training in Artificial Neural  Networks; Ludvig Ericson,  Rendani Mbuvha;"  Artificial Neural Networks (ANNs) have received increasing attention in recent years with applications that span a wide range of disciplines including vital domains such as medicine, network security and autonomous transportation. However, neural network architectures are becoming increasingly complex and with an increasing need to obtain real-time results from such models, it has become pivotal to use parallelization as a mechanism for speeding up network training and deployment. In this work we propose an implementation of Network Parallel Training through Cannon's Algorithm for matrix multiplication. We show that increasing the number of processes speeds up training until the point where process communication costs become prohibitive; this point varies by network complexity. We also show through empirical efficiency calculations that the speedup obtained is superlinear. ";"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Performance (cs.PF); Machine Learning (stat.ML)"
https://arxiv.org/abs/1701.05226;Reasoning in Non-Probabilistic Uncertainty: Logic Programming and  Neural-Symbolic Computing as Examples; Tarek R. Besold,  Artur d'Avila Garcez,  Keith Stenning,  Leendert van der Torre,  Michiel van Lambalgen;"  This article aims to achieve two goals: to show that probability is not the only way of dealing with uncertainty (and even more, that there are kinds of uncertainty which are for principled reasons not addressable with probabilistic means); and to provide evidence that logic-based methods can well support reasoning with uncertainty. For the latter claim, two paradigmatic examples are presented: Logic Programming with Kleene semantics for modelling reasoning from information in a discourse, to an interpretation of the state of affairs of the intended model, and a neural-symbolic implementation of Input/Output logic for dealing with uncertainty in dynamic normative contexts. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.05291;Heterogeneous Information Network Embedding for Meta Path based  Proximity; Zhipeng Huang,  Nikos Mamoulis;  A network embedding is a representation of a large graph in a low-dimensional space, where vertices are modeled as vectors. The objective of a good embedding is to preserve the proximity between vertices in the original graph. This way, typical search and mining methods can be applied in the embedded space with the help of off-the-shelf multidimensional indexing approaches. Existing network embedding techniques focus on homogeneous networks, where all vertices are considered to belong to a single class. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.05334;Fuzzy Ontology-Based Sentiment Analysis of Transportation and City  Feature Reviews for Safe Traveling; Farman Ali,  D. Kwak,  Pervez Khan,  S.M. Riazul Islam,  K.H. Kim,  K.S. Kwak;"  Traffic congestion is rapidly increasing in urban areas, particularly in mega cities. To date, there exist a few sensor network based systems to address this problem. However, these techniques are not suitable enough in terms of monitoring an entire transportation system and delivering emergency services when needed. These techniques require real-time data and intelligent ways to quickly determine traffic activity from useful information. In addition, these existing systems and websites on city transportation and travel rely on rating scores for different factors (e.g., safety, low crime rate, cleanliness, etc.). These rating scores are not efficient enough to deliver precise information, whereas reviews or tweets are significant, because they help travelers and transportation administrators to know about each aspect of the city. However, it is difficult for travelers to read, and for transportation systems to process, all reviews and tweets to obtain expressive sentiments regarding the needs of the city. The optimum solution for this kind of problem is analyzing the information available on social network platforms and performing sentiment analysis. On the other hand, crisp ontology-based frameworks cannot extract blurred information from tweets and reviews; therefore, they produce inadequate results. In this regard, this paper proposes fuzzy ontology-based sentiment analysis and SWRL rule-based decision-making to monitor transportation activities and to make a city- feature polarity map for travelers. This system retrieves reviews and tweets related to city features and transportation activities. The feature opinions are extracted from these retrieved data, and then fuzzy ontology is used to determine the transportation and city-feature polarity. A fuzzy ontology and an intelligent system prototype are developed by using Prot\'eg\'e OWL and Java, respectively. ";"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1701.05724;Logical Inferences with Contexts of RDF Triples; Vinh Nguyen,  Amit Sheth;  Logical inference, an integral feature of the Semantic Web, is the process of deriving new triples by applying entailment rules on knowledge bases. The entailment rules are determined by the model-theoretic semantics. Incorporating context of an RDF triple (e.g., provenance, time, and location) into the inferencing process requires the formal semantics to be capable of describing the context of RDF triples also in the form of triples, or in other words, RDF contextual triples about triples. The formal semantics should also provide the rules that could entail new contextual triples about triples. In this paper, we propose the first inferencing mechanism that allows context of RDF triples, represented in the form of RDF triples about triples, to be the first-class citizens in the model-theoretic semantics and in the logical rules. Our inference mechanism is well-formalized with all new concepts being captured in the model-theoretic semantics. This formal semantics also allows us to derive a new set of entailment rules that could entail new contextual triples about triples. To demonstrate the feasibility and the scalability of the proposed mechanism, we implement a new tool in which we transform the existing knowledge bases to our representation of RDF triples about triples and provide the option for this tool to compute the inferred triples for the proposed rules. We evaluate the computation of the proposed rules on a large scale using various real-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results show that the computation of the inferred triples can be highly scalable. On average, one billion inferred triples adds 5-6 minutes to the overall transformation process. NCBI Genes, with 20 billion triples in total, took only 232 minutes for the transformation of 12 billion triples and added 42 minutes for inferring 8 billion triples to the overall process. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1701.06049;Interactive Learning from Policy-Dependent Human Feedback; James MacGlashan,  Mark K Ho,  Robert Loftin,  Bei Peng,  David Roberts,  Matthew E. Taylor,  Michael L. Littman;  For agents and robots to become more useful, they must be able to quickly learn from non-technical users. This paper investigates the problem of interactively learning behaviors communicated by a human teacher using positive and negative feedback. Much previous work on this problem has made the assumption that people provide feedback for decisions that is dependent on the behavior they are teaching and is independent from the learner's current policy. We present empirical results that show this assumption to be false---whether human trainers give a positive or negative feedback for a decision is influenced by the learner's current policy. We argue that policy-dependent feedback, in addition to being commonplace, enables useful training strategies from which agents should benefit. Based on this insight, we introduce Convergent Actor-Critic by Humans (COACH), an algorithm for learning from policy-dependent feedback that converges to a local optimum. Finally, we demonstrate that COACH can successfully learn multiple behaviors on a physical robot, even with noisy image features. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.06167;Binary Matrix Guessing Problem; Çağrı Latifoğlu;  We introduce the Binary Matrix Guessing Problem and provide two algorithms to solve this problem. The first algorithm we introduce is Elementwise Probing Algorithm (EPA) which is very fast under a score which utilizes Frobenius Distance. The second algorithm is Additive Reinforcement Learning Algorithm which combines ideas from perceptron algorithm and reinforcement learning algorithm. This algorithm is significantly slower compared to first one, but less restrictive and generalizes better. We compare computational performance of both algorithms and provide numerical results. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.06388;Constraint programming for planning test campaigns of communications  satellites; Emmanuel Hébrard (LAAS-ROC),  Marie-José Huguet (LAAS-ROC),  Daniel Veysseire (LAAS-ROC),  Ludivine Sauvan (LAAS-ROC),  Bertrand Cabon;  The payload of communications satellites must go through a series of tests to assert their ability to survive in space. Each test involves some equipment of the payload to be active, which has an impact on the temperature of the payload. Sequencing these tests in a way that ensures the thermal stability of the payload and minimizes the overall duration of the test campaign is a very important objective for satellite manufacturers. The problem can be decomposed in two sub-problems corresponding to two objectives: First, the number of distinct configurations necessary to run the tests must be minimized. This can be modeled as packing the tests into configurations, and we introduce a set of implied constraints to improve the lower bound of the model. Second, tests must be sequenced so that the number of times an equipment unit has to be switched on or off is minimized. We model this aspect using the constraint Switch, where a buffer with limited capacity represents the currently active equipment units, and we introduce an improvement of the propagation algorithm for this constraint. We then introduce a search strategy in which we sequentially solve the sub-problems (packing and sequencing). Experiments conducted on real and random instances show the respective interest of our contributions. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.06635;Space-Time Graph Modeling of Ride Requests Based on Real-World Data; Abhinav Jauhri,  Brian Foo,  Jerome Berclaz,  Chih Chi Hu,  Radek Grzeszczuk,  Vasu Parameswaran,  John Paul Shen;  This paper focuses on modeling ride requests and their variations over location and time, based on analyzing extensive real-world data from a ride-sharing service. We introduce a graph model that captures the spatial and temporal variability of ride requests and the potentials for ride pooling. We discover these ride request graphs exhibit a well known property called densification power law often found in real graphs modelling human behaviors. We show the pattern of ride requests and the potential of ride pooling for a city can be characterized by the densification factor of the ride request graphs. Previous works have shown that it is possible to automatically generate synthetic versions of these graphs that exhibit a given densification factor. We present an algorithm for automatic generation of synthetic ride request graphs that match quite well the densification factor of ride request graphs from actual ride request data. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.06699;Imitating Driver Behavior with Generative Adversarial Networks; Alex Kuefler,  Jeremy Morton,  Tim Wheeler,  Mykel Kochenderfer;  The ability to accurately predict and simulate human driving behavior is critical for the development of intelligent transportation systems. Traditional modeling methods have employed simple parametric models and behavioral cloning. This paper adopts a method for overcoming the problem of cascading errors inherent in prior approaches, resulting in realistic behavior that is robust to trajectory perturbations. We extend Generative Adversarial Imitation Learning to the training of recurrent policies, and we demonstrate that our model outperforms rule-based controllers and maximum likelihood models in realistic highway simulations. Our model both reproduces emergent behavior of human drivers, such as lane change rate, while maintaining realistic control over long time horizons. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.06972;Deep Network Guided Proof Search; Sarah Loos,  Geoffrey Irving,  Christian Szegedy,  Cezary Kaliszyk;  Deep learning techniques lie at the heart of several significant AI advances in recent years including object recognition and detection, image captioning, machine translation, speech recognition and synthesis, and playing the game of Go. Automated first-order theorem provers can aid in the formalization and verification of mathematical theorems and play a crucial role in program analysis, theory reasoning, security, interpolation, and system verification. Here we suggest deep learning based guidance in the proof search of the theorem prover E. We train and compare several deep neural network models on the traces of existing ATP proofs of Mizar statements and use them to select processed clauses during proof search. We give experimental evidence that with a hybrid, two-phase approach, deep learning based guidance can significantly reduce the average number of proof search steps while increasing the number of theorems proved. Using a few proof guidance strategies that leverage deep neural networks, we have found first-order proofs of 7.36% of the first-order logic translations of the Mizar Mathematical Library theorems that did not previously have ATP generated proofs. This increases the ratio of statements in the corpus with ATP generated proofs from 56% to 59%. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1701.07103;Artificial Intelligence Approaches To UCAV Autonomy; Amir Husain (1),  Bruce Porter (2) ((1) SparkCognition Inc. (2) Department of Computer Science, University of Texas at Austin);  This paper covers a number of approaches that leverage Artificial Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle (UCAV) autonomy. An analysis of current approaches to autonomous control is provided followed by an exploration of how these techniques can be extended and enriched with AI techniques including Artificial Neural Networks (ANN), Ensembling and Reinforcement Learning (RL) to evolve control strategies for UCAVs. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1701.07232;Learn&Fuzz: Machine Learning for Input Fuzzing; Patrice Godefroid,  Hila Peleg,  Rishabh Singh;  Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss (and measure) the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs. ;"Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)"
https://arxiv.org/abs/1701.07657;Logic Programming Petri Nets; Giovanni Sileno;  With the purpose of modeling, specifying and reasoning in an integrated fashion with procedural and declarative aspects (both commonly present in cases or scenarios), the paper introduces Logic Programming Petri Nets (LPPN), an extension to the Petri Net notation providing an interface to logic programming constructs. Two semantics are presented. First, a hybrid operational semantics that separates the process component, treated with Petri nets, from the constraint/terminological component, treated with Answer Set Programming (ASP). Second, a denotational semantics maps the notation to ASP fully, via Event Calculus. These two alternative specifications enable a preliminary evaluation in terms of reasoning efficiency. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.07696;Identifying Consistent Statements about Numerical Data with  Dispersion-Corrected Subgroup Discovery; Mario Boley,  Bryan R. Goldsmith,  Luca M. Ghiringhelli,  Jilles Vreeken;  Existing algorithms for subgroup discovery with numerical targets do not optimize the error or target variable dispersion of the groups they find. This often leads to unreliable or inconsistent statements about the data, rendering practical applications, especially in scientific domains, futile. Therefore, we here extend the optimistic estimator framework for optimal subgroup discovery to a new class of objective functions: we show how tight estimators can be computed efficiently for all functions that are determined by subgroup size (non-decreasing dependence), the subgroup median value, and a dispersion measure around the median (non-increasing dependence). In the important special case when dispersion is measured using the average absolute deviation from the median, this novel approach yields a linear time algorithm. Empirical evaluation on a wide range of datasets shows that, when used within branch-and-bound search, this approach is highly efficient and indeed discovers subgroups with much smaller errors. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1701.07756;Dynamic time warping distance for message propagation classification in  Twitter; Siwar Jendoubi,  Arnaud Martin,  Ludovic Liétard,  Boutheina Ben Yaghlane,  Hend Ben Hadji;  Social messages classification is a research domain that has attracted the attention of many researchers in these last years. Indeed, the social message is different from ordinary text because it has some special characteristics like its shortness. Then the development of new approaches for the processing of the social message is now essential to make its classification more efficient. In this paper, we are mainly interested in the classification of social messages based on their spreading on online social networks (OSN). We proposed a new distance metric based on the Dynamic Time Warping distance and we use it with the probabilistic and the evidential k Nearest Neighbors (k-NN) classifiers to classify propagation networks (PrNets) of messages. The propagation network is a directed acyclic graph (DAG) that is used to record propagation traces of the message, the traversed links and their types. We tested the proposed metric with the chosen k-NN classifiers on real world propagation traces that were collected from Twitter social network and we got good classification accuracies. ;"Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1701.07769;Ethical Considerations in Artificial Intelligence Courses; Emanuelle Burton,  Judy Goldsmith,  Sven Koenig,  Benjamin Kuipers,  Nicholas Mattei,  Toby Walsh;  The recent surge in interest in ethics in artificial intelligence may leave many educators wondering how to address moral, ethical, and philosophical issues in their AI courses. As instructors we want to develop curriculum that not only prepares students to be artificial intelligence practitioners, but also to understand the moral, ethical, and philosophical impacts that artificial intelligence will have on society. In this article we provide practical case studies and links to resources for use by AI educators. We also provide concrete suggestions on how to integrate AI ethics into a general artificial intelligence course and how to teach a stand-alone artificial intelligence ethics course. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY); General Literature (cs.GL)"
https://arxiv.org/abs/1701.08096;Efficiently Summarising Event Sequences with Rich Interleaving Patterns; Apratim Bhattacharyya,  Jilles Vreeken;  Discovering the key structure of a database is one of the main goals of data mining. In pattern set mining we do so by discovering a small set of patterns that together describe the data well. The richer the class of patterns we consider, and the more powerful our description language, the better we will be able to summarise the data. In this paper we propose \ourmethod, a novel greedy MDL-based method for summarising sequential data using rich patterns that are allowed to interleave. Experiments show \ourmethod is orders of magnitude faster than the state of the art, results in better models, as well as discovers meaningful semantics in the form patterns that identify multiple choices of values. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1701.08100;The Causal Frame Problem: An Algorithmic Perspective; Ardavan Salehi Nobandegani,  Ioannis N. Psaromiligkos;"  The Frame Problem (FP) is a puzzle in philosophy of mind and epistemology, articulated by the Stanford Encyclopedia of Philosophy as follows: ""How do we account for our apparent ability to make decisions on the basis only of what is relevant to an ongoing situation without having explicitly to consider all that is not relevant?"" In this work, we focus on the causal variant of the FP, the Causal Frame Problem (CFP). Assuming that a reasoner's mental causal model can be (implicitly) represented by a causal Bayes net, we first introduce a notion called Potential Level (PL). PL, in essence, encodes the relative position of a node with respect to its neighbors in a causal Bayes net. Drawing on the psychological literature on causal judgment, we substantiate the claim that PL may bear on how time is encoded in the mind. Using PL, we propose an inference framework, called the PL-based Inference Framework (PLIF), which permits a boundedly-rational approach to the CFP to be formally articulated at Marr's algorithmic level of analysis. We show that our proposed framework, PLIF, is consistent with a wide range of findings in causal judgment literature, and that PL and PLIF make a number of predictions, some of which are already supported by existing findings. ";"Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)"
https://arxiv.org/abs/1701.08190;Comparative Study Of Data Mining Query Languages; Mohamed Anis Bach Tobji;  Since formulation of Inductive Database (IDB) problem, several Data Mining (DM) languages have been proposed, confirming that KDD process could be supported via inductive queries (IQ) answering. This paper reviews the existing DM languages. We are presenting important primitives of the DM language and classifying our languages according to primitives' satisfaction. In addition, we presented languages' syntaxes and tried to apply each one to a database sample to test a set of KDD operations. This study allows us to highlight languages capabilities and limits, which is very useful for future work and perspectives. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1701.08191;Incremental Maintenance Of Association Rules Under Support Threshold  Change; Mohamed Anis Bach Tobji,  Mohamed Salah Gouider;  Maintenance of association rules is an interesting problem. Several incremental maintenance algorithms were proposed since the work of (Cheung et al, 1996). The majority of these algorithms maintain rule bases assuming that support threshold doesn't change. In this paper, we present incremental maintenance algorithm under support threshold change. This solution allows user to maintain its rule base under any support threshold. ;"Artificial Intelligence (cs.AI); Databases (cs.DB)"
https://arxiv.org/abs/1701.08301;Pure Rough Mereology and Counting; A. Mani;  The study of mereology (parts and wholes) in the context of formal approaches to vagueness can be approached in a number of ways. In the context of rough sets, mereological concepts with a set-theoretic or valuation based ontology acquire complex and diverse behavior. In this research a general rough set framework called granular operator spaces is extended and the nature of parthood in it is explored from a minimally intrusive point of view. This is used to develop counting strategies that help in classifying the framework. The developed methodologies would be useful for drawing involved conclusions about the nature of data (and validity of assumptions about it) from antichains derived from context. The problem addressed is also about whether counting procedures help in confirming that the approximations involved in formation of data are indeed rough approximations? ;"Artificial Intelligence (cs.AI); Information Theory (cs.IT); Logic in Computer Science (cs.LO); Logic (math.LO)"
https://arxiv.org/abs/1701.08302;A Study of FOSS'2013 Survey Data Using Clustering Techniques; Mani A,  Rebeka Mukherjee;  FOSS is an acronym for Free and Open Source Software. The FOSS 2013 survey primarily targets FOSS contributors and relevant anonymized dataset is publicly available under CC by SA license. In this study, the dataset is analyzed from a critical perspective using statistical and clustering techniques (especially multiple correspondence analysis) with a strong focus on women contributors towards discovering hidden trends and facts. Important inferences are drawn about development practices and other facets of the free software and OSS worlds. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Software Engineering (cs.SE); Machine Learning (stat.ML)"
https://arxiv.org/abs/1701.08305;Multiclass MinMax Rank Aggregation; Pan Li,  Olgica Milenkovic;  We introduce a new family of minmax rank aggregation problems under two distance measures, the Kendall {\tau} and the Spearman footrule. As the problems are NP-hard, we proceed to describe a number of constant-approximation algorithms for solving them. We conclude with illustrative applications of the aggregation methods on the Mallows model and genomic data. ;"Learning (cs.LG); Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)"
https://arxiv.org/abs/1701.08306;Practical Reasoning with Norms for Autonomous Software Agents (Full  Edition); Zohreh Shams,  Marina De Vos,  Julian Padget,  Wamberto W. Vasconcelos;  Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.08317;Plan Explanations as Model Reconciliation: Moving Beyond Explanation as  Soliloquy; Tathagata Chakraborti,  Sarath Sreedharan,  Yu Zhang,  Subbarao Kambhampati;"  When AI systems interact with humans in the loop, they are often called on to provide explanations for their plans and behavior. Past work on plan explanations primarily involved the AI system explaining the correctness of its plan and the rationale for its decision in terms of its own model. Such soliloquy is wholly inadequate in most realistic scenarios where the humans have domain and task models that differ significantly from that used by the AI system. We posit that the explanations are best studied in light of these differing models. In particular, we show how explanation can be seen as a ""model reconciliation problem"" (MRP), where the AI system in effect suggests changes to the human's model, so as to make its plan be optimal with respect to that changed human model. We will study the properties of such explanations, present algorithms for automatically computing them, and evaluate the performance of the algorithms. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.08343;Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output  HMM for Multiple Voices; Eita Nakamura,  Kazuyoshi Yoshii,  Shigeki Sagayama;  In a recent conference paper, we have reported a rhythm transcription method based on a merged-output hidden Markov model (HMM) that explicitly describes the multiple-voice structure of polyphonic music. This model solves a major problem of conventional methods that could not properly describe the nature of multiple voices as in polyrhythmic scores or in the phenomenon of loose synchrony between voices. In this paper we present a complete description of the proposed model and develop an inference technique, which is valid for any merged-output HMMs for which output probabilities depend on past events. We also examine the influence of the architecture and parameters of the method in terms of accuracies of rhythm transcription and voice separation and perform comparative evaluations with six other algorithms. Using MIDI recordings of classical piano pieces, we found that the proposed model outperformed other methods by more than 12 points in the accuracy for polyrhythmic performances and performed almost as good as the best one for non-polyrhythmic performances. This reveals the state-of-the-art methods of rhythm transcription for the first time in the literature. Publicly available source codes are also provided for future comparisons. ;"Artificial Intelligence (cs.AI); Sound (cs.SD)"
https://arxiv.org/abs/1701.08546;Survey on Models and Techniques for Root-Cause Analysis; Marc Solé,  Victor Muntés-Mulero,  Annie Ibrahim Rana,  Giovani Estrada;  Automation and computer intelligence to support complex human decisions becomes essential to manage large and distributed systems in the Cloud and IoT era. Understanding the root cause of an observed symptom in a complex system has been a major problem for decades. As industry dives into the IoT world and the amount of data generated per year grows at an amazing speed, an important question is how to find appropriate mechanisms to determine root causes that can handle huge amounts of data or may provide valuable feedback in real-time. While many survey papers aim at summarizing the landscape of techniques for modelling system behavior and infering the root cause of a problem based in the resulting models, none of those focuses on analyzing how the different techniques in the literature fit growing requirements in terms of performance and scalability. In this survey, we provide a review of root-cause analysis, focusing on these particular aspects. We also provide guidance to choose the best root-cause analysis strategy depending on the requirements of a particular system and application. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.08661;Credal Networks under Epistemic Irrelevance; Jasper De Bock;  A credal network under epistemic irrelevance is a generalised type of Bayesian network that relaxes its two main building blocks. On the one hand, the local probabilities are allowed to be partially specified. On the other hand, the assessments of independence do not have to hold exactly. Conceptually, these two features turn credal networks under epistemic irrelevance into a powerful alternative to Bayesian networks, offering a more flexible approach to graph-based multivariate uncertainty modelling. However, in practice, they have long been perceived as very hard to work with, both theoretically and computationally. The aim of this paper is to demonstrate that this perception is no longer justified. We provide a general introduction to credal networks under epistemic irrelevance, give an overview of the state of the art, and present several new theoretical results. Most importantly, we explain how these results can be combined to allow for the design of recursive inference methods. We provide numerous concrete examples of how this can be achieved, and use these to demonstrate that computing with credal networks under epistemic irrelevance is most definitely feasible, and in some cases even highly efficient. We also discuss several philosophical aspects, including the lack of symmetry, how to deal with probability zero, the interpretation of lower expectations, the axiomatic status of graphoid properties, and the difference between updating and conditioning. ;"Artificial Intelligence (cs.AI); Probability (math.PR)"
https://arxiv.org/abs/1701.08665;Redefinition of the concept of fuzzy set based on vague partition from  the perspective of axiomatization; Xiaodong Pan,  Yang Xu;  Based on the in-depth analysis of the essence and features of vague phenomena, this paper focuses on establishing the axiomatical foundation of membership degree theory for vague phenomena, presents an axiomatic system to govern membership degrees and their interconnections. On this basis, the concept of vague partition is introduced, further, the concept of fuzzy set introduced by Zadeh in 1965 is redefined based on vague partition from the perspective of axiomatization. The thesis defended in this paper is that the relationship among vague attribute values should be the starting point to recognize and model vague phenomena from a quantitative view. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.08709;Diversification Methods for Zero-One Optimization; Fred Glover;  We introduce new diversification methods for zero-one optimization that significantly extend strategies previously introduced in the setting of metaheuristic search. Our methods incorporate easily implemented strategies for partitioning assignments of values to variables, accompanied by processes called augmentation and shifting which create greater flexibility and generality. We then show how the resulting collection of diversified solutions can be further diversified by means of permutation mappings, which equally can be used to generate diversified collections of permutations for applications such as scheduling and routing. These methods can be applied to non-binary vectors by the use of binarization procedures and by Diversification-Based Learning (DBL) procedures which also provide connections to applications in clustering and machine learning. Detailed pseudocode and numerical illustrations are provided to show the operation of our methods and the collections of solutions they create. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.08832;Expert Level control of Ramp Metering based on Multi-task Deep  Reinforcement Learning; Francois Belletti,  Daniel Haziza,  Gabriel Gomes,  Alexandre M. Bayen;  This article shows how the recent breakthroughs in Reinforcement Learning (RL) that have enabled robots to learn to play arcade video games, walk or assemble colored bricks, can be used to perform other tasks that are currently at the core of engineering cyberphysical systems. We present the first use of RL for the control of systems modeled by discretized non-linear Partial Differential Equations (PDEs) and devise a novel algorithm to use non-parametric control techniques for large multi-agent systems. We show how neural network based RL enables the control of discretized PDEs whose parameters are unknown, random, and time-varying. We introduce an algorithm of Mutual Weight Regularization (MWR) which alleviates the curse of dimensionality of multi-agent control schemes by sharing experience between agents while giving each agent the opportunity to specialize its action policy so as to tailor it to the local parameters of the part of the system it is located in. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.08868;Interaction Information for Causal Inference: The Case of Directed  Triangle; AmirEmad Ghassami,  Negar Kiyavash;  Interaction information is one of the multivariate generalizations of mutual information, which expresses the amount information shared among a set of variables, beyond the information, which is shared in any proper subset of those variables. Unlike (conditional) mutual information, which is always non-negative, interaction information can be negative. We utilize this property to find the direction of causal influences among variables in a triangle topology under some mild assumptions. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1701.09000;On the Semantics and Complexity of Probabilistic Logic Programs; Fabio Gagliardi Cozman,  Denis Deratani Mauá;"  We examine the meaning and the complexity of probabilistic logic programs that consist of a set of rules and a set of independent probabilistic facts (that is, programs based on Sato's distribution semantics). We focus on two semantics, respectively based on stable and on well-founded models. We show that the semantics based on stable models (referred to as the ""credal semantics"") produces sets of probability models that dominate infinitely monotone Choquet capacities, we describe several useful consequences of this result. We then examine the complexity of inference with probabilistic logic programs. We distinguish between the complexity of inference when a probabilistic program and a query are given (the inferential complexity), and the complexity of inference when the probabilistic program is fixed and the query is given (the query complexity, akin to data complexity as used in database theory). We obtain results on the inferential and query complexity for acyclic, stratified, and cyclic propositional and relational programs, complexity reaches various levels of the counting hierarchy and even exponential levels. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.00054;Outlier Detection from Network Data with Subnetwork Interpretation; Xuan-Hong Dang,  Arlei Silva,  Ambuj Singh,  Ananthram Swami,  Prithwish Basu;  Detecting a small number of outliers from a set of data observations is always challenging. This problem is more difficult in the setting of multiple network samples, where computing the anomalous degree of a network sample is generally not sufficient. In fact, explaining why the network is exceptional, expressed in the form of subnetwork, is also equally important. In this paper, we develop a novel algorithm to address these two key problems. We treat each network sample as a potential outlier and identify subnetworks that mostly discriminate it from nearby regular samples. The algorithm is developed in the framework of network regression combined with the constraints on both network topology and L1-norm shrinkage to perform subnetwork discovery. Our method thus goes beyond subspace/subgraph discovery and we show that it converges to a global optimum. Evaluation on various real-world network datasets demonstrates that our algorithm not only outperforms baselines in both network and high dimensional setting, but also discovers highly relevant and interpretable local subnetworks, further enhancing our understanding of anomalous networks. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1610.00081;Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows  Prediction; Junbo Zhang,  Yu Zheng,  Dekang Qi;  Forecasting the flow of crowds is of great importance to traffic management and public safety, yet a very challenging task affected by many complex factors, such as inter-region traffic, events and weather. In this paper, we propose a deep-learning-based approach, called ST-ResNet, to collectively forecast the in-flow and out-flow of crowds in each and every region through a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically, we employ the framework of the residual neural networks to model the temporal closeness, period, and trend properties of the crowd traffic, respectively. For each property, we design a branch of residual convolutional units, each of which models the spatial properties of the crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions. The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region. We evaluate ST-ResNet based on two types of crowd flows in Beijing and NYC, finding that its performance exceeds six well-know methods. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1610.00366;Funneled Bayesian Optimization for Design, Tuning and Control of  Autonomous Systems; Ruben Martinez-Cantin;  Bayesian optimization has become a fundamental global optimization algorithm in many problems where sample efficiency is of paramount importance. Recently, there has been proposed a large number of new applications in fields such as robotics, machine learning, experimental design, simulation, etc. In this paper, we focus on several problems that appear in robotics and autonomous systems: algorithm tuning, automatic control and intelligent design. All those problems can be mapped to global optimization problems. However, they become hard optimization problems. Bayesian optimization internally uses a probabilistic surrogate model (e.g.: Gaussian process) to learn from the process and reduce the number of samples required. In order to generalize to unknown functions in a black-box fashion, the common assumption is that the underlying function can be modeled with a stationary process. Nonstationary Gaussian process regression cannot generalize easily and it typically requires prior knowledge of the function. Some works have designed techniques to generalize Bayesian optimization to nonstationary functions in an indirect way, but using techniques originally designed for regression, where the objective is to improve the quality of the surrogate model everywhere. Instead optimization should focus on improving the surrogate model near the optimum. In this paper, we present a novel kernel function specially designed for Bayesian optimization, that allows nonstationary behavior of the surrogate model in an adaptive local region. In our experiments, we found that this new kernel results in an improved local search (exploitation), without penalizing the global search (exploration). We provide results in well-known benchmarks and real applications. The new method outperforms the state of the art in Bayesian optimization both in stationary and nonstationary problems. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.00378;Improving Accuracy and Scalability of the PC Algorithm by Maximizing  P-value; Joseph Ramsey;"  A number of attempts have been made to improve accuracy and/or scalability of the PC (Peter and Clark) algorithm, some well known (Buhlmann, et al., 2010; Kalisch and Buhlmann, 2007; 2008; Zhang, 2012, to give some examples). We add here one more tool to the toolbox: the simple observation that if one is forced to choose between a variety of possible conditioning sets for a pair of variables, one should choose the one with the highest p-value. One can use the CPC (Conservative PC, Ramsey et al., 2012) algorithm as a guide to possible sepsets for a pair of variables. However, whereas CPC uses a voting rule to classify colliders versus noncolliders, our proposed algorithm, PC-Max, picks the conditioning set with the highest p-value, so that there are no ambiguities. We combine this with two other optimizations: (a) avoiding bidirected edges in the orientation of colliders, and (b) parallelization. For (b) we borrow ideas from the PC-Stable algorithm (Colombo and Maathuis, 2014). The result is an algorithm that scales quite well both in terms of accuracy and time, with no risk of bidirected edges. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.00442;A Probability Distribution Strategy with Efficient Clause Selection for  Hard Max-SAT Formulas; Sixue Liu,  Yulong Ceng,  Gerard de Melo;  Many real-world problems involving constraints can be regarded as instances of the Max-SAT problem, which is the optimization variant of the classic satisfiability problem. In this paper, we propose a novel probabilistic approach for Max-SAT called ProMS. Our algorithm relies on a stochastic local search strategy using a novel probability distribution function with two strategies for picking variables, one based on available information and another purely random one. Moreover, while most previous algorithms based on WalkSAT choose unsatisfied clauses randomly, we introduce a novel clause selection strategy to improve our algorithm. Experimental results illustrate that ProMS outperforms many state-of-the-art stochastic local search solvers on hard unweighted random Max-SAT benchmarks. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.00689;Phase-Mapper: An AI Platform to Accelerate High Throughput Materials  Discovery; Yexiang Xue,  Junwen Bai,  Ronan Le Bras,  Brendan Rappazzo,  Richard Bernstein,  Johan Bjorck,  Liane Longpre,  Santosh K. Suram,  Robert B. van Dover,  John Gregoire,  Carla P. Gomes;  High-Throughput materials discovery involves the rapid synthesis, measurement, and characterization of many different but structurally-related materials. A key problem in materials discovery, the phase map identification problem, involves the determination of the crystal phase diagram from the materials' composition and structural characterization data. We present Phase-Mapper, a novel AI platform to solve the phase map identification problem that allows humans to interact with both the data and products of AI algorithms, including the incorporation of human feedback to constrain or initialize solutions. Phase-Mapper affords incorporation of any spectral demixing algorithm, including our novel solver, AgileFD, which is based on a convolutive non-negative matrix factorization algorithm. AgileFD can incorporate constraints to capture the physics of the materials as well as human feedback. We compare three solver variants with previously proposed methods in a large-scale experiment involving 20 synthetic systems, demonstrating the efficacy of imposing physical constrains using AgileFD. Phase-Mapper has also been used by materials scientists to solve a wide variety of phase diagrams, including the previously unsolved Nb-Mn-V oxide system, which is provided here as an illustrative example. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.00946;Micro-Data Learning: The Other End of the Spectrum; Jean-Baptiste Mouret (LORIA, LARSEN);  Many fields are now snowed under with an avalanche of data, which raises considerable challenges for computer scientists. Meanwhile, robotics (among other fields) can often only use a few dozen data points because acquiring them involves a process that is expensive or time-consuming. How can an algorithm learn with only a few data points? ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Robotics (cs.RO)"
https://arxiv.org/abs/1610.00976;A Constraint-Handling Technique for Genetic Algorithms using a Violation  Factor; Adam Chehouri,  Rafic Younes,  Jean Perron,  Adrian Ilinca (UQAR);  Over the years, several meta-heuristic algorithms were proposed and are now emerging as common methods for constrained optimization problems. Among them, genetic algorithms (GA's) shine as popular evolutionary algorithms (EA's) in engineering optimization. Most engineering design problems are difficult to resolve with conventional optimization algorithms because they are highly nonlinear and contain constraints. In order to handle these constraints, the most common technique is to apply penalty functions. The major drawback is that they require tuning of parameters, which can be very challenging. In this paper, we present a constraint-handling technique for GA's solely using the violation factor, called VCH (Violation Constraint-Handling) method. Several benchmark problems from the literature are examined. The VCH technique was able to provide a consistent performance and match results from other GA-based techniques. ;"Artificial Intelligence (cs.AI); Optimization and Control (math.OC)"
https://arxiv.org/abs/1610.01044;DeepAlgebra - an outline of a program; Przemyslaw Chojecki;  We outline a program in the area of formalization of mathematics to automate theorem proving in algebra and algebraic geometry. We propose a construction of a dictionary between automated theorem provers and (La)TeX exploiting syntactic parsers. We describe its application to a repository of human-written facts and definitions in algebraic geometry (The Stacks Project). We use deep learning techniques. ;"Artificial Intelligence (cs.AI); Algebraic Geometry (math.AG)"
https://arxiv.org/abs/1610.01085;Towards the Design of Prospect-Theory based Human Decision Rules for  Hypothesis Testing; V. Sriram Siddhardh Nadendla,  Swastik Brahma,  Pramod K. Varshney;  Detection rules have traditionally been designed for rational agents that minimize the Bayes risk (average decision cost). With the advent of crowd-sensing systems, there is a need to redesign binary hypothesis testing rules for behavioral agents, whose cognitive behavior is not captured by traditional utility functions such as Bayes risk. In this paper, we adopt prospect theory based models for decision makers. We consider special agent models namely optimists and pessimists in this paper, and derive optimal detection rules under different scenarios. Using an illustrative example, we also show how the decision rule of a human agent deviates from the Bayesian decision rule under various behavioral models, considered in this paper. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.01381;The Predictive Context Tree: Predicting Contexts and Interactions; Alasdair Thomason,  Nathan Griffiths,  Victor Sanchez;  With a large proportion of people carrying location-aware smartphones, we have an unprecedented platform from which to understand individuals and predict their future actions. This work builds upon the Context Tree data structure that summarises the historical contexts of individuals from augmented geospatial trajectories, and constructs a predictive model for their likely future contexts. The Predictive Context Tree (PCT) is constructed as a hierarchical classifier, capable of predicting both the future locations that a user will visit and the contexts that a user will be immersed within. The PCT is evaluated over real-world geospatial trajectories, and compared against existing location extraction and prediction techniques, as well as a proposed hybrid approach that uses identified land usage elements in combination with machine learning to predict future interactions. Our results demonstrate that higher predictive accuracies can be achieved using this hybrid approach over traditional extracted location datasets, and the PCT itself matches the performance of the hybrid approach at predicting future interactions, while adding utility in the form of context predictions. Such a prediction system is capable of understanding not only where a user will visit, but also their context, in terms of what they are likely to be doing. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.01476;$\ell_1$ Regularized Gradient Temporal-Difference Learning; Dominik Meyer,  Hao Shen,  Klaus Diepold;  In this paper, we study the Temporal Difference (TD) learning with linear value function approximation. It is well known that most TD learning algorithms are unstable with linear function approximation and off-policy learning. Recent development of Gradient TD (GTD) algorithms has addressed this problem successfully. However, the success of GTD algorithms requires a set of well chosen features, which are not always available. When the number of features is huge, the GTD algorithms might face the problem of overfitting and being computationally expensive. To cope with this difficulty, regularization techniques, in particular $\ell_1$ regularization, have attracted significant attentions in developing TD learning algorithms. The present work combines the GTD algorithms with $\ell_1$ regularization. We propose a family of $\ell_1$ regularized GTD algorithms, which employ the well known soft thresholding operator. We investigate convergence properties of the proposed algorithms, and depict their performance with several numerical experiments. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1610.01525;Lifted Message Passing for the Generalized Belief Propagation; Udi Apsel;  We introduce the lifted Generalized Belief Propagation (GBP) message passing algorithm, for the computation of sum-product queries in Probabilistic Relational Models (e.g. Markov logic network). The algorithm forms a compact region graph and establishes a modified version of message passing, which mimics the GBP behavior in a corresponding ground model. The compact graph is obtained by exploiting a graphical representation of clusters, which reduces cluster symmetry detection to isomorphism tests on small local graphs. The framework is thus capable of handling complex models, while remaining domain-size independent. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.01922;Adaptive Online Sequential ELM for Concept Drift Tackling; Arif Budiman,  Mohamad Ivan Fanany,  Chan Basaruddin;  A machine learning method needs to adapt to over time changes in the environment. Such changes are known as concept drift. In this paper, we propose concept drift tackling method as an enhancement of Online Sequential Extreme Learning Machine (OS-ELM) and Constructive Enhancement OS-ELM (CEOS-ELM) by adding adaptive capability for classification and regression problem. The scheme is named as adaptive OS-ELM (AOS-ELM). It is a single classifier scheme that works well to handle real drift, virtual drift, and hybrid drift. The AOS-ELM also works well for sudden drift and recurrent context change type. The scheme is a simple unified method implemented in simple lines of code. We evaluated AOS-ELM on regression and classification problem by using concept drift public data set (SEA and STAGGER) and other public data sets such as MNIST, USPS, and IDS. Experiments show that our method gives higher kappa value compared to the multiclassifier ELM ensemble. Even though AOS-ELM in practice does not need hidden nodes increase, we address some issues related to the increasing of the hidden nodes such as error condition and rank values. We propose taking the rank of the pseudoinverse matrix as an indicator parameter to detect underfitting condition. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.02293;Learning Macro-actions for State-Space Planning; Sandra Castellanos-Paez (LIG Laboratoire d'Informatique de Grenoble),  Damien Pellier (LIG Laboratoire d'Informatique de Grenoble),  Humbert Fiorino (LIG Laboratoire d'Informatique de Grenoble),  Sylvie Pesty (LIG Laboratoire d'Informatique de Grenoble);  Planning has achieved significant progress in recent years. Among the various approaches to scale up plan synthesis, the use of macro-actions has been widely explored. As a first stage towards the development of a solution to learn on-line macro-actions, we propose an algorithm to identify useful macro-actions based on data mining techniques. The integration in the planning search of these learned macro-actions shows significant improvements over four classical planning benchmarks. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.02348;Adaptive Convolutional ELM For Concept Drift Handling in Online Stream  Data; Arif Budiman,  Mohamad Ivan Fanany,  Chan Basaruddin;  In big data era, the data continuously generated and its distribution may keep changes overtime. These challenges in online stream of data are known as concept drift. In this paper, we proposed the Adaptive Convolutional ELM method (ACNNELM) as enhancement of Convolutional Neural Network (CNN) with a hybrid Extreme Learning Machine (ELM) model plus adaptive capability. This method is aimed for concept drift handling. We enhanced the CNN as convolutional hiererchical features representation learner combined with Elastic ELM (E$^2$LM) as a parallel supervised classifier. We propose an Adaptive OS-ELM (AOS-ELM) for concept drift adaptability in classifier level (named ACNNELM-1) and matrices concatenation ensembles for concept drift adaptability in ensemble level (named ACNNELM-2). Our proposed Adaptive CNNELM is flexible that works well in classifier level and ensemble level while most current methods only proposed to work on either one of the levels. We verified our method in extended MNIST data set and not MNIST data set. We set the experiment to simulate virtual drift, real drift, and hybrid drift event and we demonstrated how our CNNELM adaptability works. Our proposed method works well and gives better accuracy, computation scalability, and concept drifts adaptability compared to the regular ELM and CNN. Further researches are still required to study the optimum parameters and to use more varied image data set. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.02424;Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence  Models; Ashwin K Vijayakumar,  Michael Cogswell,  Ramprasath R. Selvaraju,  Qing Sun,  Stefan Lee,  David Crandall,  Dhruv Batra;  Neural sequence models are widely used to model time-series data in many fields. Equally ubiquitous is the usage of beam search (BS) as an approximate inference algorithm to decode output sequences from these models. BS explores the search space in a greedy left-right fashion retaining only the top-$B$ candidates -- resulting in sequences that differ only slightly from each other. Producing lists of nearly identical sequences is not only computationally wasteful but also typically fails to capture the inherent ambiguity of complex AI tasks. To overcome this problem, we propose \emph{Diverse Beam Search} (DBS), an alternative to BS that decodes a list of diverse outputs by optimizing for a diversity-augmented objective. We observe that our method finds better top-1 solutions by controlling for the exploration and exploitation of the search space -- implying that DBS is a \emph{better search algorithm}. Moreover, these gains are achieved with minimal computational or memory overhead as compared to beam search. To demonstrate the broad applicability of our method, we present results on image captioning, machine translation and visual question generation using both standard quantitative metrics and qualitative human studies. Our method consistently outperforms BS and previously proposed techniques for diverse decoding from neural sequence models. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1610.02591;Solving Marginal MAP Problems with NP Oracles and Parity Constraints; Yexiang Xue,  Zhiyuan Li,  Stefano Ermon,  Carla P. Gomes,  Bart Selman;  Arising from many applications at the intersection of decision making and machine learning, Marginal Maximum A Posteriori (Marginal MAP) Problems unify the two main classes of inference, namely maximization (optimization) and marginal inference (counting), and are believed to have higher complexity than both of them. We propose XOR_MMAP, a novel approach to solve the Marginal MAP Problem, which represents the intractable counting subproblem with queries to NP oracles, subject to additional parity constraints. XOR_MMAP provides a constant factor approximation to the Marginal MAP Problem, by encoding it as a single optimization in polynomial size of the original problem. We evaluate our approach in several machine learning and decision making applications, and show that our approach outperforms several state-of-the-art Marginal MAP solvers. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.02707;Multi-Objective Deep Reinforcement Learning; Hossam Mossalam,  Yannis M. Assael,  Diederik M. Roijers,  Shimon Whiteson;  We propose Deep Optimistic Linear Support Learning (DOL) to solve high-dimensional multi-objective decision problems where the relative importances of the objectives are not known a priori. Using features from the high-dimensional inputs, DOL computes the convex coverage set containing all potential optimal solutions of the convex combinations of the objectives. To our knowledge, this is the first time that deep reinforcement learning has succeeded in learning multi-objective policies. In addition, we provide a testbed with two experiments to be used as a benchmark for deep multi-objective reinforcement learning. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.02828;Ranking academic institutions on potential paper acceptance in upcoming  conferences; Jobin Wilson,  Ram Mohan,  Muhammad Arif,  Santanu Chaudhury,  Brejesh Lall;  The crux of the problem in KDD Cup 2016 involves developing data mining techniques to rank research institutions based on publications. Rank importance of research institutions are derived from predictions on the number of full research papers that would potentially get accepted in upcoming top-tier conferences, utilizing public information on the web. This paper describes our solution to KDD Cup 2016. We used a two step approach in which we first identify full research papers corresponding to each conference of interest and then train two variants of exponential smoothing models to make predictions. Our solution achieves an overall score of 0.7508, while the winning submission scored 0.7656 in the overall results. ;"Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Learning (cs.LG)"
https://arxiv.org/abs/1610.02847;Situational Awareness by Risk-Conscious Skills; Daniel J. Mankowitz,  Aviv Tamar,  Shie Mannor;  Hierarchical Reinforcement Learning has been previously shown to speed up the convergence rate of RL planning algorithms as well as mitigate feature-based model misspecification (Mankowitz et. al. 2016a,b, Bacon 2015). To do so, it utilizes hierarchical abstractions, also known as skills -- a type of temporally extended action (Sutton et. al. 1999) to plan at a higher level, abstracting away from the lower-level details. We incorporate risk sensitivity, also referred to as Situational Awareness (SA), into hierarchical RL for the first time by defining and learning risk aware skills in a Probabilistic Goal Semi-Markov Decision Process (PG-SMDP). This is achieved using our novel Situational Awareness by Risk-Conscious Skills (SARiCoS) algorithm which comes with a theoretical convergence guarantee. We show in a RoboCup soccer domain that the learned risk aware skills exhibit complex human behaviors such as `time-wasting' in a soccer game. In addition, the learned risk aware skills are able to mitigate reward-based model misspecification. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.02891;Personalizing a Dialogue System with Transfer Reinforcement Learning; Kaixiang Mo,  Shuangyin Li,  Yu Zhang,  Jiajun Li,  Qiang Yang;"  It is difficult to train a personalized task-oriented dialogue system because the data collected from each individual is often insufficient. Personalized dialogue systems trained on a small dataset can overfit and make it difficult to adapt to different user needs. One way to solve this problem is to consider a collection of multiple users' data as a source domain and an individual user's data as a target domain, and to perform a transfer learning from the source to the target domain. By following this idea, we propose ""PETAL""(PErsonalized Task-oriented diALogue), a transfer-learning framework based on POMDP to learn a personalized dialogue system. The system first learns common dialogue knowledge from the source domain and then adapts this knowledge to the target user. This framework can avoid the negative transfer problem by considering differences between source and target users. The policy in the personalized POMDP can learn to choose different actions appropriately for different users. Experimental results on a real-world coffee-shopping data and simulation data show that our personalized dialogue system can choose different optimal actions for different users, and thus effectively improve the dialogue quality under the personalized setting. ";"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Learning (cs.LG)"
https://arxiv.org/abs/1610.03024;ABA+: Assumption-Based Argumentation with Preferences; Kristijonas Čyras,  Francesca Toni;  We present ABA+, a new approach to handling preferences in a well known structured argumentation formalism, Assumption-Based Argumentation (ABA). In ABA+, preference information given over assumptions is incorporated directly into the attack relation, thus resulting in attack reversal. ABA+ conservatively extends ABA and exhibits various desirable features regarding relationship among argumentation semantics as well as preference handling. We also introduce Weak Contraposition, a principle concerning reasoning with rules and preferences that relaxes the standard principle of contraposition, while guaranteeing additional desirable features for ABA+. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.03138;PCG-Based Game Design Patterns; Michael Cook,  Mirjam Eladhari,  Andy Nealen,  Mike Treanor,  Eddy Boxerman,  Alex Jaffe,  Paul Sottosanti,  Steve Swink;  People enjoy encounters with generative software, but rarely are they encouraged to interact with, understand or engage with it. In this paper we define the term 'PCG-based game', and explain how this concept follows on from the idea of an AI-based game. We look at existing examples of games which foreground their AI, put forward a methodology for designing PCG-based games, describe some example case study designs for PCG-based games, and describe lessons learned during this process of sketching and developing ideas. ;"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1610.03263;Error Asymmetry in Causal and Anticausal Regression; Patrick Blöbaum,  Takashi Washio,  Shohei Shimizu;  It is generally difficult to make any statements about the expected prediction error in an univariate setting without further knowledge about how the data were generated. Recent work showed that knowledge about the real underlying causal structure of a data generation process has implications for various machine learning settings. Assuming an additive noise and an independence between data generating mechanism and its input, we draw a novel connection between the intrinsic causal relationship of two variables and the expected prediction error. We formulate the theorem that the expected error of the true data generating function as prediction model is generally smaller when the effect is predicted from its cause and, on the contrary, greater when the cause is predicted from its effect. The theorem implies an asymmetry in the error depending on the prediction direction. This is further corroborated with empirical evaluations in artificial and real-world data sets. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.03295;Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving; Shai Shalev-Shwartz,  Shaked Shammah,  Amnon Shashua;"  Autonomous driving is a multi-agent setting where the host vehicle must apply sophisticated negotiation skills with other road users when overtaking, giving way, merging, taking left and right turns and while pushing ahead in unstructured urban roadways. Since there are many possible scenarios, manually tackling all possible cases will likely yield a too simplistic policy. Moreover, one must balance between unexpected behavior of other drivers/pedestrians and at the same time not to be too defensive so that normal traffic flow is maintained. In this paper we apply deep reinforcement learning to the problem of forming long term driving strategies. We note that there are two major challenges that make autonomous driving different from other robotic tasks. First, is the necessity for ensuring functional safety - something that machine learning has difficulty with given that performance is optimized at the level of an expectation over many instances. Second, the Markov Decision Process model often used in robotics is problematic in our case because of unpredictable behavior of other agents in this multi-agent scenario. We make three contributions in our work. First, we show how policy gradient iterations can be used without Markovian assumptions. Second, we decompose the problem into a composition of a Policy for Desires (which is to be learned) and trajectory planning with hard constraints (which is not learned). The goal of Desires is to enable comfort of driving, while hard constraints guarantees the safety of driving. Third, we introduce a hierarchical temporal abstraction we call an ""Option Graph"" with a gating mechanism that significantly reduces the effective horizon and thereby reducing the variance of the gradient estimation even further. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.03573;A Chain-Detection Algorithm for Two-Dimensional Grids; Paul Bonham,  Azlan Iqbal;  We describe a general method of detecting valid chains or links of pieces on a two-dimensional grid. Specifically, using the example of the chess variant known as Switch-Side Chain-Chess (SSCC). Presently, no foolproof method of detecting such chains in any given chess position is known and existing graph theory, to our knowledge, is unable to fully address this problem either. We therefore propose a solution implemented and tested using the C++ programming language. We have been unable to find an incorrect result and therefore offer it as the most viable solution thus far to the chain-detection problem in this chess variant. The algorithm is also scalable, in principle, to areas beyond two-dimensional grids such as 3D analysis and molecular chemistry. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.03606;Maximum entropy models for generation of expressive music; Simon Moulieras,  François Pachet;  In the context of contemporary monophonic music, expression can be seen as the difference between a musical performance and its symbolic representation, i.e. a musical score. In this paper, we show how Maximum Entropy (MaxEnt) models can be used to generate musical expression in order to mimic a human performance. As a training corpus, we had a professional pianist play about 150 melodies of jazz, pop, and latin jazz. The results show a good predictive power, validating the choice of our model. Additionally, we set up a listening test whose results reveal that on average, people significantly prefer the melodies generated by the MaxEnt model than the ones without any expression, or with fully random expression. Furthermore, in some cases, MaxEnt melodies are almost as popular as the human performed ones. ;"Artificial Intelligence (cs.AI); Sound (cs.SD)"
https://arxiv.org/abs/1610.04005;Stream Reasoning-Based Control of Caching Strategies in CCN Routers; Harald Beck,  Bruno Bierbaumer,  Minh Dao-Tran,  Thomas Eiter,  Hermann Hellwagner,  Konstantin Schekotihin;  Content-Centric Networking (CCN) research addresses the mismatch between the modern usage of the Internet and its outdated architecture. Importantly, CCN routers may locally cache frequently requested content in order to speed up delivery to end users. Thus, the issue of caching strategies arises, i.e., which content shall be stored and when it should be replaced. In this work, we employ novel techniques towards intelligent administration of CCN routers that autonomously switch between existing strategies in response to changing content request patterns. In particular, we present a router architecture for CCN networks that is controlled by rule-based stream reasoning, following the recent formal framework LARS which extends Answer Set Programming for streams. The obtained possibility for flexible router configuration at runtime allows for faster experimentation and may thus help to advance the further development of CCN. Moreover, the empirical evaluation of our feasibility study shows that the resulting caching agent may give significant performance gains. ;"Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1610.04028;A fuzzy expert system for earthquake prediction, case study: the Zagros  range; Arash Andalib,  Mehdi Zare,  Farid Atry;  A methodology for the development of a fuzzy expert system (FES) with application to earthquake prediction is presented. The idea is to reproduce the performance of a human expert in earthquake prediction. To do this, at the first step, rules provided by the human expert are used to generate a fuzzy rule base. These rules are then fed into an inference engine to produce a fuzzy inference system (FIS) and to infer the results. In this paper, we have used a Sugeno type fuzzy inference system to build the FES. At the next step, the adaptive network-based fuzzy inference system (ANFIS) is used to refine the FES parameters and improve its performance. The proposed framework is then employed to attain the performance of a human expert used to predict earthquakes in the Zagros area based on the idea of coupled earthquakes. While the prediction results are promising in parts of the testing set, the general performance indicates that prediction methodology based on coupled earthquakes needs more investigation and more complicated reasoning procedure to yield satisfactory predictions. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.04073;Improved Knowledge Base Completion by Path-Augmented TransR Model; Wenhao Huang,  Ge Li,  Zhi Jin;  Knowledge base completion aims to infer new relations from existing information. In this paper, we propose path-augmented TransR (PTransR) model to improve the accuracy of link prediction. In our approach, we base PTransR model on TransR, which is the best one-hop model at present. Then we regularize TransR with information of relation paths. In our experiment, we evaluate PTransR on the task of entity prediction. Experimental results show that PTransR outperforms previous models. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.04120;Exploiting Sentence and Context Representations in Deep Neural Models  for Spoken Language Understanding; Lina M. Rojas Barahona,  Milica Gasic,  Nikola Mrkšić,  Pei-Hao Su,  Stefan Ultes,  Tsung-Hsien Wen,  Steve Young;  This paper presents a deep learning architecture for the semantic decoder component of a Statistical Spoken Dialogue System. In a slot-filling dialogue, the semantic decoder predicts the dialogue act and a set of slot-value pairs from a set of n-best hypotheses returned by the Automatic Speech Recognition. Most current models for spoken language understanding assume (i) word-aligned semantic annotations as in sequence taggers and (ii) delexicalisation, or a mapping of input words to domain-specific concepts using heuristics that try to capture morphological variation but that do not scale to other domains nor to language variation (e.g., morphology, synonyms, paraphrasing ). In this work the semantic decoder is trained using unaligned semantic annotations and it uses distributed semantic representation learning to overcome the limitations of explicit delexicalisation. The proposed architecture uses a convolutional neural network for the sentence representation and a long-short term memory network for the context representation. Results are presented for the publicly available DSTC2 corpus and an In-car corpus which is similar to DSTC2 but has a significantly higher word error rate (WER). ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.04154;An Information Theoretic Feature Selection Framework for Big Data under  Apache Spark; Sergio Ramírez-Gallego,  Héctor Mouriño-Talín,  David Martínez-Rego,  Verónica Bolón-Canedo,  José Manuel Benítez,  Amparo Alonso-Betanzos,  Francisco Herrera;  With the advent of extremely high dimensional datasets, dimensionality reduction techniques are becoming mandatory. Among many techniques, feature selection has been growing in interest as an important tool to identify relevant features on huge datasets --both in number of instances and features--. The purpose of this work is to demonstrate that standard feature selection methods can be parallelized in Big Data platforms like Apache Spark, boosting both performance and accuracy. We thus propose a distributed implementation of a generic feature selection framework which includes a wide group of well-known Information Theoretic methods. Experimental results on a wide set of real-world datasets show that our distributed framework is capable of dealing with ultra-high dimensional datasets as well as those with a huge number of samples in a short period of time, outperforming the sequential version in all the cases studied. ;"Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Learning (cs.LG)"
https://arxiv.org/abs/1610.04872;Fault Detection Engine in Intelligent Predictive Analytics Platform for  DCIM; Bodhisattwa Prasad Majumder,  Ayan Sengupta,  Sajal jain,  Parikshit Bhaduri;  With the advancement of huge data generation and data handling capability, Machine Learning and Probabilistic modelling enables an immense opportunity to employ predictive analytics platform in high security critical industries namely data centers, electricity grids, utilities, airport etc. where downtime minimization is one of the primary objectives. This paper proposes a novel, complete architecture of an intelligent predictive analytics platform, Fault Engine, for huge device network connected with electrical/information flow. Three unique modules, here proposed, seamlessly integrate with available technology stack of data handling and connect with middleware to produce online intelligent prediction in critical failure scenarios. The Markov Failure module predicts the severity of a failure along with survival probability of a device at any given instances. The Root Cause Analysis model indicates probable devices as potential root cause employing Bayesian probability assignment and topological sort. Finally, a community detection algorithm produces correlated clusters of device in terms of failure probability which will further narrow down the search space of finding route cause. The whole Engine has been tested with different size of network with simulated failure environments and shows its potential to be scalable in real-time implementation. ;"Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)"
https://arxiv.org/abs/1610.04964;Improvements in Sub-optimal Solving of the $(N^2-1)$-Puzzle via Joint  Relocation of Pebbles and its Applications to Rule-based Cooperative  Path-Finding; Pavel Surynek,  Petr Michalík;  The problem of solving $(n^2-1)$-puzzle and cooperative path-finding (CPF) sub-optimally by rule based algorithms is addressed in this manuscript. The task in the puzzle is to rearrange $n^2-1$ pebbles on the square grid of the size of n x n using one vacant position to a desired goal configuration. An improvement to the existent polynomial-time algorithm is proposed and experimentally analyzed. The improved algorithm is trying to move pebbles in a more efficient way than the original algorithm by grouping them into so-called snakes and moving them jointly within the snake. An experimental evaluation showed that the algorithm using snakes produces solutions that are 8% to 9% shorter than solutions generated by the original algorithm. The snake-based relocation has been also integrated into rule-based algorithms for solving the CPF problem sub-optimally, which is a closely related task. The task in CPF is to relocate a group of abstract robots that move over an undirected graph to given goal vertices. Robots can move to unoccupied neighboring vertices and at most one robot can be placed in each vertex. The $(n^2-1)$-puzzle is a special case of CPF where the underlying graph is represented by a 4-connected grid and there is only one vacant vertex. Two major rule-based algorithms for CPF were included in our study - BIBOX and PUSH-and-SWAP (PUSH-and-ROTATE). Improvements gained by using snakes in the BIBOX algorithm were stable around 30% in $(n^2-1)$-puzzle solving and up to 50% in CPFs over bi-connected graphs with various ear decompositions and multiple vacant vertices. In the case of the PUSH-and-SWAP algorithm the improvement achieved by snakes was around 5% to 8%. However, the improvement was unstable and hardly predictable in the case of PUSH-and-SWAP. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.05287;Internet of Things Applications: Animal Monitoring with Unmanned Aerial  Vehicle; Jun Xu,  Gurkan Solmaz,  Rouhollah Rahmatizadeh,  Damla Turgut,  Ladislau Boloni;  In animal monitoring applications, both animal detection and their movement prediction are major tasks. While a variety of animal monitoring strategies exist, most of them rely on mounting devices. However, in real world, it is difficult to find these animals and install mounting devices. In this paper, we propose an animal monitoring application by utilizing wireless sensor networks (WSNs) and unmanned aerial vehicle (UAV). The objective of the application is to detect locations of endangered species in large-scale wildlife areas and monitor movement of animals without any attached devices. In this application, sensors deployed throughout the observation area are responsible for gathering animal information. The UAV flies above the observation area and collects the information from sensors. To achieve the information efficiently, we propose a path planning approach for the UAV based on a Markov decision process (MDP) model. The UAV receives a certain amount of reward from an area if some animals are detected at that location. We solve the MDP using Q-learning such that the UAV prefers going to those areas that animals are detected before. Meanwhile, the UAV explores other areas as well to cover the entire network and detects changes in the animal positions. We first define the mathematical model underlying the animal monitoring problem in terms of the value of information (VoI) and rewards. We propose a network model including clusters of sensor nodes and a single UAV that acts as a mobile sink and visits the clusters. Then, one MDP-based path planning approach is designed to maximize the VoI while reducing message delays. The effectiveness of the proposed approach is evaluated using two real-world movement datasets of zebras and leopard. Simulation results show that our approach outperforms greedy, random heuristics and the path planning based on the traveling salesman problem. ;"Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1610.05402;VRPBench: A Vehicle Routing Benchmark Tool; Guilherme A. Zeni,  Mauro Menzori,  P. S. Martins,  Luis A. A. Meira;  The number of optimization techniques in the combinatorial domain is large and diversified. Nevertheless, there is still a lack of real benchmarks to validate optimization algorithms. In this work we introduce VRPBench, a tool to create instances and visualize solutions to the Vehicle Routing Problem (VRP) in a planar graph embedded in the Euclidean 2D space. We use VRPBench to model a real-world mail delivery case of the city of Artur Nogueira. Such scenarios were characterized as a multi-objective optimization of the VRP. We extracted a weighted graph from a digital map of the city to create a challenging benchmark for the VRP. Each instance models one generic day of mail delivery with hundreds to thousands of delivery points, thus allowing both the comparison and validation of optimization algorithms for routing problems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.05452;Makespan Optimal Solving of Cooperative Path-Finding via Reductions to  Propositional Satisfiability; Pavel Surynek;  The problem of makespan optimal solving of cooperative path finding (CPF) is addressed in this paper. The task in CPF is to relocate a group of agents in a non-colliding way so that each agent eventually reaches its goal location from the given initial location. The abstraction adopted in this work assumes that agents are discrete items moving in an undirected graph by traversing edges. Makespan optimal solving of CPF means to generate solutions that are as short as possi-ble in terms of the total number of time steps required for the execution of the solution. We show that reducing CPF to propositional satisfiability (SAT) represents a viable option for obtaining makespan optimal solutions. Several encodings of CPF into propositional formulae are suggested and experimentally evaluated. The evaluation indicates that SAT based CPF solving outperforms other makespan optimal methods significantly in highly constrained situations (environments that are densely occupied by agents). ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.05521;Diagnosis of aerospace structure defects by a HPC implemented soft  computing algorithm; Gianni D'Angelo,  Salvatore Rampone;  This study concerns with the diagnosis of aerospace structure defects by applying a HPC parallel implementation of a novel learning algorithm, named U-BRAIN. The Soft Computing approach allows advanced multi-parameter data processing in composite materials testing. The HPC parallel implementation overcomes the limits due to the great amount of data and the complexity of data processing. Our experimental results illustrate the effectiveness of the U-BRAIN parallel implementation as defect classifier in aerospace structures. The resulting system is implemented on a Linux-based cluster with multi-core architecture. ;"Artificial Intelligence (cs.AI); Data Analysis, Statistics and Probability (physics.data-an)"
https://arxiv.org/abs/1610.05551;Weighted Positive Binary Decision Diagrams for Exact Probabilistic  Inference; Giso H. Dal,  Peter J.F. Lucas;  Recent work on weighted model counting has been very successfully applied to the problem of probabilistic inference in Bayesian networks. The probability distribution is encoded into a Boolean normal form and compiled to a target language, in order to represent local structure expressed among conditional probabilities more efficiently. We show that further improvements are possible, by exploiting the knowledge that is lost during the encoding phase and incorporating it into a compiler inspired by Satisfiability Modulo Theories. Constraints among variables are used as a background theory, which allows us to optimize the Shannon decomposition. We propose a new language, called Weighted Positive Binary Decision Diagrams, that reduces the cost of probabilistic inference by using this decomposition variant to induce an arithmetic circuit of reduced size. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1610.05556;Identifiability and Transportability in Dynamic Causal Networks; Gilles Blondel,  Marta Arias,  Ricard Gavaldà;  In this paper we propose a causal analog to the purely observational Dynamic Bayesian Networks, which we call Dynamic Causal Networks. We provide a sound and complete algorithm for identification of Dynamic Causal Net- works, namely, for computing the effect of an intervention or experiment, based on passive observations only, whenever possible. We note the existence of two types of confounder variables that affect in substantially different ways the iden- tification procedures, a distinction with no analog in either Dynamic Bayesian Networks or standard causal graphs. We further propose a procedure for the transportability of causal effects in Dynamic Causal Network settings, where the re- sult of causal experiments in a source domain may be used for the identification of causal effects in a target domain. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.05612;Census Signal Temporal Logic Inference for Multi-Agent Group Behavior  Analysis; Zhe Xu,  Agung Julius;"  In this paper, we define a novel census signal temporal logic (CensusSTL) that focuses on the number of agents in different subsets of a group that complete a certain task specified by the signal temporal logic (STL). CensusSTL consists of an ""inner logic"" STL formula and an ""outer logic"" STL formula. We present a new inference algorithm to infer CensusSTL formulae from the trajectory data of a group of agents. We first identify the ""inner logic"" STL formula and then infer the subgroups based on whether the agents' behaviors satisfy the ""inner logic"" formula at each time point. We use two different approaches to infer the subgroups based on similarity and complementarity, respectively. The ""outer logic"" CensusSTL formula is inferred from the census trajectories of different subgroups. We apply the algorithm in analyzing data from a soccer match by inferring the CensusSTL formula for different subgroups of a soccer team. ";"Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Logic (math.LO); Optimization and Control (math.OC)"
https://arxiv.org/abs/1610.05735;Deep Amortized Inference for Probabilistic Programs; Daniel Ritchie,  Paul Horsfall,  Noah D. Goodman;"  Probabilistic programming languages (PPLs) are a powerful modeling tool, able to represent any computable probability distribution. Unfortunately, probabilistic program inference is often intractable, and existing PPLs mostly rely on expensive, approximate sampling-based methods. To alleviate this problem, one could try to learn from past inferences, so that future inferences run faster. This strategy is known as amortized inference; it has recently been applied to Bayesian networks and deep generative models. This paper proposes a system for amortized inference in PPLs. In our system, amortization comes in the form of a parameterized guide program. Guide programs have similar structure to the original program, but can have richer data flow, including neural network components. These networks can be optimized so that the guide approximately samples from the posterior distribution defined by the original program. We present a flexible interface for defining guide programs and a stochastic gradient-based scheme for optimizing guide parameters, as well as some preliminary results on automatically deriving guide programs. We explore in detail the common machine learning pattern in which a 'local' model is specified by 'global' random values and used to generate independent observed data points; this gives rise to amortized local inference supporting global model learning. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.06009;Constrained Cohort Intelligence using Static and Dynamic Penalty  Function Approach for Mechanical Components Design; Omkar Kulkarni,  Ninad Kulkarni,  Anand J Kulkarni,  Ganesh Kakandikar;"  Most of the metaheuristics can efficiently solve unconstrained problems; however, their performance may degenerate if the constraints are involved. This paper proposes two constraint handling approaches for an emerging metaheuristic of Cohort Intelligence (CI). More specifically CI with static penalty function approach (SCI) and CI with dynamic penalty function approach (DCI) are proposed. The approaches have been tested by solving several constrained test problems. The performance of the SCI and DCI have been compared with algorithms like GA, PSO, ABC, d-Ds. In addition, as well as three real world problems from mechanical engineering domain with improved solutions. The results were satisfactory and validated the applicability of CI methodology for solving real world problems. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.06402;A Growing Long-term Episodic & Semantic Memory; Marc Pickett,  Rami Al-Rfou,  Louis Shao,  Chris Tar;  The long-term memory of most connectionist systems lies entirely in the weights of the system. Since the number of weights is typically fixed, this bounds the total amount of knowledge that can be learned and stored. Though this is not normally a problem for a neural network designed for a specific task, such a bound is undesirable for a system that continually learns over an open range of domains. To address this, we describe a lifelong learning system that leverages a fast, though non-differentiable, content-addressable memory which can be exploited to encode both a long history of sequential episodic knowledge and semantic knowledge over many episodes for an unbounded number of domains. This opens the door for investigation into transfer learning, and leveraging prior knowledge that has been learned over a lifetime of experiences to new domains. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.06473;Generalized Interval-valued OWA Operators with Interval Weights Derived  from Interval-valued Overlap Functions; Benjamin Bedregal,  Humberto Bustince,  Eduardo Palmeira,  Graçaliz Pereira Dimuro,  Javier Fernandez;  In this work we extend to the interval-valued setting the notion of an overlap functions and we discuss a method which makes use of interval-valued overlap functions for constructing OWA operators with interval-valued weights. . Some properties of interval-valued overlap functions and the derived interval-valued OWA operators are analysed. We specially focus on the homogeneity and migrativity properties. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.06483;An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm; Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Daria S. Kopaliani;  A modification of the neo-fuzzy neuron is proposed (an extended neo-fuzzy neuron (ENFN)) that is characterized by improved approximating properties. An adaptive learning algorithm is proposed that has both tracking and smoothing properties. An ENFN distinctive feature is its computational simplicity compared to other artificial neural networks and neuro-fuzzy systems. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.06484;An Evolving Cascade System Based on A Set Of Neo Fuzzy Nodes; Zhengbing Hu,  Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Olena O. Boiko;  Neo-fuzzy elements are used as nodes for an evolving cascade system. The proposed system can tune both its parameters and architecture in an online mode. It can be used for solving a wide range of Data Mining tasks (namely time series forecasting). The evolving cascade system with neo-fuzzy nodes can process rather large data sets with high speed and effectiveness. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.06485;A Multidimensional Cascade Neuro-Fuzzy System with Neuron Pool  Optimization in Each Cascade; Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Daria S. Kopaliani;  A new architecture and learning algorithms for the multidimensional hybrid cascade neural network with neuron pool optimization in each cascade are proposed in this paper. The proposed system differs from the well-known cascade systems in its capability to process multidimensional time series in an online mode, which makes it possible to process non-stationary stochastic and chaotic signals with the required accuracy. Compared to conventional analogs, the proposed system provides computational simplicity and possesses both tracking and filtering capabilities. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.06486;Adaptive Forecasting of Non-Stationary Nonlinear Time Series Based on  the Evolving Weighted Neuro-Neo-Fuzzy-ANARX-Model; Zhengbing Hu,  Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Olena O. Boiko;  An evolving weighted neuro-neo-fuzzy-ANARX model and its learning procedures are introduced in the article. This system is basically used for time series forecasting. This system may be considered as a pool of elements that process data in a parallel manner. The proposed evolving system may provide online processing data streams. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.06488;An Evolving Neuro-Fuzzy System with Online Learning/Self-learning; Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Anastasiia O. Deineko;  An architecture of a new neuro-fuzzy system is proposed. The basic idea of this approach is to tune both synaptic weights and membership functions with the help of the supervised learning and self-learning paradigms. The approach to solving the problem has to do with evolving online neuro-fuzzy systems that can process data under uncertainty conditions. The results prove the effectiveness of the developed architecture and the learning procedure. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.06490;An Ensemble of Adaptive Neuro-Fuzzy Kohonen Networks for Online Data  Stream Fuzzy Clustering; Zhengbing Hu,  Yevgeniy V. Bodyanskiy,  Oleksii K. Tyshchenko,  Olena O. Boiko;  A new approach to data stream clustering with the help of an ensemble of adaptive neuro-fuzzy systems is proposed. The proposed ensemble is formed with adaptive neuro-fuzzy self-organizing Kohonen maps in a parallel processing mode. A final result is chosen by the best neuro-fuzzy self-organizing Kohonen map. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.06912;KGEval: Estimating Accuracy of Automatically Constructed Knowledge  Graphs; Prakhar Ojha,  Partha Talukdar;  Automatic construction of large knowledge graphs (KG) by mining web-scale text datasets has received considerable attention recently. Estimating accuracy of such automatically constructed KGs is a challenging problem due to their size and diversity. This important problem has largely been ignored in prior research we fill this gap and propose KGEval. KGEval binds facts of a KG using coupling constraints and crowdsources the facts that infer correctness of large parts of the KG. We demonstrate that the objective optimized by KGEval is submodular and NP-hard, allowing guarantees for our approximation algorithm. Through extensive experiments on real-world datasets, we demonstrate that KGEval is able to estimate KG accuracy more accurately compared to other competitive baselines, while requiring significantly lesser number of human evaluations. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.06940;Safety Verification of Deep Neural Networks; Xiaowei Huang,  Marta Kwiatkowska,  Sen Wang,  Min Wu;  Deep neural networks have achieved impressive experimental results in image classification, but can surprisingly be unstable with respect to adversarial perturbations, that is, minimal changes to the input image that cause the network to misclassify it. With potential applications including perception modules and end-to-end controllers for self-driving cars, this raises concerns about their safety. We develop a novel automated verification framework for feed-forward multi-layer neural networks based on Satisfiability Modulo Theory (SMT). We focus on safety of image classification decisions with respect to image manipulations, such as scratches or changes to camera angle or lighting conditions that would result in the same class being assigned by a human, and define safety for an individual decision in terms of invariance of the classification within a small neighbourhood of the original image. We enable exhaustive search of the region by employing discretisation, and propagate the analysis layer by layer. Our method works directly with the network code and, in contrast to existing methods, can guarantee that adversarial examples, if they exist, are found for the given region and family of manipulations. If found, adversarial examples can be shown to human testers and/or used to fine-tune the network. We implement the techniques using Z3 and evaluate them on state-of-the-art networks, including regularised and deep learning networks. We also compare against existing techniques to search for adversarial examples and estimate network robustness. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.06972;Learning Cost-Effective Treatment Regimes using Markov Decision  Processes; Himabindu Lakkaraju,  Cynthia Rudin;  Decision makers, such as doctors and judges, make crucial decisions such as recommending treatments to patients, and granting bails to defendants on a daily basis. Such decisions typically involve weighting the potential benefits of taking an action against the costs involved. In this work, we aim to automate this task of learning \emph{cost-effective, interpretable and actionable treatment regimes}. We formulate this as a problem of learning a decision list -- a sequence of if-then-else rules -- which maps characteristics of subjects (eg., diagnostic test results of patients) to treatments. We propose a novel objective to construct a decision list which maximizes outcomes for the population, and minimizes overall costs. We model the problem of learning such a list as a Markov Decision Process (MDP) and employ a variant of the Upper Confidence Bound for Trees (UCT) strategy which leverages customized checks for pruning the search space effectively. Experimental results on real world observational data capturing judicial bail decisions and treatment recommendations for asthma patients demonstrate the effectiveness of our approach. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.07045;p-Causality: Identifying Spatiotemporal Causal Pathways for Air  Pollutants with Urban Big Data; Julie Yixuan Zhu,  Chao Zhang,  Shi Zhi,  Victor O.K. Li,  Jiawei Han,  Yu Zheng;"  Many countries are suffering from severe air pollution. Understanding how different air pollutants accumulate and propagate is critical to making relevant public policies. In this paper, we use urban big data (air quality data and meteorological data) to identify the \emph{spatiotemporal (ST) causal pathways} for air pollutants. This problem is challenging because: (1) there are numerous noisy and low-pollution periods in the raw air quality data, which may lead to unreliable causality analysis, (2) for large-scale data in the ST space, the computational complexity of constructing a causal structure is very high, and (3) the \emph{ST causal pathways} are complex due to the interactions of multiple pollutants and the influence of environmental factors. Therefore, we present \emph{p-Causality}, a novel pattern-aided causality analysis approach that combines the strengths of \emph{pattern mining} and \emph{Bayesian learning} to efficiently and faithfully identify the \emph{ST causal pathways}. First, \emph{Pattern mining} helps suppress the noise by capturing frequent evolving patterns (FEPs) of each monitoring sensor, and greatly reduce the complexity by selecting the pattern-matched sensors as ""causers"". Then, \emph{Bayesian learning} carefully encodes the local and ST causal relations with a Gaussian Bayesian network (GBN)-based graphical model, which also integrates environmental influences to minimize biases in the final results. We evaluate our approach with three real-world data sets containing 982 air quality sensors, in three regions of China from 01-Jun-2013 to 19-Dec-2015. Results show that our approach outperforms the traditional causal structure learning methods in time efficiency, inference accuracy and interpretability. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.07089;Reinforcement Learning in Conflicting Environments for Autonomous  Vehicles; Dominik Meyer,  Johannes Feldmaier,  Hao Shen;  In this work, we investigate the application of Reinforcement Learning to two well known decision dilemmas, namely Newcomb's Problem and Prisoner's Dilemma. These problems are exemplary for dilemmas that autonomous agents are faced with when interacting with humans. Furthermore, we argue that a Newcomb-like formulation is more adequate in the human-machine interaction case and demonstrate empirically that the unmodified Reinforcement Learning algorithms end up with the well known maximum expected utility solution. ;"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Robotics (cs.RO)"
https://arxiv.org/abs/1610.07388;Characterization of an inconsistency ranking for pairwise comparison  matrices; László Csató;  Pairwise comparisons between alternatives are a well-known method for measuring preferences of a decision-maker. Since these often do not exhibit consistency, a number of inconsistency indices has been introduced in order to measure the deviation from this ideal case. We axiomatically characterize the inconsistency ranking induced by the Koczkodaj inconsistency index: six independent properties are presented such that they determine a unique linear order on the set of all pairwise comparison matrices. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.07432;Virtual Embodiment: A Scalable Long-Term Strategy for Artificial  Intelligence Research; Douwe Kiela,  Luana Bulat,  Anita L. Vero,  Stephen Clark;"  Meaning has been called the ""holy grail"" of a variety of scientific disciplines, ranging from linguistics to philosophy, psychology and the neurosciences. The field of Artifical Intelligence (AI) is very much a part of that list: the development of sophisticated natural language semantics is a sine qua non for achieving a level of intelligence comparable to humans. Embodiment theories in cognitive science hold that human semantic representation depends on sensori-motor experience; the abundant evidence that human meaning representation is grounded in the perception of physical reality leads to the conclusion that meaning must depend on a fusion of multiple (perceptual) modalities. Despite this, AI research in general, and its subdisciplines such as computational linguistics and computer vision in particular, have focused primarily on tasks that involve a single modality. Here, we propose virtual embodiment as an alternative, long-term strategy for AI research that is multi-modal in nature and that allows for the kind of scalability required to develop the field coherently and incrementally, in an ethically responsible fashion. ";"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1610.07505;Balancing Suspense and Surprise: Timely Decision Making with Endogenous  Information Acquisition; Ahmed M. Alaa,  Mihaela van der Schaar;"  We develop a Bayesian model for decision-making under time pressure with endogenous information acquisition. In our model, the decision maker decides when to observe (costly) information by sampling an underlying continuous-time stochastic process (time series) that conveys information about the potential occurrence or non-occurrence of an adverse event which will terminate the decision-making process. In her attempt to predict the occurrence of the adverse event, the decision-maker follows a policy that determines when to acquire information from the time series (continuation), and when to stop acquiring information and make a final prediction (stopping). We show that the optimal policy has a rendezvous structure, i.e. a structure in which whenever a new information sample is gathered from the time series, the optimal ""date"" for acquiring the next sample becomes computable. The optimal interval between two information samples balances a trade-off between the decision maker's surprise, i.e. the drift in her posterior belief after observing new information, and suspense, i.e. the probability that the adverse event occurs in the time interval between two information samples. Moreover, we characterize the continuation and stopping regions in the decision-maker's state-space, and show that they depend not only on the decision-maker's beliefs, but also on the context, i.e. the current realization of the time series. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.07708;Knowledge will Propel Machine Understanding of Content: Extrapolating  from Current Examples; Amit Sheth,  Sujan Perera,  Sanjaya Wijeratne;  Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to unsupervised learning from a massive amount of data, albeit much of it relates to one modality/type of data at a time. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition of utilizing knowledge whenever it is available or can be created purposefully. In this paper, we focus on discussing the indispensable role of knowledge for deeper understanding of complex text and multimodal data in situations where (i) large amounts of training data (labeled/unlabeled) are not available or labor intensive to create, (ii) the objects (particularly text) to be recognized are complex (i.e., beyond simple entity-person/location/organization names), such as implicit entities and highly subjective content, and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create knowledge, varying from comprehensive or cross domain to domain or application specific, and (b) carefully exploit the knowledge to further empower or extend the applications of ML/NLP techniques. Using the early results in several diverse situations - both in data types and applications - we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1610.07862;Intelligence in Artificial Intelligence; Shoumen Palit Austin Datta;"  The elusive quest for intelligence in artificial intelligence prompts us to consider that instituting human-level intelligence in systems may be (still) in the realm of utopia. In about a quarter century, we have witnessed the winter of AI (1990) being transformed and transported to the zenith of tabloid fodder about AI (2015). The discussion at hand is about the elements that constitute the canonical idea of intelligence. The delivery of intelligence as a pay-per-use-service, popping out of an app or from a shrink-wrapped software defined point solution, is in contrast to the bio-inspired view of intelligence as an outcome, perhaps formed from a tapestry of events, cross-pollinated by instances, each with its own microcosm of experiences and learning, which may not be discrete all-or-none functions but continuous, over space and time. The enterprise world may not require, aspire or desire such an engaged solution to improve its services for enabling digital transformation through the deployment of digital twins, for example. One might ask whether the ""work-flow on steroids"" version of decision support may suffice for intelligence? Are we harking back to the era of rule based expert systems? The image conjured by the publicity machines offers deep solutions with human-level AI and preposterous claims about capturing the ""brain in a box"" by 2020. Even emulating insects may be difficult in terms of real progress. Perhaps we can try to focus on worms (Caenorhabditis elegans) which may be better suited for what business needs to quench its thirst for so-called intelligence in AI. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.07989;Process Discovery using Inductive Miner and Decomposition; Raji Ghawi;"  This report presents a submission to the Process Discovery Contest. The contest is dedicated to the assessment of tools and techniques that discover business process models from event logs. The objective is to compare the efficiency of techniques to discover process models that provide a proper balance between ""overfitting"" and ""underfitting"". In the context of the Process Discovery Contest, process discovery is turned into a classification task with a training set and a test set; where a process model needs to decide whether traces are fitting or not. In this report, we first show how we use two discovery techniques, namely: Inductive Miner and Decomposition, to discover process models from the training set using ProM tool. Second, we show how we use replay results to 1) check the rediscoverability of models, and to 2) classify unseen traces (in test logs) as fitting or not. Then, we discuss the classification results of validation logs, the complexity of discovered models, and their impact on the selection of models for submission. The report ends with the pictures of the submitted process models. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.07997;Artificial Intelligence Safety and Cybersecurity: a Timeline of AI  Failures; Roman V. Yampolskiy,  M. S. Spellchecker;"  In this work, we present and analyze reported failures of artificially intelligent systems and extrapolate our analysis to future AIs. We suggest that both the frequency and the seriousness of future AI failures will steadily increase. AI Safety can be improved based on ideas developed by cybersecurity experts. For narrow AIs safety failures are at the same, moderate, level of criticality as in cybersecurity, however for general AI, failures have a fundamentally different impact. A single failure of a superintelligent system may cause a catastrophic event without a chance for recovery. The goal of cybersecurity is to reduce the number of successful attacks on the system; the goal of AI Safety is to make sure zero attacks succeed in bypassing the safety mechanisms. Unfortunately, such a level of performance is unachievable. Every security system will eventually fail; there is no such thing as a 100% secure system. ";"Artificial Intelligence (cs.AI); Computers and Society (cs.CY)"
https://arxiv.org/abs/1610.08115;A Physician Advisory System for Chronic Heart Failure Management Based  on Knowledge Patterns; Zhuo Chen,  Kyle Marple,  Elmer Salazar,  Gopal Gupta,  Lakshman Tamil;  Management of chronic diseases such as heart failure, diabetes, and chronic obstructive pulmonary disease (COPD) is a major problem in health care. A standard approach that the medical community has devised to manage widely prevalent chronic diseases such as chronic heart failure (CHF) is to have a committee of experts develop guidelines that all physicians should follow. These guidelines typically consist of a series of complex rules that make recommendations based on a patient's information. Due to their complexity, often the guidelines are either ignored or not complied with at all, which can result in poor medical practices. It is not even clear whether it is humanly possible to follow these guidelines due to their length and complexity. In the case of CHF management, the guidelines run nearly 80 pages. In this paper we describe a physician-advisory system for CHF management that codes the entire set of clinical practice guidelines for CHF using answer set programming. Our approach is based on developing reasoning templates (that we call knowledge patterns) and using these patterns to systemically code the clinical guidelines for CHF as ASP rules. Use of the knowledge patterns greatly facilitates the development of our system. Given a patient's medical information, our system generates a recommendation for treatment just as a human physician would, using the guidelines. Our system will work even in the presence of incomplete information. Our work makes two contributions: (i) it shows that highly complex guidelines can be successfully coded as ASP rules, and (ii) it develops a series of knowledge patterns that facilitate the coding of knowledge expressed in a natural language and that can be used for other application domains. This paper is under consideration for acceptance in TPLP. ;"Artificial Intelligence (cs.AI); Programming Languages (cs.PL)"
https://arxiv.org/abs/1610.08222;A self-tuning Firefly algorithm to tune the parameters of Ant Colony  System (ACSFA); M. K. A. Ariyaratne,  T. G. I. Fernando,  S. Weerakoon;  Ant colony system (ACS) is a promising approach which has been widely used in problems such as Travelling Salesman Problems (TSP), Job shop scheduling problems (JSP) and Quadratic Assignment problems (QAP). In its original implementation, parameters of the algorithm were selected by trial and error approach. Over the last few years, novel approaches have been proposed on adapting the parameters of ACS in improving its performance. The aim of this paper is to use a framework introduced for self-tuning optimization algorithms combined with the firefly algorithm (FA) to tune the parameters of the ACS solving symmetric TSP problems. The FA optimizes the problem specific parameters of ACS while the parameters of the FA are tuned by the selected framework itself. With this approach, the user neither has to work with the parameters of ACS nor the parameters of FA. Using common symmetric TSP problems we demonstrate that the framework fits well for the ACS. A detailed statistical analysis further verifies the goodness of the new ACS over the existing ACS and also of the other techniques used to tune the parameters of ACS. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.08445;New Liftable Classes for First-Order Probabilistic Inference; Seyed Mehran Kazemi,  Angelika Kimmig,  Guy Van den Broeck,  David Poole;  Statistical relational models provide compact encodings of probabilistic dependencies in relational domains, but result in highly intractable graphical models. The goal of lifted inference is to carry out probabilistic inference without needing to reason about each individual separately, by instead treating exchangeable, undistinguished objects as a whole. In this paper, we study the domain recursion inference rule, which, despite its central role in early theoretical results on domain-lifted inference, has later been believed redundant. We show that this rule is more powerful than expected, and in fact significantly extends the range of models for which lifted inference runs in time polynomial in the number of individuals in the domain. This includes an open problem called S4, the symmetric transitivity model, and a first-order logic encoding of the birthday paradox. We further identify new classes S2FO2 and S2RU of domain-liftable theories, which respectively subsume FO2 and recursively unary theories, the largest classes of domain-liftable theories known so far, and show that using domain recursion can achieve exponential speedup even in theories that cannot fully be lifted with the existing set of inference rules. ;"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.08602;A Review of 40 Years of Cognitive Architecture Research: Core Cognitive  Abilities and Practical Applications; Iuliia Kotseruba,  John K. Tsotsos;  In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of well-established architectures. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 85 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning and reasoning. In order to assess the breadth of practical applications of cognitive architectures we gathered information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.08640;Anomaly Detection with the Voronoi Diagram Evolutionary Algorithm; Marti Luis (TAO, LRI),  Fansi-Tchango Arsene (TRT),  Navarro Laurent (TRT),  Marc Schoenauer (TAO, LRI);  This paper presents the Voronoi diagram-based evolutionary algorithm (VorEAl). VorEAl partitions input space in abnormal/normal subsets using Voronoi diagrams. Diagrams are evolved using a multi-objective bio-inspired approach in order to conjointly optimize classification metrics while also being able to represent areas of the data space that are not present in the training dataset. As part of the paper VorEAl is experimentally validated and contrasted with similar approaches. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.08853;Personalized Risk Scoring for Critical Care Prognosis using Mixtures of  Gaussian Processes; Ahmed M. Alaa,  Jinsung Yoon,  Scott Hu,  Mihaela van der Schaar;"  Objective: In this paper, we develop a personalized real-time risk scoring algorithm that provides timely and granular assessments for the clinical acuity of ward patients based on their (temporal) lab tests and vital signs; the proposed risk scoring system ensures timely intensive care unit (ICU) admissions for clinically deteriorating patients. Methods: The risk scoring system learns a set of latent patient subtypes from the offline electronic health record data, and trains a mixture of Gaussian Process (GP) experts, where each expert models the physiological data streams associated with a specific patient subtype. Transfer learning techniques are used to learn the relationship between a patient's latent subtype and her static admission information (e.g. age, gender, transfer status, ICD-9 codes, etc). Results: Experiments conducted on data from a heterogeneous cohort of 6,321 patients admitted to Ronald Reagan UCLA medical center show that our risk score significantly and consistently outperforms the currently deployed risk scores, such as the Rothman index, MEWS, APACHE and SOFA scores, in terms of timeliness, true positive rate (TPR), and positive predictive value (PPV). Conclusion: Our results reflect the importance of adopting the concepts of personalized medicine in critical care settings; significant accuracy and timeliness gains can be achieved by accounting for the patients' heterogeneity. Significance: The proposed risk scoring methodology can confer huge clinical and social benefits on more than 200,000 critically ill inpatient who exhibit cardiac arrests in the US every year. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.09064;Identifying Unknown Unknowns in the Open World: Representations and  Policies for Guided Exploration; Himabindu Lakkaraju,  Ece Kamar,  Rich Caruana,  Eric Horvitz;  Predictive models deployed in the real world may assign incorrect labels to instances with high confidence. Such errors or unknown unknowns are rooted in model incompleteness, and typically arise because of the mismatch between training data and the cases encountered at test time. As the models are blind to such errors, input from an oracle is needed to identify these failures. In this paper, we formulate and address the problem of informed discovery of unknown unknowns of any given predictive model where unknown unknowns occur due to systematic biases in the training data. We propose a model-agnostic methodology which uses feedback from an oracle to both identify unknown unknowns and to intelligently guide the discovery. We employ a two-phase approach which first organizes the data into multiple partitions based on the feature similarity of instances and the confidence scores assigned by the predictive model, and then utilizes an explore-exploit strategy for discovering unknown unknowns across these partitions. We demonstrate the efficacy of our framework by varying the underlying causes of unknown unknowns across various applications. To the best of our knowledge, this paper presents the first algorithmic approach to the problem of discovering unknown unknowns of predictive models. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.09263;Flexible constrained sampling with guarantees for pattern mining; Vladimir Dzyuba,  Matthijs van Leeuwen,  Luc De Raedt;  Pattern sampling has been proposed as a potential solution to the infamous pattern explosion. Instead of enumerating all patterns that satisfy the constraints, individual patterns are sampled proportional to a given quality measure. Several sampling algorithms have been proposed, but each of them has its limitations when it comes to 1) flexibility in terms of quality measures and constraints that can be used, and/or 2) guarantees with respect to sampling accuracy. We therefore present Flexics, the first flexible pattern sampler that supports a broad class of quality measures and constraints, while providing strong guarantees regarding sampling accuracy. To achieve this, we leverage the perspective on pattern mining as a constraint satisfaction problem and build upon the latest advances in sampling solutions in SAT as well as existing pattern mining algorithms. Furthermore, the proposed algorithm is applicable to a variety of pattern languages, which allows us to introduce and tackle the novel task of sampling sets of patterns. We introduce and empirically evaluate two variants of Flexics: 1) a generic variant that addresses the well-known itemset sampling task and the novel pattern set sampling task as well as a wide range of expressive constraints within these tasks, and 2) a specialized variant that exploits existing frequent itemset techniques to achieve substantial speed-ups. Experiments show that Flexics is both accurate and efficient, making it a useful tool for pattern-based data exploration. ;"Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.09372;Multi-agent projective simulation: A starting point; Rasoul Kheiri;  We develop a two-defender (Alice and Bob) invasion game using the method of projective simulation as an embodied model for artificial intelligence. We hope that it will be the first step towards the effect of perception on different actions in a given game. As a given perception of a given situation, the agent, say Alice, encounters some attack symbols coming from the right attacker where she can learn to prevent. However, some of these percepts are invisible for her. Instead, she perceives some other signs that are related to her partner's (Bob) task. We elaborate an example in which an agent perceives an equal portion of percepts from both attackers. Alice can choose to concentrate on her job, though she loses some attacks. Alternatively, she can have some sort of cooperation with Bob to get and give help. It follows that the maximum blocking efficiency in concentration is just the minimum blocking efficiency in cooperation. Furthermore, Alice would have a choice to select two different forgetting factors for blocking attacks and for helping task. Therefore, she can choose between herself and the other. Consequently, selfishness is discerned as an only Nash equilibrium in this game. It is a pure strategy and Pareto optimal and containing Shapley value in this superadditive coalition. Finally, we propose another perception for the same situation that can be tracked in the future regarding the present study. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1610.09409;Probabilistic Model Checking for Complex Cognitive Tasks -- A case study  in human-robot interaction; Sebastian Junges,  Nils Jansen,  Joost-Pieter Katoen,  Ufuk Topcu;  This paper proposes to use probabilistic model checking to synthesize optimal robot policies in multi-tasking autonomous systems that are subject to human-robot interaction. Given the convincing empirical evidence that human behavior can be related to reinforcement models, we take as input a well-studied Q-table model of the human behavior for flexible scenarios. We first describe an automated procedure to distill a Markov decision process (MDP) for the human in an arbitrary but fixed scenario. The distinctive issue is that -- in contrast to existing models -- under-specification of the human behavior is included. Probabilistic model checking is used to predict the human's behavior. Finally, the MDP model is extended with a robot model. Optimal robot policies are synthesized by analyzing the resulting two-player stochastic game. Experimental results with a prototypical implementation using PRISM show promising results. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1610.09882;A Survey of Brain Inspired Technologies for Engineering; Jarryd Son,  Amit Kumar Mishra;  Cognitive engineering is a multi-disciplinary field and hence it is difficult to find a review article consolidating the leading developments in the field. The in-credible pace at which technology is advancing pushes the boundaries of what is achievable in cognitive engineering. There are also differing approaches to cognitive engineering brought about from the multi-disciplinary nature of the field and the vastness of possible applications. Thus research communities require more frequent reviews to keep up to date with the latest trends. In this paper we shall dis-cuss some of the approaches to cognitive engineering holistically to clarify the reasoning behind the different approaches and to highlight their strengths and weaknesses. We shall then show how developments from seemingly disjointed views could be integrated to achieve the same goal of creating cognitive machines. By reviewing the major contributions in the different fields and showing the potential for a combined approach, this work intends to assist the research community in devising more unified methods and techniques for developing cognitive machines. ;"Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1610.09900;Inference Compilation and Universal Probabilistic Programming; Tuan Anh Le,  Atilim Gunes Baydin,  Frank Wood;"  We introduce a method for using deep neural networks to amortize the cost of inference in models from the family induced by universal probabilistic programming languages, establishing a framework that combines the strengths of probabilistic programming and deep learning methods. We call what we do ""compilation of inference"" because our method transforms a denotational specification of an inference problem in the form of a probabilistic program written in a universal programming language into a trained neural network denoted in a neural network specification language. When at test time this neural network is fed observational data and executed, it performs approximate inference in the original model specified by the probabilistic program. Our training objective and learning procedure are designed to allow the trained neural network to be used as a proposal distribution in a sequential importance sampling inference engine. We illustrate our method on mixture models and Captcha solving and show significant speedups in the efficiency of inference. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1610.09964;Ontology Verbalization using Semantic-Refinement; Vinu E.V,  P Sreenivasa Kumar;  We propose a rule-based technique to generate redundancy-free NL descriptions of OWL entities.The existing approaches which address the problem of verbalizing OWL ontologies generate NL text segments which are close to their counterpart OWL statements.Some of these approaches also perform grouping and aggregating of these NL text segments to generate a more fluent and comprehensive form of the content.Restricting our attention to description of individuals and concepts, we find that the approach currently followed in the available tools is that of determining the set of all logical conditions that are satisfied by the given individual/concept name and translate these conditions verbatim into corresponding NL descriptions.Human-understandability of such descriptions is affected by the presence of repetitions and redundancies, as they have high fidelity to their OWL representation.In the literature, no efforts had been taken to remove redundancies and repetitions at the logical-level before generating the NL descriptions of entities and we find this to be the main reason for lack of readability of the generated text.Herein, we propose a technique called semantic-refinement(SR) to generate meaningful and easily-understandable descriptions of individuals and concepts of a given OWLontology.We identify the combinations of OWL/DL constructs that lead to repetitive/redundant descriptions and propose a series of refinement rules to rewrite the conditions that are satisfied by an individual/concept in a meaning-preserving manner.The reduced set of conditions are then employed for generating NL descriptions.Our experiments show that, SR leads to significantly improved descriptions of ontology entities.We also test the effectiveness and usefulness of the the generated descriptions for the purpose of validating the ontologies and find that the proposed technique is indeed helpful in the context. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1611.00094;Learning recurrent representations for hierarchical behavior modeling; Eyrun Eyjolfsdottir,  Kristin Branson,  Yisong Yue,  Pietro Perona;  We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules. ;"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1611.00183;Local Subspace-Based Outlier Detection using Global Neighbourhoods; Bas van Stein,  Matthijs van Leeuwen,  Thomas Bäck;  Outlier detection in high-dimensional data is a challenging yet important task, as it has applications in, e.g., fraud detection and quality control. State-of-the-art density-based algorithms perform well because they 1) take the local neighbourhoods of data points into account and 2) consider feature subspaces. In highly complex and high-dimensional data, however, existing methods are likely to overlook important outliers because they do not explicitly take into account that the data is often a mixture distribution of multiple components. We therefore introduce GLOSS, an algorithm that performs local subspace outlier detection using global neighbourhoods. Experiments on synthetic data demonstrate that GLOSS more accurately detects local outliers in mixed data than its competitors. Moreover, experiments on real-world data show that our approach identifies relevant outliers overlooked by existing methods, confirming that one should keep an eye on the global perspective even when doing local outlier detection. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.00274;Detecting Affordances by Visuomotor Simulation; Wolfram Schenck,  Hendrik Hasenbein,  Ralf Möller;"  The term ""affordance"" denotes the behavioral meaning of objects. We propose a cognitive architecture for the detection of affordances in the visual modality. This model is based on the internal simulation of movement sequences. For each movement step, the resulting sensory state is predicted by a forward model, which in turn triggers the generation of a new (simulated) motor command by an inverse model. Thus, a series of mental images in the sensory and in the motor domain is evoked. Starting from a real sensory state, a large number of such sequences is simulated in parallel. Final affordance detection is based on the generated motor commands. We apply this model to a real-world mobile robot which is faced with obstacle arrangements some of which are passable (corridor) and some of which are not (dead ends). The robot's task is to detect the right affordance (""pass-through-able"" or ""non-pass-through-able""). The required internal models are acquired in a hierarchical training process. Afterwards, the robotic agent is able to distinguish reliably between corridors and dead ends. This real-world result enhances the validity of the proposed mental simulation approach. In addition, we compare several key factors in the simulation process regarding performance and efficiency. ";"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1611.00538;An application of incomplete pairwise comparison matrices for ranking  top tennis players; Sándor Bozóki,  László Csató,  József Temesi;  Pairwise comparison is an important tool in multi-attribute decision making. Pairwise comparison matrices (PCM) have been applied for ranking criteria and for scoring alternatives according to a given criterion. Our paper presents a special application of incomplete PCMs: ranking of professional tennis players based on their results against each other. The selected 25 players have been on the top of the ATP rankings for a shorter or longer period in the last 40 years. Some of them have never met on the court. One of the aims of the paper is to provide ranking of the selected players, however, the analysis of incomplete pairwise comparison matrices is also in the focus. The eigenvector method and the logarithmic least squares method were used to calculate weights from incomplete PCMs. In our results the top three players of four decades were Nadal, Federer and Sampras. Some questions have been raised on the properties of incomplete PCMs and remains open for further investigation. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Applications (stat.AP)"
https://arxiv.org/abs/1611.00549;Inferring Coupling of Distributed Dynamical Systems via Transfer Entropy; Oliver M. Cliff,  Mikhail Prokopenko,  Robert Fitch;  In this work, we are interested in structure learning for a set of spatially distributed dynamical systems, where individual subsystems are coupled via latent variables and observed through a filter. We represent this model as a directed acyclic graph (DAG) that characterises the unidirectional coupling between subsystems. Standard approaches to structure learning are not applicable in this framework due to the hidden variables, however we can exploit the properties of certain dynamical systems to formulate exact methods based on state space reconstruction. We approach the problem by using reconstruction theorems to analytically derive a tractable expression for the KL-divergence of a candidate DAG from the observed dataset. We show this measure can be decomposed as a function of two information-theoretic measures, transfer entropy and stochastic interaction. We then present two mathematically robust scoring functions based on transfer entropy and statistical independence tests. These results support the previously held conjecture that transfer entropy can be used to infer effective connectivity in complex networks. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.00576;Strong Neutrosophic Graphs and Subgraph Topological Subspaces; W. B. Vasantha Kandasamy,  Ilanthenral K,  Florentin Smarandache;  In this book authors for the first time introduce the notion of strong neutrosophic graphs. They are very different from the usual graphs and neutrosophic graphs. Using these new structures special subgraph topological spaces are defined. Further special lattice graph of subgraphs of these graphs are defined and described. Several interesting properties using subgraphs of a strong neutrosophic graph are obtained. Several open conjectures are proposed. These new class of strong neutrosophic graphs will certainly find applications in Neutrosophic Cognitive Maps (NCM), Neutrosophic Relational Maps (NRM) and Neutrosophic Relational Equations (NRE) with appropriate modifications. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.00685;A Framework for Searching for General Artificial Intelligence; Marek Rosa,  Jan Feyereisl,  The GoodAI Collective;  There is a significant lack of unified approaches to building generally intelligent machines. The majority of current artificial intelligence research operates within a very narrow field of focus, frequently without considering the importance of the 'big picture'. In this document, we seek to describe and unify principles that guide the basis of our development of general artificial intelligence. These principles revolve around the idea that intelligence is a tool for searching for general solutions to problems. We define intelligence as the ability to acquire skills that narrow this search, diversify it and help steer it to more promising areas. We also provide suggestions for studying, measuring, and testing the various skills and abilities that a human-level intelligent machine needs to acquire. The document aims to be both implementation agnostic, and to provide an analytic, systematic, and scalable way to generate hypotheses that we believe are needed to meet the necessary conditions in the search for general artificial intelligence. We believe that such a framework is an important stepping stone for bringing together definitions, highlighting open problems, connecting researchers willing to collaborate, and for unifying the arguably most significant search of this century. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.00873;Extracting Actionability from Machine Learning Models by Sub-optimal  Deterministic Planning; Qiang Lyu,  Yixin Chen,  Zhaorong Li,  Zhicheng Cui,  Ling Chen,  Xing Zhang,  Haihua Shen;  A main focus of machine learning research has been improving the generalization accuracy and efficiency of prediction models. Many models such as SVM, random forest, and deep neural nets have been proposed and achieved great success. However, what emerges as missing in many applications is actionability, i.e., the ability to turn prediction results into actions. For example, in applications such as customer relationship management, clinical prediction, and advertisement, the users need not only accurate prediction, but also actionable instructions which can transfer an input to a desirable goal (e.g., higher profit repays, lower morbidity rates, higher ads hit rates). Existing effort in deriving such actionable knowledge is few and limited to simple action models which restricted to only change one attribute for each action. The dilemma is that in many real applications those action models are often more complex and harder to extract an optimal solution. In this paper, we propose a novel approach that achieves actionability by combining learning with planning, two core areas of AI. In particular, we propose a framework to extract actionable knowledge from random forest, one of the most widely used and best off-the-shelf classifiers. We formulate the actionability problem to a sub-optimal action planning (SOAP) problem, which is to find a plan to alter certain features of a given input so that the random forest would yield a desirable output, while minimizing the total costs of actions. Technically, the SOAP problem is formulated in the SAS+ planning formalism, and solved using a Max-SAT based approach. Our experimental results demonstrate the effectiveness and efficiency of the proposed approach on a personal credit dataset and other benchmarks. Our work represents a new application of automated planning on an emerging and challenging machine learning paradigm. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1611.01080;Probabilistic Modeling of Progressive Filtering; Giuliano Armano;  Progressive filtering is a simple way to perform hierarchical classification, inspired by the behavior that most humans put into practice while attempting to categorize an item according to an underlying taxonomy. Each node of the taxonomy being associated with a different category, one may visualize the categorization process by looking at the item going downwards through all the nodes that accept it as belonging to the corresponding category. This paper is aimed at modeling the progressive filtering technique from a probabilistic perspective, in a hierarchical text categorization setting. As a result, the designer of a system based on progressive filtering should be facilitated in the task of devising, training, and testing it. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.01802;Self-Wiring Question Answering Systems; Ricardo Usbeck,  Jonathan Huthmann,  Nico Duldhardt,  Axel-Cyrille Ngonga Ngomo;  Question answering (QA) has been the subject of a resurgence over the past years. The said resurgence has led to a multitude of question answering (QA) systems being developed both by companies and research facilities. While a few components of QA systems get reused across implementations, most systems do not leverage the full potential of component reuse. Hence, the development of QA systems is currently still a tedious and time-consuming process. We address the challenge of accelerating the creation of novel or tailored QA systems by presenting a concept for a self-wiring approach to composing QA systems. Our approach will allow the reuse of existing, web-based QA systems or modules while developing new QA platforms. To this end, it will rely on QA modules being described using the Web Ontology Language. Based on these descriptions, our approach will be able to automatically compose QA systems using a data-driven approach automatically. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1611.01855;Neuro-Symbolic Program Synthesis; Emilio Parisotto,  Abdel-rahman Mohamed,  Rishabh Singh,  Lihong Li,  Dengyong Zhou,  Pushmeet Kohli;  Recent years have seen the proposal of a number of neural architectures for the problem of Program Induction. Given a set of input-output examples, these architectures are able to learn mappings that generalize to new test inputs. While achieving impressive results, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). In this paper, we propose a novel technique, Neuro-Symbolic Program Synthesis, to overcome the above-mentioned problems. Once trained, our approach can automatically construct computer programs in a domain-specific language that are consistent with a set of input-output examples provided at test time. Our method is based on two novel neural modules. The first module, called the cross correlation I/O network, given a set of input-output examples, produces a continuous representation of the set of I/O examples. The second module, the Recursive-Reverse-Recursive Neural Network (R3NN), given the continuous representation of the examples, synthesizes a program by incrementally expanding partial programs. We demonstrate the effectiveness of our approach by applying it to the rich and complex domain of regular expression based string transformations. Experiments show that the R3NN model is not only able to construct programs from new input-output examples, but it is also able to construct new programs for tasks that it had never observed before during training. ;"Artificial Intelligence (cs.AI); Programming Languages (cs.PL)"
https://arxiv.org/abs/1611.01929;Averaged-DQN: Variance Reduction and Stabilization for Deep  Reinforcement Learning; Oron Anschel,  Nir Baram,  Nahum Shimkin;  Instability and variability of Deep Reinforcement Learning (DRL) algorithms tend to adversely affect their performance. Averaged-DQN is a simple extension to the DQN algorithm, based on averaging previously learned Q-values estimates, which leads to a more stable training procedure and improved performance by reducing approximation error variance in the target values. To understand the effect of the algorithm, we examine the source of value function estimation errors and provide an analytical comparison within a simplified model. We further present experiments on the Arcade Learning Environment benchmark that demonstrate significantly improved stability and performance due to the proposed extension. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.02126;Dependence and Relevance: A probabilistic view; Dan Geiger,  David Heckerman;"  We examine three probabilistic concepts related to the sentence ""two variables have no bearing on each other"". We explore the relationships between these three concepts and establish their relevance to the process of constructing similarity networks---a tool for acquiring probabilistic knowledge from human experts. We also establish a precise relationship between connectedness in Bayesian networks and relevance in probability. ";"Artificial Intelligence (cs.AI); Combinatorics (math.CO); Probability (math.PR)"
https://arxiv.org/abs/1611.02154;Bayesian Non-parametric model to Target Gamification Notifications Using  Big Data; Meisam Hejazi Nia,  Brian Ratchford;  I suggest an approach that helps the online marketers to target their Gamification elements to users by modifying the order of the list of tasks that they send to users. It is more realistic and flexible as it allows the model to learn more parameters when the online marketers collect more data. The targeting approach is scalable and quick, and it can be used over streaming data. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.02385;Combining observational and experimental data to find heterogeneous  treatment effects; Alexander Peysakhovich,  Akos Lada;  Every design choice will have different effects on different units. However traditional A/B tests are often underpowered to identify these heterogeneous effects. This is especially true when the set of unit-level attributes is high-dimensional and our priors are weak about which particular covariates are important. However, there are often observational data sets available that are orders of magnitude larger. We propose a method to combine these two data sources to estimate heterogeneous treatment effects. First, we use observational time series data to estimate a mapping from covariates to unit-level effects. These estimates are likely biased but under some conditions the bias preserves unit-level relative rank orderings. If these conditions hold, we only need sufficient experimental data to identify a monotonic, one-dimensional transformation from observationally predicted treatment effects to real treatment effects. This reduces power demands greatly and makes the detection of heterogeneous effects much easier. As an application, we show how our method can be used to improve Facebook page recommendations. ;"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.02439;Proceedings of the First International Workshop on Argumentation in  Logic Programming and Non-Monotonic Reasoning (Arg-LPNMR 2016); Sarah Alice Gaggl,  Juan Carlos Nieves,  Hannes Strass;  This volume contains the papers presented at Arg-LPNMR 2016: First International Workshop on Argumentation in Logic Programming and Nonmonotonic Reasoning held on July 8-10, 2016 in New York City, NY. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.02453;The Data Complexity of Description Logic Ontologies; Carsten Lutz,  Frank Wolter;  We analyze the data complexity of ontology-mediated querying where the ontologies are formulated in a description logic (DL) of the ALC family and queries are conjunctive queries, positive existential queries, or acyclic conjunctive queries. Our approach is non-uniform in the sense that we aim to understand the complexity of each single ontology instead of for all ontologies formulated in a certain language. While doing so, we quantify over the queries and are interested, for example, in the question whether all queries can be evaluated in polynomial time w.r.t. a given ontology. Our results include a PTime/coNP-dichotomy for ontologies of depth one in the description logic ALCFI, the equivalence of a PTime/coNP-dichotomy for ALC and ALCI-ontologies of unrestricted depth to the famous dichotomy conjecture for CSPs by Feder and Vardi, and the failure of PTime/coNP-dichotomy theorem for ALCF-ontologies. Regarding the latter DL, we also show that it is undecidable whether a given ontology admits PTime query evaluation. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.02512;Cognitive Discriminative Mappings for Rapid Learning; Wen-Chieh Fang,  Yi-ting Chiang;  Humans can learn concepts or recognize items from just a handful of examples, while machines require many more samples to perform the same task. In this paper, we build a computational model to investigate the possibility of this kind of rapid learning. The proposed method aims to improve the learning task of input from sensory memory by leveraging the information retrieved from long-term memory. We present a simple and intuitive technique called cognitive discriminative mappings (CDM) to explore the cognitive problem. First, CDM separates and clusters the data instances retrieved from long-term memory into distinct classes with a discrimination method in working memory when a sensory input triggers the algorithm. CDM then maps each sensory data instance to be as close as possible to the median point of the data group with the same class. The experimental results demonstrate that the CDM approach is effective for learning the discriminative features of supervised classifications with few training sensory input instances. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1611.02646;On interestingness measures of formal concepts; Sergei O. Kuznetsov,  Tatiana Makhalova;  Formal concepts and closed itemsets proved to be of big importance for knowledge discovery, both as a tool for concise representation of association rules and a tool for clustering and constructing domain taxonomies and ontologies. Exponential explosion makes it difficult to consider the whole concept lattice arising from data, one needs to select most useful and interesting concepts. In this paper interestingness measures of concepts are considered and compared with respect to various aspects, such as efficiency of computation and applicability to noisy data and performing ranking correlation. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.02755;Recursive Decomposition for Nonconvex Optimization; Abram L. Friesen,  Pedro Domingos;  Continuous optimization is an important problem in many areas of AI, including vision, robotics, probabilistic inference, and machine learning. Unfortunately, most real-world optimization problems are nonconvex, causing standard convex techniques to find only local optima, even with extensions like random restarts and simulated annealing. We observe that, in many cases, the local modes of the objective function have combinatorial structure, and thus ideas from combinatorial optimization can be brought to bear. Based on this, we propose a problem-decomposition approach to nonconvex optimization. Similarly to DPLL-style SAT solvers and recursive conditioning in probabilistic inference, our algorithm, RDIS, recursively sets variables so as to simplify and decompose the objective function into approximately independent sub-functions, until the remaining functions are simple enough to be optimized by standard techniques like gradient descent. The variables to set are chosen by graph partitioning, ensuring decomposition whenever possible. We show analytically that RDIS can solve a broad class of nonconvex optimization problems exponentially faster than gradient descent with random restarts. Experimentally, RDIS outperforms standard techniques on problems like structure from motion and protein folding. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.02779;RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning; Yan Duan,  John Schulman,  Xi Chen,  Peter L. Bartlett,  Ilya Sutskever,  Pieter Abbeel;"  Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a ""fast"" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (""slow"") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the ""fast"" RL algorithm on the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL$^2$ is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL$^2$ on a vision-based navigation task and show that it scales up to high-dimensional problems. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.02885;Encoding monotonic multi-set preferences using CI-nets: preliminary  report; Martin Diller,  Anthony Hunter;"  CP-nets and their variants constitute one of the main AI approaches for specifying and reasoning about preferences. CI-nets, in particular, are a CP-inspired formalism for representing ordinal preferences over sets of goods, which are typically required to be monotonic. Considering also that goods often come in multi-sets rather than sets, a natural question is whether CI-nets can be used more or less directly to encode preferences over multi-sets. We here provide some initial ideas on how to achieve this, in the sense that at least a restricted form of reasoning on our framework, which we call ""confined reasoning"", can be efficiently reduced to reasoning on CI-nets. Our framework nevertheless allows for encoding preferences over multi-sets with unbounded multiplicities. We also show the extent to which it can be used to represent preferences where multiplicites of the goods are not stated explicitly (""purely qualitative preferences"") as well as a potential use of our generalization of CI-nets as a component of a recent system for evidence aggregation. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.03218;Learning to Play Guess Who? and Inventing a Grounded Language as a  Consequence; Emilio Jorge,  Mikael Kågebäck,  Fredrik D. Johansson,  Emil Gustavsson;  Acquiring your first language is an incredible feat and not easily duplicated. Learning to communicate using nothing but a few pictureless books, a corpus, would likely be impossible even for humans. Nevertheless, this is the dominating approach in most natural language processing today. As an alternative, we propose the use of situated interactions between agents as a driving force for communication, and the framework of Deep Recurrent Q-Networks for evolving a shared language grounded in the provided environment. We task the agents with interactive image search in the form of the game Guess Who?. The images from the game provide a non trivial environment for the agents to discuss and a natural grounding for the concepts they decide to encode in their communication. Our experiments show that the agents learn not only to encode physical concepts in their words, i.e. grounding, but also that the agents learn to hold a multi-step dialogue remembering the state of the dialogue from step to step. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Learning (cs.LG); Multiagent Systems (cs.MA)"
https://arxiv.org/abs/1611.03398;XCSP3: An Integrated Format for Benchmarking Combinatorial Constrained  Problems; Frederic Boussemart,  Christophe Lecoutre,  Cédric Piette;  We propose a major revision of the format XCSP 2.1, called XCSP3, to build integrated representations of combinatorial constrained problems. This new format is able to deal with mono/multi optimization, many types of variables, cost functions, reification, views, annotations, variable quantification, distributed, probabilistic and qualitative reasoning. The new format is made compact, highly readable, and rather easy to parse. Interestingly, it captures the structure of the problem models, through the possibilities of declaring arrays of variables, and identifying syntactic and semantic groups of constraints. The number of constraints is kept under control by introducing a limited set of basic constraint forms, and producing almost automatically some of their variations through lifting, restriction, sliding, logical combination and relaxation mechanisms. As a result, XCSP3 encompasses practically all constraints that can be found in major constraint solvers developed by the CP community. A website, which is developed conjointly with the format, contains many models and series of instances. The user can make sophisticated queries for selecting instances from very precise criteria. The objective of XCSP3 is to ease the effort required to test and compare different algorithms by providing a common test-bed of combinatorial constrained instances. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.03652;Show me the material evidence: Initial experiments on evaluating  hypotheses from user-generated multimedia data; Bernardo Gonçalves;  Subjective questions such as `does neymar dive', or `is clinton lying', or `is trump a fascist', are popular queries to web search engines, as can be seen by autocompletion suggestions on Google, Yahoo and Bing. In the era of cognitive computing, beyond search, they could be handled as hypotheses issued for evaluation. Our vision is to leverage on unstructured data and metadata of the rich user-generated multimedia that is often shared as material evidence in favor or against hypotheses in social media platforms. In this paper we present two preliminary experiments along those lines and discuss challenges for a cognitive computing system that collects material evidence from user-generated multimedia towards aggregating it into some form of collective decision on the hypothesis. ;"Artificial Intelligence (cs.AI); Databases (cs.DB); Multimedia (cs.MM)"
https://arxiv.org/abs/1611.03673;Learning to Navigate in Complex Environments; Piotr Mirowski,  Razvan Pascanu,  Fabio Viola,  Hubert Soyer,  Andrew J. Ballard,  Andrea Banino,  Misha Denil,  Ross Goroshin,  Laurent Sifre,  Koray Kavukcuoglu,  Dharshan Kumaran,  Raia Hadsell;  Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour, its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities. ;"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Learning (cs.LG); Robotics (cs.RO)"
https://arxiv.org/abs/1611.03799;Applying Chatbots to the Internet of Things: Opportunities and  Architectural Elements; Rohan Kar,  Rishin Haldar;  Internet of Things (IoT) is emerging as a significant technology in shaping the future by connecting physical devices or things with internet. It also presents various opportunities for intersection of other technological trends which can allow it to become even more intelligent and efficient. In this paper we focus our attention on the integration of Intelligent Conversational Software Agents or Chatbots with IoT. Literature surveys have looked into various applications, features, underlying technologies and known challenges of IoT. On the other hand, Chatbots are being adopted in greater numbers due to major strides in development of platforms and frameworks. The novelty of this paper lies in the specific integration of Chatbots in the IoT scenario. We analyzed the shortcomings of existing IoT systems and put forward ways to tackle them by incorporating chatbots. A general architecture is proposed for implementing such a system, as well as platforms and frameworks, both commercial and open source, which allow for implementation of such systems. Identification of the newer challenges and possible future directions with this new integration, have also been addressed. ;"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1611.03907;Reinforcement Learning in Rich-Observation MDPs using Spectral Methods; Kamyar Azizzadenesheli,  Alessandro Lazaric,  Animashree Anandkumar;  Designing effective exploration-exploitation algorithms in Markov decision processes (MDPs) with large state-action spaces is the main challenge in reinforcement learning (RL). In fact, the learning performance degrades with the number of states and actions in the MDP. However, MDPs often exhibit a low-dimensional latent structure in practice, where a small hidden state is observable through a possibly large number of observations. In this paper, we study the setting of rich-observation Markov decision processes (\richmdp), where hidden states are mapped to observations through an injective mapping, so that an observation can be generated by only one hidden state. While this mapping is unknown a priori, we introduce a spectral decomposition method that consistently estimates how observations are clustered in the hidden states. The estimated clustering is then integrated into an optimistic algorithm for RL (UCRL), which operates on the smaller clustered space. The resulting algorithm proceeds through phases and we show that its per-step regret (i.e., the difference in cumulative reward between the algorithm and the optimal policy) decreases as more observations are clustered together and finally, matches the (ideal) performance of an RL algorithm running directly on the hidden MDP. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.03954;Multilingual Knowledge Graph Embeddings for Cross-lingual Knowledge  Alignment; Muhao Chen,  Yingtao Tian,  Mohan Yang,  Carlo Zaniolo;  Many recent works have demonstrated the benefits of knowledge graph embeddings in completing monolingual knowledge graphs. Inasmuch as related knowledge bases are built in several different languages, achieving cross-lingual knowledge alignment will help people in constructing a coherent knowledge base, and assist machines in dealing with different expressions of entity relationships across diverse human languages. Unfortunately, achieving this highly desirable crosslingual alignment by human labor is very costly and errorprone. Thus, we propose MTransE, a translation-based model for multilingual knowledge graph embeddings, to provide a simple and automated solution. By encoding entities and relations of each language in a separated embedding space, MTransE provides transitions for each embedding vector to its cross-lingual counterparts in other spaces, while preserving the functionalities of monolingual embeddings. We deploy three different techniques to represent cross-lingual transitions, namely axis calibration, translation vectors, and linear transformations, and derive five variants for MTransE using different loss functions. Our models can be trained on partially aligned graphs, where just a small portion of triples are aligned with their cross-lingual counterparts. The experiments on cross-lingual entity matching and triple-wise alignment verification show promising results, with some variants consistently outperforming others on different tasks. We also explore how MTransE preserves the key properties of its monolingual counterpart TransE. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1611.03977;A Review on Algorithms for Constraint-based Causal Discovery; Kui Yu,  Jiuyong Li,  Lin Liu;  Causal discovery studies the problem of mining causal relationships between variables from data, which is of primary interest in science. During the past decades, significant amount of progresses have been made toward this fundamental data mining paradigm. Recent years, as the availability of abundant large-sized and complex observational data, the constrain-based approaches have gradually attracted a lot of interest and have been widely applied to many diverse real-world problems due to the fast running speed and easy generalizing to the problem of causal insufficiency. In this paper, we aim to review the constraint-based causal discovery algorithms. Firstly, we discuss the learning paradigm of the constraint-based approaches. Secondly and primarily, the state-of-the-art constraint-based casual inference algorithms are surveyed with the detailed analysis. Thirdly, several related open-source software packages and benchmark data repositories are briefly summarized. As a conclusion, some open problems in constraint-based causal discovery are outlined for future research. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.04035;Entropic Causal Inference; Murat Kocaoglu,  Alexandros G. Dimakis,  Sriram Vishwanath,  Babak Hassibi;  We consider the problem of identifying the causal direction between two discrete random variables using observational data. Unlike previous work, we keep the most general functional model but make an assumption on the unobserved exogenous variable: Inspired by Occam's razor, we assume that the exogenous variable is simple in the true causal direction. We quantify simplicity using R\'enyi entropy. Our main result is that, under natural assumptions, if the exogenous variable has low $H_0$ entropy (cardinality) in the true direction, it must have high $H_0$ entropy in the wrong direction. We establish several algorithmic hardness results about estimating the minimum entropy exogenous variable. We show that the problem of finding the exogenous variable with minimum entropy is equivalent to the problem of finding minimum joint entropy given $n$ marginal distributions, also known as minimum entropy coupling problem. We propose an efficient greedy algorithm for the minimum entropy coupling problem, that for $n=2$ provably finds a local optimum. This gives a greedy algorithm for finding the exogenous variable with minimum $H_1$ (Shannon Entropy). Our greedy entropy-based causal inference algorithm has similar performance to the state of the art additive noise models in real datasets. One advantage of our approach is that we make no use of the values of random variables but only their distributions. Our method can therefore be used for causal inference for both ordinal and also categorical data, unlike additive noise models. ;"Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.04146;Commonsense Knowledge Enhanced Embeddings for Solving Pronoun  Disambiguation Problems in Winograd Schema Challenge; Quan Liu,  Hui Jiang,  Zhen-Hua Ling,  Xiaodan Zhu,  Si Wei,  Yu Hu;  In this paper, we propose commonsense knowledge enhanced embeddings (KEE) for solving the Pronoun Disambiguation Problems (PDP). The PDP task we investigate in this paper is a complex coreference resolution task which requires the utilization of commonsense knowledge. This task is a standard first round test set in the 2016 Winograd Schema Challenge. In this task, traditional linguistic features that are useful for coreference resolution, e.g. context and gender information, are no longer effective anymore. Therefore, the KEE models are proposed to provide a general framework to make use of commonsense knowledge for solving the PDP problems. Since the PDP task doesn't have training data, the KEE models would be used during the unsupervised feature extraction process. To evaluate the effectiveness of the KEE models, we propose to incorporate various commonsense knowledge bases, including ConceptNet, WordNet, and CauseCom, into the KEE training process. We achieved the best performance by applying the proposed methods to the 2016 Winograd Schema Challenge. In addition, experiments conducted on the standard PDP task indicate that, the proposed KEE models could solve the PDP problems by achieving 66.7% accuracy, which is a new state-of-the-art performance. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.04363;Learning for Expertise Matching with Declination Prediction; Yujie Qian,  Jie Tang;"  We study the problem of finding appropriate experts who are able to complete timely reviews and would not say ""no"" to the invitation. The problem is a central issue in many question-and-answer systems, but has received little research attention. Different from most existing studies that focus on expertise matching, we want to further predict the expert's response: given a question, how can we find the expert who is able to provide a quality review and will agree to do it. We formalize the problem as a ranking problem. We first present an embedding-based question-to-expert distance metric for expertise matching and propose a ranking factor graph (RankFG) model to predict expert response. For online evaluation, we developed a Chrome Extension for reviewer recommendation and deployed it in the Google Chrome Web Store, and then collected the reviewers' feedback. We also used the review bidding of a CS conference for evaluation. In the experiments, the proposed method demonstrates its superiority (+6.6-21.2% by MAP) over several state-of-the-art algorithms. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.04369;Feature Engineering and Ensemble Modeling for Paper Acceptance Rank  Prediction; Yujie Qian,  Yinpeng Dong,  Ye Ma,  Hailong Jin,  Juanzi Li;  Measuring research impact and ranking academic achievement are important and challenging problems. Having an objective picture of research institution is particularly valuable for students, parents and funding agencies, and also attracts attention from government and industry. KDD Cup 2016 proposes the paper acceptance rank prediction task, in which the participants are asked to rank the importance of institutions based on predicting how many of their papers will be accepted at the 8 top conferences in computer science. In our work, we adopt a three-step feature engineering method, including basic features definition, finding similar conferences to enhance the feature set, and dimension reduction using PCA. We propose three ranking models and the ensemble methods for combining such models. Our experiment verifies the effectiveness of our approach. In KDD Cup 2016, we achieved the overall rank of the 2nd place. ;"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1611.04636;When Saliency Meets Sentiment: Understanding How Image Content Invokes  Emotion and Sentiment; Honglin Zheng,  Tianlang Chen,  Jiebo Luo;  Sentiment analysis is crucial for extracting social signals from social media content. Due to the prevalence of images in social media, image sentiment analysis is receiving increasing attention in recent years. However, most existing systems are black-boxes that do not provide insight on how image content invokes sentiment and emotion in the viewers. Psychological studies have confirmed that salient objects in an image often invoke emotions. In this work, we investigate more fine-grained and more comprehensive interaction between visual saliency and visual sentiment. In particular, we partition images in several primary scene-type dimensions, including: open-closed, natural-manmade, indoor-outdoor, and face-noface. Using state of the art saliency detection algorithm and sentiment classification algorithm, we examine how the sentiment of the salient region(s) in an image relates to the overall sentiment of the image. The experiments on a representative image emotion dataset have shown interesting correlation between saliency and sentiment in different scene types and in turn shed light on the mechanism of visual sentiment evocation. ;"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1611.04642;Modeling Large-Scale Structured Relationships with Shared Memory for  Knowledge Base Completion; Yelong Shen,  Po-Sen Huang,  Ming-Wei Chang,  Jianfeng Gao;  Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed triplets could be costly. Hence, a manually designed procedure is often used when training the models. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform multi-step inference implicitly through a controller and shared memory. Without a human-designed inference procedure, IRNs use training data to learn to perform multi-step inference in an embedding neural space through the shared memory and controller. While the inference procedure does not explicitly operate on top of observed triplets, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Learning (cs.LG)"
https://arxiv.org/abs/1611.04660;Causal Inference in Observational Data; Pranjul Yadav,  Lisiane Prunelli,  Alexander Hoff,  Michael Steinbach,  Bonnie Westra,  Vipin Kumar,  Gyorgy Simon;  Our aging population increasingly suffers from multiple chronic diseases simultaneously, necessitating the comprehensive treatment of these conditions. Finding the optimal set of drugs for a combinatorial set of diseases is a combinatorial pattern exploration problem. Association rule mining is a popular tool for such problems, but the requirement of health care for finding causal, rather than associative, patterns renders association rule mining unsuitable. To address this issue, we propose a novel framework based on the Rubin-Neyman causal model for extracting causal rules from observational data, correcting for a number of common biases. Specifically, given a set of interventions and a set of items that define subpopulations (e.g., diseases), we wish to find all subpopulations in which effective intervention combinations exist and in each such subpopulation, we wish to find all intervention combinations such that dropping any intervention from this combination will reduce the efficacy of the treatment. A key aspect of our framework is the concept of closed intervention sets which extend the concept of quantifying the effect of a single intervention to a set of concurrent interventions. We also evaluated our causal rule mining framework on the Electronic Health Records (EHR) data of a large cohort of patients from Mayo Clinic and showed that the patterns we extracted are sufficiently rich to explain the controversial findings in the medical literature regarding the effect of a class of cholesterol drugs on Type-II Diabetes Mellitus (T2DM). ;"Artificial Intelligence (cs.AI); Applications (stat.AP)"
https://arxiv.org/abs/1611.04717;Exploration: A Study of Count-Based Exploration for Deep Reinforcement  Learning; Haoran Tang,  Rein Houthooft,  Davis Foote,  Adam Stooke,  Xi Chen,  Yan Duan,  John Schulman,  Filip De Turck,  Pieter Abbeel;  Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various high-dimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1611.04845;An Evaluation of Information Sharing Parking Guidance Policies Using a  Bayesian Approach; Xinyi Wu,  Kartik Balkumar,  Qi Luo,  Robert Hampshire,  Romesh Saigal;  Real-time parking occupancy information is critical for a parking management system to facilitate drivers to park more efficiently. Recent advances in connected and automated vehicle technologies enable sensor-equipped cars (probe cars) to detect and broadcast available parking spaces when driving through parking lots. In this paper, we evaluate the impact of market penetration of probe cars on the system performance, and investigate different parking guidance policies to improve the data acquisition process. We adopt a simulation-based approach to impose four policies on an off- street parking lot influencing the behavior of probe cars to park in assigned parking spaces. This in turn effects the scanning route and the parking space occupancy estimations. The last policy we propose is a near-optimal guidance strategy that maximizes the information gain of posteriors. The results suggest that an efficient information gathering policy can compensate for low penetration of connected and automated vehicles. We also highlight the policy trade-off that occur while attempting to maximize information gain through explorations and improve assignment accuracy through exploitations. Our results can assist urban policy makers in designing and managing smart parking systems. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Robotics (cs.RO)"
https://arxiv.org/abs/1611.04969;An integrated Graphical User Interface for Debugging Answer Set Programs; Philip Gasteiger,  Carmine Dodaro,  Benjamin Musitsch,  Kristian Reale,  Francesco Ricca,  Konstantin Schekotihin;  Answer Set Programming (ASP) is an expressive knowledge representation and reasoning framework. Due to its rather simple syntax paired with high-performance solvers, ASP is interesting for industrial applications. However, to err is human and thus debugging is an important activity during the development process. Therefore, tools for debugging non-ground answer set programs are needed. In this paper, we present a new graphical debugging interface for non-ground answer set programs. The tool is based on the recently-introduced DWASP approach for debugging and it simplifies the interaction with the debugger. Furthermore, the debugging interface is integrated in ASPIDE, a rich IDE for answer set programs. With our extension ASPIDE turns into a full-fledged IDE by offering debugging support. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1611.05170;The Effects of Relative Importance of User Constraints in Cloud of  Things Resource Discovery: A Case Study; Luiz H. Nunes,  Julio C. Estrella,  Alexandre C. B. Delbem,  Charith Perera,  Stephan Reiff-Marganiec;  Over the last few years, the number of smart objects connected to the Internet has grown exponentially in comparison to the number of services and applications. The integration between Cloud Computing and Internet of Things, named as Cloud of Things, plays a key role in managing the connected things, their data and services. One of the main challenges in Cloud of Things is the resource discovery of the smart objects and their reuse in different contexts. Most of the existent work uses some kind of multi-criteria decision analysis algorithm to perform the resource discovery, but do not evaluate the impact that the user constraints has in the final solution. In this paper, we analyse the behaviour of the SAW, TOPSIS and VIKOR multi-objective decision analyses algorithms and the impact of user constraints on them. We evaluated the quality of the proposed solutions using the Pareto-optimality concept. ;"Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)"
https://arxiv.org/abs/1611.05190;Driving CDCL Search; Carmine Dodaro,  Philip Gasteiger,  Nicola Leone,  Benjamin Musitsch,  Francesco Ricca,  Konstantin Schekotihin;  The CDCL algorithm is the leading solution adopted by state-of-the-art solvers for SAT, SMT, ASP, and others. Experiments show that the performance of CDCL solvers can be significantly boosted by embedding domain-specific heuristics, especially on large real-world problems. However, a proper integration of such criteria in off-the-shelf CDCL implementations is not obvious. In this paper, we distill the key ingredients that drive the search of CDCL solvers, and propose a general framework for designing and implementing new heuristics. We implemented our strategy in an ASP solver, and we experimented on two industrial domains. On hard problem instances, state-of-the-art implementations fail to find any solution in acceptable time, whereas our implementation is very successful and finds all solutions. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.05379;PCT and Beyond: Towards a Computational Framework for `Intelligent'  Communicative Systems; Prof. Roger K. Moore;  Recent years have witnessed increasing interest in the potential benefits of `intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot, iRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired the imagination of the general public, and social media buzz with speculation about a utopian world of helpful robot assistants or the coming robot apocalypse! However, there is a long way to go before autonomous systems reach the level of capabilities required for even the simplest of tasks involving human-robot interaction - especially if it involves communicative behaviour such as speech and language. Of course the field of Artificial Intelligence (AI) has made great strides in these areas, and has moved on from abstract high-level rule-based paradigms to embodied architectures whose operations are grounded in real physical environments. What is still missing, however, is an overarching theory of intelligent communicative behaviour that informs system-level design decisions in order to provide a more coherent approach to system integration. This chapter introduces the beginnings of such a framework inspired by the principles of Perceptual Control Theory (PCT). In particular, it is observed that PCT has hitherto tended to view perceptual processes as a relatively straightforward series of transformations from sensation to perception, and has overlooked the potential of powerful generative model-based solutions that have emerged in practical fields such as visual or auditory scene analysis. Starting from first principles, a sequence of arguments is presented which not only shows how these ideas might be integrated into PCT, but which also extend PCT towards a remarkably symmetric architecture for a needs-driven communicative agent. It is concluded that, if behaviour is the control of perception, then perception is the simulation of behaviour. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Robotics (cs.RO)"
https://arxiv.org/abs/1611.05425;ProjE: Embedding Projection for Knowledge Graph Completion; Baoxu Shi,  Tim Weninger;  With the large volume of new information created every day, determining the validity of information in a knowledge graph and filling in its missing parts are crucial tasks for many researchers and practitioners. To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings. Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering. In this work, we present a shared variable neural network model called ProjE that fills-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph's entities and edges, and through subtle, but important, changes to the standard loss function. In doing so, ProjE has a parameter size that is smaller than 11 out of 15 existing methods while performing $37\%$ better than the current-best method on standard datasets. We also show, via a new fact checking task, that ProjE is capable of accurately determining the veracity of many declarative statements. ;"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.05497;Explicable Robot Planning as Minimizing Distance from Expected Behavior; Anagha Kulkarni,  Tathagata Chakraborti,  Yantian Zha,  Satya Gautam Vadlamudi,  Yu Zhang,  Subbarao Kambhampati;  In order for robots to be integrated effectively into human work-flows, it is not enough to address the question of autonomy but also how their actions or plans are being perceived by their human counterparts. When robots generate task plans without such considerations, they may often demonstrate what we refer to as inexplicable behavior from the point of view of humans who may be observing it. This problem arises due to the human observer's partial or inaccurate understanding of the robot's deliberative process and/or the model (i.e. capabilities of the robot) that informs it. This may have serious implications on the human-robot work-space, from increased cognitive load and reduced trust in the robot from the human, to more serious concerns of safety in human-robot interactions. In this paper, we propose to address this issue by learning a distance function that can accurately model the notion of explicability, and develop an anytime search algorithm that can use this measure in its search process to come up with progressively explicable plans. As the first step, robot plans are evaluated by human subjects based on how explicable they perceive the plan to be, and a scoring function called explicability distance based on the different plan distance measures is learned. We then use this explicability distance as a heuristic to guide our search in order to generate explicable robot plans, by minimizing the plan distances between the robot's plan and the human's expected plans. We conduct our experiments in a toy autonomous car domain, and provide empirical evaluations that demonstrate the usefulness of the approach in making the planning process of an autonomous agent conform to human expectations. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1611.05735;Optimal Dynamic Coverage Infrastructure for Large-Scale Fleets of  Reconnaissance UAVs; Yaniv Altshuler,  Alex Pentland,  Shlomo Bekhor,  Yoram Shiftan,  Alfred Bruckstein;  Current state of the art in the field of UAV activation relies solely on human operators for the design and adaptation of the drones' flying routes. Furthermore, this is being done today on an individual level (one vehicle per operators), with some exceptions of a handful of new systems, that are comprised of a small number of self-organizing swarms, manually guided by a human operator. Drones-based monitoring is of great importance in variety of civilian domains, such as road safety, homeland security, and even environmental control. In its military aspect, efficiently detecting evading targets by a fleet of unmanned drones has an ever increasing impact on the ability of modern armies to engage in warfare. The latter is true both traditional symmetric conflicts among armies as well as asymmetric ones. Be it a speeding driver, a polluting trailer or a covert convoy, the basic challenge remains the same -- how can its detection probability be maximized using as little number of drones as possible. In this work we propose a novel approach for the optimization of large scale swarms of reconnaissance drones -- capable of producing on-demand optimal coverage strategies for any given search scenario. Given an estimation cost of the threat's potential damages, as well as types of monitoring drones available and their comparative performance, our proposed method generates an analytically provable strategy, stating the optimal number and types of drones to be deployed, in order to cost-efficiently monitor a pre-defined region for targets maneuvering using a given roads networks. We demonstrate our model using a unique dataset of the Israeli transportation network, on which different deployment schemes for drones deployment are evaluated. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.05740;Fast Non-Parametric Tests of Relative Dependency and Similarity; Wacha Bounliphone,  Eugene Belilovsky,  Arthur Tenenhaus,  Ioannis Antonoglou,  Arthur Gretton,  Matthew B. Blashcko;  We introduce two novel non-parametric statistical hypothesis tests. The first test, called the relative test of dependency, enables us to determine whether one source variable is significantly more dependent on a first target variable or a second. Dependence is measured via the Hilbert-Schmidt Independence Criterion (HSIC). The second test, called the relative test of similarity, is use to determine which of the two samples from arbitrary distributions is significantly closer to a reference sample of interest and the relative measure of similarity is based on the Maximum Mean Discrepancy (MMD). To construct these tests, we have used as our test statistics the difference of HSIC statistics and of MMD statistics, respectively. The resulting tests are consistent and unbiased, and have favorable convergence properties. The effectiveness of the relative dependency test is demonstrated on several real-world problems: we identify languages groups from a multilingual parallel corpus, and we show that tumor location is more dependent on gene expression than chromosome imbalance. We also demonstrate the performance of the relative test of similarity over a broad selection of model comparisons problems in deep generative models. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.05950;Analysis of a Design Pattern for Teaching with Features and Labels; Christopher Meek,  Patrice Simard,  Xiaojin Zhu;  We study the task of teaching a machine to classify objects using features and labels. We introduce the Error-Driven-Featuring design pattern for teaching using features and labels in which a teacher prefers to introduce features only if they are needed. We analyze the potential risks and benefits of this teaching pattern through the use of teaching protocols, illustrative examples, and by providing bounds on the effort required for an optimal machine teacher using a linear learning algorithm, the most commonly used type of learners in interactive machine learning systems. Our analysis provides a deeper understanding of potential trade-offs of using different learning algorithms and between the effort required for featuring (creating new features) and labeling (providing labels for objects). ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1611.05973;NCBO Ontology Recommender 2.0: An Enhanced Approach for Biomedical  Ontology Recommendation; Marcos Martinez-Romero,  Clement Jonquet,  Martin J. O'Connor,  John Graybeal,  Alejandro Pazos,  Mark A. Musen;"  Biomedical researchers use ontologies to annotate their data with ontology terms, enabling better data integration and interoperability. However, the number, variety and complexity of current biomedical ontologies make it cumbersome for researchers to determine which ones to reuse for their specific needs. To overcome this problem, in 2010 the National Center for Biomedical Ontology (NCBO) released the Ontology Recommender, which is a service that receives a biomedical text corpus or a list of keywords and suggests ontologies appropriate for referencing the indicated terms. We developed a new version of the NCBO Ontology Recommender. Called Ontology Recommender 2.0, it uses a new recommendation approach that evaluates the relevance of an ontology to biomedical text data according to four criteria: (1) the extent to which the ontology covers the input data; (2) the acceptance of the ontology in the biomedical community; (3) the level of detail of the ontology classes that cover the input data; and (4) the specialization of the ontology to the domain of the input data. Our evaluation shows that the enhanced recommender provides higher quality suggestions than the original approach, providing better coverage of the input data, more detailed information about their concepts, increased specialization for the domain of the input data, and greater acceptance and use in the community. In addition, it provides users with more explanatory information, along with suggestions of not only individual ontologies but also groups of ontologies. It also can be customized to fit the needs of different scenarios. Ontology Recommender 2.0 combines the strengths of its predecessor with a range of adjustments and new features that improve its reliability and usefulness. Ontology Recommender 2.0 recommends over 500 biomedical ontologies from the NCBO BioPortal platform, where it is openly available. ";"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1611.06108;Navigational Rule Derivation: An algorithm to determine the effect of  traffic signs on road networks; Daniil Galaktionov,  Miguel R. Luaces,  Ángeles S. Places;  In this paper we present an algorithm to build a road network map enriched with traffic rules such as one-way streets and forbidden turns, based on the interpretation of already detected and classified traffic signs. Such algorithm helps to automatize the elaboration of maps for commercial navigation systems. Our solution is based on simulating navigation along the road network, determining at each point of interest the visibility of the signs and their effect on the roads. We test our approach in a small urban network and discuss various ways to generalize it to support more complex environments. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.06134;Team-maxmin equilibrium: efficiency bounds and algorithms; Nicola Basilico,  Andrea Celli,  Giuseppe De Nittis,  Nicola Gatti;  The Team-maxmin equilibrium prescribes the optimal strategies for a team of rational players sharing the same goal and without the capability of correlating their strategies in strategic games against an adversary. This solution concept can capture situations in which an agent controls multiple resources-corresponding to the team members-that cannot communicate. It is known that such equilibrium always exists and it is unique (unless degeneracy) and these properties make it a credible solution concept to be used in real-world applications, especially in security scenarios. Nevertheless, to the best of our knowledge, the Team-maxmin equilibrium is almost completely unexplored in the literature. In this paper, we investigate bounds of (in)efficiency of the Team-maxmin equilibrium w.r.t. the Nash equilibria and w.r.t. the Maxmin equilibrium when the team members can play correlated strategies. Furthermore, we study a number of algorithms to find and/or approximate an equilibrium, discussing their theoretical guarantees and evaluating their performance by using a standard testbed of game instances. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)"
https://arxiv.org/abs/1611.06174;Stratified Knowledge Bases as Interpretable Probabilistic Models  (Extended Abstract); Ondrej Kuzelka,  Jesse Davis,  Steven Schockaert;  In this paper, we advocate the use of stratified logical theories for representing probabilistic models. We argue that such encodings can be more interpretable than those obtained in existing frameworks such as Markov logic networks. Among others, this allows for the use of domain experts to improve learned models by directly removing, adding, or modifying logical formulas. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.06468;Generating machine-executable plans from end-user's natural-language  instructions; Rui Liu,  Xiaoli Zhang;  It is critical for advanced manufacturing machines to autonomously execute a task by following an end-user's natural language (NL) instructions. However, NL instructions are usually ambiguous and abstract so that the machines may misunderstand and incorrectly execute the task. To address this NL-based human-machine communication problem and enable the machines to appropriately execute tasks by following the end-user's NL instructions, we developed a Machine-Executable-Plan-Generation (exePlan) method. The exePlan method conducts task-centered semantic analysis to extract task-related information from ambiguous NL instructions. In addition, the method specifies machine execution parameters to generate a machine-executable plan by interpreting abstract NL instructions. To evaluate the exePlan method, an industrial robot Baxter was instructed by NL to perform three types of industrial tasks {'drill a hole', 'clean a spot', 'install a screw'}. The experiment results proved that the exePlan method was effective in generating machine-executable plans from the end-user's NL instructions. Such a method has the promise to endow a machine with the ability of NL-instructed task execution. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)"
https://arxiv.org/abs/1611.06928;Memory Lens: How Much Memory Does an Agent Use?; Christoph Dann,  Katja Hofmann,  Sebastian Nowozin;  We propose a new method to study the internal memory used by reinforcement learning policies. We estimate the amount of relevant past information by estimating mutual information between behavior histories and the current action of an agent. We perform this estimation in the passive setting, that is, we do not intervene but merely observe the natural behavior of the agent. Moreover, we provide a theoretical justification for our approach by showing that it yields an implementation-independent lower bound on the minimal memory capacity of any agent that implement the observed policy. We demonstrate our approach by estimating the use of memory of DQN policies on concatenated Atari frames, demonstrating sharply different use of memory across 49 games. The study of memory as information that flows from the past to the current action opens avenues to understand and improve successful reinforcement learning algorithms. ;"Artificial Intelligence (cs.AI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.07078;A Deep Learning Approach for Joint Video Frame and Reward Prediction in  Atari Games; Felix Leibfried,  Nate Kushman,  Katja Hofmann;  Reinforcement learning is concerned with identifying reward-maximizing behaviour policies in environments that are initially unknown. State-of-the-art reinforcement learning approaches, such as deep Q-networks, are model-free and learn to act effectively across a wide range of environments such as Atari games, but require huge amounts of data. Model-based techniques are more data-efficient, but need to acquire explicit knowledge about the environment. In this paper, we take a step towards using model-based techniques in environments with a high-dimensional visual state space by demonstrating that it is possible to learn system dynamics and the reward structure jointly. Our contribution is to extend a recently developed deep neural network for video frame prediction in Atari games to enable reward prediction as well. To this end, we phrase a joint optimization problem for minimizing both video frame and reward reconstruction loss, and adapt network parameters accordingly. Empirical evaluations on five Atari games demonstrate accurate cumulative reward prediction of up to 200 frames. We consider these results as opening up important directions for model-based reinforcement learning in complex, initially unknown environments. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.07478;An unexpected unity among methods for interpreting model predictions; Scott Lundberg,  Su-In Lee;  Understanding why a model made a certain prediction is crucial in many data science fields. Interpretable predictions engender appropriate trust and provide insight into how the model may be improved. However, with large modern datasets the best accuracy is often achieved by complex models even experts struggle to interpret, which creates a tension between accuracy and interpretability. Recently, several methods have been proposed for interpreting predictions from complex models by estimating the importance of input features. Here, we present how a model-agnostic additive representation of the importance of input features unifies current methods. This representation is optimal, in the sense that it is the only set of additive values that satisfies important properties. We show how we can leverage these properties to create novel visual explanations of model predictions. The thread of unity that this representation weaves through the literature indicates that there are common principles to be learned about the interpretation of model predictions that apply in many scenarios. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.07567;Feature Importance Measure for Non-linear Learning Algorithms; Marina M.-C. Vidovic,  Nico Görnitz,  Klaus-Robert Müller,  Marius Kloft;  Complex problems may require sophisticated, non-linear learning methods such as kernel machines or deep neural networks to achieve state of the art prediction accuracies. However, high prediction accuracies are not the only objective to consider when solving problems using machine learning. Instead, particular scientific applications require some explanation of the learned prediction function. Unfortunately, most methods do not come with out of the box straight forward interpretation. Even linear prediction functions are not straight forward to explain if features exhibit complex correlation structure. In this paper, we propose the Measure of Feature Importance (MFI). MFI is general and can be applied to any arbitrary learning machine (including kernel machines and deep learning). MFI is intrinsically non-linear and can detect features that by itself are inconspicuous and only impact the prediction function through their interaction with other features. Lastly, MFI can be used for both --- model-based feature importance and instance-based feature importance (i.e, measuring the importance of a feature for a particular data point). ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.08037;A Spatio-Temporal Representation for the Orienteering Problem with  Time-Varying Profits; Zhibei Ma,  Kai Yin,  Lantao Liu,  Gaurav S. Sukhatme;  We consider an orienteering problem (OP) where an agent needs to visit a series (possibly a subset) of depots, from which the maximal accumulated profits are desired within given limited time budget. Different from most existing works where the profits are assumed to be static, in this work we investigate a variant that has arbitrary time-dependent profits. Specifically, the profits to be collected change over time and they follow different (e.g., independent) time-varying functions. The problem is of inherent nonlinearity and difficult to solve by existing methods. To tackle the challenge, we present a simple and effective framework that incorporates time-variations into the fundamental planning process. Specifically, we propose a deterministic spatio-temporal representation where both spatial description and temporal logic are unified into one routing topology. By employing existing basic sorting and searching algorithms, the routing solutions can be computed in an extremely efficient way. The proposed method is easy to implement and extensive numerical results show that our approach is time efficient and generates near-optimal solutions. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08103;Double-quantitative $γ^{\ast}-$fuzzy coverings approximation  operators; Guangming Lang;  In digital-based information boom, the fuzzy covering rough set model is an important mathematical tool for artificial intelligence, and how to build the bridge between the fuzzy covering rough set theory and Pawlak's model is becoming a hot research topic. In this paper, we first present the $\gamma-$fuzzy covering based probabilistic and grade approximation operators and double-quantitative approximation operators. We also study the relationships among the three types of $\gamma-$fuzzy covering based approximation operators. Second, we propose the $\gamma^{\ast}-$fuzzy coverings based multi-granulation probabilistic and grade lower and upper approximation operators and multi-granulation double-quantitative lower and upper approximation operators. We also investigate the relationships among these types of $\gamma-$fuzzy coverings based approximation operators. Finally, we employ several examples to illustrate how to construct the lower and upper approximations of fuzzy sets with the absolute and relative quantitative information. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08108;Dynamic Key-Value Memory Networks for Knowledge Tracing; Jiani Zhang,  Xingjian Shi,  Irwin King,  Dit-Yan Yeung;  Knowledge Tracing (KT) is a task of tracing evolving knowledge state of students with respect to one or more concepts as they engage in a sequence of learning activities. One important purpose of KT is to personalize the practice sequence to help students learn knowledge concepts efficiently. However, existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing either model knowledge state for each predefined concept separately or fail to pinpoint exactly which concepts a student is good at or unfamiliar with. To solve these problems, this work introduces a new model called Dynamic Key-Value Memory Networks (DKVMN) that can exploit the relationships between underlying concepts and directly output a student's mastery level of each concept. Unlike standard memory-augmented neural networks that facilitate a single memory matrix or two static memory matrices, our model has one static matrix called key, which stores the knowledge concepts and the other dynamic matrix called value, which stores and updates the mastery levels of corresponding concepts. Experiments show that our model consistently outperforms the state-of-the-art model in a range of KT datasets. Moreover, the DKVMN model can automatically discover underlying concepts of exercises typically performed by human annotations and depict the changing knowledge state of a student. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1611.08219;The Off-Switch Game; Dylan Hadfield-Menell,  Anca Dragan,  Pieter Abbeel,  Stuart Russell;  It is clear that one of the primary tools we can use to mitigate the potential risk from a misbehaving AI system is the ability to turn the system off. As the capabilities of AI systems improve, it is important to ensure that such systems do not adopt subgoals that prevent a human from switching them off. This is a challenge because many formulations of rational agents create strong incentives for self-preservation. This is not caused by a built-in instinct, but because a rational agent will maximize expected utility and cannot achieve whatever objective it has been given if it is dead. Our goal is to study the incentives an agent has to allow itself to be switched off. We analyze a simple game between a human H and a robot R, where H can press R's off switch but R can disable the off switch. A traditional agent takes its reward function for granted: we show that such agents have an incentive to disable the off switch, except in the special case where H is perfectly rational. Our key insight is that for R to want to preserve its off switch, it needs to be uncertain about the utility associated with the outcome, and to treat H's actions as important observations about that utility. (R also has no incentive to switch itself off in this setting.) We conclude that giving machines an appropriate level of uncertainty about their objectives leads to safer designs, and we argue that this setting is a useful generalization of the classical AI paradigm of rational agents. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08374;Decision Support Systems in Fisheries and Aquaculture: A systematic  review; Bjørn Magnus Mathisen,  Peter Haro,  Bård Hanssen,  Sara Björk,  Ståle Walderhaug;  Decision support systems help decision makers make better decisions in the face of complex decision problems (e.g. investment or policy decisions). Fisheries and Aquaculture is a domain where decision makers face such decisions since they involve factors from many different scientific fields. No systematic overview of literature describing decision support systems and their application in fisheries and aquaculture has been conducted. This paper summarizes scientific literature that describes decision support systems applied to the domain of Fisheries and Aquaculture. We use an established systematic mapping survey method to conduct our literature mapping. Our research questions are: What decision support systems for fisheries and aquaculture exists? What are the most investigated fishery and aquaculture decision support systems topics and how have these changed over time? Do any current DSS for fisheries provide real- time analytics? Do DSSes in Fisheries and Aquaculture build their models using machine learning done on captured and grounded data? The paper then detail how we employ the systematic mapping method in answering these questions. This results in 27 papers being identified as relevant and gives an exposition on the primary methods concluded in the study for designing a decision support system. We provide an analysis of the research done in the studies collected. We discovered that most literature does not consider multiple aspects for multiple stakeholders in their work. In addition we observed that little or no work has been done with real-time analysis in these decision support systems. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08481;GuessWhat?! Visual object discovery through multi-modal dialogue; Harm de Vries,  Florian Strub,  Sarath Chandar,  Olivier Pietquin,  Hugo Larochelle,  Aaron Courville;  We introduce GuessWhat?!, a two-player guessing game as a testbed for research on the interplay of computer vision and dialogue systems. The goal of the game is to locate an unknown object in a rich image scene by asking a sequence of questions. Higher-level image understanding, like spatial reasoning and language grounding, is required to solve the proposed task. Our key contribution is the collection of a large-scale dataset consisting of 150K human-played games with a total of 800K visual question-answer pairs on 66K images. We explain our design decisions in collecting the dataset and introduce the oracle and questioner tasks that are associated with the two players of the game. We prototyped deep learning models to establish initial baselines of the introduced tasks. ;"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)"
https://arxiv.org/abs/1611.08499;An Analysis of Tournament Structure; Nhien Pham Hoang Bao,  Hiroyuki Iida;  This paper explores a novel way for analyzing the tournament structures to find a best suitable one for the tournament under consideration. It concerns about three aspects such as tournament conducting cost, competitiveness development and ranking precision. It then proposes a new method using progress tree to detect potential throwaway matches. The analysis performed using the proposed method reveals the strengths and weaknesses of tournament structures. As a conclusion, single elimination is best if we want to qualify one winner only, all matches conducted are exciting in term of competitiveness. Double elimination with proper seeding system is a better choice if we want to qualify more winners. A reasonable number of extra matches need to be conducted in exchange of being able to qualify top four winners. Round-robin gives reliable ranking precision for all participants. However, its conduction cost is very high, and it fails to maintain competitiveness development. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08555;New Trends in Neutrosophic Theory and Applications; Florentin Smarandache,  Surapati Pramanik (Editors);  Neutrosophic theory and applications have been expanding in all directions at an astonishing rate especially after the introduction the journal entitled Neutrosophic Sets and Systems. New theories, techniques, algorithms have been rapidly developed. One of the most striking trends in the neutrosophic theory is the hybridization of neutrosophic set with other potential sets such as rough set, bipolar set, soft set, hesitant fuzzy set, etc. The different hybrid structure such as rough neutrosophic set, single valued neutrosophic rough set, bipolar neutrosophic set, single valued neutrosophic hesitant fuzzy set, etc. are proposed in the literature in a short period of time. Neutrosophic set has been a very important tool in all various areas of data mining, decision making, e-learning, engineering, medicine, social science, and some more. The book New Trends in Neutrosophic Theories and Applications focuses on theories, methods, algorithms for decision making and also applications involving neutrosophic information. Some topics deal with data mining, decision making, e-learning, graph theory, medical diagnosis, probability theory, topology, and some more. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08572;Bipolar Weighted Argumentation Graphs; Till Mossakowski,  Fabian Neuhaus;  This paper discusses the semantics of weighted argumentation graphs that are biplor, i.e. contain both attacks and support graphs. The work builds on previous work by Amgoud, Ben-Naim et. al., which presents and compares several semantics for argumentation graphs that contain only supports or only attacks relationships, respectively. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08675;Deep Reinforcement Learning for Multi-Domain Dialogue Systems; Heriberto Cuayáhuitl,  Seunghak Yu,  Ashley Williamson,  Jacob Carse;  Standard deep reinforcement learning methods such as Deep Q-Networks (DQN) for multiple tasks (domains) face scalability problems. We propose a method for multi-domain dialogue policy learning---termed NDQN, and apply it to an information-seeking spoken dialogue system in the domains of restaurants and hotels. Experimental results comparing DQN (baseline) versus NDQN (proposed) using simulations report that our proposed method exhibits better scalability and is promising for optimising the behaviour of multi-domain dialogue systems. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1611.08696;Optimizing Expectation with Guarantees in POMDPs (Technical Report); Krishnendu Chatterjee,  Petr Novotný,  Guillermo A. Pérez,  Jean-François Raskin,  Đorđe Žikelić;"  A standard objective in partially-observable Markov decision processes (POMDPs) is to find a policy that maximizes the expected discounted-sum payoff. However, such policies may still permit unlikely but highly undesirable outcomes, which is problematic especially in safety-critical applications. Recently, there has been a surge of interest in POMDPs where the goal is to maximize the probability to ensure that the payoff is at least a given threshold, but these approaches do not consider any optimization beyond satisfying this threshold constraint. In this work we go beyond both the ""expectation"" and ""threshold"" approaches and consider a ""guaranteed payoff optimization (GPO)"" problem for POMDPs, where we are given a threshold $t$ and the objective is to find a policy $\sigma$ such that a) each possible outcome of $\sigma$ yields a discounted-sum payoff of at least $t$, and b) the expected discounted-sum payoff of $\sigma$ is optimal (or near-optimal) among all policies satisfying a). We present a practical approach to tackle the GPO problem and evaluate it on standard POMDP benchmarks. ";"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)"
https://arxiv.org/abs/1611.08773;Embedded Bandits for Large-Scale Black-Box Optimization; Abdullah Al-Dujaili,  S. Suresh;  Random embedding has been applied with empirical success to large-scale black-box optimization problems with low effective dimensions. This paper proposes the EmbeddedHunter algorithm, which incorporates the technique in a hierarchical stochastic bandit setting, following the optimism in the face of uncertainty principle and breaking away from the multiple-run framework in which random embedding has been conventionally applied similar to stochastic black-box optimization solvers. Our proposition is motivated by the bounded mean variation in the objective value for a low-dimensional point projected randomly into the decision space of Lipschitz-continuous problems. In essence, the EmbeddedHunter algorithm expands optimistically a partitioning tree over a low-dimensional---equal to the effective dimension of the problem---search space based on a bounded number of random embeddings of sampled points from the low-dimensional space. In contrast to the probabilistic theoretical guarantees of multiple-run random-embedding algorithms, the finite-time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm's number of iterations. Furthermore, numerical experiments were conducted to validate its performance. The results show a clear performance gain over recently proposed random embedding methods for large-scale problems, provided the intrinsic dimensionality is low. ;"Artificial Intelligence (cs.AI); Optimization and Control (math.OC)"
https://arxiv.org/abs/1611.08908;"""Model and Run"" Constraint Networks with a MILP Engine"; Thierry Petit;"  Constraint Programming (CP) users need significant expertise in order to model their problems appropriately, notably to select propagators and search strategies. This puts the brakes on a broader uptake of CP. In this paper, we introduce MICE, a complete Java CP modeler that can use any Mixed Integer Linear Programming (MILP) solver as a solution technique. Our aim is to provide an alternative tool for democratizing the ""CP-style"" modeling thanks to its simplicity of use, with reasonable solving capabilities. Our contributions include new decompositions of (reified) constraints and constraints on numerical variables. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.08942;The BIN_COUNTS Constraint: Filtering and Applications; Roberto Rossi,  Özgür Akgün,  Steven Prestwich,  Armagan Tarim;  We introduce the BIN_COUNTS constraint, which deals with the problem of counting the number of decision variables in a set which are assigned values that lie in given bins. We illustrate a decomposition and a filtering algorithm that achieves generalised arc consistency. We contrast the filtering power of these two approaches and we discuss a number of applications. We show that BIN_COUNTS can be employed to develop a decomposition for the $\chi^2$ test constraint, a new statistical constraint that we introduce in this work. We also show how this new constraint can be employed in the context of the Balanced Academic Curriculum Problem and of the Balanced Nursing Workload Problem. For both these problems we carry out numerical studies involving our reformulations. Finally, we present a further application of the $\chi^2$ test constraint in the context of confidence interval analysis. ;"Artificial Intelligence (cs.AI); Probability (math.PR); Other Statistics (stat.OT)"
https://arxiv.org/abs/1611.08944;Nonparametric General Reinforcement Learning; Jan Leike;  Reinforcement learning (RL) problems are often phrased in terms of Markov decision processes (MDPs). In this thesis we go beyond MDPs and consider RL in environments that are non-Markovian, non-ergodic and only partially observable. Our focus is not on practical algorithms, but rather on the fundamental underlying problems: How do we balance exploration and exploitation? How do we explore optimally? When is an agent optimal? We follow the nonparametric realizable paradigm. We establish negative results on Bayesian RL agents, in particular AIXI. We show that unlucky or adversarial choices of the prior cause the agent to misbehave drastically. Therefore Legg-Hutter intelligence and balanced Pareto optimality, which depend crucially on the choice of the prior, are entirely subjective. Moreover, in the class of all computable environments every policy is Pareto optimal. This undermines all existing optimality properties for AIXI. However, there are Bayesian approaches to general RL that satisfy objective optimality guarantees: We prove that Thompson sampling is asymptotically optimal in stochastic environments in the sense that its value converges to the value of the optimal policy. We connect asymptotic optimality to regret given a recoverability assumption on the environment that allows the agent to recover from mistakes. Hence Thompson sampling achieves sublinear regret in these environments. Our results culminate in a formal solution to the grain of truth problem: A Bayesian agent acting in a multi-agent environment learns to predict the other agents' policies if its prior assigns positive probability to them (the prior contains a grain of truth). We construct a large but limit computable class containing a grain of truth and show that agents based on Thompson sampling over this class converge to play Nash equilibria in arbitrary unknown computable multi-agent environments. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.09014;Blocking and Other Enhancements for Bottom-Up Model Generation Methods; Peter Baumgartner,  Renate A. Schmidt;  Model generation is a problem complementary to theorem proving and is important for fault analysis and debugging of formal specifications of security protocols, programs and terminological definitions. This paper discusses several ways of enhancing the paradigm of bottom-up model generation. The two main contributions are new, generalized blocking techniques and a new range-restriction transformation. The blocking techniques are based on simple transformations of the input set together with standard equality reasoning and redundancy elimination techniques. These provide general methods for finding small, finite models. The range-restriction transformation refines existing transformations to range-restricted clauses by carefully limiting the creation of domain terms. All possible combinations of the introduced techniques and classical range-restriction were tested on the clausal problems of the TPTP Version 6.0.0 with an implementation based on the SPASS theorem prover using a hyperresolution-like refinement. Unrestricted domain blocking gave best results for satisfiable problems showing it is a powerful technique indispensable for bottom-up model generation methods. Both in combination with the new range-restricting transformation, and the classical range-restricting transformation, good results have been obtained. Limiting the creation of terms during the inference process by using the new range restricting transformation has paid off, especially when using it together with a shifting transformation. The experimental results also show that classical range restriction with unrestricted blocking provides a useful complementary method. Overall, the results showed bottom-up model generation methods were good for disproving theorems and generating models for satisfiable problems, but less efficient than SPASS in auto mode for unsatisfiable problems. ;"Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)"
https://arxiv.org/abs/1611.09328;Accelerated Gradient Temporal Difference Learning; Yangchen Pan,  Adam White,  Martha White;  The family of temporal difference (TD) methods span a spectrum from computationally frugal linear methods like TD({\lambda}) to data efficient least squares methods. Least square methods make the best use of available data directly computing the TD solution and thus do not require tuning a typically highly sensitive learning rate parameter, but require quadratic computation and storage. Recent algorithmic developments have yielded several sub-quadratic methods that use an approximation to the least squares TD solution, but incur bias. In this paper, we propose a new family of accelerated gradient TD (ATD) methods that (1) provide similar data efficiency benefits to least-squares methods, at a fraction of the computation and storage (2) significantly reduce parameter sensitivity compared to linear TD methods, and (3) are asymptotically unbiased. We illustrate these claims with a proof of convergence in expectation and experiments on several benchmark domains and a large-scale industrial energy allocation domain. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.09351;Adams Conditioning and Likelihood Ratio Transfer Mediated Inference; Jan A. Bergstra;"  Forensic science advocates the use of inference mechanisms which may be viewed as simple multi-agent protocols. An important protocol of this kind involves an agent FE (forensic expert) who communicates to a second agent TOF (trier of fact) first its value of a certain likelihood ratio with respect to its own belief state which is supposed to be captured by a probability function on FE's proposition space. Subsequently FE communicates its recently acquired confirmation that a certain evidence proposition is true. The inference part of this sort of reasoning, here referred to as likelihood ratio transfer mediated reasoning, involves TOF's revision of its own belief state, and in particular an evaluation of the resulting belief in the hypothesis proposition. Different realizations of likelihood ratio transfer mediated reasoning are distinguished: if the evidence hypothesis is included in the prior proposition space of TOF then a comparison is made between understanding the TOF side of a belief revision step as a composition of two successive steps of single likelihood Adams conditioning followed by a Bayes conditioning step, and as a single step of double likelihood Adams conditioning followed by Bayes conditioning; if, however the evidence hypothesis is initially outside the proposition space of TOF an application of proposition kinetics for the introduction of the evidence proposition precedes Bayesian conditioning, which is followed by Jeffrey conditioning on the hypothesis proposition. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1611.09434;Input Switched Affine Networks: An RNN Architecture Designed for  Interpretability; Jakob N. Foerster,  Justin Gilmer,  Jan Chorowski,  Jascha Sohl-Dickstein,  David Sussillo;"  There exist many problem domains where the interpretability of neural network models is essential for deployment. Here we introduce a recurrent architecture composed of input-switched affine transformations - in other words an RNN without any explicit nonlinearities, but with input-dependent recurrent weights. This simple form allows the RNN to be analyzed via straightforward linear methods: we can exactly characterize the linear contribution of each input to the model predictions; we can use a change-of-basis to disentangle input, output, and computational hidden unit subspaces; we can fully reverse-engineer the architecture's solution to a simple task. Despite this ease of interpretation, the input switched affine network achieves reasonable performance on a text modeling tasks, and allows greater computational efficiency than networks with standard nonlinearities. ";"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)"
https://arxiv.org/abs/1611.09573;Learning Concept Hierarchies through Probabilistic Topic Modeling; V. S. Anoop,  S. Asharaf,  P. Deepak;"  With the advent of semantic web, various tools and techniques have been introduced for presenting and organizing knowledge. Concept hierarchies are one such technique which gained significant attention due to its usefulness in creating domain ontologies that are considered as an integral part of semantic web. Automated concept hierarchy learning algorithms focus on extracting relevant concepts from unstructured text corpus and connect them together by identifying some potential relations exist between them. In this paper, we propose a novel approach for identifying relevant concepts from plain text and then learns hierarchy of concepts by exploiting subsumption relation between them. To start with, we model topics using a probabilistic topic model and then make use of some lightweight linguistic process to extract semantically rich concepts. Then we connect concepts by identifying an ""is-a"" relationship between pair of concepts. The proposed method is completely unsupervised and there is no need for a domain specific training corpus for concept extraction and learning. Experiments on large and real-world text corpora such as BBC News dataset and Reuters News corpus shows that the proposed method outperforms some of the existing methods for concept extraction and efficient concept hierarchy learning is possible if the overall task is guided by a probabilistic topic modeling algorithm. ";"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1611.09823;Dialogue Learning With Human-In-The-Loop; Jiwei Li,  Alexander H. Miller,  Sumit Chopra,  Marc'Aurelio Ranzato,  Jason Weston;  An important aspect of developing conversational agents is to give a bot the ability to improve through communicating with humans and to learn from the mistakes that it makes. Most research has focused on learning from fixed training sets of labeled data rather than interacting with a dialogue partner in an online fashion. In this paper we explore this direction in a reinforcement learning setting where the bot improves its question-answering ability from feedback a teacher gives following its generated responses. We build a simulator that tests various aspects of such learning in a synthetic environment, and introduce models that work in this regime. Finally, real experiments with Mechanical Turk validate the approach. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1611.09894;Exploration for Multi-task Reinforcement Learning with Deep Generative  Models; Sai Praveen Bangaru,  JS Suhas,  Balaraman Ravindran;  Exploration in multi-task reinforcement learning is critical in training agents to deduce the underlying MDP. Many of the existing exploration frameworks such as $E^3$, $R_{max}$, Thompson sampling assume a single stationary MDP and are not suitable for system identification in the multi-task setting. We present a novel method to facilitate exploration in multi-task reinforcement learning using deep generative models. We supplement our method with a low dimensional energy model to learn the underlying MDP distribution and provide a resilient and adaptive exploration signal to the agent. We evaluate our method on a new set of environments and provide intuitive interpretation of our results. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.09904;C-RNN-GAN: Continuous recurrent neural networks with adversarial  training; Olof Mogren;  Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1611.09940;Neural Combinatorial Optimization with Reinforcement Learning; Irwan Bello,  Hieu Pham,  Quoc V. Le,  Mohammad Norouzi,  Samy Bengio;  This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent network that, given a set of city coordinates, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent network using a policy gradient method. We compare learning the network parameters on a set of training graphs against learning them on individual test graphs. Despite the computational expense, without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to 100 nodes. Applied to the KnapSack, another NP-hard problem, the same method obtains optimal solutions for instances with up to 200 items. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.09948;Contextualizing Geometric Data Analysis and Related Data Analytics: A  Virtual Microscope for Big Data Analytics; Fionn Murtagh,  Mohsen Farid;  The relevance and importance of contextualizing data analytics is described. Qualitative characteristics might form the context of quantitative analysis. Topics that are at issue include: contrast, baselining, secondary data sources, supplementary data sources, dynamic and heterogeneous data. In geometric data analysis, especially with the Correspondence Analysis platform, various case studies are both experimented with, and are reviewed. In such aspects as paradigms followed, and technical implementation, implicitly and explicitly, an important point made is the major relevance of such work for both burgeoning analytical needs and for new analytical areas including Big Data analytics, and so on. For the general reader, it is aimed to display and describe, first of all, the analytical outcomes that are subject to analysis here, and then proceed to detail the more quantitative outcomes that fully support the analytics carried out. ;"Artificial Intelligence (cs.AI); Computers and Society (cs.CY)"
https://arxiv.org/abs/1611.09957;Low-dimensional Data Embedding via Robust Ranking; Ehsan Amid,  Nikos Vlassis,  Manfred K. Warmuth;  We describe a new method called t-ETE for finding a low-dimensional embedding of a set of objects in Euclidean space. We formulate the embedding problem as a joint ranking problem over a set of triplets, where each triplet captures the relative similarities between three objects in the set. By exploiting recent advances in robust ranking, t-ETE produces high-quality embeddings even in the presence of a significant amount of noise and better preserves local scale than known methods, such as t-STE and t-SNE. In particular, our method produces significantly better results than t-SNE on signature datasets while also being faster to compute. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1611.10095;System-Generated Requests for Rewriting Proposals; Pietro Speroni di Fenizio,  Cyril Velikanov;"  We present an online deliberation system using mutual evaluation in order to collaboratively develop solutions. Participants submit their proposals and evaluate each other's proposals; some of them may then be invited by the system to rewrite 'problematic' proposals. Two cases are discussed: a proposal supported by many, but not by a given person, who is then invited to rewrite it for making yet more acceptable; and a poorly presented but presumably interesting proposal. The first of these cases has been successfully implemented. Proposals are evaluated along two axes-understandability (or clarity, or, more generally, quality), and agreement. The latter is used by the system to cluster proposals according to their ideas, while the former is used both to present the best proposals on top of their clusters, and to find poorly written proposals candidates for rewriting. These functionalities may be considered as important components of a large scale online deliberation system. ";"Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)"
https://arxiv.org/abs/1611.10120;Fusion of EEG and Musical Features in Continuous Music-emotion  Recognition; Nattapong Thammasan,  Ken-ichi Fukui,  Masayuki Numao;  Emotion estimation in music listening is confronting challenges to capture the emotion variation of listeners. Recent years have witnessed attempts to exploit multimodality fusing information from musical contents and physiological signals captured from listeners to improve the performance of emotion recognition. In this paper, we present a study of fusion of signals of electroencephalogram (EEG), a tool to capture brainwaves at a high-temporal resolution, and musical features at decision level in recognizing the time-varying binary classes of arousal and valence. Our empirical results showed that the fusion could outperform the performance of emotion recognition using only EEG modality that was suffered from inter-subject variability, and this suggested the promise of multimodal fusion in improving the accuracy of music-emotion recognition. ;"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1612.00092;Computer Assisted Composition with Recurrent Neural Networks; Christian Walder,  Dongwoo Kim;  Sequence modeling with neural networks has lead to powerful models of symbolic music data. We address the problem of exploiting these models to reach creative musical goals, by combining with human input. To this end we generalise previous work, which sampled Markovian sequence models under the constraint that the sequence belong to the language of a given finite state machine provided by the human. We consider more expressive non-Markov models, thereby requiring approximate sampling which we provide in the form of an efficient sequential Monte Carlo method. In addition we provide and compare with a beam search strategy for conditional probability maximisation. Our algorithms are capable of convincingly re-harmonising famous musical works. To demonstrate this we provide visualisations, quantitative experiments, a human listening test and audio examples. We find both the sampling and optimisation procedures to be effective, yet complementary in character. For the case of highly permissive constraint sets, we find that sampling is to be preferred due to the overly regular nature of the optimisation based results. The generality of our algorithms permits countless other creative applications. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.00094;Optimizing Quantiles in Preference-based Markov Decision Processes; Hugo Gilbert,  Paul Weng,  Yan Xu;  In the Markov decision process model, policies are usually evaluated by expected cumulative rewards. As this decision criterion is not always suitable, we propose in this paper an algorithm for computing a policy optimal for the quantile criterion. Both finite and infinite horizons are considered. Finally we experimentally evaluate our approach on random MDPs and on a data center control problem. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.00104;Robust Optimization for Tree-Structured Stochastic Network Design; Xiaojian Wu,  Akshat Kumar,  Daniel Sheldon,  Shlomo Zilberstein;  Stochastic network design is a general framework for optimizing network connectivity. It has several applications in computational sustainability including spatial conservation planning, pre-disaster network preparation, and river network optimization. A common assumption in previous work has been made that network parameters (e.g., probability of species colonization) are precisely known, which is unrealistic in real- world settings. We therefore address the robust river network design problem where the goal is to optimize river connectivity for fish movement by removing barriers. We assume that fish passability probabilities are known only imprecisely, but are within some interval bounds. We then develop a planning approach that computes the policies with either high robust ratio or low regret. Empirically, our approach scales well to large river networks. We also provide insights into the solutions generated by our robust approach, which has significantly higher robust ratio than the baseline solution with mean parameter estimates. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.00222;Interaction Networks for Learning about Objects, Relations and Physics; Peter W. Battaglia,  Razvan Pascanu,  Matthew Lai,  Danilo Rezende,  Koray Kavukcuoglu;  Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1612.00227;On Coreferring Text-extracted Event Descriptions with the aid of  Ontological Reasoning; Stefano Borgo,  Loris Bozzato,  Alessio Palmero Aprosio,  Marco Rospocher,  Luciano Serafini;  Systems for automatic extraction of semantic information about events from large textual resources are now available: these tools are capable to generate RDF datasets about text extracted events and this knowledge can be used to reason over the recognized events. On the other hand, text based tasks for event recognition, as for example event coreference (i.e. recognizing whether two textual descriptions refer to the same event), do not take into account ontological information of the extracted events in their process. In this paper, we propose a method to derive event coreference on text extracted event data using semantic based rule reasoning. We demonstrate our method considering a limited (yet representative) set of event types: we introduce a formal analysis on their ontological properties and, on the base of this, we define a set of coreference criteria. We then implement these criteria as RDF-based reasoning rules to be applied on text extracted event data. We evaluate the effectiveness of our approach over a standard coreference benchmark dataset. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1612.00240;An Evaluation of Models for Runtime Approximation in Link Discovery; Kleanthi Georgala,  Micheal Hoffmann,  Axel-Cyrille Ngonga Ngomo;  Time-efficient link discovery is of central importance to implement the vision of the Semantic Web. Some of the most rapid Link Discovery approaches rely internally on planning to execute link specifications. In newer works, linear models have been used to estimate the runtime the fastest planners. However, no other category of models has been studied for this purpose so far. In this paper, we study non-linear runtime estimation functions for runtime estimation. In particular, we study exponential and mixed models for the estimation of the runtimes of planners. To this end, we evaluate three different models for runtime on six datasets using 400 link specifications. We show that exponential and mixed models achieve better fits when trained but are only to be preferred in some cases. Our evaluation also shows that the use of better runtime approximation models has a positive impact on the overall execution of link specifications. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.00341;A Compositional Object-Based Approach to Learning Physical Dynamics; Michael B. Chang,  Tomer Ullman,  Antonio Torralba,  Joshua B. Tenenbaum;"  We present the Neural Physics Engine (NPE), a framework for learning simulators of intuitive physics that naturally generalize across variable object count and different scene configurations. We propose a factorization of a physical scene into composable object-based representations and a neural network architecture whose compositional structure factorizes object dynamics into pairwise interactions. Like a symbolic physics engine, the NPE is endowed with generic notions of objects and their interactions; realized as a neural network, it can be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the efficacy of our approach on simple rigid body dynamics in two-dimensional worlds. By comparing to less structured architectures, we show that the NPE's compositional representation of the structure in physical interactions improves its ability to predict movement, generalize across variable object count and different scene configurations, and infer latent properties of objects such as mass. ";"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1612.00380;Playing Doom with SLAM-Augmented Deep Reinforcement Learning; Shehroze Bhatti,  Alban Desmaison,  Ondrej Miksik,  Nantas Nardelli,  N. Siddharth,  Philip H. S. Torr;  A number of recent approaches to policy learning in 2D game domains have been successful going directly from raw input images to actions. However when employed in complex 3D environments, they typically suffer from challenges related to partial observability, combinatorial exploration spaces, path planning, and a scarcity of rewarding scenarios. Inspired from prior work in human cognition that indicates how humans employ a variety of semantic concepts and abstractions (object categories, localisation, etc.) to reason about the world, we build an agent-model that incorporates such abstractions into its policy-learning framework. We augment the raw image input to a Deep Q-Learning Network (DQN), by adding details of objects and structural elements encountered, along with the agent's localisation. The different components are automatically extracted and composed into a topological representation using on-the-fly object detection and 3D-scene reconstruction.We evaluate the efficacy of our approach in Doom, a 3D first-person combat game that exhibits a number of challenges discussed, and show that our augmented framework consistently learns better, more effective policies. ;"Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)"
https://arxiv.org/abs/1612.00742;Comparison of the COG Defuzzification Technique and Its Variations to  the GPA Index; Michael Gr. Voskoglou;  The Center of Gravity (COG) method is one of the most popular defuzzification techniques of fuzzy mathematics. In earlier works the COG technique was properly adapted to be used as an assessment model (RFAM)and several variations of it (GRFAM, TFAM and TpFAM)were also constructed for the same purpose. In this paper the outcomes of all these models are compared to the corresponding outcomes of a traditional assessment method of the bi-valued logic, the Grade Point Average (GPA) Index. Examples are also presented illustrating our results. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.00916;A Matrix Splitting Perspective on Planning with Options; Pierre-Luc Bacon,  Doina Precup;  We show that the Bellman operator underlying the options framework leads to a matrix splitting, an approach traditionally used to speed up convergence of iterative solvers for large linear systems of equations. Based on standard comparison theorems for matrix splittings, we then show how the asymptotic rate of convergence varies as a function of the inherent timescales of the options. This new perspective highlights a trade-off between asymptotic performance and the cost of computation associated with building a good set of options. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.00944;Using Discourse Signals for Robust Instructor Intervention Prediction; Muthu Kumar Chandrasekaran,  Carrie Demmans Epp,  Min-Yen Kan,  Diane Litman;  We tackle the prediction of instructor intervention in student posts from discussion forums in Massive Open Online Courses (MOOCs). Our key finding is that using automatically obtained discourse relations improves the prediction of when instructors intervene in student discussions, when compared with a state-of-the-art, feature-rich baseline. Our supervised classifier makes use of an automatic discourse parser which outputs Penn Discourse Treebank (PDTB) tags that represent in-post discourse features. We show PDTB relation-based features increase the robustness of the classifier and complement baseline features in recalling more diverse instructor intervention patterns. In comprehensive experiments over 14 MOOC offerings from several disciplines, the PDTB discourse features improve performance on average. The resultant models are less dependent on domain-specific vocabulary, allowing them to better generalize to new courses. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)"
https://arxiv.org/abs/1612.00959;RecSys Challenge 2016: job recommendations based on preselection of  offers and gradient boosting; Andrzej Pacuk,  Piotr Sankowski,  Karol Węgrzycki,  Adam Witkowski,  Piotr Wygocki;  We present the Mim-Solution's approach to the RecSys Challenge 2016, which ranked 2nd. The goal of the competition was to prepare job recommendations for the users of the website Xing.com. Our two phase algorithm consists of candidate selection followed by the candidate ranking. We ranked the candidates by the predicted probability that the user will positively interact with the job offer. We have used Gradient Boosting Decision Trees as the regression tool. ;"Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1612.01010;DeepBach: a Steerable Model for Bach Chorales Generation; Gaëtan Hadjeres,  François Pachet,  Frank Nielsen;  This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data. This is in contrast with many automatic music composition approaches which tend to compose music sequentially. Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score. We also provide a plugin on top of the MuseScore music editor making the interaction with DeepBach easy to use. ;"Artificial Intelligence (cs.AI); Sound (cs.SD)"
https://arxiv.org/abs/1612.01058;Algorithmic Songwriting with ALYSIA; Margareta Ackerman,  David Loker;  This paper introduces ALYSIA: Automated LYrical SongwrIting Application. ALYSIA is based on a machine learning model using Random Forests, and we discuss its success at pitch and rhythm prediction. Next, we show how ALYSIA was used to create original pop songs that were subsequently recorded and produced. Finally, we discuss our vision for the future of Automated Songwriting for both co-creative and autonomous systems. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD)"
https://arxiv.org/abs/1612.01086;Deep Learning of Robotic Tasks without a Simulator using Strong and Weak  Human Supervision; Bar Hilleli,  Ran El-Yaniv;"  We propose a scheme for training a computerized agent to perform complex human tasks such as highway steering. The scheme is designed to follow a natural learning process whereby a human instructor teaches a computerized trainee. The learning process consists of five elements: (i) unsupervised feature learning; (ii) supervised imitation learning; (iii) supervised reward induction; (iv) supervised safety module construction; and (v) reinforcement learning. We implemented the last four elements of the scheme using deep convolutional networks and applied it to successfully create a computerized agent capable of autonomous highway steering over the well-known racing game Assetto Corsa. We demonstrate that the use of the last four elements is essential to effectively carry out the steering task using vision alone, without access to a driving simulator internals, and operating in wall-clock time. This is made possible also through the introduction of a safety network, a novel way for preventing the agent from performing catastrophic mistakes during the reinforcement learning stage. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Robotics (cs.RO)"
https://arxiv.org/abs/1612.01120;The Complexity of Bayesian Networks Specified by Propositional and  Relational Languages; Fabio Gagliardi Cozman,  Denis Deratani Mauá;"  We examine the complexity of inference in Bayesian networks specified by logical languages. We consider representations that range from fragments of propositional logic to function-free first-order logic with equality; in doing so we cover a variety of plate models and of probabilistic relational models. We study the complexity of inferences when network, query and domain are the input (the inferential and the combined complexity), when the network is fixed and query and domain are the input (the query/data complexity), and when the network and query are fixed and the domain is the input (the domain complexity). We draw connections with probabilistic databases and liftability results, and obtain complexity classes that range from polynomial to exponential levels. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.01608;AI Researchers, Video Games Are Your Friends!; Julian Togelius;"  If you are an artificial intelligence researcher, you should look to video games as ideal testbeds for the work you do. If you are a video game developer, you should look to AI for the technology that makes completely new types of games possible. This chapter lays out the case for both of these propositions. It asks the question ""what can video games do for AI"", and discusses how in particular general video game playing is the ideal testbed for artificial general intelligence research. It then asks the question ""what can AI do for video games"", and lays out a vision for what video games might look like if we had significantly more advanced AI at our disposal. The chapter is based on my keynote at IJCCI 2015, and is written in an attempt to be accessible to a broad audience. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.01691;Fleet Size and Mix Split-Delivery Vehicle Routing; Arthur Mahéo,  Tommaso Urli,  Philip Kilby;  In the classic Vehicle Routing Problem (VRP) a fleet of of vehicles has to visit a set of customers while minimising the operations' costs. We study a rich variant of the VRP featuring split deliveries, an heterogeneous fleet, and vehicle-commodity incompatibility constraints. Our goal is twofold: define the cheapest routing and the most adequate fleet. To do so, we split the problem into two interdependent components: a fleet design component and a routing component. First, we define two Mixed Integer Programming (MIP) formulations for each component. Then we discuss several improvements in the form of valid cuts and symmetry breaking constraints. The main contribution of this paper is a comparison of the four resulting models for this Rich VRP. We highlight their strengths and weaknesses with extensive experiments. Finally, we explore a lightweight integration with Constraint Programming (CP). We use a fast CP model which gives good solutions and use the solution to warm-start our models. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.01857;On a Well-behaved Relational Generalisation of Rough Set Approximations; Alexa Gopaulsingh;  We examine non-dual relational extensions of rough set approximations and find an extension which satisfies surprisingly many of the usual rough set properties. We then use this definition to give an explanation for an observation made by Samanta and Chakraborty in their recent paper [P. Samanta and M.K. Chakraborty. Interface of rough set systems and modal logics: A survey. Transactions on Rough Sets XIX, pages 114-137, 2015]. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.01892;Cross-Lingual Predicate Mapping Between Linked Data Ontologies; Gautam Singh,  Saemi Jang,  Mun Y. Yi;  Ontologies in different natural languages often differ in quality in terms of richness of schema or richness of internal links. This difference is markedly visible when comparing a rich English language ontology with a non-English language counterpart. Discovering alignment between them is a useful endeavor as it serves as a starting point in bridging the disparity. In particular, our work is motivated by the absence of inter-language links for predicates in the localised versions of DBpedia. In this paper, we propose and demonstrate an ad-hoc system to find possible owl:equivalentProperty links between predicates in ontologies of different natural languages. We seek to achieve this mapping by using pre-existing inter-language links of the resources connected by the given predicate. Thus, our methodology stresses on semantic similarity rather than lexical. Moreover, through an evaluation, we show that our system is capable of outperforming a baseline system that is similar to the one used in recent OAEI campaigns. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1612.01941;Coactive Critiquing: Elicitation of Preferences and Features; Stefano Teso,  Paolo Dragone,  Andrea Passerini;  When faced with complex choices, users refine their own preference criteria as they explore the catalogue of options. In this paper we propose an approach to preference elicitation suited for this scenario. We extend Coactive Learning, which iteratively collects manipulative feedback, to optionally query example critiques. User critiques are integrated into the learning model by dynamically extending the feature space. Our formulation natively supports constructive learning tasks, where the option catalogue is generated on-the-fly. We present an upper bound on the average regret suffered by the learner. Our empirical analysis highlights the promise of our approach. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.02088;Effect of Reward Function Choices in MDPs with Value-at-Risk; Shuai Ma,  Jia Yuan Yu;  This paper studies Value-at-Risk (VaR) problems in short- and long-horizon Markov decision processes (MDPs) with finite state space and two different reward functions. Firstly we examine the effects of two reward functions under two criteria in a short-horizon MDP. We show that under the VaR criterion, when the original reward function is on both current and next states, the reward simplification will change the VaR. Secondly, for long-horizon MDPs, we estimate the Pareto front of the total reward distribution set with the aid of spectral theory and the central limit theorem. Since the estimation is for a Markov process with the simplified reward function only, we present a transformation algorithm for the Markov process with the original reward function, in order to estimate the Pareto front with an intact total reward distribution. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.02161;Measuring the non-asymptotic convergence of sequential Monte Carlo  samplers using probabilistic programming; Marco F. Cusumano-Towner,  Vikash K. Mansinghka;  A key limitation of sampling algorithms for approximate inference is that it is difficult to quantify their approximation error. Widely used sampling schemes, such as sequential importance sampling with resampling and Metropolis-Hastings, produce output samples drawn from a distribution that may be far from the target posterior distribution. This paper shows how to upper-bound the symmetric KL divergence between the output distribution of a broad class of sequential Monte Carlo (SMC) samplers and their target posterior distributions, subject to assumptions about the accuracy of a separate gold-standard sampler. The proposed method applies to samplers that combine multiple particles, multinomial resampling, and rejuvenation kernels. The experiments show the technique being used to estimate bounds on the divergence of SMC samplers for posterior inference in a Bayesian linear regression model and a Dirichlet process mixture model. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1612.02255;Knowledge Representation in Graphs using Convolutional Neural Networks; Armando Vieira;  Knowledge Graphs (KG) constitute a flexible representation of complex relationships between entities particularly useful for biomedical data. These KG, however, are very sparse with many missing edges (facts) and the visualisation of the mesh of interactions nontrivial. Here we apply a compositional model to embed nodes and relationships into a vectorised semantic space to perform graph completion. A visualisation tool based on Convolutional Neural Networks and Self-Organised Maps (SOM) is proposed to extract high-level insights from the KG. We apply this technique to a subset of CTD, containing interactions of compounds with human genes / proteins and show that the performance is comparable to the one obtained by structural models. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.02310;Extend natural neighbor: a novel classification method with  self-adaptive neighborhood parameters in different stages; Ji Feng,  Qingsheng Zhu,  Jinlong Huang,  Lijun Yang;  Various kinds of k-nearest neighbor (KNN) based classification methods are the bases of many well-established and high-performance pattern-recognition techniques, but both of them are vulnerable to their parameter choice. Essentially, the challenge is to detect the neighborhood of various data sets, while utterly ignorant of the data characteristic. This article introduces a new supervised classification method: the extend natural neighbor (ENaN) method, and shows that it provides a better classification result without choosing the neighborhood parameter artificially. Unlike the original KNN based method which needs a prior k, the ENaNE method predicts different k in different stages. Therefore, the ENaNE method is able to learn more from flexible neighbor information both in training stage and testing stage, and provide a better classification result. ;"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1612.02487;Interactive Elicitation of Knowledge on Feature Relevance Improves  Predictions in Small Data Sets; Luana Micallef,  Iiris Sundin,  Pekka Marttinen,  Muhammad Ammad-ud-din,  Tomi Peltola,  Marta Soare,  Giulio Jacucci,  Samuel Kaski;  Providing accurate predictions is challenging for machine learning algorithms when the number of features is larger than the number of samples in the data. Prior knowledge can improve machine learning models by indicating relevant variables and parameter values. Yet, this prior knowledge is often tacit and only available from domain experts. We present a novel approach that uses interactive visualization to elicit the tacit prior knowledge and uses it to improve the accuracy of prediction models. The main component of our approach is a user model that models the domain expert's knowledge of the relevance of different features for a prediction task. In particular, based on the expert's earlier input, the user model guides the selection of the features on which to elicit user's knowledge next. The results of a controlled user study show that the user model significantly improves prior knowledge elicitation and prediction accuracy, when predicting the relative citation counts of scientific documents in a specific domain. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1612.02587;Inverses, Conditionals and Compositional Operators in Separative  Valuation Algebra; Juerg Kohlas;  Compositional models were introduce by Jirousek and Shenoy in the general framework of valuation-based systems. They based their theory on an axiomatic system of valuations involving not only the operations of combination and marginalisation, but also of removal. They claimed that this systems covers besides the classical case of discrete probability distributions, also the cases of Gaussian densities and belief functions, and many other systems. Whereas their results on the compositional operator are correct, the axiomatic basis is not sufficient to cover the examples claimed above. We propose here a different axiomatic system of valuation algebras, which permits a rigorous mathematical theory of compositional operators in valuation-based systems and covers all the examples mentioned above. It extends the classical theory of inverses in semigroup theory and places thereby the present theory into its proper mathematical frame. Also this theory sheds light on the different structures of valuation-based systems, like regular algebras (represented by probability potentials), canncellative algebras (Gaussian potentials) and general separative algebras (density functions). ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.02660;Decision Theory in an Algebraic Setting; Maurizio Negri;  In decision theory an act is a function from a set of conditions to the set of real numbers. The set of conditions is a partition in some algebra of events. The expected value of an act can be calculated when a probability measure is given. We adopt an algebraic point of view by substituting the algebra of events with a finite distributive lattice and the probability measure with a lattice valuation. We introduce a partial order on acts that generalizes the dominance relation and show that the set of acts is a lattice with respect to this order. Finally we analyze some different kinds of comparison between acts, without supposing a common set of conditions for the acts to be compared. ;"Artificial Intelligence (cs.AI); Probability (math.PR)"
https://arxiv.org/abs/1612.02757;Hierarchy through Composition with Linearly Solvable Markov Decision  Processes; Andrew M. Saxe,  Adam Earle,  Benjamin Rosman;  Hierarchical architectures are critical to the scalability of reinforcement learning methods. Current hierarchical frameworks execute actions serially, with macro-actions comprising sequences of primitive actions. We propose a novel alternative to these control hierarchies based on concurrent execution of many actions in parallel. Our scheme uses the concurrent compositionality provided by the linearly solvable Markov decision process (LMDP) framework, which naturally enables a learning agent to draw on several macro-actions simultaneously to solve new tasks. We introduce the Multitask LMDP module, which maintains a parallel distributed representation of tasks and may be stacked to form deep hierarchies abstracted in space and time. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.02904;GOTM: a Goal-oriented Framework for Capturing Uncertainty of Medical  Treatments; Davoud Mougouei,  David Powers;  It has been widely recognized that uncertainty is an inevitable aspect of diagnosis and treatment of medical disorders. Such uncertainties hence, need to be considered in computerized medical models. The existing medical modeling techniques however, have mainly focused on capturing uncertainty associated with diagnosis of medical disorders while ignoring uncertainty of treatments. To tackle this issue, we have proposed using a fuzzy-based modeling and description technique for capturing uncertainties in treatment plans. We have further contributed a formal framework which allows for goal-oriented modeling and analysis of medical treatments. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.03055;Measuring Adverse Drug Effects on Multimorbity using Tractable Bayesian  Networks; Jessa Bekker,  Arjen Hommersom,  Martijn Lappenschaar,  Jesse Davis;  Managing patients with multimorbidity often results in polypharmacy: the prescription of multiple drugs. However, the long-term effects of specific combinations of drugs and diseases are typically unknown. In particular, drugs prescribed for one condition may result in adverse effects for the other. To investigate which types of drugs may affect the further progression of multimorbidity, we query models of diseases and prescriptions that are learned from primary care data. State-of-the-art tractable Bayesian network representations, on which such complex queries can be computed efficiently, are employed for these large medical networks. Our results confirm that prescriptions may lead to unintended negative consequences in further development of multimorbidity in cardiovascular diseases. Moreover, a drug treatment for one disease group may affect diseases of another group. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.03211;DeepCancer: Detecting Cancer through Gene Expressions via Deep  Generative Learning; Rajendra Rana Bhat,  Vivek Viswanath,  Xiaolin Li;  Transcriptional profiling on microarrays to obtain gene expressions has been used to facilitate cancer diagnosis. We propose a deep generative machine learning architecture (called DeepCancer) that learn features from unlabeled microarray data. These models have been used in conjunction with conventional classifiers that perform classification of the tissue samples as either being cancerous or non-cancerous. The proposed model has been tested on two different clinical datasets. The evaluation demonstrates that DeepCancer model achieves a very high precision score, while significantly controlling the false positive and false negative scores. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Genomics (q-bio.GN)"
https://arxiv.org/abs/1612.03328;Knowledge Elicitation via Sequential Probabilistic Inference for  High-Dimensional Prediction; Pedram Daee,  Tomi Peltola,  Marta Soare,  Samuel Kaski;"  Prediction in a small-sized sample with a large number of covariates, the ""small n, large p"" problem, is challenging. This setting is encountered in multiple applications, such as precision medicine, where obtaining additional samples can be extremely costly or even impossible, and extensive research effort has recently been dedicated to finding principled solutions for accurate prediction. However, a valuable source of additional information, domain experts, has not yet been efficiently exploited. We formulate knowledge elicitation generally as a probabilistic inference process, where expert knowledge is sequentially queried to improve predictions. In the specific case of sparse linear regression, where we assume the expert has knowledge about the values of the regression coefficients or about the relevance of the features, we propose an algorithm and computational approximation for fast and efficient interaction, which sequentially identifies the most informative features on which to query expert knowledge. Evaluations of our method in experiments with simulated and real users show improved prediction accuracy already with a small effort from the expert. ";"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1612.03353;FOCA: A Methodology for Ontology Evaluation; Judson Bandeira,  Ig Ibert Bittencourt,  Patricia Espinheira,  Seiji Isotani;"  Modeling an ontology is a hard and time-consuming task. Although methodologies are useful for ontologists to create good ontologies, they do not help with the task of evaluating the quality of the ontology to be reused. For these reasons, it is imperative to evaluate the quality of the ontology after constructing it or before reusing it. Few studies usually present only a set of criteria and questions, but no guidelines to evaluate the ontology. The effort to evaluate an ontology is very high as there is a huge dependence on the evaluator's expertise to understand the criteria and questions in depth. Moreover, the evaluation is still very subjective. This study presents a novel methodology for ontology evaluation, taking into account three fundamental principles: i) it is based on the Goal, Question, Metric approach for empirical evaluation; ii) the goals of the methodologies are based on the roles of knowledge representations combined with specific evaluation criteria; iii) each ontology is evaluated according to the type of ontology. The methodology was empirically evaluated using different ontologists and ontologies of the same domain. The main contributions of this study are: i) defining a step-by-step approach to evaluate the quality of an ontology; ii) proposing an evaluation based on the roles of knowledge representations; iii) the explicit difference of the evaluation according to the type of the ontology iii) a questionnaire to evaluate the ontologies; iv) a statistical model that automatically calculates the quality of the ontologies. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.03471;Reinforcement Learning With Temporal Logic Rewards; Xiao Li,  Cristian-Ioan Vasile,  Calin Belta;  Reinforcement learning (RL) depends critically on the choice of reward functions used to capture the de- sired behavior and constraints of a robot. Usually, these are handcrafted by a expert designer and represent heuristics for relatively simple tasks. Real world applications typically involve more complex tasks with rich temporal and logical structure. In this paper we take advantage of the expressive power of temporal logic (TL) to specify complex rules the robot should follow, and incorporate domain knowledge into learning. We propose Truncated Linear Temporal Logic (TLTL) as specifications language, that is arguably well suited for the robotics applications, together with quantitative semantics, i.e., robustness degree. We propose a RL approach to learn tasks expressed as TLTL formulae that uses their associated robustness degree as reward functions, instead of the manually crafted heuristics trying to capture the same specifications. We show in simulated trials that learning is faster and policies obtained using the proposed approach outperform the ones learned using heuristic rewards in terms of the robustness degree, i.e., how well the tasks are satisfied. Furthermore, we demonstrate the proposed RL approach in a toast-placing task learned by a Baxter robot. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1612.03494;Flu Detector: Estimating influenza-like illness rates from online  user-generated content; Vasileios Lampos;  We provide a brief technical description of an online platform for disease monitoring, titled as the Flu Detector (fludetector.cs.ucl.ac.uk). Flu Detector, in its current version (v.0.5), uses either Twitter or Google search data in conjunction with statistical Natural Language Processing models to estimate the rate of influenza-like illness in the population of England. Its back-end is a live service that collects online data, utilises modern technologies for large-scale text processing, and finally applies statistical inference models that are trained offline. The front-end visualises the various disease rate estimates. Notably, the models based on Google data achieve a high level of accuracy with respect to the most recent four flu seasons in England (2012/13 to 2015/16). This highlighted Flu Detector as having a great potential of becoming a complementary source to the domestic traditional flu surveillance schemes. ;"Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)"
https://arxiv.org/abs/1612.03653;Learning to Drive using Inverse Reinforcement Learning and Deep  Q-Networks; Sahand Sharifzadeh,  Ioannis Chiotellis,  Rudolph Triebel,  Daniel Cremers;  We propose an inverse reinforcement learning (IRL) approach using Deep Q-Networks to extract the rewards in problems with large state spaces. We evaluate the performance of this approach in a simulation-based autonomous driving scenario. Our results resemble the intuitive relation between the reward function and readings of distance sensors mounted at different poses on the car. We also show that, after a few learning rounds, our simulated agent generates collision-free motions and performs human-like lane change behaviour. ;"Artificial Intelligence (cs.AI); Robotics (cs.RO)"
https://arxiv.org/abs/1612.03780;Online Reinforcement Learning for Real-Time Exploration in Continuous  State and Action Markov Decision Processes; Ludovic Hofer,  Hugo Gimbert;"  This paper presents a new method to learn online policies in continuous state, continuous action, model-free Markov decision processes, with two properties that are crucial for practical applications. First, the policies are implementable with a very low computational cost: once the policy is computed, the action corresponding to a given state is obtained in logarithmic time with respect to the number of samples used. Second, our method is versatile: it does not rely on any a priori knowledge of the structure of optimal policies. We build upon the Fitted Q-iteration algorithm which represents the $Q$-value as the average of several regression trees. Our algorithm, the Fitted Policy Forest algorithm (FPF), computes a regression forest representing the Q-value and transforms it into a single tree representing the policy, while keeping control on the size of the policy using resampling and leaf merging. We introduce an adaptation of Multi-Resolution Exploration (MRE) which is particularly suited to FPF. We assess the performance of FPF on three classical benchmarks for reinforcement learning: the ""Inverted Pendulum"", the ""Double Integrator"" and ""Car on the Hill"" and show that FPF equals or outperforms other algorithms, although these algorithms rely on the use of particular representations of the policies, especially chosen in order to fit each of the three problems. Finally, we exhibit that the combination of FPF and MRE allows to find nearly optimal solutions in problems where $\epsilon$-greedy approaches would fail. ";"Artificial Intelligence (cs.AI); Learning (cs.LG)"
https://arxiv.org/abs/1612.03801;DeepMind Lab; Charles Beattie,  Joel Z. Leibo,  Denis Teplyashin,  Tom Ward,  Marcus Wainwright,  Heinrich Küttler,  Andrew Lefrancq,  Simon Green,  Víctor Valdés,  Amir Sadik,  Julian Schrittwieser,  Keith Anderson,  Sarah York,  Max Cant,  Adam Cain,  Adrian Bolton,  Stephen Gaffney,  Helen King,  Demis Hassabis,  Shane Legg,  Stig Petersen;  DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.03871;Knowledge Completion for Generics using Guided Tensor Factorization; Hanie Sedghi,  Ashish Sabharwal;"  Given a knowledge base (KB) rich in facts about common nouns or generics, such as ""all trees produce oxygen"" or ""some animals live in forests"", we consider the problem of deriving additional such facts at a high precision. While this problem has received much attention for named entity KBs such as Freebase, little emphasis has been placed on generics despite their importance for capturing general knowledge. Different from named entity KBs, generics KBs involve implicit or explicit quantification, have more complex underlying regularities, are substantially more incomplete, and violate the commonly used locally closed world assumption (LCWA). Consequently, existing completion methods struggle with this new task. We observe that external information, such as relation schemas and entity taxonomies, if used correctly, can be surprisingly powerful in addressing the challenges associated with generics. Using this insight, we propose a simple yet effective knowledge guided tensor factorization approach that achieves state-of-the-art results on two generics KBs for science, doubling their size at 74\%-86\% precision. Further, to address the paucity of facts about rare entities such as oriole (a bird), we present a novel taxonomy guided submodular active learning method to collect additional annotations that are over five times more effective in inferring further new facts than multiple active learning baselines. ";"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1612.04469;Web-based Argumentation; Kenrick;"  Assumption-Based Argumentation (ABA) is an argumentation framework that has been proposed in the late 20th century. Since then, there was still no solver implemented in a programming language which is easy to setup and no solver have been interfaced to the web, which impedes the interests of the public. This project aims to implement an ABA solver in a modern programming language that performs reasonably well and interface it to the web for easier access by the public. This project has demonstrated the novelty of development of an ABA solver, that computes conflict-free, stable, admissible, grounded, ideal, and complete semantics, in Python programming language which can be used via an easy-to-use web interface for visualization of the argument and dispute trees. Experiments were conducted to determine the project's best configurations and to compare this project with proxdd, a state-of-the-art ABA solver, which has no web interface and computes less number of semantics. From the results of the experiments, this project's best configuration is achieved by utilizing ""pickle"" technique and tree caching technique. Using this project's best configuration, this project achieved a lower average runtime compared to proxdd. On other aspect, this project encountered more cases with exceptions compared to proxdd, which might be caused by this project computing more semantics and hence requires more resources to do so. Hence, it can be said that this project run comparably well to the state-of-the-art ABA solver proxdd. Future works of this project include computational complexity analysis and efficiency analysis of algorithms implemented, implementation of more semantics in argumentation framework, and usability testing of the web interface. ";Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.04687;Real-time interactive sequence generation and control with Recurrent  Neural Network ensembles; Memo Akten,  Mick Grierson;  Recurrent Neural Networks (RNN), particularly Long Short Term Memory (LSTM) RNNs, are a popular and very successful method for learning and generating sequences. However, current generative RNN techniques do not allow real-time interactive control of the sequence generation process, thus aren't well suited for live creative expression. We propose a method of real-time continuous control and 'steering' of sequence generation using an ensemble of RNNs and dynamically altering the mixture weights of the models. We demonstrate the method using character based LSTM networks and a gestural interface allowing users to 'conduct' the generation of text. ;"Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)"
https://arxiv.org/abs/1612.04759;Encapsulating models and approximate inference programs in probabilistic  modules; Marco F. Cusumano-Towner,  Vikash K. Mansinghka;  This paper introduces the probabilistic module interface, which allows encapsulation of complex probabilistic models with latent variables alongside custom stochastic approximate inference machinery, and provides a platform-agnostic abstraction barrier separating the model internals from the host probabilistic inference system. The interface can be seen as a stochastic generalization of a standard simulation and density interface for probabilistic primitives. We show that sound approximate inference algorithms can be constructed for networks of probabilistic modules, and we demonstrate that the interface can be implemented using learned stochastic inference networks and MCMC and SMC approximate inference programs. ;"Artificial Intelligence (cs.AI); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1612.04791;Scalable Computation of Optimized Queries for Sequential Diagnosis; Patrick Rodler,  Wolfgang Schmid,  Kostyantyn Shchekotykhin;  In many model-based diagnosis applications it is impossible to provide such a set of observations and/or measurements that allow to identify the real cause of a fault. Therefore, diagnosis systems often return many possible candidates, leaving the burden of selecting the correct diagnosis to a user. Sequential diagnosis techniques solve this problem by automatically generating a sequence of queries to some oracle. The answers to these queries provide additional information necessary to gradually restrict the search space by removing diagnosis candidates inconsistent with the answers. During query computation, existing sequential diagnosis methods often require the generation of many unnecessary query candidates and strongly rely on expensive logical reasoners. We tackle this issue by devising efficient heuristic query search methods. The proposed methods enable for the first time a completely reasoner-free query generation while at the same time guaranteeing optimality conditions, e.g. minimal cardinality or best understandability, of the returned query that existing methods cannot realize. Hence, the performance of this approach is independent of the (complexity of the) diagnosed system. Experiments conducted using real-world problems show that the new approach is highly scalable and outperforms existing methods by orders of magnitude. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.04876;Collaborative creativity with Monte-Carlo Tree Search and Convolutional  Neural Networks; Memo Akten,  Mick Grierson;  We investigate a human-machine collaborative drawing environment in which an autonomous agent sketches images while optionally allowing a user to directly influence the agent's trajectory. We combine Monte Carlo Tree Search with image classifiers and test both shallow models (e.g. multinomial logistic regression) and deep Convolutional Neural Networks (e.g. LeNet, Inception v3). We found that using the shallow model, the agent produces a limited variety of images, which are noticably recogonisable by humans. However, using the deeper models, the agent produces a more diverse range of images, and while the agent remains very confident (99.99%) in having achieved its objective, to humans they mostly resemble unrecognisable 'random' noise. We relate this to recent research which also discovered that 'deep neural networks are easily fooled' \cite{Nguyen2015} and we discuss possible solutions and future directions for the research. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.04885;Crowdsourced Outcome Determination in Prediction Markets; Rupert Freeman,  Sebastien Lahaie,  David M. Pennock;  A prediction market is a useful means of aggregating information about a future event. To function, the market needs a trusted entity who will verify the true outcome in the end. Motivated by the recent introduction of decentralized prediction markets, we introduce a mechanism that allows for the outcome to be determined by the votes of a group of arbiters who may themselves hold stakes in the market. Despite the potential conflict of interest, we derive conditions under which we can incentivize arbiters to vote truthfully by using funds raised from market fees to implement a peer prediction mechanism. Finally, we investigate what parameter values could be used in a real-world implementation of our mechanism. ;"Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)"
https://arxiv.org/abs/1612.05028;Ontohub: A semantic repository for heterogeneous ontologies; Mihai Codescu,  Eugen Kuksa,  Oliver Kutz,  Till Mossakowski,  Fabian Neuhaus;  Ontohub is a repository engine for managing distributed heterogeneous ontologies. The distributed nature enables communities to share and exchange their contributions easily. The heterogeneous nature makes it possible to integrate ontologies written in various ontology languages. Ontohub supports a wide range of formal logical and ontology languages, as well as various structuring and modularity constructs and inter-theory (concept) mappings, building on the OMG-standardized DOL language. Ontohub repositories are organised as Git repositories, thus inheriting all features of this popular version control system. Moreover, Ontohub is the first repository engine meeting a substantial amount of the requirements formulated in the context of the Open Ontology Repository (OOR) initiative, including an API for federation as well as support for logical inference and axiom selection. ;Artificial Intelligence (cs.AI)
https://arxiv.org/abs/1612.05309;Multi-Agent Path Finding with Delay Probabilities; Hang Ma,  T. K. Satish Kumar,  Sven Koenig;  Several recently developed Multi-Agent Path Finding (MAPF) solvers scale to large MAPF instances by searching for MAPF plans on 2 levels: The high-level search resolves collisions between agents, and the low-level search plans paths for single agents under the constraints imposed by the high-level search. We make the following contributions to solve the MAPF problem with imperfect plan execution with small average makespans: First, we formalize the MAPF Problem with Delay Probabilities (MAPF-DP), define valid MAPF-DP plans and propose the use of robust plan-execution policies for valid MAPF-DP plans to control how each agent proceeds along its path. Second, we discuss 2 classes of decentralized robust plan-execution policies (called Fully Synchronized Policies and Minimal Communication Policies) that prevent collisions during plan execution for valid MAPF-DP plans. Third, we present a 2-level MAPF-DP solver (called Approximate Minimization in Expectation) that generates valid MAPF-DP plans. ;"Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)"
https://arxiv.org/abs/1612.05348;Machine Reading with Background Knowledge; Ndapandula Nakashole,  Tom M. Mitchell;"  Intelligent systems capable of automatically understanding natural language text are important for many artificial intelligence applications including mobile phone voice assistants, computer vision, and robotics. Understanding language often constitutes fitting new information into a previously acquired view of the world. However, many machine reading systems rely on the text alone to infer its meaning. In this paper, we pursue a different approach; machine reading methods that make use of background knowledge to facilitate language understanding. To this end, we have developed two methods: The first method addresses prepositional phrase attachment ambiguity. It uses background knowledge within a semi-supervised machine learning algorithm that learns from both labeled and unlabeled data. This approach yields state-of-the-art results on two datasets against strong baselines; The second method extracts relationships from compound nouns. Our knowledge-aware method for compound noun analysis accurately extracts relationships and significantly outperforms a baseline that does not make use of background knowledge. ";"Artificial Intelligence (cs.AI); Computation and Language (cs.CL)"
https://arxiv.org/abs/1612.05497;A correlation coefficient of belief functions; Wen Jiang;  How to manage conflict is still an open issue in Dempster-Shafer evidence theory. The correlation coefficient can be used to measure the similarity of evidence in Dempster-Shafer evidence theory. However, existing correlation coefficients of belief functions have some shortcomings. In this paper, a new correlation coefficient is proposed with many desirable properties. One of its applications is to measure the conflict degree among belief functions. Some numerical examples and comparisons demonstrate the effectiveness of the correlation coefficient. ;Artificial Intelligence (cs.AI)
