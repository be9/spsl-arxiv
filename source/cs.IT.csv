url;title;authors;abstract;subject
https://arxiv.org/abs/1602.00036;On the Automorphism Groups of the Z2Z4-Linear 1-Perfect and  Preparata-Like Codes; Denis Krotov (Sobolev Institute of Mathematics, Novosibirsk, Russia);  We consider the symmetry group of a $Z_2Z_4$-linear code with parameters of a $1$-perfect, extended $1$-perfect, or Preparata-like code. We show that, provided the code length is greater than $16$, this group consists only of symmetries that preserve the $Z_2Z_4$ structure. We find the orders of the symmetry groups of the $Z_2Z_4$-linear (extended) $1$-perfect codes. Keywords: additive codes, $Z_2Z_4$-linear codes, $1$-perfect codes, Preparata-like codes, automorphism group, symmetry group. ;"Information Theory (cs.IT); Discrete Mathematics (cs.DM); Combinatorics (math.CO)"
https://arxiv.org/abs/1602.00043;On the Symmetries and the Capacity Achieving Input Covariance Matrices  of Multiantenna Channels; Mario Diaz;  In this paper we study the capacity achieving input covariance matrices of a single user multiantenna channel based solely on the group of symmetries of its matrix of propagation coefficients. Our main result, which unifies and improves the techniques used in a variety of classical capacity theorems, uses the Haar (uniform) measure on the group of symmetries to establish the existence of a capacity achieving input covariance matrix in a very particular subset of the covariance matrices. This result allows us to provide simple proofs for old and new capacity theorems. Among other results, we show that for channels with two or more standard symmetries, the isotropic input is optimal. Overall, this paper provides a precise explanation of why the capacity achieving input covariance matrices of a channel depend more on the symmetries of the matrix of propagation coefficients than any other distributional assumption. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00057;Separation of Signals Consisting of Amplitude and Instantaneous  Frequency RRC Pulses Using SNR Uniform Training; Mohammad Bari,  Milos Doroslovacki;  This work presents sample mean and sample variance based features that distinguish continuous phase FSK from QAM and PSK modulations. Root raised cosine pulses are used for signal generation. Support vector machines are employed for signals separation. They are trained for only one value of SNR and used to classify the signals from a wide range of SNR. A priori information about carrier amplitude, carrier phase, carrier offset, roll-off factor and initial symbol phase is relaxed. Effectiveness of the method is tested by observing the joint effects of AWGN, carrier offset, lack of symbol and sampling synchronization, and fast fading. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00095;Walsh Sampling with Incomplete Noisy Signals; Yi Lu;  With the advent of massive data outputs at a regular rate, admittedly, signal processing technology plays an increasingly key role. Nowadays, signals are not merely restricted to physical sources, they have been extended to digital sources as well. Under the general assumption of discrete statistical signal sources, we propose a practical problem of sampling incomplete noisy signals for which we do not know a priori and the sample size is bounded. We approach this sampling problem by Shannon's channel coding theorem. Our main results demonstrate that it is the large Walsh coefficient(s) that characterize(s) discrete statistical signals, regardless of the signal sources. By the connection of Shannon's theorem, we establish the necessary and sufficient condition for our generic sampling problem for the first time. Our generic sampling results find practical and powerful applications in not only cryptanalysis, but software system performance optimization. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00132;Source and Physical-Layer Network Coding for Correlated Two-Way Relaying; Qiang Huo,  Lingyang Song,  Yonghui Li,  Bingli Jiao;  In this paper, we study a half-duplex two-way relay channel (TWRC) with correlated sources exchanging bidirectional information. In the case, when both sources have the knowledge of correlation statistics, a source compression with physical-layer network coding (SCPNC) scheme is proposed to perform the distributed compression at each source node. When only the relay has the knowledge of correlation statistics, we propose a relay compression with physical-layer network coding (RCPNC) scheme to compress the bidirectional messages at the relay. The closed-form block error rate (BLER) expressions of both schemes are derived and verified through simulations. It is shown that the proposed schemes achieve considerable improvements in both error performance and throughput compared with the conventional non-compression scheme in correlated two-way relay networks (CTWRNs). ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00139;One generator quasi-cyclic codes over F2 + uF2 + vF2 + uvF2; Srinivasulu B,  Maheshanand Bhaintwal;  In this paper, we study the structure of 1-generator quasi-cyclic codes over the ring R = F2 + uF2 + vF2 + uvF2, with u2 = v2 = 0 and uv = vu. We determine the minimal spanning sets for these codes. As a generalization of these codes, we also investigate the structure of 1-generator generalized quasi-cyclic codes over R and determine a BCH type bound for them. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00145;Throughput Analysis and Optimization of Wireless-Powered Multiple  Antenna Full-Duplex Relay Systems; Mohammadali Mohammadi,  Batu K. Chalise,  Himal A. Suraweera,  Caijun Zhong,  Gan Zheng,  Ioannis Krikidis;  We consider a full-duplex (FD) decode-and-forward system in which the time-switching protocol is employed by the multi-antenna relay to receive energy from the source and transmit information to the destination. The instantaneous throughput is maximized by optimizing receive and transmit beamformers at the relay and the time-split parameter. We study both optimum and suboptimum schemes. The reformulated problem in the optimum scheme achieves closed-form solutions in terms of transmit beamformer for some scenarios. In other scenarios, the optimization problem is formulated as a semi-definite relaxation problem and a rank-one optimum solution is always guaranteed. In the suboptimum schemes, the beamformers are obtained using maximum ratio combining, zero-forcing, and maximum ratio transmission. When beamformers have closed-form solutions, the achievable instantaneous and delay-constrained throughput are analytically characterized. Our results reveal that, beamforming increases both the energy harvesting and loop interference suppression capabilities at the FD relay. Moreover, simulation results demonstrate that the choice of the linear processing scheme as well as the time-split plays a critical role in determining the FD gains. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00169;A Linearithmic Time Algorithm for a Shortest Vector Problem in  Compute-and-Forward Design; Jinming Wen,  Xiao-Wen Chang;  We propose an algorithm with expected complexity of $\bigO(n\log n)$ arithmetic operations to solve a special shortest vector problem arising in computer-and-forward design, where $n$ is the dimension of the channel vector. This algorithm is more efficient than the best known algorithms with proved complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00173;Wireless Caching: Technical Misconceptions and Business Barriers; Georgios Paschos,  Ejder Baştuğ,  Ingmar Land,  Giuseppe Caire,  Mérouane Debbah;  Caching is a hot research topic and poised to develop into a key technology for the upcoming 5G wireless networks. The successful implementation of caching techniques however, crucially depends on joint research developments in different scientific domains such as networking, information theory, machine learning, and wireless communications. Moreover, there exist business barriers related to the complex interactions between the involved stakeholders, the users, the cellular operators, and the Internet content providers. In this article we discuss several technical misconceptions with the aim to uncover enabling research directions for caching in wireless systems. Ultimately we make a speculative stakeholder analysis for wireless caching in 5G. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1602.00225;Transmitter Optimization in Slow Fading MISO Wiretap Channel; Sanjay Vishwakarma,  A. Chockalingam;  In this paper, we consider the transmitter optimization problem in slow fading multiple-input-single-output (MISO) wiretap channel. The source transmits a secret message intended for $K$ users in the presence of $J$ non-colluding eavesdroppers, and operates under a total power constraint. The channels between the source and all users and eavesdroppers are assumed to be slow fading, and only statistical channel state information (CSI) is known at the source. For a given code rate and secrecy rate pair of the wiretap code, denoted by $(R_{D}, R_{s})$, we define the non-outage event as the joint event of the link information rates to $K$ users be greater than or equal to $R_{D}$ and the link information rates to $J$ eavesdroppers be less than or equal to $(R_{D} - R_{s})$. We minimize the transmit power subject to the total power constraint and satisfying the probability of the non-outage event to be greater than or equal to a desired threshold $(1-\epsilon)$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00276;The Capacity of Online (Causal) $q$-ary Error-Erasure Channels; Zitan Chen,  Sidharth Jaggi,  Michael Langberg;"  In the $q$-ary online (or ""causal"") channel coding model, a sender wishes to communicate a message to a receiver by transmitting a codeword $\mathbf{x} =(x_1,\ldots,x_n) \in \{0,1,\ldots,q-1\}^n$ symbol by symbol via a channel limited to at most $pn$ errors and/or $p^{*} n$ erasures. The channel is ""online"" in the sense that at the $i$th step of communication the channel decides whether to corrupt the $i$th symbol or not based on its view so far, i.e., its decision depends only on the transmitted symbols $(x_1,\ldots,x_i)$. This is in contrast to the classical adversarial channel in which the corruption is chosen by a channel that has a full knowledge on the sent codeword $\mathbf{x}$. In this work we study the capacity of $q$-ary online channels for a combined corruption model, in which the channel may impose at most $pn$ {\em errors} and at most $p^{*} n$ {\em erasures} on the transmitted codeword. The online channel (in both the error and erasure case) has seen a number of recent studies which present both upper and lower bounds on its capacity. In this work, we give a full characterization of the capacity as a function of $q,p$, and $p^{*}$. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.00339;Distributed Multi-Relay Selection in Accumulate-then-Forward Energy  Harvesting Relay Networks; Yifan Gu,  He Chen,  Yonghui Li,  Branka Vucetic;  This paper investigates a wireless-powered cooperative network (WPCN) consisting of one source-destination pair and multiple decode-and-forward (DF) relays. We develop an energy threshold based multi-relay selection (ETMRS) scheme for the considered WPCN. The proposed ETMRS scheme can be implemented in a fully distributed manner as the relays only need local information to switch between energy harvesting and information forwarding modes. By modeling the charging/discharging behaviours of the finite-capacity battery at each relay as a finite-state Markov Chain (MC), we derive an analytical expression for the system outage probability of the proposed ETMRS scheme over mixed Nakagami-$m$ and Rayleigh fading channels. Based on the derived expression, the optimal energy thresholds for all the relays corresponding to the minimum system outage probability can be obtained via an exhaustive search. However, this approach becomes computationally prohibitive when the number of relays and the associated number of battery energy levels is large. To resolve this issue, we propose a heuristic approach to optimize the energy threshold for each relay. To gain some useful insights for practical relay design, we also derive the upper bound for system outage probability corresponding to the case that all relays are equipped with infinite-capacity batteries. Numerical results validate our theoretical analysis. It is shown that the proposed heuristic approach can achieve a near-optimal system performance and our ETMRS scheme outperforms the existing single-relay selection scheme and common energy threshold scheme. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00366;Multi-Channel MAC Protocol for Full-Duplex Cognitive Radio Networks with  Optimized Access Control and Load Balancing; Tan Le Thanh,  Long Bao Le;  In this paper, we propose a multi-channel full-duplex Medium Access Control (MAC) protocol for cognitive radio networks (MFDC-MAC). Our design exploits the fact that full-duplex (FD) secondary users (SUs) can perform spectrum sensing and access simultaneously, and we employ the randomized dynamic channel selection for load balancing among channels and the standard backoff mechanism for contention resolution on each available channel. Then, we develop a mathematical model to analyze the throughput performance of the proposed MFDC-MAC protocol. Furthermore, we study the protocol configuration optimization to maximize the network throughput where we show that this optimization can be performed in two steps, namely optimization of access and transmission parameters on each channel and optimization of channel selection probabilities of the users. Such optimization aims at achieving efficient self-interference management for FD transceivers, sensing overhead control, and load balancing among the channels. Numerical results demonstrate the impacts of different protocol parameters and the importance of parameter optimization on the throughput performance as well as the significant performance gain of the proposed design compared to traditional design. ;"Information Theory (cs.IT); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI); Statistics Theory (math.ST); Applications (stat.AP)"
https://arxiv.org/abs/1602.00376;Beyond Countable Alphabets: An Extension of the Information-Spectrum  Approach; Shengtian Yang,  Thomas Honold,  Zhaoyang Zhang;"  A general approach is established for deriving one-shot performance bounds for information-theoretic problems on general alphabets beyond countable alphabets. It is mainly based on the quantization idea and a novel form of ""likelihood ratio"". As an example, one-shot lower and upper bounds for random number generation from correlated sources on general alphabets are derived. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.00413;Linear Programming Bounds for Entanglement-Assisted Quantum  Error-Correcting Codes by Split Weight Enumerators; Ching-Yi Lai,  Alexei Ashikhmin;  Linear programming approaches have been applied to derive upper bounds on the size of classical codes and quantum codes. In this paper, we derive similar results for general quantum codes with entanglement assistance, including nonadditive codes, by considering a type of split weight enumerators. After deriving the MacWilliams identities for these split weight enumerators, we are able to prove algebraic linear programming bounds, such as the Singleton bound, the Hamming bound, and the first linear programming bound. In particular, we show that the first linear programming bound improves the Hamming bound when the relative distance is sufficiently large. On the other hand, we obtain additional constraints on the size of Pauli subgroups for quantum codes, which allow us to improve the linear programming bounds on the minimum distance of small quantum codes. In particular, we show that there is no [[27,15,5]] or [[28,14,6]] quantum stabilizer code. We also discuss the existence of some entanglement-assisted quantum stabilizer codes with maximal entanglement. As a result, the upper and lower bounds on the minimum distance of maximal-entanglement quantum stabilizer codes with length up to 20 are significantly improved. ;"Information Theory (cs.IT); Quantum Physics (quant-ph)"
https://arxiv.org/abs/1602.00430;Compressed Sensing for Implantable Neural Recordings Using Co-sparse  Analysis Model and Weighted $\ell_1$-Optimization; Biao Sun,  Wenfeng Zhao,  Xinshan Zhu;  Reliable and energy-efficient wireless data transmission remains a major challenge in resource-constrained wireless neural recording tasks, where data compression is generally adopted to relax the burdens on the wireless data link. Recently, Compressed Sensing (CS) theory has successfully demonstrated its potential in neural recording application. The main limitation of CS, however, is that the neural signals have no good sparse representation with commonly used dictionaries and learning a reliable dictionary is often data dependent and computationally demanding. In this paper, a novel CS approach for implantable neural recording is proposed. The main contributions are: 1) The co-sparse analysis model is adopted to enforce co-sparsity of the neural signals, therefore overcoming the drawbacks of conventional synthesis model and enhancing the reconstruction performance. 2) A multi-fractional-order difference matrix is constructed as the analysis dictionary, thus avoiding the dictionary learning procedure and reducing the need for previously acquired data and computational resources. 3) By exploiting the statistical priors of the analysis coefficients, a weighted analysis $\ell_1$-minimization (WALM) algorithm is proposed to reconstruct the neural signals. Experimental results on Leicester neural signal database reveal that the proposed approach outperforms the state-of-the-art CS-based methods. On the challenging high compression ratio task, the proposed approach still achieves high reconstruction performance and spike classification accuracy. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00446;A Graph Representation for Two-Dimensional Finite Type Constrained  Systems; Takahiro Ota,  Akiko Manada,  Hiroyoshi Morita;  The demand of two-dimensional source coding and constrained coding has been getting higher these days, but compared to the one-dimensional case, many problems have remained open as the analysis is cumbersome. A main reason for that would be because there are no graph representations discovered so far. In this paper, we focus on a two-dimensional finite type constrained system, a set of two-dimensional blocks characterized by a finite number of two-dimensional constraints, and propose its graph representation. We then show how to generate an element of the two-dimensional finite type constrained system from the graph representation. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00453;Power Allocation and Scheduling for SWIPT Systems with Non-linear Energy  Harvesting Model; Elena Boshkovska,  Rania Morsi,  Derrick Wing Kwan Ng,  Robert Schober;  In this paper, we design a resource allocation algorithm for multiuser simultaneous wireless information and power transfer systems for a realistic non-linear energy harvesting (EH) model. In particular, the algorithm design is formulated as a non-convex optimization problem for the maximization of the long-term average total harvested power at EH receivers subject to quality of service requirements for information decoding receivers. To obtain a tractable solution, we transform the corresponding non-convex sum-of-ratios objective function into an equivalent objective function in parametric subtractive form. This leads to a computationally efficient iterative resource allocation algorithm. Numerical results reveal a significant performance gain that can be achieved if the resource allocation algorithm design is based on the non-linear EH model instead of the traditional linear model. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00542;Cluster-Seeking James-Stein Estimators; K. Pavan Srinath,  Ramji Venkataramanan;  This paper considers the problem of estimating a high-dimensional vector of parameters $\boldsymbol{\theta} \in \mathbb{R}^n$ from a noisy observation. The noise vector is i.i.d. Gaussian with known variance. For a squared-error loss function, the James-Stein (JS) estimator is known to dominate the simple maximum-likelihood (ML) estimator when the dimension $n$ exceeds two. The JS-estimator shrinks the observed vector towards the origin, and the risk reduction over the ML-estimator is greatest for $\boldsymbol{\theta}$ that lie close to the origin. JS-estimators can be generalized to shrink the data towards any target subspace. Such estimators also dominate the ML-estimator, but the risk reduction is significant only when $\boldsymbol{\theta}$ lies close to the subspace. This leads to the question: in the absence of prior information about $\boldsymbol{\theta}$, how do we design estimators that give significant risk reduction over the ML-estimator for a wide range of $\boldsymbol{\theta}$? In this paper, we propose shrinkage estimators that attempt to infer the structure of $\boldsymbol{\theta}$ from the observed data in order to construct a good attracting subspace. In particular, the components of the observed vector are separated into clusters, and the elements in each cluster shrunk towards a common attractor. The number of clusters and the attractor for each cluster are determined from the observed vector. We provide concentration results for the squared-error loss and convergence results for the risk of the proposed estimators. The results show that the estimators give significant risk reduction over the ML-estimator for a wide range of $\boldsymbol{\theta}$, particularly for large $n$. Simulation results are provided to support the theoretical claims. ;"Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.00639;Online Ski Rental for ON/OFF Scheduling of Energy Harvesting Base  Stations; Gilsoo Lee,  Walid Saad,  Mehdi Bennis,  Abolfazl Mehbodniya,  Fumiyuki Adachi;  The co-existence of small cell base stations (SBSs) with conventional macrocell base station is a promising approach to boost the capacity and coverage of cellular networks. However, densifying the network with a viral deployment of SBSs can significantly increase energy consumption. To reduce the reliance on unsustainable energy sources, one can adopt self-powered SBSs that rely solely on energy harvesting. Due to the uncertainty of energy arrival and the finite capacity of energy storage systems, self-powered SBSs must smartly optimize their ON and OFF schedule. In this paper, the problem of ON/OFF scheduling of self-powered SBSs is studied, in the presence of energy harvesting uncertainty with the goal of minimizing the operational costs consisted of energy consumption and transmission delay of a network. For the original problem, we show an algorithm can solve the problem in the illustrative case. To reduce the complexity of the original problem, an approximation is proposed. To solve the approximated problem, a novel approach based on the ski rental framework, a powerful online optimization tool, is proposed. Using this approach, each SBS can effectively decide on its ON/OFF schedule autonomously, without any prior information on future energy arrivals. By using competitive analysis, a deterministic online algorithm (DOA) and a randomized online algorithm (ROA) are developed. ROA is shown to achieve the optimal competitive ratio in the approximation problem. Simulation results show that, compared to a baseline approach, the ROA can yield performance gains reaching up to 15.6% in terms of reduced total energy consumption of SBSs and up to 20.6% in terms of per-SBS network delay reduction. The results shed light on the fundamental aspects that impact the ON time of SBSs while demonstrating that the proposed ROA can reduce up to 69.9% the total cost compared to a baseline approach. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00648;Hybrid Beamforming for Massive MIMO Backhaul (Working Title); Namal Rajatheva,  Elvino Sousa;  The uplink where both the transmitter and receiver can use a large antenna array is considered. This is proposed as a method of antenna offloading and connecting small cell access points (SCAP) in a Two-Tier cellular network. Due to having a limited number of RF-chains, hybrid beamformers are designed where phase-only processing is done at the RF-band, followed by digital processing at the baseband. The proposed receiver is a row combiner that clusters sufficiently correlated antenna elements, and its' performance is compared against random projection via a Discrete Fourier Transform (DFT) matrix. The analogue to the row combiner is a column spreader, which is dependent on the transmit correlation, and repeats the transmitted signal over antenna elements that are correlated. A key benefit of this approach is to reduce the number of phase shifters used, while outperforming the DFT scheme. When only the transmitter has correlation and is RF-chain limited, the baseband precoding vectors are shown to be the eigenvectors of the effective transmit correlation matrix. Depending on the channel correlation, this matrix can be approximated to have a tridiagonal Toeplitz structure with the proposed column spreader (CS). The resulting eigenvalues have a closed form solution which allows us to characterize the sum rate of the system. Most interestingly, the associated eigenvectors do not require knowledge of the effective transmit correlation matrix to be calculated using an Eigenvalue Decomposition (EVD) method. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00734;Learning Data Triage: Linear Decoding Works for Compressive MRI; Yen-Huan Li,  Volkan Cevher;  The standard approach to compressive sampling considers recovering an unknown deterministic signal with certain known structure, and designing the sub-sampling pattern and recovery algorithm based on the known structure. This approach requires looking for a good representation that reveals the signal structure, and solving a non-smooth convex minimization problem (e.g., basis pursuit). In this paper, another approach is considered: We learn a good sub-sampling pattern based on available training signals, without knowing the signal structure in advance, and reconstruct an accordingly sub-sampled signal by computationally much cheaper linear reconstruction. We provide a theoretical guarantee on the recovery error, and show via experiments on real-world MRI data the effectiveness of the proposed compressive MRI scheme. ;"Information Theory (cs.IT); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.00761;Optimality and Rate-Compatibility for Erasure-Coded Packet Transmissions  when Fading Channel Diversity Increases with Packet Length; Sudarsan V. S. Ranganathan,  Tong Mu,  Richard D. Wesel;  A message composed of packets is transmitted using erasure and channel coding over a fading channel with no feedback. For this scenario, the paper explores the trade-off between the redundancies allocated to the packet-level erasure code and the channel code, along with an objective of a low probability of failure to recover the message. To this end, we consider a fading model that we term proportional-diversity block fading (PD block fading). For a fixed overall code rate and transmit power, we formulate an optimization problem to numerically find the optimal channel-coding rate (and thus the optimal erasure-coding rate) that minimizes the probability of failure for various approximations of the problem. Furthermore, an interpretation of the results from an incremental redundancy point of view shows how rate-compatibility affects the possible trajectories of the failure probability as a function of the overall code rate. Our numerical results suggest that an optimal, rateless, hybrid coding scheme for a single-user wireless system over the PD block-fading channel should have the rate of the erasure code approach one. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00766;User Access Mode Selection in Fog Computing Based Radio Access Networks; Shi Yan,  Mugen Peng,  Wenbo Wang;  Fog computing based radio access network is a promising paradigm for the fifth generation wireless communication system to provide high spectral and energy efficiency. With the help of the new designed fog computing based access points (F-APs), the user-centric objectives can be achieved through the adaptive technique and will relieve the load of fronthaul and alleviate the burden of base band unit pool. In this paper, we derive the coverage probability and ergodic rate for both F-AP users and device-to-device users by taking into account the different nodes locations, cache sizes as well as user access modes. Particularly, the stochastic geometry tool is used to derive expressions for above performance metrics. Simulation results validate the accuracy of our analysis and we obtain interesting trade-offs that depend on the effect of the cache size, user node density, and the quality of service constrains on the different performance metrics. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00802;Spectrum Sharing Between A Surveillance Radar and Secondary Wi-Fi  Networks; Farzad Hessar,  Sumit Roy;  Co-existence between unlicensed networks that share spectrum spatio-temporally with terrestrial (e.g. Air Traffic Control) and shipborne radars in 3-GHz band is attracting significant interest. Similar to every primary-secondary coexistence scenario, interference from unlicensed devices to a primary receiver must be within acceptable bounds. In this work, we formulate the spectrum sharing problem between a pulsed, search radar (primary) and 802.11 WLAN as the secondary. We compute the protection region for such a search radar for a) a single secondary user (initially) as well as b) a random spatial distribution of multiple secondary users. Furthermore, we also analyze the interference to the WiFi devices from the radar's transmissions to estimate the impact on achievable WLAN throughput as a function of distance to the primary radar. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00833;Practical Non-Linear Energy Harvesting Model and Resource Allocation in  SWIPT Systems; Elena Boshkovska;  Simultaneous wireless information and power transfer (SWIPT) is a promising solution for enabling long-life, and self-sustainable wireless networks. In this thesis, we propose a practical non-linear energy harvesting (EH) model and design a resource allocation algorithm for SWIPT systems. In particular, the algorithm design is formulated as a non-convex optimization problem for the maximization of the total harvested power at the EH receivers subject to quality of service (QoS) constraints for the information decoding (ID) receivers. To circumvent the non-convexity of the problem, we transform the corresponding non-convex sum-of-ratios objective function into an equivalent objective function in parametric subtractive form. Furthermore, we design a computationally efficient iterative resource allocation algorithm to obtain the globally optimal solution. Numerical results illustrate significant performance gain in terms of average total harvested power for the proposed non-linear EH receiver model, when compared to the traditional linear model.\ ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00844;A sufficient condition for tail asymptotics of SIR distribution in  downlink cellular networks; Naoto Miyoshi,  Tomoyuki Shirai;  We consider the spatial stochastic model of single-tier downlink cellular networks, where the wireless base stations are deployed according to a general stationary point process on the Euclidean plane with general i.i.d. propagation effects. Recently, Ganti & Haenggi (2016) consider the same general cellular network model and, as one of many significant results, derive the tail asymptotics of the signal-to-interference ratio (SIR) distribution. However, they do not mention any conditions under which the result holds. In this paper, we compensate their result for the lack of the condition and expose a sufficient condition for the asymptotic result to be valid. We further illustrate some examples satisfying such a sufficient condition and indicate the corresponding asymptotic results for the example models. We give also a simple counterexample violating the sufficient condition. ;"Information Theory (cs.IT); Probability (math.PR)"
https://arxiv.org/abs/1602.00875;Converse Bounds for Noisy Group Testing with Arbitrary Measurement  Matrices; Jonathan Scarlett,  Volkan Cevher;  We consider the group testing problem, in which one seeks to identify a subset of defective items within a larger set of items based on a number of noisy tests. While matching achievability and converse bounds are known in several cases of interest for i.i.d.~measurement matrices, less is known regarding converse bounds for arbitrary measurement matrices. We address this by presenting two converse bounds for arbitrary matrices and general noise models. First, we provide a strong converse bound ($\mathbb{P}[\mathrm{error}] \to 1$) that matches existing achievability bounds in several cases of interest. Second, we provide a weak converse bound ($\mathbb{P}[\mathrm{error}] \not\to 0$) that matches existing achievability bounds in greater generality. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00877;Partial Recovery Bounds for the Sparse Stochastic Block Model; Jonathan Scarlett,  Volkan Cevher;  In this paper, we study the information-theoretic limits of community detection in the symmetric two-community stochastic block model, with intra-community and inter-community edge probabilities $\frac{a}{n}$ and $\frac{b}{n}$ respectively. We consider the sparse setting, in which $a$ and $b$ do not scale with $n$, and provide upper and lower bounds on the proportion of community labels recovered on average. We provide a numerical example for which the bounds are near-matching for moderate values of $a - b$, and matching in the limit as $a-b$ grows large. ;"Information Theory (cs.IT); Social and Information Networks (cs.SI); Machine Learning (stat.ML)"
https://arxiv.org/abs/1602.00878;Input Constraints and Noise Density Functions: A Simple Relation for  Bounded-Support and Discrete Capacity-Achieving Inputs; Jihad Fahs,  Ibrahim Abou-Faycal;  We study the classical problem of characterizing the channel capacity and its achieving distribution in a generic fashion. We derive a simple relation between three parameters: the input-output function, the input cost function and the noise probability density function, one which dictates the type of the optimal input. In Layman terms we prove that the support of the optimal input is bounded whenever the cost grows faster than a cut-off rate equal to the logarithm of the noise PDF evaluated at the input-output function. Furthermore, we prove a converse statement that says whenever the cost grows slower than the cut-off rate, the optimal input has necessarily an unbounded support. In addition, we show how the discreteness of the optimal input is guaranteed whenever the triplet satisfy some analyticity properties. We argue that a suitable cost function to be imposed on the channel input is one that grows similarly to the cut-off rate. Our results are valid for any cost function that is super-logarithmic. They summarize a large number of previous channel capacity results and give new ones for a wide range of communication channel models, such as Gaussian mixtures, generalized-Gaussians and heavy-tailed noise models, that we state along with numerical computations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00883;Distributed Scheduling in Multiple Access with Bursty Arrivals and Delay  Constraints; Sakshi Kapoor,  Sreejith Sreekumar,  Sibi Raj B Pillai;  A multiple access system with bursty data arrivals to the terminals is considered. The users are frame-synchronized, with variable sized packets independently arriving in each slot at every transmitter. Each packet needs to be delivered to a common receiver within a certain number of slots specified by a maximum delay constraint. The key assumption is that the terminals know only their own packet arrival process, i.e. the arrivals at the rest of the terminals are unknown to each transmitter, except for their statistics. For this interesting distributed multiple access model, we design novel online communication schemes which transport the arriving data without any outage, while ensuring the delay constraint. In particular, the transmit powers in each slot are chosen in a distributed manner, ensuring at the same time that the joint power vector is sufficient to support the distributed choice of data-rates employed in that slot. The proposed schemes not only are optimal for minimizing the average transmit sum-power, but they also considerably outperform conventional orthogonal multiple access techniques like TDMA. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00910;5G Waveforms for Overlay D2D Communications: Effects of Time-Frequency  Misalignment; Quentin Bodinier,  Arman Farhang,  Faouzi Bader,  Hamed Ahmadi,  Jacques Palicot,  Luiz A. DaSilva;  This paper analyses a scenario where a Device-To-Device (D2D) pair coexists with an Orthogonal Frequency Division Multiplexing (OFDM) based incumbent network. D2D transmitter communicates in parts of spectrum left free by cellular users, while respecting a given spectral mask. The D2D pair is misaligned in time and frequency with the cellular users. Furthermore, the D2D pair utilizes alternative waveforms to OFDM proposed for 5G. In this study, we show that it is not worth synchronising the D2D pair in time with respect to the cellular users. Indeed, the interference injected into the incumbent network has small variations with respect to time misalignment. We provide interference tables that encompass both time and frequency misalignment. We use them to analyse the maximum rate achievable by the D2D pair when it uses different waveforms. Then, we present numerical results showing what waveform should be utilized by the D2D pair according to the time-frequency resources that are not used by the incumbent network. Our results show that the delay induced by linearly convolved waveforms make them hardly applicable to short time windows, but that they dominate OFDM for long transmissions, mainly in the case where cellular users are very sensitive to interference. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00914;Binary linear codes with at most 4 weights; Fei Li,  Yang Yan,  Qiuyan Wang,  Tongjiang Yan;  For the past decades, linear codes with few weights have been widely studied, since they have applications in space communications, data storage and cryptography. In this paper, a class of binary linear codes is constructed and their weight distribution is determined. Results show that they are at most 4-weight linear codes. Additionally, these codes can be used in secret sharing schemes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.00928;Spatial Continuum Extensions of Asymmetric Gaussian Channels (Multiple  Access and Broadcast); Jean-Marie Gorce (SOCRATE),  H. Vincent Poor,  Jean-Marc Kelif;  This paper proposes a new model called \emph{spatial continuum asymmetric channels} to study the channel capacity region of asymmetric scenarios in which either one source transmits to a spatial density of receivers or a density of transmitters transmit to a unique receiver.This approach is built upon the classical broadcast channel (BC) and multiple access channel (MAC). For the sake of consistency, the study is limited to Gaussian channels with power constraints and is restricted to the asymptotic regime (zero-error capacity).The reference scenario comprises one base station (BS) in Tx or Rx mode, a spatial random distribution of nodes (resp. in Rx or Tx mode) characterized by a probability spatial density $u(x)$ and a request for a quantity of information with no delay constraint. This system is modeled as an $\infty-$user asymmetric channel (BC or MAC). To derive the properties of this model, a spatial discretization is performed and the equivalence with either a BC or MAC is established. A discretization sequence is then defined to refine infinitely the approximation. Achievability and capacity results are obtained in the limit of this sequence. The uniform capacity is then defined as the maximal symmetric achievable rate at which the distributed users can transmit/receive with no delay constraint.The capacity region is also established as the set of information distributions that are achievable. The tightness of these limits and their practical interest are briefly illustrated and discussed. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01038;Interactive Multiple Model Estimation of Doubly-Selective Channels for  OFDM systems; Mahmoud Ashour,  Amr El-Keyi;  In this paper, we propose an algorithm for channel estimation, acquisition and tracking, for orthogonal frequency division multiplexing (OFDM) systems. The proposed algorithm is suitable for vehicular communications that encounter very high mobility. A preamble sequence is used to derive an initial estimate of the channel using least squares (LS). The temporal variation of the channel within one OFDM symbol is approximated by two complex exponential basis expansion models (CE-BEM). One of the Fourier-based BEMs is intended to capture the low frequencies in the channel (slow variations corresponding to low Doppler), while the other is destined to capture high frequencies (fast variations corresponding to high Doppler). Kalman filtering is employed to track the BEM coefficients iteratively on an OFDM symbol-by-symbol basis. An interactive multiple model (IMM) estimator is implemented to dynamically mix the estimates obtained by the two Kalman filters, each of which matched to one of the BEMs. Extensive numerical simulations are conducted to signify the gain obtained by the proposed combining technique. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01042;Improved Achievability and Converse Bounds for Erdős-Rényi Graph  Matching; Daniel Cullina,  Negar Kiyavash;  We consider the problem of perfectly recovering the vertex correspondence between two correlated Erd\H{o}s-R\'enyi (ER) graphs. For a pair of correlated graphs on the same vertex set, the correspondence between the vertices can be obscured by randomly permuting the vertex labels of one of the graphs. In some cases, the structural information in the graphs allow this correspondence to be recovered. We investigate the information-theoretic threshold for exact recovery, i.e. the conditions under which the entire vertex correspondence can be correctly recovered given unbounded computational resources. Pedarsani and Grossglauser provided an achievability result of this type. Their result establishes the scaling dependence of the threshold on the number of vertices. We improve on their achievability bound. We also provide a converse bound, establishing conditions under which exact recovery is impossible. Together, these establish the scaling dependence of the threshold on the level of correlation between the two graphs. The converse and achievability bounds differ by a factor of two for sparse, significantly correlated graphs. ;"Information Theory (cs.IT); Learning (cs.LG)"
https://arxiv.org/abs/1602.01061;Waveform Optimization for SWIPT with Nonlinear Energy Harvester Modeling; Bruno Clerckx;  Simultaneous Wireless Information and Power Transfer (SWIPT) has attracted significant attention in the communication community. The problem of waveform design for SWIPT has however never been addressed so far. In this paper, a novel SWIPT transceiver architecture is introduced relying on the superposition of multisine and OFDM waveforms at the transmitter and a power-splitter receiver equipped with an energy harvester and an information decoder capable of cancelling the multisine waveforms. The SWIPT multisine/OFDM waveforms are optimized so as to maximize the rate-energy region of the whole system. They are adaptive to the channel state information and result from a posynomial maximization problem that originates from the non-linearity of the energy harvester. Numerical results illustrate the performance of the derived waveforms and SWIPT architecture. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1602.01066;Robust Beamforming for SWIPT Systems with Non-linear Energy Harvesting  Model; Elena Boshkovska,  Alexander Koelpin,  Derrick Wing Kwan Ng,  Nikola Zlatanov,  Robert Schober;  This paper investigates resource allocation for simultaneous wireless information and power transfer (SWIPT) downlink systems based on a non-linear energy harvesting model. The resource allocation algorithm design is formulated as a non-convex optimization problem for the maximization of the total harvested power. The proposed problem formulation not only takes into account imperfect channel state information (CSI) but also guarantees the quality-of-service (QoS) of information transfer. A novel iterative algorithm is proposed to obtain the globally optimal solution of the considered non-convex optimization problem. In each iteration, a rank-constrained semidefinite program (SDP) is solved optimally by SDP relaxation. Simulation results demonstrate the significant gains in harvested power and the robustness against CSI imperfection for the proposed optimal resource allocation, compared to a baseline scheme designed for perfect CSI and the conventional linear energy harvesting model. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01139;Throughput Analysis of Massive MIMO Uplink with Low-Resolution ADCs; Sven Jacobsson,  Giuseppe Durisi,  Mikael Coldrey,  Ulf Gustavsson,  Christoph Studer;  We investigate the uplink throughput achievable by a multiple-user (MU) massive multiple-input multiple-output (MIMO) system in which the base station is equipped with a large number of low-resolution analog-to-digital converters (ADCs). Our focus is on the case where neither the transmitter nor the receiver have any a priori channel state information. This implies that the fading realizations have to be learned through pilot transmission followed by channel estimation at the receiver, based on coarsely quantized observations. We propose a novel channel estimator, based on Bussgang's decomposition, and a novel approximation to the rate achievable with finite-resolution ADCs, both for the case of finite-cardinality constellations and of Gaussian inputs, that is accurate for a broad range of system parameters. Through numerical results, we illustrate that, for the 1-bit quantized case, pilot-based channel estimation together with maximal-ratio combing or zero-forcing detection enables reliable multi-user communication with high-order constellations in spite of the severe nonlinearity introduced by the ADCs. Furthermore, we show that the rate achievable in the infinite-resolution (no quantization) case can be approached using ADCs with only a few bits of resolution. We finally investigate the robustness of low-ADC-resolution MU-MIMO uplink against receive power imbalances between the different users, caused for example by imperfect power control. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01149;Secure Index Coding: Existence and Construction; Lawrence Ong,  Badri N. Vellambi,  Phee Lep Yeoh,  Jörg Kliewer,  Jinhong Yuan;  We investigate the construction of weakly-secure index codes for a sender to send messages to multiple receivers with side information in the presence of an eavesdropper. We derive a sufficient and necessary condition for the existence of index codes that are secure against an eavesdropper with access to any subset of messages of cardinality $t$, for any fixed $t$. In contrast to the benefits of using random keys in secure network coding, we prove that random keys do not promote security in three classes of index-coding instances. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01161;Energy Efficient Scheduling and Groupping for Machine-TYpe  Communications over Cellular Networks; Amin Azari;  In this paper, energy-efficient scheduling for grouped machine-type devices deployed in cellular networks is investigated. We introduce a scheduling-based cooperation incentive scheme which enables machine nodes to organize themselves locally, create machine groups, and communicate through group representatives to the base station. This scheme benefits from a novel scheduler design which takes into account the cooperation level of each node, reimburses the extra energy consumptions of group representatives, and maximizes the network lifetime. As reusing cellular uplink resources for communications inside the groups degrades the Quality of Service (QoS) of the primary users, analytical results are provided which present a tradeoff between maximum allowable number of simultaneously active machine groups in a given cell and QoS of the primary users. Furthermore, we extend our derived solutions for the existing cellular networks, propose a cooperation-incentive LTE scheduler, and present our simulation results in the context of LTE. The simulation results show that the proposed solutions significantly prolong the network lifetime. Also, it is shown that under certain circumstances, reusing uplink resource by machine devices can degrade the outage performance of the primary users significantly, and hence, coexistence management of machine devices and cellular users is of paramount importance for next generations of cellular networks in order to enable group-based machine-type communications while guaranteeing QoS for the primary users. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01202;Locally rewritable codes for resistive memories; Yongjune Kim,  Abhishek A. Sharma,  Robert Mateescu,  Seung-Hwan Song,  Zvonimir Z. Bandic,  James A. Bain,  B. V. K. Vijaya Kumar;  We propose locally rewritable codes (LWC) for resistive memories inspired by locally repairable codes (LRC) for distributed storage systems. Small values of repair locality of LRC enable fast repair of a single failed node since the lost data in the failed node can be recovered by accessing only a small fraction of other nodes. By using rewriting locality, LWC can improve endurance limit and power consumption which are major challenges for resistive memories. We point out the duality between LRC and LWC, which indicates that existing construction methods of LRC can be applied to construct LWC. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01218;On the Accuracy of Interference Models in Wireless Communications; Hossein Shokri-Ghadikolaei,  Carlo Fischione,  Eytan Modiano;  We develop a new framework for measuring and comparing the accuracy of any wireless interference models used in the analysis and design of wireless networks. Our approach is based on a new index that assesses the ability of the interference model to correctly predict harmful interference events, i.e., link outages. We use this new index to quantify the accuracy of various interference models used in the literature, under various scenarios such as Rayleigh fading wireless channels, directional antennas, and blockage (impenetrable obstacles) in the network. Our analysis reveals that in highly directional antenna settings with obstructions, even simple interference models (e.g., the classical protocol model) are accurate, while with omnidirectional antennas, more sophisticated and complex interference models (e.g., the classical physical model) are necessary. Our new approach makes it possible to adopt the appropriate interference model of adequate accuracy and simplicity in different settings. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1602.01242;Galois Correspondence on Linear Codes over Finite Chain Rings; A. Fotue Tabue,  E. Martínez-Moro,  C. Mouaha;  Given $\texttt{S}|\texttt{R}$ a finite Galois extension of finite chain rings and $\mathcal{B}$ an $\texttt{S}$-linear code we define two Galois operators, the closure operator and the interior operator. We proof that a linear code is Galois invariant if and only if the row standard form of its generator matrix has all entries in the fixed ring by the Galois group and show a Galois correspondence in the class of $\texttt{S}$-linear codes. As applications some improvements of upper and lower bounds for the rank of the restriction and trace code are given and some applications to $\texttt{S}$-linear cyclic codes are shown. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01265;Quantifying synergistic information using intermediate stochastic  variables; Rick Quax,  Omri Har-Shemesh,  Peter M.A. Sloot;  Quantifying synergy among stochastic variables is an important open problem in information theory. Information synergy occurs when multiple sources together predict an outcome variable better than the sum of single-source predictions. It is an essential phenomenon in biology such as in neuronal networks and cellular regulatory processes, where different information flows integrate to produce a single response, but also in social cooperation processes as well as in statistical inference tasks in machine learning. Here we propose a metric of synergistic entropy and synergistic information from first principles. The proposed measure relies on so-called synergistic random variables (SRVs) which are constructed to have zero mutual information about individual source variables but non-zero mutual information about the complete set of source variables. We prove several basic and desired properties of our measure, including bounds and additivity properties. In addition, we prove several important consequences of our measure, including the fact that different types of synergistic information may co-exist between the same sets of variables. A numerical implementation is provided, which we use to demonstrate that synergy is associated with resilience to noise. Our measure may be a marked step forward in the study of multivariate information theory and its numerous applications. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01327;On The Construction of Capacity-Achieving Lattice Gaussian Codes; Wael Alghamdi,  Walid Abediseid,  Mohamed-Slim Alouini;  In this paper, we propose a new approach to proving results regarding channel coding schemes based on construction-A lattices for the Additive White Gaussian Noise (AWGN) channel that yields new characterizations of the code construction parameters, i.e., the primes and dimensions of the codes, as functions of the block-length. The approach we take introduces an averaging argument that explicitly involves the considered parameters. This averaging argument is applied to a generalized Loeliger ensemble to provide a more practical proof of the existence of AWGN-good lattices, and to characterize suitable parameters for the lattice Gaussian coding scheme proposed by Ling and Belfiore. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01416;On the Relay-Fallback Tradeoff in Millimeter Wave Wireless System; Roberto Congiu,  Hossein Shokri-Ghadikolaei,  Carlo Fischione,  Fortunato Santucci;  Millimeter wave (mmWave) communications systems are promising candidate to support extremely high data rate services in future wireless networks. MmWave communications exhibit high penetration loss (blockage) and require directional transmissions to compensate for severe channel attenuations and for high noise powers. When blockage occurs, there are at least two simple prominent options: 1) switching to the conventional microwave frequencies (fallback option) and 2) using an alternative non-blocked path (relay option). However, currently it is not clear under which conditions and network parameters one option is better than the other. To investigate the performance of the two options, this paper proposes a novel blockage model that allows deriving maximum achievable throughput and delay performance of both options. A simple criterion to decide which option should be taken under which network condition is provided. By a comprehensive performance analysis, it is shown that the right option depends on the payload size, beam training overhead, and blockage probability. For a network with light traffic and low probability of blockage in the direct link, the fallback option is throughput- and delay-optimal. For a network with heavy traffic demands and semi-static topology (low beam-training overhead), the relay option is preferable. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01458;Private Information Retrieval from MDS Coded Data in Distributed Storage  Systems; Razan Tajeddine,  Oliver W. Gnilke,  Salim El Rouayheb;  The problem of providing privacy, in the private information retrieval (PIR) sense, to users requesting data from a distributed storage system (DSS), is considered. The DSS is coded by an $(n,k,d)$ Maximum Distance Separable (MDS) code to store the data reliably on unreliable storage nodes. Some of these nodes can be spies which report to a third party, such as an oppressive regime, which data is being requested by the user. An information theoretic PIR scheme ensures that a user can satisfy its request while revealing, to the spy nodes, no information on which data is being requested. A user can trivially achieve PIR by downloading all the data in the DSS. However, this is not a feasible solution due to its high communication cost. We construct PIR schemes with low download communication cost. When there is $b=1$ spy node in the DSS, we construct PIR schemes with download cost $\frac{1}{1-R}$ per unit of requested data ($R=k/n$ is the code rate), achieving the information theoretic limit for linear schemes. The proposed schemes are universal since they depend on the code rate, but not on the generator matrix of the code. Also, when $b\leq n-\delta k$, for some $\delta \in \mathbb{N^+}$, we construct linear PIR schemes with $cPoP = \frac{b+\delta k}{\delta}$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01511;Linear codes with a few weights from inhomogeneous quadratic functions; Chunming Tang,  Can Xiang,  Keqin Feng;  Linear codes with few weights have been an interesting subject of study for many years, as these codes have applications in secrete sharing, authentication codes, association schemes, and strongly regular graphs. In this paper, linear codes with a few weights are constructed from inhomogeneous quadratic functions over the finite field $\gf(p)$, where $p$ is an odd prime. They include some earlier linear codes as special cases. The weight distributions of these linear codes are also determined. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01532;Optimal Transport Theory for Power-Efficient Deployment of Unmanned  Aerial Vehicles; Mohammad Mozaffari,  Walid Saad,  Mehdi Bennis,  Merouane Debbah;  In this paper, the optimal deployment of multiple unmanned aerial vehicles (UAVs) acting as flying base stations is investigated. Considering the downlink scenario, the goal is to minimize the total required transmit power of UAVs while satisfying the users' rate requirements. To this end, the optimal locations of UAVs as well as the cell boundaries of their coverage areas are determined. To find those optimal parameters, the problem is divided into two sub-problems that are solved iteratively. In the first sub-problem, given the cell boundaries corresponding to each UAV, the optimal locations of the UAVs are derived using the facility location framework. In the second sub-problem, the locations of UAVs are assumed to be fixed, and the optimal cell boundaries are obtained using tools from optimal transport theory. The analytical results show that the total required transmit power is significantly reduced by determining the optimal coverage areas for UAVs. These results also show that, moving the UAVs based on users' distribution, and adjusting their altitudes can lead to a minimum power consumption. Finally, it is shown that the proposed deployment approach, can improve the system's power efficiency by a factor of 20 compared to the classical Voronoi cell association technique with fixed UAVs locations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01545;Correction of Data and Syndrome Errors by Stabilizer Codes; Alexei Ashikhmin,  Ching-Yi Lai,  Todd Brun;  Performing active quantum error correction to protect fragile quantum states highly depends on the correctness of error information--error syndromes. To obtain reliable error syndromes using imperfect physical circuits, we propose the idea of quantum data-syndrome (DS) codes that are capable of correcting both data qubits and syndrome bits errors. We study fundamental properties of quantum DS codes and provide several CSS-type code constructions of quantum DS codes. ;"Information Theory (cs.IT); Quantum Physics (quant-ph)"
https://arxiv.org/abs/1602.01560;Online energy efficient packet scheduling for a common deadline with and  without energy harvesting; Aditya Deshmukh,  Rahul Vaze;  The problem of online packet scheduling to minimize the required conventional grid energy for transmitting a fixed number of packets given a common deadline is considered. The total number of packets arriving within the deadline is known, but the packet arrival times are unknown, and can be arbitrary. The proposed algorithm tries to finish the transmission of each packet assuming all future packets are going to arrive at equal time intervals within the left-over time. The proposed online algorithm is shown to have competitive ratio that is logarithmic in the number of packet arrivals. The hybrid energy paradigm is also considered, where in addition to grid energy, energy is also available via extraction from renewable sources. The objective here is to minimize the grid energy use. A suitably modified version of the previous algorithm is also shown to have competitive ratio that is logarithmic in the number of packet arrivals. ;"Information Theory (cs.IT); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1602.01565;Context-Aware Scheduling of Joint Millimeter Wave and Microwave  Resources for Dual-Mode Base Stations; Omid Semiari,  Walid Saad,  Mehdi Bennis;  One of the most promising approaches to overcome the drastic channel variations of millimeter wave (mmW) communications is to deploy dual-mode base stations that integrate both mmW and microwave (\muW) frequencies. Reaping the benefits of a dual-mode operation requires scheduling mechanisms that can allocate resources efficiently and jointly at both frequency bands. In this paper, a novel resource allocation framework is proposed that exploits users' context, in terms of user application (UA) delay requirements, to maximize the quality-of-service (QoS) of a dual-mode base station. In particular, such a context-aware approach enables the network to dynamically schedule UAs, instead of users, thus providing more precise delay guarantees and a more efficient exploitation of the mmW resources. The scheduling of UAs is formulated as a one-to-many matching problem between UAs and resources and a novel algorithm is proposed to solve it. The proposed algorithm is shown to converge to a two-sided stable matching between UAs and network resources. Simulation results show that the proposed approach outperforms classical CSI-based scheduling in terms of the per UA QoS, yielding up to 36% improvement. The results also show that exploiting mmW resources provides significant traffic offloads reaching up to 43% from \muW band. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01569;Unraveling the Rank-One Solution Mystery of Robust MISO Downlink  Transmit Optimization: A Verifiable Sufficient Condition via a New Duality  Result; Wing-Kin Ma,  Jiaxian Pan,  Anthony Man-Cho So,  Tsung-Hui Chang;  This paper concentrates on a robust transmit optimization problem for the multiuser multi-input single-output (MISO) downlink scenario and under inaccurate channel state information (CSI). This robust problem deals with a general-rank transmit covariance design, and it follows a safe rate-constrained formulation under spherically bounded CSI uncertainties. Curiously, simulation results in previous works suggested that the robust problem admits rank-one optimal transmit covariances in most cases. Such a numerical finding is appealing because transmission with rank-one covariances can be easily realized by single-stream transmit beamforming. This gives rise to a fundamentally important question, namely, whether we can theoretically identify conditions under which the robust problem admits a rank-one solution. In this paper, we identify one such condition. Simply speaking, we show that the robust problem is guaranteed to admit a rank-one solution if the CSI uncertainties are not too large and the multiuser channel is not too poorly conditioned. To establish the aforementioned condition, we develop a novel duality framework, through which an intimate relationship between the robust problem and a related maximin problem is revealed. Our condition involves only a simple expression with respect to the multiuser channel and other system parameters. In particular, unlike other sufficient rank-one conditions that have appeared in the literature, ours is verifiable. The application of our analysis framework to several other CSI uncertainty models is also discussed. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01577;New Coupled Codes Constructed by Overlapping Circular SC-LDPC Codes; Heeyoul Kwak,  Bohwan Jun,  Pilwoong Yang,  Jong-Seon No,  Dong-Joon Shin;  In this paper, we propose new coupled codes constructed by overlapping circular spatially-coupled low-density parity-check (SC-LDPC) codes, which show better asymptotic and finite-length decoding performance compared to the conventional SC-LDPC codes. The performance improvement comes from the property that the proposed codes effectively split into two separated SC-LDPC codes with shorter chain length during the decoding process. We verify that the property of the proposed codes is valid in asymptotic setting via analysis tools such as the density evolution and the expected graph evolution. Experimental results show that the proposed codes also outperform the conventional SC-LDPC codes in terms of the finite-length performance under belief propagation decoding. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01600;Design of Geometric Molecular Bonds; David Doty,  Andrew Winslow;"  An example of a nonspecific molecular bond is the affinity of any positive charge for any negative charge (like-unlike), or of nonpolar material for itself when in aqueous solution (like-like). This contrasts specific bonds such as the affinity of the DNA base A for T, but not for C, G, or another A. Recent experimental breakthroughs in DNA nanotechnology demonstrate that a particular nonspecific like-like bond (""blunt-end DNA stacking"" that occurs between the ends of any pair of DNA double-helices) can be used to create specific ""macrobonds"" by careful geometric arrangement of many nonspecific blunt ends, motivating the need for sets of macrobonds that are orthogonal: two macrobonds not intended to bind should have relatively low binding strength, even when misaligned. To address this need, we introduce geometric orthogonal codes that abstractly model the engineered DNA macrobonds as two-dimensional binary codewords. While motivated by completely different applications, geometric orthogonal codes share similar features to the optical orthogonal codes studied by Chung, Salehi, and Wei. The main technical difference is the importance of 2D geometry in defining codeword orthogonality. ";"Information Theory (cs.IT); Computational Geometry (cs.CG); Emerging Technologies (cs.ET); Molecular Networks (q-bio.MN)"
https://arxiv.org/abs/1602.01648;Uniformity Properties of Construction C; Maiara F. Bollauf,  Ram Zamir;  Construction C (also known as Forney's multi-level code formula) forms a Euclidean code for the additive white Gaussian noise (AWGN) channel from $L$ binary code components. If the component codes are linear, then the minimum distance is the same for all the points, although the kissing number may vary. In fact, while in the single level ($L=1$) case it reduces to lattice Construction A, a multi-level Construction C is in general not a lattice. We show that the two-level ($L=2$) case is special: a two-level Construction C satisfies Forney's definition for a geometrically uniform constellation. Specifically, every point sees the same configuration of neighbors, up to a reflection of the coordinates in which the lower level code is equal to 1. In contrast, for three levels and up ($L\geq 3$), we construct examples where the distance spectrum varies between the points, hence the constellation is not geometrically uniform. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01731;Multi-Objective Framework for Dynamic Optimization of OFDMA Cellular  Systems; Prabhu Chandhar,  Suvra Sekhar Das;  Green cellular networking has become an important research area in recent years due to environmental and economical concerns. Switching off under-utilized BSs during off-peak traffic load conditions is a promising approach to reduce energy consumption in cellular networks. In practice, during initial cell planning, the BS locations and RAN parameters are optimized to meet the basic system design requirements like coverage, capacity, overlap, QoS etc. As these metrics are tightly coupled with each other due to co-channel interference, switching off certain BSs may affect the system requirements. Therefore, identifying a subset of large number of BSs which are to be put into sleep mode, is a challenging dynamic optimization problem. In this work, we develop a multiobjective framework for dynamic optimization framework for OFDMA based cellular systems. The objective is to identify the appropriate set of active sectors and RAN parameters that maximize coverage and area spectral efficiency while minimizing overlap and area power consumption without violating the QoS requirements for a given traffic demand density. The objective functions and constraints are obtained using appropriate analytical models which capture the traffic characteristics, propagation characteristics (pathloss, shadowing, and small scale fading) as well as load condition in neighbouring cells. A low complexity evolutionary algorithm is used for identifying the global Pareto optimal solutions at a faster convergence rate. The inter-relationships between the system objectives are studied and guidelines are provided to find an appropriate network configuration that provides the best achievable trade-offs. The results show that using the proposed framework, significant amount of energy saving can be achieved and with a low computational complexity while maintaining good trade-offs among the other objectives. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01870;Polar Coding for Processes with Memory; Eren Sasoglu,  Ido Tal;  We study polar coding over channels and sources with memory. We show that $\psi$-mixing processes polarize under the standard transform, and that the rate of polarization to deterministic distributions is roughly $O(2^{-\sqrt{N}})$ as in the memoryless case, where $N$ is the blocklength. This implies that the error probability guarantees of polar channel and source codes extend to a large class of models with memory, including finite-order Markov sources and finite-state channels. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01906;Selecting wavelengths for least squares range estimation; Assad Akhlaq,  Robby McKilliam,  Ramanan Subramanian,  Andre Pollok;  We consider the problem of estimating the distance, or range, between two locations by measuring the phase of multiple sinusoidal signals transmitted between the locations. Traditional estimators developed for optical interferometry include the beat wavelength and excess fractions methods. More recently, estimators based on the Chinese remainder theorem (CRT) and least squares have appeared. Recent research suggests the least squares estimator to be most accurate in many cases. The accuracy of all of these range estimators depends upon the wavelengths chosen. This leads to the problem of selecting wavelengths that maximise accuracy. Procedures for selecting wavelengths for the beat wavelength and excess fractions methods have previously been described, but procedures for the CRT and least squares estimators are yet to be developed. In this paper we develop an algorithm to automatically select wavelengths for use with the least square range estimator. The algorithm minimises an optimisation criterion connected with the mean square error. Interesting properties of a particular class of lattices simplify the criterion allowing minimisation by depth first search. Monte-Carlo simulations indicate that wavelengths that minimise the criterion can result is considerably more accurate range estimates than wavelengths selected by ad hoc means. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01911;An Achievable Rate-Distortion Region for Multiple Descriptions Source  Coding Based on Coset Codes; Farhad Shirani,  S. Sandeep Pradhan;  We consider the problem of multiple descriptions (MD) source coding and propose new coding strategies involving both unstructured and structured coding layers. Previously, the most general achievable rate-distortion (RD) region for the $l$-descriptions problem was the Combinatorial Message Sharing with Binning (CMSB) region. The CMSB scheme utilizes unstructured quantizers and unstructured binning. In the first part of the paper, we show that this strategy can be improved upon using more general unstructured quantizers and a more general unstructured binning method. In the second part, structured coding strategies are considered. First, structured coding strategies are developed by considering specific MD examples involving three or more descriptions. We show that application of structured quantizers results in strict RD improvements when there are more than two descriptions. Furthermore, we show that structured binning also yields improvements. These improvements are in addition to the ones derived in the first part of the paper. This suggests that structured coding is essential when coding over more than two descriptions. Using the ideas developed through these examples we provide a new unified coding strategy by considering several structured coding layers. Finally, we characterize its performance in the form of an inner bound to the optimal rate-distortion region using computable single-letter information quantities. The new RD region strictly contains all of the previous known achievable regions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01982;On the Capacity of the Half-Duplex MIMO Gaussian Diamond Channel; Antony V. Mampilly,  Srikrishna Bhashyam;  In this paper, we analyze the 2-relay multiple-input multiple-output (MIMO) Gaussian diamond channel. We show that a multihopping decode-and-forward with multiple access (MDF-MAC) protocol achieves rates within a constant gap from capacity when a channel parameter $\Delta$ is greater than zero. We also identify the transmit covariance matrices to be used by each relay in the multiple-access (MAC) state of the MDF-MAC protocol. As done for the single-antenna 2-relay Gaussian diamond channel, the channel parameter $\Delta$ is defined to be the difference between the product of the capacities of the links from the source to the two relays and the product of the capacities of the links from the two relays to the destination. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.01995;Efficient distribution and improved security for reliable cloud storage  system; Ninoslav Marina,  Aneta Velkoska,  Natasa Paunkoska;  The distributed data storage systems are constructed by large number of nodes which are interconnected over a network. Each node in such peer-to-peer network is vulnerable and at a potential risk for attack. The attackers can eavesdrop the nodes and possibly modify their data. Hence distributed storage systems should be secure apart from satisfying the reconstruction and repair requirements. We constructed a distributed storage system, Twin MDS code framework which is more efficient than the regenerating codes based storage systems. We prove that this Twin MDS code framework gives better performance than MBR codes and equal with MSR codes in the distribution process and investigate its security performance comparing with the security of the MBR and MSR codes. Such Twin MDS code framework is examined in an eavesdropper model where passive attackers can access to the stored data or/and downloaded data during the repair process. We demonstrate that the Twin MDS code framework manages better results than MBR and MSR codes regarding the security in the system. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02040;Efficient and Scalable Distributed Autonomous Spatial Aloha Networks via  Local Leader Election; Jiangbin Lyu,  Yong Huat Chew,  Wai-Choong Wong;  This paper uses a spatial Aloha model to describe a distributed autonomous wireless network in which a group of transmit-receive pairs (users) shares a common collision channel via slotted-Aloha-like random access. The objective of this study is to develop an intelligent algorithm to be embedded into the transceivers so that all users know how to self-tune their medium access probability (MAP) to achieve overall Pareto optimality in terms of network throughput under spatial reuse while maintaining network stability. While the optimal solution requires each user to have complete information about the network, our proposed algorithm only requires users to have local information. The fundamental of our algorithm is that the users will first self-organize into a number of non-overlapping neighborhoods, and the user with the maximum node degree in each neighborhood is elected as the local leader (LL). Each LL then adjusts its MAP according to a parameter R which indicates the radio intensity level in its neighboring region, whereas the remaining users in the neighborhood simply follow the same MAP value. We show that by ensuring R less than or equal to 2 at the LLs, the stability of the entire network can be assured even when each user only has partial network information. For practical implementation, we propose each LL to use R=2 as the constant reference signal to its built-in proportional and integral controller. The settings of the control parameters are discussed and we validate through simulations that the proposed method is able to achieve close-to-Pareto-front throughput. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02057;A Generalised Differential Framework for Measuring Signal Sparsity; Anastasios Maronidis,  Elisavet Chatzilari,  Spiros Nikolopoulos,  Ioannis Kompatsiaris;  The notion of signal sparsity has been gaining increasing interest in information theory and signal processing communities. As a consequence, a plethora of sparsity metrics has been presented in the literature. The appropriateness of these metrics is typically evaluated against a set of objective criteria that has been proposed for assessing the credibility of any sparsity metric. In this paper, we propose a Generalised Differential Sparsity (GDS) framework for generating novel sparsity metrics whose functionality is based on the concept that sparsity is encoded in the differences among the signal coefficients. We rigorously prove that every metric generated using GDS satisfies all the aforementioned criteria and we provide a computationally efficient formula that makes GDS suitable for high-dimensional signals. The great advantage of GDS is its flexibility to offer sparsity metrics that can be well-tailored to certain requirements stemming from the nature of the data and the problem to be solved. This is in contrast to current state-of-the-art sparsity metrics like Gini Index (GI), which is actually proven to be only a specific instance of GDS, demonstrating the generalisation power of our framework. In verifying our claims, we have incorporated GDS in a stochastic signal recovery algorithm and experimentally investigated its efficacy in reconstructing randomly projected sparse signals. As a result, it is proven that GDS, in comparison to GI, both loosens the bounds of the assumed sparsity of the original signals and reduces the minimum number of projected dimensions, required to guarantee an almost perfect reconstruction of heavily compressed signals. The superiority of GDS over GI in conjunction with the fact that the latter is considered as a standard in numerous scientific domains, prove the great potential of GDS as a general purpose framework for measuring sparsity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02178;Cooperative Hierarchical Caching in 5G Cloud Radio Access Networks  (C-RANs); Tuyen X. Tran,  Abolfazl Hajisami,  Dario Pompili;  Over the last few years, Cloud Radio Access Network (C-RAN) has arisen as a transformative architecture for 5G cellular networks that brings the flexibility and agility of cloud computing to wireless communications. At the same time, content caching in wireless networks has become an essential solution to lower the content-access latency and backhaul traffic loading, which translate into user Quality of Experience (QoE) improvement and network cost reduction. In this article, a novel Cooperative Hierarchical Caching (CHC) framework in C-RAN is introduced where contents are jointly cached at the BaseBand Unit (BBU) and at the Radio Remote Heads (RRHs). Unlike in traditional approaches, the cache at the BBU, cloud cache, presents a new layer in the cache hierarchy, bridging the latency/capacity gap between the traditional edge-based and core-based caching schemes. Trace-driven simulations reveal that CHC yields up to 80% improvement in cache hit ratio, 21% decrease in average content-access latency, and 20% reduction in backhaul traffic load compared to the edge-only caching scheme with the same total cache capacity. Before closing the article, several challenges and promising opportunities for deploying content caching in C-RAN are highlighted towards a content-centric mobile wireless network. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1602.02201;Compress and Estimate in Multiterminal Source Coding; Alon Kipnis,  Stefano Rini,  Andrea J. Goldsmith;"  We consider a multiterminal remote source coding problem in which a source sequence is estimated from the output of multiple source encoders, each having access only to a noisy observation of the source realization. Each remote encoder compresses its noisy observation sequence so as to minimize a local distortion measure which depends only on the distribution of its observed sequence, and is otherwise independent from the distribution of the underlying source. The latter is estimated at a central location from the output of each of the remote encoders. This source compression and estimation scenario leads to an achievable scheme for the remote multiterminal source coding problem which we term the ""compress-and-estimate"" (CE) scheme. For the case of a source with independently and identically distributed (i.i.d) elements observed through multiple memoryless channels, we derive a single-letter expression for the distortion in the CE scheme, which we refer to as the CE distortion-rate function (CE-DRF). We prove that the CE-DRF can be achieved by estimating the source realization from the output of any set of encoders, as long as each encoder attains its local rate-distortion function. We prove in addition a converse result saying that, for large enough blocklength, the distortion in estimating a finite sub-block of the source from the output of such encoders, averaged over all sub-blocks, does not exceed the CE-DRF. Finally, we derive closed-form expressions for the CE-DRF in the case of a Gaussian source observed through multiple AWGN channels under quadratic distortion, and for the case of a binary source observed through multiple biflip channels under Hamming distortion. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.02203;GDoF of the MISO BC: Bridging the Gap between Finite Precision and  Perfect CSIT; Arash Gholami Davoodi,  Bofeng Yuan,  Syed A. Jafar;  For the $K=2$ user MISO BC, i.e., the wireless broadcast channel where a transmitter equipped with $K=2$ antennas sends independent messages to $K=2$ receivers each of which is equipped with a single antenna, the sum generalized degrees of freedom (GDoF) are characterized for arbitrary channel strength and channel uncertainty levels for each of the channel coefficients. The result is extended to $K>2$ users under additional restrictions which include the assumption of symmetry. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02205;On the Capacity of the Dirty Paper Channel with Fast Fading and Discrete  Channel States; Stefano Rini,  Shlomo Shamai Shitz;"  The ""writing dirty paper"" capacity result crucially dependents on the perfect channel knowledge at the transmitter as the presence of even a small uncertainty in the channel realization gravely hampers the ability of the transmitter to pre-code its transmission against the channel state. This is particularly disappointing as it implies that interference pre-coding in practical systems is effective only when the channel estimates at the users have very high precision, a condition which is generally unattainable in wireless environments. In this paper we show that substantial improvements are possible when the state sequence is drawn from a discrete distribution, such as a constrained input constellation, for which state decoding can be approximately optimal. We consider the ""writing on dirty paper"" channel in which the state sequence is multiplied by a fast fading process and derive conditions on the fading and state distributions for which state decoding closely approaches capacity. These conditions intuitively relate to the ability of the receiver to correctly identify both the input and the state realization despite of the uncertainty introduced by fading. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.02206;The Carbon Copy onto Dirty Paper Channel with Statistically Equivalent  States; Stefano Rini,  Shlomo Shamai Shitz;"  Costa's ""writing on dirty paper"" capacity result establishes that full state pre-cancellation can be attained in Gelfand-Pinsker channel with additive state and additive Gaussian noise. The ""carbon copy onto dirty paper"" channel is the extension of Costa's model to the compound setting: M receivers each observe the sum of the channel input, Gaussian noise and one of M Gaussian state sequences and attempt to decode the same common message. The state sequences are all non-causally known at the transmitter which attempts to simultaneously pre-code its transmission against the channel state affecting each output. In this correspondence we derive the capacity to within 2.25 bits-per-channel-use of the carbon copying onto dirty paper channel in which the state sequences are statistically equivalent, having the same variance and the same pairwise correlation. For this channel capacity is approached by letting the channel input be the superposition of two codewords: a base codeword, simultaneously decoded at each user, and a top codeword which is pre-coded against the state realization at each user for a portion 1/M of the time. The outer bound relies on a recursive bounding in which incremental side information is provided at each receiver. This result represents a significant first step toward determining the capacity of the most general ""carbon copy onto dirty paper"" channel in which state sequences appearing in the different channel outputs have any jointly Gaussian distribution. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.02216;Smoothing Brascamp-Lieb Inequalities and Strong Converses for Common  Randomness Generation; Jingbo Liu,  Thomas A. Courtade,  Paul Cuff,  Sergio Verdu;  We study the infimum of the best constant in a functional inequality, the Brascamp-Lieb-like inequality, over auxiliary measures within a neighborhood of a product distribution. In the finite alphabet and the Gaussian cases, such an infimum converges to the best constant in a mutual information inequality. Implications for strong converse properties of two common randomness (CR) generation problems are discussed. In particular, we prove the strong converse property of the rate region for the omniscient helper CR generation problem in the discrete and the Gaussian cases. The latter case is perhaps the first instance of a strong converse for a continuous source when the rate region involves auxiliary random variables. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02250;On the Limits of Coexisting Coverage and Capacity in Multi-RAT  Heterogeneous Networks; Chun-Hung Liu,  Hong-Cheng Tsai;  This paper devises a general modeling and analyzing framework for a heterogeneous wireless network (HetNet) in which several wireless subnetworks coexist and use multiple radio access technologies (multi-RATs). The coexisting coverage and network capacity in such a multi-RAT HetNet are hardly investigated in prior works. To characterize the coexisting interactions in a multi-RAT HetNet, in this paper we consider a HetNet consisting of K-tier APs and two different RATs, RAT-L and RAT-U, are adopted in the HetNet. RAT-L is adopted by the access points (APs) in the first K-1 tiers and APs in the Kth tier only use RAT-U. Both noncrossing-RAT and crossing-RAT user association scenarios are considered. In each scenario, the void probability and channel access probability of the APs in each tier are first found and then the tight lower bounds and their lowest limits on the proposed coexisting coverage and network capacity are derived. We show that multi-RAT networks in general can achieve higher link coverage and capacity by using opportunistic CSMA/CA that avoids/alleviates severe interfering between all coexisting APs. Also, crossing-RAT user association is shown to achieve much higher coexisting coverage and network capacity than noncrossing-RAT user association. Finally, numerical simulations for the LTE-U and WiFi networks coexisting in the HetNet validate our findings. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1602.02294;A Source-Channel Separation Theorem with Application to the Source  Broadcast Problem; Kia Khezeli,  Jun Chen;  A converse method is developed for the source broadcast problem. Specifically, it is shown that the separation architecture is optimal for a variant of the source broadcast problem and the associated source-channel separation theorem can be leveraged, via a reduction argument, to establish a necessary condition for the original problem, which unifies several existing results in the literature. Somewhat surprisingly, this method, albeit based on the source-channel separation theorem, can be used to prove the optimality of non-separation based schemes and determine the performance limits in certain scenarios where the separation architecture is suboptimal. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02366;On the Degrees-of-Freedom of the Large-Scale Interfering Two-Way Relay  Network; Hyun Jong Yang,  Won-Yong Shin,  Bang Chul Jung;  Achievable degrees-of-freedom (DoF) of the large-scale interfering two-way relay network is investigated. The network consists of $K$ pairs of communication nodes (CNs) and $N$ relay nodes (RNs). It is assumed that $K\ll N$ and each pair of CNs communicates with each other through one of the $N$ relay nodes without a direct link between them. Interference among RNs is also considered. Assuming local channel state information (CSI) at each RN, a distributed and opportunistic RN selection technique is proposed for the following three promising relaying protocols: amplify--forward, decode--forward, and compute--forward. As a main result, the asymptotically achievable DoF is characterized as $N$ increases for the three relaying protocols. In particular, a sufficient condition on $N$ required to achieve the certain DoF of the network is analyzed. Through extensive simulations, it is shown that the proposed RN selection techniques outperform conventional schemes in terms of achievable rate even in practical communication scenarios. Note that the proposed technique operates with a distributed manner and requires only local CSI, leading to easy implementation for practical wireless systems. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1602.02367;A Diffusion Kernel LMS algorithm for nonlinear adaptive networks; Symeon Chouvardas,  Moez Draief;"  This work presents a distributed algorithm for nonlinear adaptive learning. In particular, a set of nodes obtain measurements, sequentially one per time step, which are related via a nonlinear function; their goal is to collectively minimize a cost function by employing a diffusion based Kernel Least Mean Squares (KLMS). The algorithm follows the Adapt Then Combine mode of cooperation. Moreover, the theoretical properties of the algorithm are studied and it is proved that under certain assumptions the algorithm suffers a no regret bound. Finally, comparative experiments verify that the proposed scheme outperforms other variants of the LMS. ";"Information Theory (cs.IT); Systems and Control (cs.SY)"
https://arxiv.org/abs/1602.02384;The benefit of a 1-bit jump-start, and the necessity of stochastic  encoding, in jamming channels; Bikash Kumar Dey,  Sidharth Jaggi,  Michael Langberg,  Anand D. Sarwate;"  We consider the problem of communicating a message $m$ in the presence of a malicious jamming adversary (Calvin), who can erase an arbitrary set of up to $pn$ bits, out of $n$ transmitted bits $(x_1,\ldots,x_n)$. The capacity of such a channel when Calvin is exactly causal, i.e. Calvin's decision of whether or not to erase bit $x_i$ depends on his observations $(x_1,\ldots,x_i)$ was recently characterized to be $1-2p$. In this work we show two (perhaps) surprising phenomena. Firstly, we demonstrate via a novel code construction that if Calvin is delayed by even a single bit, i.e. Calvin's decision of whether or not to erase bit $x_i$ depends only on $(x_1,\ldots,x_{i-1})$ (and is independent of the ""current bit"" $x_i$) then the capacity increases to $1-p$ when the encoder is allowed to be stochastic. Secondly, we show via a novel jamming strategy for Calvin that, in the single-bit-delay setting, if the encoding is deterministic (i.e. the transmitted codeword is a deterministic function of the message $m$) then no rate asymptotically larger than $1-2p$ is possible with vanishing probability of error, hence stochastic encoding (using private randomness at the encoder) is essential to achieve the capacity of $1-p$ against a one-bit-delayed Calvin. ";"Information Theory (cs.IT); Cryptography and Security (cs.CR)"
https://arxiv.org/abs/1602.02390;Lower Bounds for Interactive Function Computation via Wyner Common  Information; Shijin Rajakrishnan,  Sundara Rajan S,  Vinod Prabhakaran;  The question of how much communication is required between collaborating parties to compute a function of their data is of fundamental importance in the fields of theoretical computer science and information theory. In this work, the focus is on coming up with lower bounds on this. The information cost of a protocol is the amount of information the protocol reveals to Alice and Bob about each others inputs, and the information complexity of a function is the infimum of information costs over all valid protocols. For the amortized case, it is known that the optimal rate for the computation is equal to the information complexity. Exactly computing this information complexity is not straight forward however. In this work we lower bound information complexity for independent inputs in terms of the Wyner common information of a certain pair of random variables. We show a structural property for the optimal auxiliary random variable of Wyner common information and exploit this to exactly compute the Wyner common information in certain cases. The lower bound obtained through this technique is shown to be tight for a non-trivial example - equality (EQ) for the ternary alphabet. We also give an example to show that the lower bound may, in general, not be tight. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02415;On Cartesian line sampling with anisotropic total variation  regularization; Clarice Poon;  This paper considers the use of the anisotropic total variation seminorm to recover a two dimensional vector $x\in \mathbb{C}^{N\times N}$ from its partial Fourier coefficients, sampled along Cartesian lines. We prove that if $(x_{k,j} - x_{k-1,j})_{k,j}$ has at most $s_1$ nonzero coefficients in each column and $(x_{k,j} - x_{k,j-1})_{k,j}$ has at most $s_2$ nonzero coefficients in each row, then, up to multiplication by $\log$ factors, one can exactly recover $x$ by sampling along $s_1$ horizontal lines of its Fourier coefficients and along $s_2$ vertical lines of its Fourier coefficients. Finally, unlike standard compressed sensing estimates, the $\log$ factors involved are dependent on the separation distance between the nonzero entries in each row/column of the gradient of $x$ and not on $N^2$, the ambient dimension of $x$. ;"Information Theory (cs.IT); Numerical Analysis (math.NA)"
https://arxiv.org/abs/1602.02422;Approximate Capacity of Index Coding for Some Classes of Graphs; Fatemeh Arbabjolfaei,  Young-Han Kim;  For a class of graphs for which the Ramsey number $R(i,j)$ is upper bounded by $ci^aj^b$, for some constants $a,b,$ and $c$, it is shown that the clique covering scheme approximates the broadcast rate of every $n$-node index coding problem in the class within a multiplicative factor of $c^{\frac{1}{a+b+1}} n^{\frac{a+b}{a+b+1}}$ for every $n$. Using this theorem and some graph theoretic arguments, it is demonstrated that the broadcast rate of planar graphs, line graphs and fuzzy circular interval graphs is approximated by the clique covering scheme within a factor of $n^{\frac{2}{3}}$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02612;Sign-Compute-Resolve for Tree Splitting Random Access; Jasper Goseling,  Cedomir Stefanovic,  Petar Popovski;  We present an approach to random access that is based on three elements: physical-layer network coding (PLNC), signature codes and tree splitting. In presence of a collision, physical-layer network coding enables the receiver to decode, i.e. compute the sum of the packets that were transmitted by the individual users. For each user, the packet consists of the user's signature, as well as the data that the user wants to communicate. As long as no more than K users collide, their identities can be recovered from the sum of their signatures. A tree-splitting algorithm is used to deal with the case that more than K users collide. We demonstrate that our approach achieves throughput that tends to 1 rapidly as K increases. We also present results on net data-rate of the system, showing the impact of the overheads of the constituent elements of the proposed protocol. We compare the performance of our scheme with an upper bound that is obtained under the assumption that the active users are a priori known. Also, we consider an upper bound on the net data-rate for any PLNC based strategy in which one linear equation per slot is decoded. We show that already at modest packet lengths, the net data-rate of our scheme becomes close to the second upper bound, i.e. the overhead of the contention resolution algorithm and the signature codes vanishes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02648;Coding in the fork network in the framework of Kolmogorov complexity; Andrei Romashchenko;  Many statements from the classic information theory (the theory of Shannon's entropy) have natural counterparts in the algorithmic information theory (in the framework of Kolmogorov complexity). In this paper we discuss one simple instance of the parallelism between Shannon's and Kolmogorov's theories: we prove in the setting of Kolmogorov complexity a version of Wolf's characterization of admissible rates for the fork network. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02673;On Sparsity by NUV-EM, Gaussian Message Passing, and Kalman Smoothing; Hans-Andrea Loeliger,  Lukas Bruderer,  Hampus Malmberg,  Federico Wadehn,  Nour Zalmai;  Normal priors with unknown variance (NUV) have long been known to promote sparsity and to blend well with parameter learning by expectation maximization (EM). In this paper, we advocate this approach for linear state space models for applications such as the estimation of impulsive signals, the detection of localized events, smoothing with occasional jumps in the state space, and the detection and removal of outliers. The actual computations boil down to multivariate-Gaussian message passing algorithms that are closely related to Kalman smoothing. We give improved tables of Gaussian-message computations from which such algorithms are easily synthesized, and we point out two preferred such algorithms. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02704;Integrated Interleaved Codes as Locally Recoverable Codes: Properties  and Performance; Mario Blaum,  Steven R. Hetzler;  Considerable interest has been paid in recent literature to codes combining local and global properties for erasure correction. Applications are in cloud type of implementations, in which fast recovery of a failed storage device is important, but additional protection is required in order to avoid data loss, and in RAID type of architectures, in which total device failures coexist with silent failures at the page or sector level in each device. Existing solutions to these problems require in general relatively large finite fields. The techniques of Integrated Interleaved Codes (which are closely related to Generalized Concatenated Codes) are proposed to reduce significantly the size of the finite field, and it is shown that when the parameters of these codes are judiciously chosen, their performance may be competitive with the one of codes optimizing the minimum distance. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02718;Impact of Directionality on Interference Mitigation in Full-Duplex  Cellular Network; Constantinos Psomas,  Mohammadali Mohammadi,  Ioannis Krikidis,  Himal A. Suraweera;  In this paper, we consider two fundamental full-duplex (FD) architectures, two-node and three-node, in the context of cellular networks where the terminals employ directional antennas. The simultaneous transmission and reception of data in non-orthogonal channels makes FD radio a potential solution for the currently limited spectrum. However, its implementation generates high levels of interference either in the form of loopback interference (LI) from the output to the input antenna of a transceiver or in the form of co-channel interference in large-scale multicell networks due to the large number of active links. Using a stochastic geometry model, we investigate how directional antennas can control and mitigate the co-channel interference. Furthermore, we provide a model which characterizes the way directional antennas manage the LI in order to passively suppress it. Our results show that both architectures can benefit significantly by the employment of directional antennas. Finally, we consider the case where both architectures are employed in the network and derive the optimal values for the density fraction of each architecture which maximize the success probability and the network throughput. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02737;Low-Rank Positive Semidefinite Matrix Recovery from Corrupted Rank-One  Measurements; Yuanxin Li,  Yue Sun,  Yuejie Chi;  We study the problem of estimating a low-rank positive semidefinite (PSD) matrix from a set of rank-one measurements using sensing vectors composed of i.i.d. standard Gaussian entries, which are possibly corrupted by arbitrary outliers. This problem arises from applications such as phase retrieval, covariance sketching, quantum space tomography, and power spectrum estimation. We first propose a convex optimization algorithm that seeks the PSD matrix with the minimum $\ell_1$-norm of the observation residual. The advantage of our algorithm is that it is free of parameters, therefore eliminating the need for tuning parameters and allowing easy implementations. We establish that with high probability, a low-rank PSD matrix can be exactly recovered as soon as the number of measurements is large enough, even when a fraction of the measurements are corrupted by outliers with arbitrary magnitudes. Moreover, the recovery is also stable against bounded noise. With the additional information of an upper bound of the rank of the PSD matrix, we propose another non-convex algorithm based on subgradient descent that demonstrates excellent empirical performance in terms of computational efficiency and accuracy. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02831;Minimum Distances of the QC-LDPC Codes in IEEE 802 Communication  Standards; Brian K. Butler;  This work applies earlier results on Quasi-Cyclic (QC) LDPC codes to the codes specified in six separate IEEE 802 standards, specifying wireless communications from 54 MHz to 60 GHz. First, we examine the weight matrices specified to upper bound the codes' minimum distance independent of block length. Next, we search for the minimum distance achieved for the parity check matrices selected at each block length. Finally, solutions to the computational challenges encountered are addressed. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02924;Blocklength-Limited Performance of Relaying under Quasi-Static Rayleigh  Channels; Yulin Hu,  Anke Schmeink,  James Gross;  In this paper, the blocklength-limited performance of a relaying system is studied, where channels are assumed to experience quasi-static Rayleigh fading while at the same time only the average channel state information (CSI) is available at the source. Both the physical-layer performance (blocklength-limited throughput) and the link-layer performance (effective capacity) of the relaying system are investigated. We propose a simple system operation by introducing a factor based on which we weight the average CSI and let the source determine the coding rate accordingly. In particular, we prove that both the blocklength-limited throughput and the effective capacity are quasi-concave in the weight factor. Through numerical investigations, we show the appropriateness of our theoretical model. In addition, we observe that relaying is more efficient than direct transmission. Moreover, this performance advantage of relaying under the average CSI scenario is more significant than under the perfect CSI scenario. Finally, the speed of convergence (between the blocklength-limited performance and the performance in the Shannon capacity regime) in relaying system is faster in comparison to the direct transmission under both the average CSI scenario and the perfect CSI scenario. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.02944;Fast phase retrieval for high dimensions: A block-based approach; Boshra Rajaei,  Sylvain Gigan,  Florent Krzakala,  Laurent Daudet;  This paper addresses fundamental scaling issues that hinder phase retrieval (PR) in high dimensions. We show that, if the measurement matrix can be put into a generalized block-diagonal form, a large PR problem can be solved on separate blocks, at the cost of a few extra global measurements to merge the partial results. We illustrate this principle using two distinct PR methods, and discuss different design trade-offs. Experimental results indicate that this block-based PR framework can reduce computational cost and memory requirements by several orders of magnitude. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.03033;Strengthening the Entropy Power Inequality; Thomas A. Courtade;  We tighten the Entropy Power Inequality (EPI) when one of the random summands is Gaussian. Our strengthening is closely connected to the concept of strong data processing for Gaussian channels and generalizes the (vector extension of) Costa's EPI. This leads to a new reverse entropy power inequality and, as a corollary, sharpens Stam's inequality relating entropy power and Fisher information. Applications to network information theory are given, including a short self-contained proof of the rate region for the two-encoder quadratic Gaussian source coding problem. Our argument is based on weak convergence and a technique employed by Geng and Nair for establishing Gaussian optimality via rotational-invariance, which traces its roots to a `doubling trick' that has been successfully used in the study of functional inequalities. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.03061;Minimum Conditional Description Length Estimation for Markov Random  Fields; Matthew G. Reyes,  David L. Neuhoff;  In this paper we discuss a method, which we call Minimum Conditional Description Length (MCDL), for estimating the parameters of a subset of sites within a Markov random field. We assume that the edges are known for the entire graph $G=(V,E)$. Then, for a subset $U\subset V$, we estimate the parameters for nodes and edges in $U$ as well as for edges incident to a node in $U$, by finding the exponential parameter for that subset that yields the best compression conditioned on the values on the boundary $\partial U$. Our estimate is derived from a temporally stationary sequence of observations on the set $U$. We discuss how this method can also be applied to estimate a spatially invariant parameter from a single configuration, and in so doing, derive the Maximum Pseudo-Likelihood (MPL) estimate. ;"Information Theory (cs.IT); Learning (cs.LG); Statistics Theory (math.ST)"
https://arxiv.org/abs/1602.03084;Local Codes with Cooperative Repair in Distributed Storage System; Jing Wang,  Zhiyuan Yan,  Hongmei Xie;  Recently, the research on local repair codes is mainly confined to repair the failed nodes within each repair group. But if the extreme cases occur that the entire repair group has failed, the local code stored in the failed group need to be recovered as a whole. In this paper, local codes with cooperative repair, in which the local codes are constructed based on minimum storage regeneration (MSR) codes, is proposed to achieve repairing the failed groups. Specifically, the proposed local codes with cooperative repair construct a kind of mutual interleaving structure among the parity symbols, that the parity symbols of each local code, named as distributed local parity, can be generated by the parity symbols of the MSR codes in its two adjacent local codes. Taking advantage of the structure given, the failed local groups can be repaired cooperatively by their adjacent local groups with lower repair locality, and meanwhile the minimum distance of local codes with cooperative repair is derived. Theoretical analysis and simulation experiments show that, compared with codes with local regeneration (such as MSR-local codes and MBR-local codes), the proposed local codes with cooperative repair have benefits in bandwidth overhead and repair locality for the case of local groups failure. ;"Information Theory (cs.IT); Distributed, Parallel, and Cluster Computing (cs.DC)"
https://arxiv.org/abs/1602.03091;Enhancing the Estimation of mm-Wave Large Array Channels by Exploiting  Spatio-Temporal Correlation and Sparse Scattering; Saeid Haghighatshoar,  Giuseppe Caire;"  In order to cope with the large path-loss exponent of mm-Wave channels, a high beamforming gain is needed. This can be achieved with small hardware complexity and high hardware power efficiency by Hybrid Digital-Analog (HDA) beamforming, where a very large number $M\gg 1$ of antenna array elements requires only a relatively small $m\ll M$ number of A/D converters and modulators/demodulators. As such, the estimation of mm-Wave MIMO channels must deal with two specific problems: 1) high Doppler, due to the large carrier frequency; 2) impossibility of observing directly the M-dimensional channel vector at the antenna array elements, due to the mentioned HDA implementation. In this paper, we consider a novel scheme inspired by recent results on gridless multiple measurement vectors problem in compressed sensing, that is able to exploit the inherent mm-Wave channel sparsity in the angular domain in order to cope with both the above problems simultaneously. Our scheme uses past pilot-symbol observations in a window of length $T$ in order to estimate a low-dimensional subspace that approximately contains the channel vector at the current time. This subspace information can be used directly, in order to separate users in the spatial domain, or indirectly, in order to improve the estimate of the user channel vector from the current pilot-symbol observation. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.03115;Towards Robustness in Residue Number Systems; Li Xiao,  Xiang-Gen Xia,  Haiye Huo;  The problem of robustly reconstructing a large number from its erroneous remainders with respect to several moduli, namely the robust remaindering problem, may occur in many applications including phase unwrapping, frequency detection from several undersampled waveforms, wireless sensor networks, etc. Assuming that the dynamic range of the large number is the maximal possible one, i.e., the least common multiple (lcm) of all the moduli, a method called robust Chinese remainder theorem (CRT) for solving the robust remaindering problem has been recently proposed. In this paper, by relaxing the assumption that the dynamic range is fixed to be the lcm of all the moduli, a trade-off between the dynamic range and the robustness bound for two-modular systems is studied. It basically says that a decrease in the dynamic range may lead to an increase of the robustness bound. We first obtain a general condition on the remainder errors and derive the exact dynamic range with a closed-form formula for the robustness to hold. We then propose simple closed-form reconstruction algorithms. Furthermore, the newly obtained two-modular results are applied to the robust reconstruction for multi-modular systems and generalized to real numbers. Finally, some simulations are carried out to verify our proposed theoretical results. ;"Information Theory (cs.IT); Number Theory (math.NT)"
https://arxiv.org/abs/1602.03117;Layering of Communication Networks and a Forward-Backward Duality; Michael Cyran,  Birgit Schotsch,  Johannes B. Huber,  Robert F.H. Fischer,  Vahid Forutan;"  In layered communication networks there are only connections between intermediate nodes in adjacent layers. Applying network coding to such networks provides a number of benefits in theory as well as in practice. We propose a ""layering procedure"" to transform an arbitrary network into a layered structure. Furthermore, we derive a ""forward-backward duality"" for linear network codes, which can be seen as an analogon to the ""uplink-downlink duality"" in MIMO communication systems. ";Information Theory (cs.IT)
https://arxiv.org/abs/1602.03283;Performance Analysis of $l_0$ Norm Constrained Recursive Least Squares  Algorithm; Samrat Mukhopadhyay,  Bijit Kumar Das,  Mrityunjoy Chakraborty;  Performance analysis of $l_0$ norm constrained Recursive least Squares (RLS) algorithm is attempted in this paper. Though the performance pretty attractive compared to its various alternatives, no thorough study of theoretical analysis has been performed. Like the popular $l_0$ Least Mean Squares (LMS) algorithm, in $l_0$ RLS, a $l_0$ norm penalty is added to provide zero tap attractions on the instantaneous filter taps. A thorough theoretical performance analysis has been conducted in this paper with white Gaussian input data under assumptions suitable for many practical scenarios. An expression for steady state MSD is derived and analyzed for variations of different sets of predefined variables. Also a Taylor series expansion based approximate linear evolution of the instantaneous MSD has been performed. Finally numerical simulations are carried out to corroborate the theoretical analysis and are shown to match well for a wide range of parameters. ;"Information Theory (cs.IT); Adaptation and Self-Organizing Systems (nlin.AO); Methodology (stat.ME)"
https://arxiv.org/abs/1602.03313;A Remark on Channels with Transceiver Distortion; Wenyi Zhang;  Information transmission over channels with transceiver distortion is investigated via generalized mutual information (GMI) under Gaussian input distribution and nearest-neighbor decoding. A canonical transceiver structure in which the channel output is processed by a minimum mean-squared error estimator before decoding is established to maximize the GMI, and the well-known Bussgang's decomposition is shown to be a heuristic that is consistent with the GMI under linear output processing. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.03328;Degrees of Freedom Rate Region of the $K$-user Interference Channel with  Blind CSIT Using Staggered Antenna Switching; Milad Johnny,  Mohammad Reza Aref;  In this paper, we consider the problem of the interference alignment for the $K$-user SISO interference channel with blind channel state information at transmitters (CSIT). Our achievement in contrast to popular $K-$user interference alignment (IA) scheme has more practical notions. In this case every receiver is equipped with one reconfigurable antenna which tries to place its desired signal in a subspace which is linearly independent from interference signals. We show that if the channel values are known to the receivers only, the sum degrees-of-freedom (DOF) rate region of the linear BIA with staggered antenna switching is $\frac{Kr}{r^2-r+K}$, where $r = \left \lceil{\frac{\sqrt{1+4K}-1}{2}} \right \rceil$. The result indicates that the optimum DoF rate region of the $K-$user interference channel is to achieve the DoF of $\frac{\sqrt{K}}{2}$ for an asymptotically large network. Thus, the DoF of the $K$-user interference channel using staggered antenna switching grows sub-linearly with the number of the users, whereas it grows linearly in the case where transmitters access the CSI. In addition we propose both achievability and converse proof so as to show that this is the DoF rate region of blind interference alignment (BIA) with staggered antenna switching. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.03400;On the Noise Robustness of Simultaneous Orthogonal Matching Pursuit; Jean-François Determe,  Jérôme Louveaux,  Laurent Jacques,  François Horlin;  In this paper, the joint support recovery of several sparse signals whose supports present similarities is examined. Each sparse signal is acquired using the same noisy linear measurement process, which returns fewer observations than the dimension of the sparse signals. The measurement noise is assumed additive, Gaussian, and admits different variances for each sparse signal that is measured. Using the theory of compressed sensing, the performance of simultaneous orthogonal matching pursuit (SOMP) is analysed for the envisioned signal model. The cornerstone of this paper is a novel analysis method upper bounding the probability that SOMP recovers at least one incorrect entry of the joint support during a prescribed number of iterations. Furthermore, the probability of SOMP failing is investigated whenever the number of sparse signals being recovered simultaneously increases and tends to infinity. In particular, convincing observations and theoretical results suggest that SOMP committing no mistake in the noiseless case does not guarantee the absence of error in the noisy case whenever the number of acquired sparse signals scales to infinity. Finally, simulation results confirm the validity of the theoretical results. ;Information Theory (cs.IT)
https://arxiv.org/abs/1602.03471;Improved group testing rates with constant column weight designs; Matthew Aldridge,  Oliver Johnson,  Jonathan Scarlett;"  We consider nonadaptive group testing where each item is placed in a constant number of tests. The tests are chosen uniformly at random with replacement, so the testing matrix has (almost) constant column weights. We show that performance is improved compared to Bernoulli designs, where each item is placed in each test independently with a fixed probability. In particular, we show that the rate of the practical COMP detection algorithm is increased by 31% in all sparsity regimes. In dense cases, this beats the best possible algorithm with Bernoulli tests, and in sparse cases is the best proven performance of any practical algorithm. We also give an algorithm-independent upper bound for the constant column weight case; for dense cases this is again a 31% increase over the analogous Bernoulli result. ";"Information Theory (cs.IT); Statistics Theory (math.ST)"
https://arxiv.org/abs/1602.03476;Conditional Dependence via Shannon Capacity: Axioms, Estimators and  Applications; Weihao Gao,  Sreeram Kannan,  Sewoong Oh,  Pramod Viswanath;  We conduct an axiomatic study of the problem of estimating the strength of a known causal relationship between a pair of variables. We propose that an estimate of causal strength should be based on the conditional distribution of the effect given the cause (and not on the driving distribution of the cause), and study dependence measures on conditional distributions. Shannon capacity, appropriately regularized, emerges as a natural measure under these axioms. We examine the problem of calculating Shannon capacity from the observed samples and propose a novel fixed-$k$ nearest neighbor estimator, and demonstrate its consistency. Finally, we demonstrate an application to single-cell flow-cytometry, where the proposed estimators significantly reduce sample complexity. ;"Information Theory (cs.IT); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1702.00014;Sharp Bounds on Arimoto's Conditional Rényi Entropies Between Two  Distinct Orders; Yuta Sakai,  Ken-ichi Iwata;  This study examines sharp bounds on Arimoto's conditional R\'enyi entropy of order $\beta$ with a fixed another one of distinct order $\alpha \neq \beta$. Arimoto inspired the relation between the R\'enyi entropy and the $\ell_{r}$-norm of probability distributions, and he introduced a conditional version of the R\'enyi entropy. From this perspective, we analyze the $\ell_{r}$-norms of particular distributions. As results, we identify specific probability distributions whose achieve our sharp bounds on the conditional R\'enyi entropy. The sharp bounds derived in this study can be applicable to other information measures, e.g., the minimum average probability of error, the Bhattacharyya parameter, Gallager's reliability function $E_{0}$, and Sibson's $\alpha$-mutual information, whose are strictly monotone functions of the conditional R\'enyi entropy. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00027;Representation of big data by dimension reduction; A.G.Ramm,  C. Van;  Suppose the data consist of a set $S$ of points $x_j, 1 \leq j \leq J$, distributed in a bounded domain $D \subset R^N$, where $N$ and $J$ are large numbers. In this paper an algorithm is proposed for checking whether there exists a manifold $\mathbb{M}$ of low dimension near which many of the points of $S$ lie and finding such $\mathbb{M}$ if it exists. There are many dimension reduction algorithms, both linear and non-linear. Our algorithm is simple to implement and has some advantages compared with the known algorithms. If there is a manifold of low dimension near which most of the data points lie, the proposed algorithm will find it. Some numerical results are presented illustrating the algorithm and analyzing its performance compared to the classical PCA (principal component analysis) and Isomap. ;"Information Theory (cs.IT); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1702.00033;Expansion of the Kullback-Leibler Divergence, and a new class of  information metrics; David J. Galas,  T. Gregory Dewey,  James Kunert-Graf,  Nikita A. Sakhanenko;"  Inferring and comparing complex, multivariable probability density functions is fundamental to problems in several fields, including probabilistic learning, network theory, and data analysis. Classification and prediction are the two faces of this class of problem. We take an approach here that simplifies many aspects of these problems by presenting a structured, series expansion of the Kullback-Leibler divergence - a function central to information theory - and devise a distance metric based on this divergence. Using the M\""obius inversion duality between multivariable entropies and multivariable interaction information, we express the divergence as an additive series in the number of interacting variables, which provides a restricted and simplified set of distributions to use as approximation and with which to model data. Truncations of this series yield approximations based on the number of interacting variables. The first few terms of the expansion-truncation are illustrated and shown to lead naturally to familiar approximations, including the well-known Kirkwood superposition approximation. Truncation can also induce a simple relation between the multi-information and the interaction information. A measure of distance between distributions, based on Kullback-Leibler divergence, is then described and shown to be a true metric if properly restricted. The expansion is shown to generate a hierarchy of metrics and connects this work to information geometry formalisms. We give an example of the application of these metrics to a graph comparision problem that shows that the formalism can be applied to a wide range of network problems, provides a general approach for systematic approximations in numbers of interactions or connections, and a related quantitative metric. ";"Information Theory (cs.IT); Quantitative Methods (q-bio.QM)"
https://arxiv.org/abs/1702.00109;Info-Clustering: An Efficient Algorithm by Network Information Flow; Chung Chan,  Ali Al-Bashabsheh,  Qiaoqiao Zhou;  Motivated by the fact that entities in a social network or biological system often interact by exchanging information, we propose an efficient info-clustering algorithm that can group entities into communities using a parametric max-flow algorithm. This is a meaningful special case of the info-clustering paradigm where the dependency structure is graphical and can be learned readily from data. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00131;Optimal Caching in Content-Centric Mobile Hybrid Networks: A Variable  Decoupling Approach; Trung-Anh Do,  Sang-Woon Jeon,  Won-Yong Shin;  In this paper, large-scale content-centric mobile hybrid networks consisting of mobile nodes and static small base stations (SBSs) (or static helper nodes) are studied, where each node moves according to the random walk mobility model and requests a content object from the library independently at random according to a Zipf popularity distribution. Instead of allowing access to content objects at macro BSs via costly backhaul providing connection to the core network, we consider a more practical and challenging scenario where mobile nodes and SBSs, each having a finite-size cache space, are able to cache a subset of content objects so that each request is served by other mobile nodes or SBSs via multihop transmissions. We analyze the optimal throughput-delay trade-off by presenting a new cache allocation strategy using variable decoupling. In particular, under a given caching strategy, we first characterize a fundamental throughput-delay trade-off in terms of scaling laws by introducing a general content delivery multihop routing protocol. Then, the optimal throughput-delay trade-off is characterized by presenting the optimal cache allocation strategy, which jointly finds the replication sets at mobile nodes and SBSs via a novel variable decoupling approach. An interesting observation is that highly popular content objects are mainly served by mobile nodes while the rest of content objects are served by static SBSs. We perform numerical evaluation to validate our analytical results. We also show that the optimal strategy strictly outperforms a baseline approach, where the replication sets at mobile nodes and SBSs are optimized separately. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1702.00153;Structure and Performance of Generalized Quasi-Cyclic Codes; Cem Güneri,  Ferruh Özbudak,  Buket Özkaya,  Elif Saçıkara,  Zahra Sepasdar,  Patrick Solé;  Generalized quasi-cyclic (GQC) codes form a natural generalization of quasi-cyclic (QC) codes. They are viewed here as mixed alphabet codes over a family of ring alphabets. Decomposing these rings into local rings by the Chinese Remainder Theorem yields a decomposition of GQC codes into a sum of concatenated codes. This decomposition leads to a trace formula, a minimum distance bound, and to a criteria for the GQC code to be self-dual or to be linear complementary dual (LCD). Explicit long GQC codes that are LCD, but not QC, are exhibited. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00160;Short-Message Communication and FIR System Identification using Huffman  Sequences; Philipp Walk,  Peter Jung,  Babak Hassibi;  Providing short-message communication and simultaneous channel estimation for sporadic and fast fading scenarios is a challenge for future wireless networks. In this work we propose a novel blind communication and deconvolution scheme by using Huffman sequences, which allows to solve three important tasks in one step: (i) determination of the transmit power (ii) identification of the discrete-time FIR channel by providing a maximum delay of less than $L/2$ and (iii) simultaneously communicating $L-1$ bits of information. Our signal reconstruction uses a recent semi-definite program that can recover two unknown signals from their auto-correlations and cross-correlations. This convex algorithm is stable and operates fully deterministic without any further channel assumptions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00248;Location and Orientation Optimisation for Spatially Stretched Tripole  Arrays Based on Compressive Sensing; Matthew Hawes,  Lyudmila Mihaylova,  Wei Liu;  The design of sparse spatially stretched tripole arrays is an important but also challenging task and this paper proposes for the very first time efficient solutions to this problem. Unlike for the design of traditional sparse antenna arrays, the developed approaches optimise both the dipole locations and orientations. The novelty of the paper consists in formulating these optimisation problems into a form that can be solved by the proposed compressive sensing and Bayesian compressive sensing based approaches. The performance of the developed approaches is validated and it is shown that accurate approximation of a reference response can be achieved with a 67% reduction in the number of dipoles required as compared to an equivalent uniform spatially stretched tripole array, leading to a significant reduction in the cost associated with the resulting arrays. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00257;Collision vs non-Collision Distributed Time Synchronization for Dense  IoT Deployments; Maria Antonieta Alvarez,  Umberto Spagnolini;"  Massive co-located devices require new paradigms to allow proper network connectivity. Internet of things (IoT) is the paradigm that offers a solution for the inter-connectivity of devices, but in dense IoT networks time synchronization is a critical aspect. Further, the scalability is another crucial aspect. This paper focuses on synchronization for uncoordinated dense networks without any external timing reference. Two synchronization methods are proposed and compared: i) conventional synchronization that copes with the high density of nodes by frame collision-avoidance methods (e.g., CSMA/CA) to avoid the superimposition (or collision) of synchronization signals; and ii) distributed synchronization that exploits the frames' collision to drive the network to a global synchronization. The distributed synchronization algorithm allows the network to reach a timing synchronization status based on a common beacon with the same signature broadcasted by every device. The superimposition of beacons from all the other devices enables the network synchronization, rather than preventing it. Numerical analysis evaluates the synchronization performance based on the convergence time and synchronization dispersion, both on collision and non-collision scenario, by investigating the scalability of the network. Results prove that in dense network the ensemble of signatures provides remarkable improvements of synchronization performance compared to conventional master-slave reference. ";Information Theory (cs.IT)
https://arxiv.org/abs/1702.00275;The Average Dimension of the Hermitian Hull of Constayclic Codes over  Finite Fields; Somphong Jitman,  Ekkasit Sangwisut;  The hulls of linear and cyclic codes have been extensively studied due to their wide applications. In this paper, the average dimension of the Hermitian hull of constacyclic codes of length $n$ over a finite field $\mathbb{F}_{q^2}$ is determined together with some upper and lower bounds. It turns out that either the average dimension of the Hermitian hull of constacyclic codes of length $n$ over $\mathbb{F}_{q^2}$ is zero or it grows the same rate as $n$. Comparison to the average dimension of the Euclidean hull of cyclic codes is discussed as well. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00276;New Beam Tracking Technique for Millimeter Wave-band Communications; Jisu Bae,  Sun Hong Lim,  Jin Hyeok Yoo,  Jun Won Choi;"  In this paper, we propose an efficient beam tracking method for mobility scenario in mmWave-band communications. When the position of the mobile changes in mobility scenario, the base-station needs to perform beam training frequently to track the time-varying channel, thereby spending significant resources for training beams. In order to reduce the training overhead, we propose a new beam training approach called ""beam tracking"" which exploits the continuous nature of time varying angle of departure (AoD) for beam selection. We show that transmission of only two training beams is enough to track the time-varying AoD at good accuracy. We derive the optimal selection of beam pair which minimizes Cramer-Rao Lower Bound (CRLB) for AoD estimation averaged over statistical distribution of the AoD. Our numerical results demonstrate that the proposed beam tracking scheme produces better AoD estimation than the conventional beam training protocol with less training overhead. ";Information Theory (cs.IT)
https://arxiv.org/abs/1702.00493;Information-theoretic interpretation of tuning curves for multiple  motion directions; Wentao Huang,  Xin Huang,  Kechen Zhang;  We have developed an efficient information-maximization method for computing the optimal shapes of tuning curves of sensory neurons by optimizing the parameters of the underlying feedforward network model. When applied to the problem of population coding of visual motion with multiple directions, our method yields several types of tuning curves with both symmetric and asymmetric shapes that resemble what have been found in the visual cortex. Our result suggests that the diversity or heterogeneity of tuning curve shapes as observed in neurophysiological experiment might actually constitute an optimal population representation of visual motions with multiple components. ;"Information Theory (cs.IT); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)"
https://arxiv.org/abs/1702.00524;Uplink Multiuser Massive MIMO Systems with One-Bit ADCs: A  Coding-Theoretic Viewpoint; Seonho Kim,  Namyoon Lee,  Songnam Hong;  This paper investigates an uplink multiuser massive multiple-input multiple-output (MIMO) system with one-bit analog-to-digital converters (ADCs), in which $K$ users with a single-antenna communicate with one base station (BS) with $n_r$ antennas. In this system, we propose a novel MIMO detection framework, which is inspired by coding theory. The key idea of the proposed framework is to create a non-linear code $\Cc$ of length $n_r$ and rate $K/n_r$ using the encoding function that is completely characterized by a non-linear MIMO channel matrix. From this, a multiuser MIMO detection problem is converted into an equivalent channel coding problem, in which a codeword of the $\Cc$ is sent over $n_r$ parallel binary symmetric channels, each with different crossover probabilities. Levereging this framework, we develop a maximum likelihood decoding method, and show that the minimum distance of the $\Cc$ is strongly related to a diversity order. Furthermore, we propose a practical implementation method of the proposed framework when the channel state information is not known to the BS. The proposed method is to estimate the code $\Cc$ at the BS using a training sequence. Then, the proposed {\em weighted} minimum distance decoding is applied. Simulations results show that the proposed method almost achieves an ideal performance with a reasonable training overhead. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00584;Ultra Reliable Short Message Relaying with Wireless Power Transfer; Onel L. Alcaraz López,  Hirley Alves,  Richard Demo Souza,  Evelio Martín García Fernández;  We consider a dual-hop wireless network where an energy constrained relay node first harvests energy through the received radio-frequency signal from the source, and then uses the harvested energy to forward the source's information to the destination node. The throughput and delay metrics are investigated for a decode-and-forward relaying mechanism at finite blocklength regime and delay-limited transmission mode. We consider ultra-reliable communication scenarios under discussion for the next fifth-generation of wireless systems, with error and latency constraints. The impact on these metrics of the blocklength, information bits, and relay position is investigated. ;"Information Theory (cs.IT); Applications (stat.AP)"
https://arxiv.org/abs/1702.00606;Joint Offloading and Computing Optimization in Wireless Powered  Mobile-Edge Computing Systems; Feng Wang,  Jie Xu,  Xin Wang,  Shuguang Cui;  Mobile-edge computing (MEC) and wireless power transfer (WPT) have been recognized as promising techniques in the Internet of Things (IoT) era to provide massive low-power wireless devices with enhanced computation capability and sustainable energy supply. In this paper, we propose a unified MEC-WPT design by considering a wireless powered multiuser MEC system, where a multi-antenna access point (AP) (integrated with an MEC server) broadcasts wireless power to charge multiple users and each user node relies on the harvested energy to execute computation tasks. With MEC, these users can execute their respective tasks locally by themselves or offload all or part of them to the AP based on a time division multiple access (TDMA) protocol. Building on the proposed model, we develop an innovative framework to improve the MEC performance, by jointly optimizing the energy transmit beamformer at the AP, the central processing unit (CPU) frequencies and the numbers of offloaded bits at the users, as well as the time allocation among users. Under this framework, we address a practical scenario where latency-limited computation is required. In this case, we develop an optimal resource allocation scheme that minimizes the AP's total energy consumption subject to the users' individual computation latency constraints. Leveraging the state-of-the-art optimization techniques, we derive the optimal solution in a semi-closed form. Numerical results demonstrate the merits of the proposed design over alternative benchmark schemes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00608;Random Ensembles of Lattices from Generalized Reductions; Antonio Campello;  We propose a general framework to study constructions of Euclidean lattices from linear codes over finite fields. In particular, we prove general conditions for an ensemble constructed using linear codes to contain dense lattices (i.e., with packing density comparable to the Minkowski-Hlawka lower bound). Specializing to number field lattices, we obtain a number of interesting corollaries - for instance, the best known packing density of ideal lattices, and an elementary coding-theoretic construction of asymptotically dense Hurwitz lattices. All results are algorithmically effective, in the sense that, for any dimension, a finite family containing dense lattices is exhibited. For suitable constructions based on Craig's lattices, this family is significantly smaller, in terms of alphabet-size, than previous ones in the literature. ;"Information Theory (cs.IT); Metric Geometry (math.MG)"
https://arxiv.org/abs/1702.00645;On the Information Dimension of Stochastic Processes; Bernhard C. Geiger,  Tobias Koch;  In 1959, R\'enyi proposed the information dimension and the $d$-dimensional entropy to measure the information content of general random variables. This paper proposes a generalization of information dimension to stationary stochastic processes by defining the information dimension rate as the entropy rate of the uniformly-quantized stochastic process divided by minus the logarithm of the quantizer step size $1/m$ in the limit as $m\to\infty$. It is demonstrated that the information dimension rate coincides with the rate-distortion dimension, defined as twice the rate-distortion function $R(D)$ of the stochastic process divided by $-\log D$ in the limit as $D\downarrow 0$. It is further shown that, for Gaussian processes, the information dimension rate equals the Lebesgue measure of the set of harmonics where the derivative of the spectral distribution function is positive. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00727;On the Input-Degradedness and Input-Equivalence Between Channels; Rajai Nasser;  A channel $W$ is said to be input-degraded from another channel $W'$ if $W$ can be simulated from $W'$ by randomization at the input. We provide a necessary and sufficient condition for a channel to be input-degraded from another one. We show that any decoder that is good for $W'$ is also good for $W$. We provide two characterizations for input-degradedness, one of which is similar to the Blackwell-Sherman-Stein theorem. We say that two channels are input-equivalent if they are input-degraded from each other. We study the topologies that can be constructed on the space of input-equivalent channels, and we investigate their properties. Moreover, we study the continuity of several channel parameters and operations under these topologies. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00776;Complexity-Aware Scheduling for an LDPC Encoded C-RAN Uplink; Kyle Whetzel,  Matthew C. Valenti;  Centralized Radio Access Network (C-RAN) is a new paradigm for wireless networks that centralizes the signal processing in a computing cloud, allowing commodity computational resources to be pooled. While C-RAN improves utilization and efficiency, the computational load occasionally exceeds the available resources, creating a computational outage. This paper provides a mathematical characterization of the computational outage probability for low-density parity check (LDPC) codes, a common class of error-correcting codes. For tractability, a binary erasures channel is assumed. Using the concept of density evolution, the computational demand is determined for a given ensemble of codes as a function of the erasure probability. The analysis reveals a trade-off: aggressively signaling at a high rate stresses the computing pool, while conservatively backing-off the rate can avoid computational outages. Motivated by this trade-off, an effective computationally aware scheduling algorithm is developed that balances demands for high throughput and low outage rates. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00822;Autocorrelation and Lower Bound on the 2-Adic Complexity of LSB Sequence  of $p$-ary $m$-Sequence; Yuhua Sun,  Qiang Wang,  Tongjiang Yan;  In modern stream cipher, there are many algorithms, such as ZUC, LTE encryption algorithm and LTE integrity algorithm, using bit-component sequences of $p$-ary $m$-sequences as the input of the algorithm. Therefore, analyzing their statistical property (For example, autocorrelation, linear complexity and 2-adic complexity) of bit-component sequences of $p$-ary $m$-sequences is becoming an important research topic. In this paper, we first derive some autocorrelation properties of LSB (Least Significant Bit) sequences of $p$-ary $m$-sequences, i.e., we convert the problem of computing autocorrelations of LSB sequences of period $p^n-1$ for any positive $n\geq2$ to the problem of determining autocorrelations of LSB sequence of period $p-1$. Then, based on this property and computer calculation, we list some autocorrelation distributions of LSB sequences of $p$-ary $m$-sequences with order $n$ for some small primes $p$'s, such as $p=3,5,7,11,17,31$. Additionally, using their autocorrelation distributions and the method inspired by Hu, we give the lower bounds on the 2-adic complexities of these LSB sequences. Our results show that the main parts of all the lower bounds on the 2-adic complexity of these LSB sequencesare larger than $\frac{N}{2}$, where $N$ is the period of these sequences. Therefor, these bounds are large enough to resist the analysis of RAA (Rational Approximation Algorithm) for FCSR (Feedback with Carry Shift Register). Especially, for a Mersenne prime $p=2^k-1$, since all its bit-component sequences of a $p$-ary $m$-sequence are shift equivalent, our results hold for all its bit-component sequences. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00832;An Introduction to Deep Learning for the Physical Layer; Timothy J. O'Shea,  Jakob Hoydis;  We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. The paper is concluded with a discussion of open challenges and areas for future investigation. ;"Information Theory (cs.IT); Learning (cs.LG); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1702.00852;Guided Signal Reconstruction Theory; Andrew Knyazev,  Akshay Gadde,  Hassan Mansour,  Dong Tian;  An axiomatic approach to signal reconstruction is formulated, involving a sample consistent set and a guiding set, describing desired reconstructions. New frame-less reconstruction methods are proposed, based on a novel concept of a reconstruction set, defined as a shortest pathway between the sample consistent set and the guiding set. Existence and uniqueness of the reconstruction set are investigated in a Hilbert space, where the guiding set is a closed subspace and the sample consistent set is a closed plane, formed by a sampling subspace. Connections to earlier known consistent, generalized, and regularized reconstructions are clarified. New stability and reconstruction error bounds are derived, using the largest nontrivial angle between the sampling and guiding subspaces. Conjugate gradient iterative reconstruction algorithms are proposed and illustrated numerically for image magnification. ;"Information Theory (cs.IT); Functional Analysis (math.FA); Machine Learning (stat.ML)"
https://arxiv.org/abs/1702.00892;Stochastic Joint Radio and Computational Resource Management for  Multi-User Mobile-Edge Computing Systems; Yuyi Mao,  Jun Zhang,  S.H. Song,  Khaled B. Letaief;"  Mobile-edge computing (MEC) has recently emerged as a prominent technology to liberate mobile devices from computationally intensive workloads, by offloading them to the proximate MEC server. To make offloading effective, the radio and computational resources need to be dynamically managed, to cope with the time-varying computation demands and wireless fading channels. In this paper, we develop an online joint radio and computational resource management algorithm for multi-user MEC systems, with the objective as minimizing the long-term average weighted sum power consumption of the mobile devices and the MEC server, subject to a task buffer stability constraint. Specifically, at each time slot, the optimal CPU-cycle frequencies of the mobile devices are obtained in closed forms, and the optimal transmit power and bandwidth allocation for computation offloading are determined with the Gauss-Seidel method; while for the MEC server, both the optimal frequencies of the CPU cores and the optimal MEC server scheduling decision are derived in closed forms. Besides, a delay-improved mechanism is proposed to reduce the execution delay. Rigorous performance analysis is conducted for the proposed algorithm and its delay-improved version, indicating that the weighted sum power consumption and execution delay obey an $\left[O\left(1\slash V\right),O\left(V\right)\right]$ tradeoff with $V$ as a control parameter. Simulation results are provided to validate the theoretical analysis and demonstrate the impacts of various parameters. ";Information Theory (cs.IT)
https://arxiv.org/abs/1702.00977;Relay Selection in Cooperative Power Line Communication: A Multi-Armed  Bandit Approach; Babak Nikfar,  A. J. Han Vinck;  Power line communication (PLC) exploits the existence of installed infrastructure of power delivery system, in order to transmit data over power lines. In PLC networks, different nodes of the network are interconnected via power delivery transmission lines, and the data signal is flowing between them. However, the attenuation and the harsh environment of the power line communication channels, makes it difficult to establish a reliable communication between two nodes of the network which are separated by a long distance. Relaying and cooperative communication has been used to overcome this problem. In this paper a two-hop cooperative PLC has been studied, where the data is communicated between a transmitter and a receiver node, through a single array node which has to be selected from a set of available arrays. The relay selection problem can be solved by having channel state information (CSI) at transmitter and selecting the relay which results in the best performance. However, acquiring the channel state information at transmitter increases the complexity of the communication system and introduces undesired overhead to the system. We propose a class of machine learning schemes, namely multi-armed bandit (MAB), to solve the relay selection problem without the knowledge of the channel at the transmitter. Furthermore, we develop a new MAB algorithm which exploits the periodicity of the synchronous impulsive noise of the PLC channel, in order to improve the relay selection algorithm. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.00991;Stability and Instability Conditions for Slotted Aloha with Exponential  Backoff; Luca Barletta,  Flaminio Borgonovo;  This paper provides stability and instability conditions for slotted Aloha under the exponential backoff (EB) model with geometric law $i\mapsto b^{-i-i_0}$, when transmission buffers are in saturation, i.e., always full. In particular, we prove that for any number of users and for $b>1$ the system is: (i) ergodic for $i_0 >1$, (ii) null recurrent for $0<i_0\le 1$, and (iii) transient for $i_0=0$. Furthermore, when referring to a system with queues and Poisson arrivals, the system is shown to be stable whenever EB in saturation is stable with throughput $\lambda_0$ and the system input rate is upper-bounded as $\lambda<\lambda_0$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01042;Polar Codes and Polar Lattices for the Heegard-Berger Problem; Jinwen Shi,  Ling Liu,  Deniz Gündüz,  Cong Ling;  Explicit coding schemes are proposed to achieve the rate-distortion function of the Heegard-Berger problem using polar codes. Specifically, a nested polar code construction is employed to achieve the rate-distortion function for the doubly-symmetric binary sources when the side information may be absent. The nested structure contains two optimal polar codes for lossy source coding and channel coding, respectively. Moreover, a similar nested polar lattice construction is employed when the source and the side information are jointly Gaussian. The proposed polar lattice is constructed by nesting a quantization polar lattice and a capacity-achieving polar lattice for the additive white Gaussian noise channel. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01169;Mitigation of Phase Noise in Massive MIMO Systems: A Rate-Splitting  Approach; Anastasios Papazafeiropoulos,  Bruno Clerckx,  Tharm Ratnarajah;  This work encompasses Rate-Splitting (RS), providing significant benefits in multi-user settings in the context of huge degrees of freedom promised by massive Multiple-Input Multiple-Output (MIMO). However, the requirement of massive MIMO for cost-efficient implementation makes them more prone to hardware imperfections such as phase noise (PN). As a result, we focus on a realistic broadcast channel with a large number of antennas and hampered by the unavoidable PN. Moreover, we employ the RS transmission strategy, and we show its robustness against PN, since the sum-rate does not saturate at high signal-to-noise ratio (SNR). Although, the analytical results are obtained by means of the deterministic equivalent analysis, they coincide with simulation results even for finite system dimensions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01198;Achievable Rate Regions Using Novel Location Assisted Coding (LAC); Thuan Nguyen,  Thinh Nguyen;  The recent increase in number of wireless devices has been driven by the growing markets of smart homes and the Internet of Things (IoT). As a result, expanding and/or efficient utilization of the radio frequency (RF) spectrum is critical to accommodate such an increase in wireless bandwidth. Alternatively, recent free-space optical (FSO) communication technologies have demonstrated the feasibility of building WiFO, a high capacity indoor wireless network using the femtocell architecture. Since FSO transmission does not interfere with the RF signals, such a system can be integrated with the current WiFi systems to provide orders of magnitude improvement in bandwidth. A novel component of WiFO is its ability to jointly encode bits from different flows for optimal transmissions. In this paper, we introduce the WiFO architecture and a novel cooperative transmission framework using location assisted coding (LAC) technique to increase the overall wireless capacity. Specifically, achievable rate regions for WiFO using LAC will be characterized. Both numerical and theoretical analyses are given to validate the proposed coding schemes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01203;Intrinsic entropies of log-concave distributions; Varun Jog,  Venkat Anantharam;  The entropy of a random variable is well-known to equal the exponential growth rate of the volumes of its typical sets. In this paper, we show that for any log-concave random variable $X$, the sequence of the $\lfloor n\theta \rfloor^{\text{th}}$ intrinsic volumes of the typical sets of $X$ in dimensions $n \geq 1$ grows exponentially with a well-defined rate. We denote this rate by $h_X(\theta)$, and call it the $\theta^{\text{th}}$ intrinsic entropy of $X$. We show that $h_X(\theta)$ is a continuous function of $\theta$ over the range $[0,1]$, thereby providing a smooth interpolation between the values 0 and $h(X)$ at the endpoints 0 and 1, respectively. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01218;QoS Analysis of Cognitive Radios Employing HARQ; Sami Akin,  Marwan Hammouda,  Jürgen Peissig;  Recently, the demand for faster and more reliable data transmission has brought up complex communications systems. As a result, it has become more difficult to carry out closed-form solutions that can provide insight about performance levels. In this paper, different from the existing research, we study a cognitive radio system that employs hybrid-automatic-repeat-request (HARQ) protocols under quality-of-service (QoS) constraints. We assume that the secondary users access the spectrum by utilizing a strategy that is a combination of underlay and interweave access techniques. Considering that the secondary users imperfectly perform channel sensing in order to detect the active primary users and that there is a transmission deadline for each data packet at the secondary transmitter buffer, we formulate the state-transition model of the system. Then, we obtain the state-transition probabilities when HARQ-chase combining is adopted. Subsequently, we provide the packet-loss rate in the channel and achieve the effective capacity. Finally, we substantiate our analytical derivations with numerical results. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01223;Spectral Efficiency of Full-Duplex Multiuser System: Beamforming Design,  User Grouping, and Time Allocation; Van-Dinh Nguyen,  Hieu V. Nguyen,  Chuyen T. Nguyen,  Oh-Soon Shin;  Full-duplex (FD) systems have emerged as an es- sential enabling technology to further increase the data rate of wireless communication systems. The key idea of FD is to serve multiple users over the same bandwidth with a base station (BS) that can simultaneously transmit and receive the signals. The most challenging issue in designing an FD system is to address both the harmful effects of residual self-interference caused by the transmit-to-receive antennas at the BS as well as the co- channel interference from an uplink user (ULU) to a downlink user (DLU). An efficient solution to these problems is to assign the ULUs/DLUs in different groups/slots, with each user served in multiple groups. Hence, this paper studies the joint design of transmit beamformers, ULUs/DLUs group assignment, and time allocation for each group. The specific aim is to maximize the sum rate under the ULU/DLU minimum throughput constraints. The utility function of interest is a difficult nonconcave problem, and the involved constraints are also nonconvex, and so this is a computationally troublesome problem. To solve this optimization problem, we propose a new path-following algorithm for compu- tational solutions to arrive at least the local optima. Each iteration involves only a simple convex quadratic program. We prove that the proposed algorithm iteratively improves the objective while guaranteeing convergence. Simulation results confirm the fast convergence of the proposed algorithm with substantial performance improvements over existing approaches. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01241;Generalized piggybacking codes for distributed storage systems; Shuai Yuan,  Qin Huang,  Zulin Wang;  This paper generalizes the piggybacking constructions for distributed storage systems by considering various protected instances and piggybacked instances. Analysis demonstrates that the proportion of protected instances determines the average repair bandwidth for a systematic node. By optimizing the proportion of protected instances, the repair ratio of generalized piggybacking codes approaches zero instead of 50% as the number of parity check nodes tends to infinity. Furthermore, the computational complexity for repairing a single systematic node cost by generalized piggybacking codes is less than that of the existing piggybacking designs. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01285;On a Relationship between the Correct Probability of Estimation from  Correlated Data and Mutual Information; Yasutada Oohama;  Let $X$, $Y$ be two correlated discrete random variables. We consider an estimation of $X$ from encoded data $\varphi(Y)$ of $Y$ by some encoder function $\varphi(Y)$. We derive an inequality describing a relation of the correct probability of estimation and the mutual information between $X$ and $\varphi(Y)$. This inequality may be useful for the secure analysis of crypto system when we use the success probability of estimating secret data as a security criterion. It also provides an intuitive meaning of the secrecy exponent in the strong secrecy criterion. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01298;Throughput and Delay Analysis of Wireless Caching Helper Systems with  Random Availability; Nikolaos Pappas,  Zheng Chen,  Ioannis Dimitriou;  In this paper, we investigate the effect of bursty traffic and random availability of caching helpers in a wireless caching system. More explicitly, we consider a general system consisting of a caching helper with its dedicated user in proximity and another non-dedicated user requesting for content. Both the non-dedicated user and the helper have limited storage capabilities. When the user is not able to locate the requested content in its own cache, then its request shall be served either by the caching helper or by a large data center. Assuming bursty request arrivals at the caching helper from its dedicated destination, its availability to serve other users is affected by the request rate, which will further affect the system throughput and the delay experienced by the non-dedicated user. We characterize the maximum weighted throughput and the average delay per packet of the considered system, taking into account the request arrival rate of the caching helper, the request probability of the user and the availability of the data center. Our results provide fundamental insights in the throughput and delay behavior of such systems, which are essential for further investigation in larger topologies. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1702.01309;The Weight Hierarchy of a Family of Cyclic Codes with Arbitrary Number  of Nonzeroes; Shuxing Li;  The generalized Hamming weights (GHWs) are fundamental parameters of linear codes. GHWs are of great interest in many applications since they convey detailed information of linear codes. In this paper, we continue the work of [10] to study the GHWs of a family of cyclic codes with arbitrary number of nonzeroes. The weight hierarchy is determined by employing a number-theoretic approach. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01311;Physical-layer Network Coding: A Random Coding Error Exponent  Perspective; Shakeel Salamat Ullah,  Gianluigi Liva,  Soung Chang Liew;  In this work, we derive the random coding error exponent for the uplink phase of a two-way relay system where physical layer network coding (PNC) is employed. The error exponent is derived for the practical (yet sub-optimum) XOR channel decoding setting. We show that the random coding error exponent under optimum (i.e., maximum likelihood) PNC channel decoding can be achieved even under the sub-optimal XOR channel decoding. The derived achievability bounds provide us with valuable insight and can be used as a benchmark for the performance of practical channel-coded PNC systems employing low complexity decoders when finite-length codewords are used. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01314;Bounds and Constructions of Codes with All-Symbol Locality and  Availability; Stanislav Kruglik,  Alexey Frolov;  We investigate the distance properties of linear locally recoverable codes (LRC codes) with all-symbol locality and availability. New upper and lower bounds on the minimum distance of such codes are derived. The upper bound is based on the shortening method and improves existing shortening bounds. To reduce the gap in between upper and lower bounds we do not restrict the alphabet size and propose explicit constructions of codes with locality and availability via rank-metric codes. The first construction relies on expander graphs and is better in low rate region, the second construction utilizes LRC codes developed by Wang et al. as inner codes and better in high rate region. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01317;On the Gaussianity of Kolmogorov Complexity of Mixing Sequences; Morgane Austern,  Arian Maleki;  Let $ K(X_1, \ldots, X_n)$ and $H(X_n | X_{n-1}, \ldots, X_1)$ denote the Kolmogorov complexity and Shannon's entropy rate of a stationary and ergodic process $\{X_i\}_{i=-\infty}^\infty$. It has been proved that \[ \frac{K(X_1, \ldots, X_n)}{n} - H(X_n | X_{n-1}, \ldots, X_1) \rightarrow 0, \] almost surely. This paper studies the convergence rate of this asymptotic result. In particular, we show that if the process satisfies certain mixing conditions, then there exists $\sigma<\infty$ such that $$\sqrt{n}\left(\frac{K(X_{1:n})}{n}- H(X_0|X_1,\dots,X_{-\infty})\right) \rightarrow_d N(0,\sigma^2).$$ Furthermore, we show that under slightly stronger mixing conditions one may obtain non-asymptotic concentration bounds for the Kolmogorov complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01353;On the Correlation between Boolean Functions of Sequences of Random  Variables; Farhad Shirani,  S. Sandeep Pradhan;  In this paper, we establish a new inequality tying together the effective length and the maximum correlation between the outputs of an arbitrary pair of Boolean functions which operate on two sequences of correlated random variables. We derive a new upper-bound on the correlation between the outputs of these functions. The upper-bound is useful in various disciplines which deal with common-information. We build upon Witsenhausen's bound on maximum-correlation. The previous upper-bound did not take the effective length of the Boolean functions into account. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01376;On the Sub-optimality of Single-letter Coding in Multi-terminal  Communications; Farhad Shirani,  S. Sandeep Pradhan;  We investigate binary block-codes (BBC). A BBC is defined as a vector of Boolean functions. We consider BBCs which are generated randomly, and using single-letter distributions. We characterize the vector of dependency spectrums of these BBCs. We use this vector to upper-bound the correlation between the outputs of two distributed BBCs. Finally, the upper-bound is used to show that the large blocklength single-letter coding schemes in the literature are sub-optimal in some multiterminal communication settings. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01386;Joint DOA and Frequency Estimation with Sub-Nyquist Sampling for More  Sources than Sensors; Liang Liu,  Ping Wei;  In this letter, we apply previous array receiver architecture which employs time-domain sub-Nyquist sampling techniques to jointly estimate frequency and direction-of-arrival(DOA) of narrowband far-field signals. Herein, a more general situation is taken into consideration, where there may be more than one signal in a subband. We build time-space union model, analyze the identification of the model, and give the maximum signal number which can be classified. We also proof that the Cramer-Rao Bound (CRB) is lower than that of which employs Nyquist sampling. Simulation results verify the capacity to estimate the number of sources. Meanwhile, simulations show that our estimation performance closely matches the CRB and is superior for more sources than sensors, especially when the minimum redundancy array (MRA) is employed. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01389;Comparison Study between NOMA and SCMA; Mohammad. Moltafet,  Nader. Mokari,  Mohammad R. Javan,  Paiez. Azmi;  In this paper, the performance and system complexity of the candidate multiple access (MA) techniques for the next generation of cellular systems, namely, non-orthogonal multiple access (NOMA) (in this paper, we consider power domain MA as NOMA) and sparse code multiple access (SCMA), are investigated. To this end, for each MA technique, a resource allocation problem considering heterogeneous cellular networks (HetNet) is formulated. We apply successive convex approximation (SCA) method to each problem and obtain their solutions. The simulation results show that SCMA-based system achieves better performance than NOMA-based one at the cost of more complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01422;Compute-and-Forward over Block-Fading Channels Using Algebraic Lattices; Shanxiang Lyu,  Antonio Campello,  Cong Ling,  Jean-Claude Belfiore;  Previous approaches to compute-and-forward (C\&F) are mostly based on quantizing channel coefficients to integers. In this work, we investigate the C\&F strategy over block fading channels using Construction A over rings, so as to allow better quantization for the channels. Advantages in decoding error probabilities and computation rates are demonstrated, and the construction is shown to outperform the C\&F strategy over the integers $\mathbb{Z}$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01425;Design and Analysis of Sparsifying Dictionaries for FIR MIMO Equalizers; Abubakr O. Al-Abbasi,  Ridha Hamila,  Waheed U. Bajwa,  Naofal Al-Dhahir;  In this paper, we propose a general framework that transforms the problems of designing sparse finite-impulseresponse linear equalizers and non-linear decision-feedback equalizers, for multiple antenna systems, into the problem of sparsestapproximation of a vector in different dictionaries. In addition, we investigate several choices of the sparsifying dictionaries under this framework. Furthermore, the worst-case coherences of these dictionaries, which determine their sparsifying effectiveness, are analytically and/or numerically evaluated. Moreover, we show how to reduce the computational complexity of the designed sparse equalizer filters by exploiting the asymptotic equivalence of Toeplitz and circulant matrices. Finally, the superiority of our proposed framework over conventional methods is demonstrated through numerical experiments. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01591;The Partial Entropy Decomposition: Decomposing multivariate entropy and  mutual information via pointwise common surprisal; Robin A. A. Ince;"  Obtaining meaningful quantitative descriptions of the statistical dependence within multivariate systems is a difficult open problem. Recently, the Partial Information Decomposition (PID) was proposed to decompose mutual information (MI) about a target variable into components which are redundant, unique and synergistic within different subsets of predictor variables. Here, we propose to apply the elegant formalism of the PID to multivariate entropy, resulting in a Partial Entropy Decomposition (PED). We implement the PED with an entropy redundancy measure based on pointwise common surprisal; a natural definition which is closely related to the definition of MI. We show how this approach can reveal the dyadic vs triadic generative structure of multivariate systems that are indistinguishable with classical Shannon measures. The entropy perspective also shows that misinformation is synergistic entropy and hence that MI itself includes both redundant and synergistic effects. We show the relationships between the PED and MI in two predictors, and derive two alternative information decompositions which we illustrate on several example systems. This reveals that in entropy terms, univariate predictor MI is not a proper subset of the joint MI, and we suggest this previously unrecognised fact explains in part why obtaining a consistent PID has proven difficult. The PED also allows separate quantification of mechanistic redundancy (related to the function of the system) versus source redundancy (arising from dependencies between inputs); an important distinction which no existing methods can address. The new perspective provided by the PED helps to clarify some of the difficulties encountered with the PID approach and the resulting decompositions provide useful tools for practical data analysis across a wide range of application areas. ";"Information Theory (cs.IT); Statistics Theory (math.ST); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM); Methodology (stat.ME)"
https://arxiv.org/abs/1702.01605;Position and Orientation Estimation through Millimeter Wave MIMO in 5G  Systems; Arash Shahmansoori,  Gabriel E. Garcia,  Giuseppe Destino,  Gonzalo Seco-Granados,  Henk Wymeersch;  Millimeter wave signals and large antenna arrays are considered enabling technologies for future 5G networks. While their benefits for achieving high-data rate communications are well-known, their potential advantages for accurate positioning are largely undiscovered. We derive the Cram\'{e}r-Rao bound (CRB) on position and rotation angle estimation uncertainty from millimeter wave signals from a single transmitter, in the presence of scatterers. We also present a novel two-stage algorithm for position and rotation angle estimation that attains the CRB for average to high signal-to-noise ratio. The algorithm is based on multiple measurement vectors matching pursuit for coarse estimation, followed by a refinement stage based on the space-alternating generalized expectation maximization algorithm. We find that accurate position and rotation angle estimation is possible using signals from a single transmitter, in either line-of- sight, non-line-of-sight, or obstructed-line-of-sight conditions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01648;Self-Sustainability of Energy Harvesting Systems: Concept, Analysis, and  Design; Sudarshan Guruacharya,  Ekram Hossain;  Ambient energy harvesting is touted as a low cost solution to prolong the life of low-powered devices, reduce the carbon footprint, and make the system self-sustainable. Most research to date have focused either on the physical aspects of energy conversion process or on optimal consumption policy of the harvested energy at the system level. However, although intuitively understood, to the best of our knowledge, the idea of self-sustainability is yet to be made precise and studied as a performance metric. In this paper, we provide a mathematical definition of the concept of self-sustainability of an energy harvesting system, based on the complementary idea of eventual outage. In particular, we analyze the harvest-store-consume system with infinite battery capacity, stochastic energy arrivals, and fixed energy consumption rate. Using the random walk theory, we identify the necessary condition for the system to be self-sustainable. General formulas are given for the self-sustainability probability in the form of integral equations. Since these integral equations are difficult to solve analytically, an exponential upper bound for eventual outage probability is given using martingales. This bound guarantees that the eventual outage probability can be made arbitrarily small simply by increasing the initial battery energy. We also give an asymptotic formula for eventual outage. For the special case when the energy arrival follows a Poisson process, we are able to find the exact formulas for the eventual outage probability. We also show that the harvest-store-consume system is mathematically equivalent to a $GI/G/1$ queueing system, which allows us to easily find the outage probability, in case the necessary condition for self-sustainability is violated. Monte-Carlo simulations verify our analysis. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01666;On the Complexity of Estimating Renyi Divergences; Maciej Skorski;  This paper studies the complexity of estimating Renyi divergences of discrete distributions: $p$ observed from samples and the baseline distribution $q$ known \emph{a priori}. Extending the results of Acharya et al. (SODA'15) on estimating Renyi entropy, we present improved estimation techniques together with upper and lower bounds on the sample complexity. We show that, contrarily to estimating Renyi entropy where a sublinear (in the alphabet size) number of samples suffices, the sample complexity is heavily dependent on \emph{events occurring unlikely} in $q$, and is unbounded in general (no matter what an estimation technique is used). For any divergence of order bigger than $1$, we provide upper and lower bounds on the number of samples dependent on probabilities of $p$ and $q$. We conclude that the worst-case sample complexity is polynomial in the alphabet size if and only if the probabilities of $q$ are non-negligible. This gives theoretical insights into heuristics used in applied papers to handle numerical instability, which occurs for small probabilities of $q$. Our result explains that small probabilities should be handled with care not only because of numerical issues, but also because of a blow up in sample complexity. ;"Information Theory (cs.IT); Computational Complexity (cs.CC)"
https://arxiv.org/abs/1702.01670;Single Anchor Localization and Orientation Performance Limits using  Massive Arrays: MIMO vs. Beamforming; Anna Guerra,  Francesco Guidi,  Davide Dardari;  Next generation cellular networks will experience the combination of femtocells, millimeter-wave (mm-wave) communications and massive antenna arrays. Thanks to the beamforming capability as well as the high angular resolution provided by massive arrays, only one single access point (AP) acting as an anchor node could be used for localization estimation, thus avoiding over-sized infrastructures dedicated to positioning. In this context, our paper aims at investigating the localization and orientation performance limits employing massive arrays both at the AP and mobile side. Thus, we first asymptotically demonstrate the tightness of the Cramer-Rao bound (CRB) in massive array regime, and in the presence or not of multipath. Successively, we propose a comparison between MIMO and beamforming in terms of array structure, time synchronization error and multipath components. Among different array configurations, we consider also random weighting as a trade-off between the high diversity gain of MIMO and the high directivity guaranteed by phased arrays. By evaluating the CRB for the different array configurations, results show the interplay between diversity and beamforming gain as well as the benefits achievable by varying the number of array elements in terms of localization accuracy. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01672;On Coded Caching in the Overloaded MISO Broadcast Channel; Enrico Piovano,  Hamdi Joudeh,  Bruno Clerckx;  This work investigates the interplay of coded caching and spatial multiplexing in an overloaded Multiple-Input-Single-Output (MISO) Broadcast Channel (BC), i.e. a system where the number of users is greater than the number of transmitting antennas. On one hand, coded caching uses the aggregate global cache memory of the users to create multicasting opportunities. On the other hand, multiple antennas at the transmitter leverage the available CSIT to transmit multiple streams simultaneously. In this paper, we introduce a novel scheme which combines both the gain derived from coded-caching and spatial multiplexing and outperforms existing schemes in terms of delivery time and CSIT requirement. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01674;Arbitrary Beam Synthesis of Different Hybrid Beamforming Systems; Kilian Roth,  Josef A. Nossek;  For future mmWave mobile communication systems the use of analog/hybrid beamforming is envisioned be a key as- pect. The synthesis of beams is a key technology of enable the best possible operation during beamsearch, data transmission and MU MIMO operation. The developed method for synthesizing beams is based on previous work in radar technology considering only phase array antennas. With this technique it is possible to generate a desired beam of any shape with the constraints of the desired target transceiver antenna frontend. It is not constraint to a certain antenna array geometry, but can handle 1d, 2d and even 3d antenna array geometries like cylindric arrays. The numerical examples show that the method can synthesize beams by considering a user defined tradeoff between gain, transition width and passband ripples. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01679;Downlink and Uplink Decoupling in Two-Tier Heterogeneous Networks with  Multi-Antenna Base Stations; Mudasar Bacha,  Yueping Wu,  Bruno Clerckx;  In order to improve the uplink performance of future cellular networks, the idea to decouple the downlink (DL) and uplink (UL) association has recently been shown to provide significant gain in terms of both coverage and rate performance. However, all the work is limited to SISO network. Therefore, to study the gain provided by the DL and UL decoupling in multi-antenna base stations (BSs) setup, we study a two tier heterogeneous network consisting of multi-antenna BSs, and single antenna user equipments (UEs). We use maximal ratio combining (MRC) as a linear receiver at the BSs and using tools from stochastic geometry, we derive tractable expressions for both signal to interference ratio (SIR) coverage probability and rate coverage probability. We observe that as the disparity in the beamforming gain of both tiers increases, the gain in term of SIR coverage probability provided by the decoupled association over non-decoupled association decreases. We further observe that when there is asymmetry in the number of antennas of both tier, then we need further biasing towards femto-tier on the top of decoupled association to balance the load and get optimal rate coverage probability. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01734;An Algebraic-Combinatorial Proof Technique for the GM-MDS Conjecture; Anoosheh Heidarzadeh,  Alex Sprintson;  This paper considers the problem of designing maximum distance separable (MDS) codes over small fields with constraints on the support of their generator matrices. For any given $m\times n$ binary matrix $M$, the GM-MDS conjecture, due to Dau et al., states that if $M$ satisfies the so-called MDS condition, then for any field $\mathbb{F}$ of size $q\geq n+m-1$, there exists an $[n,m]_q$ MDS code whose generator matrix $G$, with entries in $\mathbb{F}$, fits $M$ (i.e., $M$ is the support matrix of $G$). Despite all the attempts by the coding theory community, this conjecture remains still open in general. It was shown, independently by Yan et al. and Dau et al., that the GM-MDS conjecture holds if the following conjecture, referred to as the TM-MDS conjecture, holds: if $M$ satisfies the MDS condition, then the determinant of a transformation matrix $T$, such that $TV$ fits $M$, is not identically zero, where $V$ is a Vandermonde matrix with distinct parameters. In this work, we generalize the TM-MDS conjecture, and present an algebraic-combinatorial approach based on polynomial-degree reduction for proving this conjecture. Our proof technique's strength is based primarily on reducing inherent combinatorics in the proof. We demonstrate the strength of our technique by proving the TM-MDS conjecture for the cases where the number of rows ($m$) of $M$ is upper bounded by $5$. For this class of special cases of $M$ where the only additional constraint is on $m$, only cases with $m\leq 4$ were previously proven theoretically, and the previously used proof techniques are not applicable to cases with $m > 4$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01739;Multi-Message Private Information Retrieval: Capacity Results and  Near-Optimal Schemes; Karim Banawan,  Sennur Ulukus;  We consider the problem of multi-message private information retrieval (MPIR) from $N$ non-communicating replicated databases. In MPIR, the user is interested in retrieving $P$ messages out of $M$ stored messages without leaking the identity of the retrieved messages. The information-theoretic sum capacity of MPIR $C_s^P$ is the maximum number of desired message symbols that can be retrieved privately per downloaded symbol. For the case $P \geq \frac{M}{2}$, we determine the exact sum capacity of MPIR as $C_s^P=\frac{1}{1+\frac{M-P}{PN}}$. The achievable scheme in this case is based on downloading MDS-coded mixtures of all messages. For $P \leq \frac{M}{2}$, we develop lower and upper bounds for all $M,P,N$. These bounds match if the total number of messages $M$ is an integer multiple of the number of desired messages $P$, i.e., $\frac{M}{P} \in \mathbb{N}$. In this case, $C_s^P=\frac{1-\frac{1}{N}}{1-(\frac{1}{N})^{M/P}}$. The achievable scheme in this case generalizes the single-message capacity achieving scheme to have unbalanced number of stages per round of download. For all the remaining cases, the difference between the lower and upper bound is at most $0.0082$, which occurs for $M=5$, $P=2$, $N=2$. Our results indicate that joint retrieval of desired messages is more efficient than successive use of single-message retrieval schemes. ;"Information Theory (cs.IT); Cryptography and Security (cs.CR); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1702.01773;Successive Local and Successive Global Omniscience; Anoosheh Heidarzadeh,  Alex Sprintson;  This paper considers two generalizations of the cooperative data exchange problem, referred to as the successive local omniscience (SLO) and the successive global omniscience (SGO). The users are divided into $\ell$ nested sub-groups. Each user initially knows a subset of packets in a ground set $X$ of size $k$, and all users wish to learn all packets in $X$. The users exchange their packets by broadcasting coded or uncoded packets. In SLO or SGO, in the $l$th ($1\leq l\leq \ell$) round of transmissions, the $l$th smallest sub-group of users need to learn all packets they collectively hold or all packets in $X$, respectively. The problem is to find the minimum sum-rate (i.e., the total transmission rate by all users) for each round, subject to minimizing the sum-rate for the previous round. To solve this problem, we use a linear-programming approach. For the cases in which the packets are randomly distributed among users, we construct a system of linear equations whose solution characterizes the minimum sum-rate for each round with high probability as $k$ tends to infinity. Moreover, for the special case of two nested groups, we derive closed-form expressions, which hold with high probability as $k$ tends to infinity, for the minimum sum-rate for each round. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01779;Sequential Coding of Gauss-Markov Sources; Anatoly Khina,  Ashish Khisti,  Victoria Kostina,  Babak Hassibi;"  We consider the problem of sequential transmission of Gauss-Markov sources. We show that in the limit of large spatial block lengths, greedy compression with respect to the squared error distortion is optimal; that is, there is no tension between optimizing the distortion of the source in the current time instant and that of future times. We then extend this result to the case where at time $t$ a random compression rate $R_t$ is allocated independently of the rate at other time instants. This, in turn, allows us to derive the optimal performance of sequential coding over packet-erasure channels with instantaneous feedback. For the case of packet erasures with delayed feedback, we connect the problem to that of compression with side information that is known at the encoder and may be known at the decoder - where the most recent packets serve as side information that may have been erased. We conclude the paper by demonstrating that the loss due to a delay by one time unit is rather small. ";Information Theory (cs.IT)
https://arxiv.org/abs/1702.01793;Multiuser Communication Based on the DFT Eigenstructure; R. M. Campello de Souza,  H. M. de Oliveira,  R. J. Cintra;  The eigenstructure of the discrete Fourier transform (DFT) is examined and new systematic procedures to generate eigenvectors of the unitary DFT are proposed. DFT eigenvectors are suggested as user signatures for data communication over the real adder channel (RAC). The proposed multiuser communication system over the 2-user RAC is detailed. ;"Information Theory (cs.IT); Applications (stat.AP)"
https://arxiv.org/abs/1702.01828;Capacity Bounds on the Downlink of Symmetric, Multi-Relay, Single  Receiver C-RAN Networks; Shirin Saeedi Bidokhti,  Gerhard Kramer,  Shlomo Shamai (Shitz);  The downlink of symmetric Cloud Radio Access Networks (C-RANs) with multiple relays and a single receiver is studied. Lower and upper bounds are derived on the capacity. The lower bound is achieved by Marton's coding which facilitates dependence among the multiple-access channel inputs. The upper bound uses Ozarow's technique to augment the system with an auxiliary random variable. The bounds are studied over scalar Gaussian C-RANs and are shown to meet and characterize the capacity for interesting regimes of operation. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01839;Temporal-Spatial Aggregation for Cache-Enabled Wireless Multicasting  Networks with Asynchronous Content Requests; Jifang Xing,  Ying Cui,  Vincent Lau;  Existing multicasting schemes for massive content delivery do not fully utilize multicasting opportunities in delay tolerant content-oriented applications. In this paper, we propose a novel temporal-spatial aggregation-based multicasting scheme in a large-scale cache-enabled wireless network. The proposed scheme can efficiently exploit multicasting opportunities in asynchronous content requests to improve spectral efficiency. By making use of the delay tolerance of elastic services, the proposed scheme achieves a better energy-throughput-delay tradeoff. Utilizing tools from stochastic geometry, we derive a tractable expression for the successful transmission probability in the general region. Using asymptotic approximations, we derive closed form successful transmission probabilities in the large delay region as well as the large and small user density regions. The asymptotic results reveal that the successful transmission probability increases and the energy consumption decreases at the cost of delay increase in these asymptotic regions. The analysis in this paper provides a new understanding of the energy-throughput-delay tradeoff for massive content delivery in large-scale cache-enabled wireless networks. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01840;Joint Pushing and Caching for Bandwidth Utilization Maximization in  Wireless Networks; Yaping Sun,  Ying Cui,  Hui Liu;  Joint pushing and caching is recognized as an efficient remedy to the problem of spectrum scarcity incurred by tremendous mobile data traffic. In this paper, by exploiting storage resources at end users and predictability of user demand processes, we design the optimal joint pushing and caching policy to maximize bandwidth utilization, which is of fundamental importance to mobile telecom carriers. In particular, we formulate the stochastic optimization problem as an infinite horizon average cost Markov Decision Process (MDP), for which there generally exist only numerical solutions without many insights. By structural analysis, we show how the optimal policy achieves a balance between the current transmission cost and the future average transmission cost. In addition, we show that the optimal average transmission cost decreases with the cache size, revealing a tradeoff between the cache size and the bandwidth utilization. Then, due to the fact that obtaining a numerical optimal solution suffers the curse of dimensionality and implementing it requires a centralized controller and global system information, we develop a decentralized policy with polynomial complexity w.r.t. the numbers of users and files as well as cache size, by a linear approximation of the value function and optimization relaxation techniques. Next, we propose an online decentralized algorithm to implement the proposed low-complexity decentralized policy using the technique of Q-learning, when priori knowledge of user demand processes is not available. Finally, using numerical results, we demonstrate the advantage of the proposed solutions over some existing designs. The results in this paper offer useful guidelines for designing practical cache-enabled content-centric wireless networks. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.01864;The Meta Distribution of the SIR for Cellular Networks with Power  Control; Yuanjie Wang,  Martin Haenggi,  Zhenhui Tan;  The meta distribution of the signal-to-interference ratio (SIR) provides fine-grained information about the performance of individual links in a wireless network. This paper focuses on the analysis of the meta distribution of the SIR for both the cellular network uplink and downlink with fractional power control. For the uplink scenario, an approximation of the interfering user point process with a non-homogeneous Poisson point process is used. The moments of the meta distribution for both scenarios are calculated. Some bounds, the analytical expression, the mean local delay, and the beta approximation of the meta distribution are provided. The results give interesting insights into the effect of the power control in both the uplink and downlink. Detailed simulations show that the approximations made in the analysis are well justified. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1702.01961;A Region Based Easy Path Wavelet Transform For Sparse Image  Representation; Renato Budinich;"  The Easy Path Wavelet Transform is an adaptive transform for bivariate functions (in particular natural images) which has been proposed in [1]. It provides a sparse representation by finding a path in the domain of the function leveraging the local correlations of the function values. It then applies a one dimensional wavelet transform to the obtained vector, decimates the points and iterates the procedure. The main drawback of such method is the need to store, for each level of the transform, the path which vectorizes the two dimensional data. Here we propose a variation on the method which consists of firstly applying a segmentation procedure to the function domain, partitioning it into regions where the variation in the function values is low; in a second step, inside each such region, a path is found in some deterministic way, i.e. not data-dependent. This circumvents the need to store the paths at each level, while still obtaining good quality lossy compression. This method is particularly well suited to encode a Region of Interest in the image with different quality than the rest of the image. [1] Gerlind Plonka. The easy path wavelet transform: A new adaptive wavelet transform for sparse representation of two-dimensional data. Multiscale Modeling & Simulation, 7(3):1474$-$1496, 2008. ";"Information Theory (cs.IT); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)"
https://arxiv.org/abs/1702.01974;An Efficient Global Algorithm for Single-Group Multicast Beamforming; Cheng Lu,  Ya-Feng Liu;  Consider the single-group multicast beamforming problem, where multiple users receive the same data stream simultaneously from a single transmitter. The problem is NP-hard and all existing algorithms for the problem either find suboptimal approximate or local stationary solutions. In this paper, we propose an efficient branch-and-bound algorithm for the problem that is guaranteed to find its global solution. To the best of our knowledge, our proposed algorithm is the first tailored global algorithm for the single-group multicast beamforming problem. Simulation results show that our proposed algorithm is computationally efficient (albeit its theoretical worst-case iteration complexity is exponential with respect to the number of receivers) and it significantly outperforms a state-of-the-art general-purpose global optimization solver called Baron. Our proposed algorithm provides an important benchmark for performance evaluation of existing algorithms for the same problem. By using it as the benchmark, we show that two state-of-the-art algorithms, semidefinite relaxation algorithm and successive linear approximation algorithm, work well when the problem dimension (i.e., the number of antennas at the transmitter and the number of receivers) is small but their performance deteriorates quickly as the problem dimension increases. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02034;Robust Regularized ZF in Cooperative Broadcast Channel under Distributed  CSIT; Qianrui Li,  Paul de Kerret,  David Gesbert,  Nicolas Gresset;  In this work, we consider the sum rate performance of joint processing coordinated multi-point transmission network (JP-CoMP, a.k.a Network MIMO) in a so-called distributed channel state information (D-CSI) setting. In the D-CSI setting, the various transmitters (TXs) acquire a local, TX-dependent, estimate of the global multi-user channel state matrix obtained via terminal feedback and limited backhauling. The CSI noise across TXs can be independent or correlated, so as to reflect the degree to which TXs can exchange information over the backhaul, hence allowing to model a range of situations bridging fully distributed and fully centralized CSI settings. In this context we aim to study the price of CSI distributiveness in terms of sum rate at finite SNR when compared with conventional centralized scenarios. We consider the family of JP-CoMP precoders known as regularized zero-forcing (RZF). We conduct our study in the large scale antenna regime, as it is currently envisioned to be used in real 5G deployments. It is then possible to obtain accurate approximations on so-called deterministic equivalents of the signal to interference and noise ratios. Guided by the obtained deterministic equivalents, we propose an approach to derive a RZF scheme that is robust to the distributed aspect of the CSI, whereby the key idea lies in the optimization of a TX-dependent power level and regularization factor. Our analysis confirms the improved robustness of the proposed scheme with respect to CSI inconsistency at different TXs, even with moderate number of antennas and receivers (RXs). ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02121;Massive MIMO Beam-forming for High Speed Train Communication:  Directivity vs Beamwidth; Xuhong Chen,  Jiaxun Lu,  Pingyi Fan;  High-mobility adaption and massive Multiple-input Multiple-output (MIMO) application are two primary evolving objectives for the next generation high speed train communication system. In this paper, we consider how to design a location-aware beam-forming for the massive MIMO system.We first analyze the tradeoff between beam directivity and beamwidth, based on which we present the sensitivity analysis of positioning accuracy. Then, we derive the maximum beam directivity and corresponding beamwidth under the restriction of diverse positioning accuracies to guarantee a high efficient transmission. Finally, we present a low-complexity beam-forming design with positioning robustness utilizing location information, which requires neither eigen-decomposing (ED) the uplink channel covariance matrix (CCM) nor ED the downlink CCM (DCCM). Numerical simulation indicates that a massive MIMO system with less than a certain positioning error can guarantee a required performance with satisfying transmission efficiency in the high-mobility scenario. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02174;Resource Allocation and Relay Selection In Full-Duplex Cooperative  Orthogonal Frequency Division Multiple Access Networks; Jafar Banar,  S. Mohammad Razavizadeh;  This paper is on relay selection in uplink of an in-band full-duplex (IBFD) cooperative cellular network. Assuming an orthogonal frequency division multiple access (OFDMA) cellular network, we develop a relay selection and resource allocation algorithm for this network. The relay selection algorithms select the best relay based on distance between users and signal to interference plus noise ratio (SINR) that operate in amplify and forward (AF) mode. The optimization problem allocates the optimum subcarriers and powers to all users to maximize the average sum-rate of the network. In addition, the constraints of the optimization problem are quality of service (QoS) and transmit power of each user. Simulation results illustrate the good performance of the proposed method. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02179;Opportunistic Content Delivery in Fading Broadcast Channels; Asma Ghorbel,  Khac-Hoang Ngo,  Richard Combes,  Mari Kobayashi,  Sheng Yang;  We consider content delivery over fading broadcast channels. A server wants to transmit K files to K users, each equipped with a cache of finite size. Using the coded caching scheme of Maddah-Ali and Niesen, we design an opportunistic delivery scheme where the long-term sum content delivery rate scales with K the number of users in the system. The proposed delivery scheme combines superposition coding together with appropriate power allocation across sub-files intended to different subsets of users. We analyze the long-term average sum content delivery rate achieved by two special cases of our scheme: a) a selection scheme that chooses the subset of users with the largest weighted rate, and b) a baseline scheme that transmits to K users using the scheme of Maddah-Ali and Niesen. We prove that coded caching with appropriate user selection is scalable since it yields a linear increase of the average sum content delivery rate. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02279;Decoding from Pooled Data: Phase Transitions of Message Passing; Ahmed El Alaoui,  Aaditya Ramdas,  Florent Krzakala,  Lenka Zdeborova,  Michael I. Jordan;  We consider the problem of decoding a discrete signal of categorical variables from the observation of several histograms of pooled subsets of it. We present an Approximate Message Passing (AMP) algorithm for recovering the signal in the random dense setting where each observed histogram involves a random subset of entries of size proportional to n. We characterize the performance of the algorithm in the asymptotic regime where the number of observations $m$ tends to infinity proportionally to n, by deriving the corresponding State Evolution (SE) equations and studying their dynamics. We initiate the analysis of the multi-dimensional SE dynamics by proving their convergence to a fixed point, along with some further properties of the iterates. The analysis reveals sharp phase transition phenomena where the behavior of AMP changes from exact recovery to weak correlation with the signal as m/n crosses a threshold. We derive formulae for the threshold in some special cases and show that they accurately match experimental behavior. ;"Information Theory (cs.IT); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1702.02330;A New Achievable Rate Region for Multiple-Access Channel with States; Mohsen Heidari,  Farhad Shirani,  S. Sandeep Pradhan;  The problem of reliable communication over the multiple-access channel (MAC) with states is investigated. We propose a new coding scheme for this problem which uses quasi-group codes (QGC). We derive a new computable single-letter characterization of the achievable rate region. As an example, we investigate the problem of doubly-dirty MAC with modulo-$4$ addition. It is shown that the sum-rate $R_1+R_2=1$ bits per channel use is achievable using the new scheme. Whereas, the natural extension of the Gel'fand-Pinsker scheme, sum-rates greater than $0.32$ are not achievable. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02362;The Necessity of Scheduling in Compute-and-Forward; Ori Shmuel,  Asaf Cohen,  Omer Gurewitz;  Compute and Forward (CF) is a promising relaying scheme which, instead of decoding single messages or forwarding/amplifying information at the relay, decodes linear combinations of the simultaneously transmitted messages. The current literature includes several coding schemes and results on the degrees of freedom in CF, yet for systems with a fixed number of transmitters and receivers. It is unclear, however, how CF behaves at the limit of a large number of transmitters. In this paper, we investigate the performance of CF in that regime. Specifically, we show that as the number of transmitters grows, CF becomes degenerated, in the sense that a relay prefers to decode only one (strongest) user instead of any other linear combination of the transmitted codewords, treating the other users as noise. Moreover, the sum-rate tends to zero as well. This makes scheduling necessary in order to maintain the superior abilities CF provides. Indeed, under scheduling, we show that non-trivial linear combinations are chosen, and the sum-rate does not decay, even without state information at the transmitters and without interference alignment. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02366;On the Spectral Efficiency of Blind Channel Estimation and  Synchronization Techniques; A. Saci,  A. Al-Dweik,  A. Shami;  In the literature, channel estimation and synchronization (CE/SY) algorithms are classified as blind, and hence spectrally efficient, if they do not require pilot symbols. However, we show in this letter that such classification is not accurate and can be misleading. Consequently, this letter presents a more reliable and accurate approach to evaluate the spectral efficiency of communications systems with various CE/SY algorithms. The proposed approach allows fair spectral efficiency comparison between various systems with blind or non-blind CE/SY algorithms. In particular, we evaluate the spectral efficiency of communications systems that incorporates blind CE/SY algorithms and compare it to other blind and pilot-based algorithms. The obtained results reveal that, on the contrary to what is widely accepted, blind CE/SY algorithms with modulation-type constrain do not necessarily improve the spectral efficiency as compared to pilot-based techniques. Consequently, such techniques are classified as conditionally blind, to distinguish them from fully blind techniques. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02372;On Multilevel Coding Schemes Based on Non-Binary LDPC Codes; Valeriya Potapova,  Alexey Frolov;  We address the problem of constructing of coding schemes for the channels with high-order modulations. It is known, that non-binary LDPC codes are especially good for such channels and significantly outperform their binary counterparts. Unfortunately, their decoding complexity is still large. In order to reduce the decoding complexity we consider multilevel coding schemes based on non-binary LDPC codes (NB-LDPC-MLC schemes) over smaller fields. The use of such schemes gives us a reasonable gain in complexity. At the same time the performance of NB-LDPC-MLC schemes is practically the same as the performance of LDPC codes over the field matching the modulation order. In particular by means of simulations we showed that the performance of NB-LDPC-MLC schemes over GF(16) is the same as the performance of non-binary LDPC codes over GF(64) and GF(256) in AWGN channel with QAM64 and QAM256 accordingly. We also perform a comparison with binary LDPC codes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02396;Smooth min-max relative entropy based bounds for one-shot classical and  quantum state redistribution; Anurag Anshu,  Rahul Jain,  Naqueeb Ahmad Warsi;  We study the problem of state redistribution both in the classical (shared randomness assisted) and quantum (entanglement assisted) one-shot settings and provide new upper bounds on the communication required. Our classical bounds are in terms of smooth-min and max relative entropies and the quantum bounds are in terms of max relative entropy and Renyi relative entropy of order $\frac{1}{2}$. We also consider a special case of this problem in the classical setting, previously studied by Braverman and Rao (2011). We show that their upper bound is optimal. In addition we provide an alternate protocol achieving a priory different looking upper bound. However, we show that our upper bound is essentially the same as their upper bound and hence also optimal. For the quantum case, we show that our achievability result is upper bounded by the achievability result obtained in Berta, Christandl, Touchette (2016). ;"Information Theory (cs.IT); Quantum Physics (quant-ph)"
https://arxiv.org/abs/1702.02414;Constructing Receiver Signal Points using Constrained Massive MIMO  Arrays; Markus Staudacher,  Gerhard Kramer,  Wolfgang Zirwas,  Berthold Panzner,  Rakash Sivasiva Ganesan;  A low cost solution for constructing receiver signal points is investigated that combines a large number of constrained radio frequency (RF) frontends with a limited number of full RF chains. The constrained RF front ends have low cost and are limited to on/off switching of antenna elements and a small number of phases. Severe degradations are typically observed for multi-user MIMO for these simple on/off antenna arrays. A few full RF frontends are shown to compensate for the signal errors of the high number of constrained RF frontends for various scenarios. An algorithm for such a hybrid RF (HRF) system is developed that achieves performance close to that of exhaustive search with respect to the mean square error of the constructed receiver signals for Rayleigh fading and the WINNER 2 Urban Macro channel model. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02497;Two-Dimensional AoD and AoA Acquisition for Wideband mmWave Systems with  Cross-Polarized MIMO; Dalin Zhu,  Junil Choi,  Robert W. Heath Jr;  In this paper, a novel two-dimensional super-resolution angle-of-departure (AoD) and angle-of-arrival (AoA) estimation technique is proposed for wideband millimeter-wave multiple-input multiple-output systems with cross-polarized antenna elements. The key ingredient of the proposed method is to form custom designed beam pairs, and devise an invertible function of the AoD/AoA to be estimated from the corresponding beam pairs. Further, a new multi-layer reference signal structure is developed for the proposed method to facilitate angle estimation for wideband channels with cross-polarized antenna elements. To facilitate feedback in closed-loop frequency division duplexing systems, a novel differential feedback strategy is proposed aiming at feedback reduction for the two-dimensional angle estimation. Numerical results demonstrate that by using the proposed method, good azimuth/elevation AoD and AoA estimation performance can be achieved under different levels of signal-to-noise ratio, channel conditions, and antenna array configurations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02562;Pilot Reuse Factor with Large Scale Fading Precoding for Massive MIMO; Tedros Salih,  Elijah Mwangi,  Kibet Langat;  The fundamental limitation of massive MIMO technology is pilot contamination effect. This effect occurs during uplink training when terminals use the same orthogonal signals. In this paper, a pilot reuse factor with large scale fading precoding is proposed to mitigate the pilot contamination effect. The pilot reuse factor is designed to assign unique orthogonal signals to the adjacent cells. These unique orthogonal signals are reused only within the cell and hence, intra-pilot contamination is the only concern. Large scale fading precoding is then used to mitigate the intra-pilot contamination effect. The average achievable sum rate is computed for different pilot reuse factors. Experimental results through MATLAB simulation show that a higher pilot reuse factor gives better average achievable sum rates. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02634;Precoding for the Sparsely Spread MC-CDMA Downlink with  Discrete-Alphabet Inputs; Min Li,  Chunshan Liu,  Stephen V. Hanly;  Sparse signatures have been proposed for the CDMA uplink to reduce multi-user detection complexity, but they have not yet been fully exploited for its downlink counterpart. In this work, we propose a Multi-Carrier CDMA (MC-CDMA) downlink communication, where regular sparse signatures are deployed in the frequency domain. Taking the symbol detection point of view, we formulate a problem appropriate for the downlink with discrete alphabets as inputs. The solution to the problem provides a power-efficient precoding algorithm for the base station, subject to minimum symbol error probability (SEP) requirements at the mobile stations. In the algorithm, signature sparsity is shown to be crucial for reducing precoding complexity. Numerical results confirm system-load-dependent power reduction gain from the proposed precoding over the zero-forcing precoding and the regularized zero-forcing precoding with optimized regularization parameter under the same SEP targets. For a fixed system load, it is also demonstrated that sparse MC-CDMA with a proper choice of sparsity level attains almost the same power efficiency and link throughput as that of dense MC-CDMA yet with reduced precoding complexity, thanks to the sparse signatures. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02642;On minimum distance of locally repairable codes; Mehrtash Mehrabi,  Massoud Ardakani;  Distributed and cloud storage systems are used to reliably store large-scale data. Erasure codes have been recently proposed and used in real-world distributed and cloud storage systems such as Google File System, Microsoft Azure Storage, and Facebook HDFS-RAID, to enhance the reliability. In order to decrease the repair bandwidth and disk I/O, a class of erasure codes called locally repairable codes (LRCs) have been proposed which have small locality compare to other erasure codes. Although LRCs have small locality, they have lower minimum distance compare to the Singleton bound. Hence, seeking the largest possible minimum distance for LRCs have been the topic of many recent studies. In this paper, we study the largest possible minimum distance of a class of LRCs and evaluate them in terms of achievability. Furthermore, we compare our results with the existence bounds in the literature. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02671;On the Local Correctabilities of Projective Reed-Muller Codes; Sian-Jheng Lin;  In this paper, we show that the projective Reed-Muller~(PRM) codes form a family of locally correctable codes~(LCC) in the regime of low query complexities. A PRM code is specified by the alphabet size $q$, the number of variables $m$, and the degree $d$. When $d\leq q-1$, we present a perfectly smooth local decoder to recover a symbol by accessing $\gamma\leq q$ symbols to the coordinates fall on a line. There are three major parameters considered in LCCs, namely the query complexity, the message length and the code length. This paper shows that PRM codes are shorter than generalized Reed-Muller~(GRM) codes in LCCs. Precisely, given a GRM code over a field of size $q$, there exists a class of shorter codes over a field of size $q-1$, while maintaining the same values on the query complexities and the message lengths. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02673;Capacity Region of Gaussian Multiple-Access Channels with Energy  Harvesting and Energy Cooperation; Yunquan Dong,  Zhengchuan Chen,  Pingyi Fan;"  We consider the capacity region of a $K$-user multiple access channel (MAC) with energy harvesting transmitters. Each user stores and schedules the randomly arriving energy using an energy buffer. Users can also perform energy cooperation by transmitting energy to other users or receiving energy from them. We derive the capacity region of this channel and show that 1) the capacity region coincides with that of a traditional $K$-user Gaussian MAC with energy cooperation, where the average power constraints are equal to the battery recharging rates of the energy harvesting case; 2) each rate on the capacity region boundary can be achieved using the save-and-forward power control and a fixed energy cooperation policy. ";Information Theory (cs.IT)
https://arxiv.org/abs/1702.02685;Combinatorial Alphabet-Dependent Bounds for Locally Recoverable Codes; Abhishek Agarwal,  Alexander Barg,  Sihuang Hu,  Arya Mazumdar,  Itzhak Tamo;  Locally recoverable codes (LRC) have recently been a subject of intense research due to the theoretical appeal and their applications in distributed storage systems. In an LRC, any erased symbol of a codeword can be recovered by accessing only few other symbols. For LRC codes over small alphabet (such as binary), the optimal rate-distance trade-off is unknown. We present several new combinatorial bounds on LRC codes including the locality-aware sphere packing and Plotkin bounds. We also develop an approach to linear programming (LP) bounds on LRC codes. The resulting LP bound gives better estimates in examples than the other upper bounds known in the literature. Further, we provide the tightest known upper bound on the rate of linear LRC codes with a given relative distance, an improvement over the previous best known bounds. ;"Information Theory (cs.IT); Discrete Mathematics (cs.DM)"
https://arxiv.org/abs/1702.02690;A New View of Multi-User Hybrid Massive MIMO: Non-Orthogonal Angle  Division Multiple Access; Hai Lin,  Feifei Gao,  Shi Jin,  Geoffrey Ye Li;  This paper presents a new view of multi-user (MU) hybrid massive multiple-input and multiple-output (MIMO) systems from array signal processing perspective. We first show that the instantaneous channel vectors corresponding to different users are asymptotically orthogonal if the angles of arrival (AOAs) of users are different. We then decompose the channel matrix into an angle domain basis matrix and a gain matrix. The former can be formulated by steering vectors and the latter has the same size as the number of RF chains, which perfectly matches the structure of hybrid precoding. A novel hybrid channel estimation is proposed by separately estimating the angle information and the gain matrix, which could significantly save the training overhead and substantially improve the channel estimation accuracy compared to the conventional beamspace approach. Moreover, with the aid of the angle domain matrix, the MU massive MIMO system can be viewed as a type of non-orthogonal angle division multiple access (ADMA) to simultaneously serve multiple users at the same frequency band. Finally, the performance of the proposed scheme is validated by computer simulation results. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02695;Wideband Distributed Spectrum Sharing with Multichannel Immediate  Multiple Access; Mingming Cai,  J. Nicholas Laneman;  This paper describes a radio architecture for distributed spectrum sharing of multiple channels among secondary users (SUs) in a wide band of frequencies and a localized area. A novel Multichannel Immediate Multiple Access (MIMA) physical layer is developed such that each SU can monitor all the channels simultaneously for incoming signals and achieve fast rendezvous within the multiple channels. The spectrum utilized by an SU pair can be changed dynamically based upon spectrum sensing at the transmitter and tracking synchronization and control messages at the receiver. Although information about the number of active SUs can be used to improve the spectrum sharing efficiency, the improvement is small relative to the cost of obtaining such information. Therefore, the architecture adopts Multichannel Carrier Sense Multiple Access (CSMA) for medium access control regardless of the number of active SUs. A prototype implementation of the architecture has been developed using an advanced software defined radio (SDR) platform. System tests demonstrate that the spectrum sharing efficiency of the prototype is close to an upper bound if the signal-to-noise ratio (SNR) is sufficiently high. Among other practical issues, imaged interference caused by hardware IQ imbalance limits system performance. In the prototype, the MIMA is based on an LTE waveform. Therefore, the spectrum sharing radio can be potentially applied to the 3.5 GHz radar band for Citizens Broadband Radio Service (CBRS). ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02716;Construction of Unrestricted Rate Parallel Random Input Output Code; Shan Lu,  Horoshi Kamabe,  Jun Cheng,  Akira Yamawaki;  A coding scheme for two-page unrestricted-rate PRIO code that each page may have different code rates is proposed. In the second page, the code for each messages consists of two complementary codewords with code length n. There are a total of 2n-1 codes which are disjoint to guarantees uniquely decodable for 2n-1 messages. In the first page, the code for each message consists of all weight-u vectors with their non-zero elements restricted to (2u-1) same positions, where non-negative integer u is less than or equal to half of code length. Finding codes to be disjoint in first page is equivalent to construction of constant-weight codes, and the numbers of disjoint codes are the best-known numbers of codewords in constant-weight codes. Our coding scheme is constructive, and the code length is arbitrary.The sum rates of our proposed codes are higher than those of previous work. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.02850;Decoding Delay Performance of Random Linear Network Coding for Broadcast; Ioannis Chatzigeorgiou,  Andrea Tassi;  Characterization of the delay profile of systems employing random linear network coding is important for the reliable provision of broadcast services. Previous studies focused on network coding over large finite fields or developed Markov chains to model the delay distribution but did not look at the effect of transmission deadlines on the delay. In this work, we consider generations of source packets that are encoded and transmitted over the erasure broadcast channel. The transmission of packets associated to a generation is taken to be deadline-constrained, that is, the transmitter drops a generation and proceeds to the next one when a predetermined deadline expires. Closed-form expressions for the average number of required packet transmissions per generation are obtained in terms of the generation size, the field size, the erasure probability and the deadline choice. An upper bound on the average decoding delay, which is tighter than previous bounds found in the literature, is also derived. Analysis shows that the proposed framework can be used to fine-tune the system parameters and ascertain that neither insufficient nor excessive amounts of packets are sent over the broadcast channel. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1702.02891;Sparse Approximation by Semidefinite Programming; Ali Çivril;  The problem of sparse approximation and the closely related compressed sensing have received tremendous attention in the past decade. Primarily studied from the viewpoint of applied harmonic analysis and signal processing, there have been two dominant algorithmic approaches to this problem: Greedy methods called the matching pursuit (MP) and the linear programming based approaches called the basis pursuit (BP). The aim of the current paper is to bring a fresh perspective to sparse approximation by treating it as a combinatorial optimization problem and providing an algorithm based on the powerful optimization technique semidefinite programming (SDP). In particular, we show that there is a randomized algorithm based on a semidefinite relaxation of the problem with performance guarantees depending on the coherence and the restricted isometry constant of the dictionary used. We then show a derandomization of the algorithm based on the method of conditional probabilities. ;"Information Theory (cs.IT); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1702.03012;Secure Multi-Source Multicast; Alejandro Cohen,  Asaf Cohen,  Muriel Medard,  Omer Gurewitz;  The principal mission of Multi-Source Multicast (MSM) is to disseminate all messages from all sources in a network to all destinations. MSM is utilized in numerous applications. In many of them, securing the messages disseminated is critical. A common secure model is to consider a network where there is an eavesdropper which is able to observe a subset of the network links, and seek a code which keeps the eavesdropper ignorant regarding all the messages. While this is solved when all messages are located at a single source, Secure MSM (SMSM) is an open problem, and the rates required are hard to characterize in general. In this paper, we consider Individual Security, which promises that the eavesdropper has zero mutual information with each message individually. We completely characterize the rate region for SMSM under individual security, and show that such a security level is achievable at the full capacity of the network, that is, the cut-set bound is the matching converse, similar to non-secure MSM. Moreover, we show that the field size is similar to non-secure MSM and does not have to be larger due to the security constraint. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03021;Elementary $L^\infty$ error estimates for super-resolution de-noising; Weilin Li;  This paper studies the problem of recovering a discrete complex measure on the torus from a finite number of corrupted Fourier samples. We assume the support of the unknown discrete measure satisfies a minimum separation condition and we use convex regularization methods to recover approximations of the original measure. We focus on two well-known convex regularization methods, and for both, we establish an error estimate that bounds the smoothed-out error in terms of the target resolution and noise level. Our $L^\infty$ approximation rate is entirely new for one of the methods, and improves upon a previously established $L^1$ estimate for the other. We provide a unified analysis and an elementary proof of the theorem. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03049;An Overview of Multi-Processor Approximate Message Passing; Junan Zhu,  Ryan Pilgrim,  Dror Baron;  Approximate message passing (AMP) is an algorithmic framework for solving linear inverse problems from noisy measurements, with exciting applications such as reconstructing images, audio, hyper spectral images, and various other signals, including those acquired in compressive signal acquisiton systems. The growing prevalence of big data systems has increased interest in large-scale problems, which may involve huge measurement matrices that are unsuitable for conventional computing systems. To address the challenge of large-scale processing, multiprocessor (MP) versions of AMP have been developed. We provide an overview of two such MP-AMP variants. In row-MP-AMP, each computing node stores a subset of the rows of the matrix and processes corresponding measurements. In column- MP-AMP, each node stores a subset of columns, and is solely responsible for reconstructing a portion of the signal. We will discuss pros and cons of both approaches, summarize recent research results for each, and explain when each one may be a viable approach. Aspects that are highlighted include some recent results on state evolution for both MP-AMP algorithms, and the use of data compression to reduce communication in the MP network. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03051;Density Functional Estimators with k-Nearest Neighbor Bandwidths; Weihao Gao,  Sewoong Oh,  Pramod Viswanath;  Estimating expected polynomials of density functions from samples is a basic problem with numerous applications in statistics and information theory. Although kernel density estimators are widely used in practice for such functional estimation problems, practitioners are left on their own to choose an appropriate bandwidth for each application in hand. Further, kernel density estimators suffer from boundary biases, which are prevalent in real world data with lower dimensional structures. We propose using the fixed-k nearest neighbor distances for the bandwidth, which adaptively adjusts to local geometry. Further, we propose a novel estimator based on local likelihood density estimators, that mitigates the boundary biases. Although such a choice of fixed-k nearest neighbor distances to bandwidths results in inconsistent estimators, we provide a simple debiasing scheme that precomputes the asymptotic bias and divides off this term. With this novel correction, we show consistency of this debiased estimator. We provide numerical experiments suggesting that it improves upon competing state-of-the-art methods. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03059;The ARMA(k) Gaussian Feedback Capacity; Tao Liu,  Guangyue Han;  Using Kim's variational formulation (with a slight yet important modification), we derive the ARMA(k) Gaussian feedback capacity, i.e., the feedback capacity of an additive channel where the noise is a k-th order autoregressive moving average Gaussian process. More specifically, the ARMA(k) Gaussian feedback capacity is expressed as a simple function evaluated at a solution to a system of polynomial equations, which has only finitely many solutions for the cases k=1, 2 and possibly beyond. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03062;Sparsity/Undersampling Tradeoffs in Anisotropic Undersampling, with  Applications in MR Imaging/Spectroscopy; Hatef Monajemi,  David L. Donoho;  We study anisotropic undersampling schemes like those used in multi-dimensional NMR spectroscopy and MR imaging, which sample exhaustively in certain time dimensions and randomly in others. Our analysis shows that anisotropic undersampling schemes are equivalent to certain block-diagonal measurement systems. We develop novel exact formulas for the sparsity/undersampling tradeoffs in such measurement systems. Our formulas predict finite-$N$ phase transition behavior differing substantially from the well known asymptotic phase transitions for classical Gaussian undersampling. Extensive empirical work shows that our formulas accurately describe observed finite-$N$ behavior, while the usual formulas based on universality are substantially inaccurate. We also vary the anisotropy, keeping the total number of samples fixed, and for each variation we determine the precise sparsity/undersampling tradeoff (phase transition). We show that, other things being equal, the ability to recover a sparse object decreases with an increasing number of exhaustively-sampled dimensions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03070;PCA in Data-Dependent Noise (Correlated-PCA): Nearly Optimal Finite  Sample Guarantees; Namrata Vaswani,  Praneeth Narayanamurthy;"  We study Principal Component Analysis (PCA) in a setting where a part of the corrupting noise is data-dependent and, as a result, the noise and the true data are correlated. Under a bounded-ness assumption on the true data and the noise, and a simple assumption on data-noise correlation, we obtain a nearly optimal sample complexity bound for the most commonly used PCA solution, singular value decomposition (SVD). This bound is a significant improvement over the bound obtained by Vaswani and Guo in recent work (NIPS 2016) where this ""correlated-PCA"" problem was first studied; and it holds under a significantly weaker data-noise correlation assumption than the one used for this earlier result. ";"Information Theory (cs.IT); Machine Learning (stat.ML)"
https://arxiv.org/abs/1702.03128;The Potential of Using Large Antenna Arrays on Intelligent Surfaces; Sha Hu,  Fredrik Rusek,  Ove Edfors;  In this paper, we consider capacities of single-antenna terminals communicating to large antenna arrays that are deployed on surfaces. That is, the entire surface is used as an intelligent receiving antenna array. Under the condition that the surface area is sufficiently large, the received signal after matched-filtering (MF) can be well approximated by an intersymbol interference (ISI) channel where channel taps are closely related to a sinc function. Based on such an approximation, we have derived the capacities for both one-dimensional (terminals on a line) and high dimensional (terminals on a plane or in a cube) terminal-deployments. In particular, we analyze the normalized capacity $\bar{\mathcal{C}}$, measured in nats/s/Hz/m$^2$, under the constraint that the transmit power per m$^2$, $\bar{P}$, is fixed. We show that when the user-density increases, the limit of $\bar{\mathcal{C}}$, achieved as the wavelength $\lambda$ approaches 0, is $\bar{P}/(2N_0)$ nats/s/Hz/m$^2$, where $N_0$ is the spatial power spectral density (PSD) of noise. In addition, we also show that the number of signal dimensions is $2/\lambda$ per meter deployed surface for the one-dimensional case, and $\pi/\lambda^2$ per m$^2$ deployed surface for two and three dimensional terminal-deployments. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03131;Cramér-Rao Lower Bounds for Positioning with Large Intelligent  Surfaces; Sha Hu,  Fredrik Rusek,  Ove Edfors;  We consider the potential for positioning with a system where antenna arrays are deployed as a large intelligent surface (LIS). We derive Fisher-informations and Cram\'{e}r-Rao lower bounds (CRLB) in closed-form for terminals along the central perpendicular line (CPL) of the LIS for all three Cartesian dimensions. For terminals at positions other than the CPL, closed-form expressions for the Fisher-informations and CRLBs seem out of reach, and we alternatively provide approximations (in closed-form) which are shown to be very accurate. We also show that under mild conditions, the CRLBs in general decrease quadratically in the surface-area for both the $x$ and $y$ dimensions. For the $z$-dimension (distance from the LIS), the CRLB decreases linearly in the surface-area when terminals are along the CPL. However, when terminals move away from the CPL, the CRLB is dramatically increased and then also decreases quadratically in the surface-area. We also extensively discuss the impact of different deployments (centralized and distributed) of the LIS. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03231;Performance of Cell-Free Massive MIMO Systems with MMSE and LSFD  Receivers; Elina Nayebi,  Alexei Ashikhmin,  Thomas L. Marzetta,  Bhaskar D. Rao;  Cell-Free Massive MIMO comprises a large number of distributed single-antenna access points (APs) serving a much smaller number of users. There is no partitioning into cells and each user is served by all APs. In this paper, the uplink performance of cell-free systems with minimum mean squared error (MMSE) and large scale fading decoding (LSFD) receivers is investigated. The main idea of LSFD receiver is to maximize achievable throughput using only large scale fading coefficients between APs and users. Capacity lower bounds for MMSE and LSFD receivers are derived. An asymptotic approximation for signal-to-interference-plus-noise ratio (SINR) of MMSE receiver is derived as a function of large scale fading coefficients only. The obtained approximation is accurate even for a small number of antennas. MMSE and LSFD receivers demonstrate five-fold and two-fold gains respectively over matched filter (MF) receiver in terms of 5%-outage rate. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03241;Spatial Oversampling in LOS MIMO Systems with 1-Bit Quantization at the  Receiver; Tim Hälsig,  Berthold Lankl;  In this paper we investigate the achievable rate of LOS MIMO systems that use 1-bit quantization and spatial oversampling at the receiver. We propose that by using additional antennas at the receiver, the loss incurred due to the strong limitation of the quantization can be decreased. Mutual information results show that considerable rate gains can be achieved depending on the number and arrangement of the antennas. In some of the cases, even the full available rate from the transmitter can be attained. Furthermore, the results also reveal that two-dimensional antenna arrays can benefit more from spatial oversampling than one-dimensional arrays, when using 1-bit quantization in the LOS MIMO scenario. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03250;Multidimensional Index Modulation in Wireless Communications; Bharath Shamasundar,  Swaroop Jacob,  Sandeep Bhat,  A. Chockalingam;  In index modulation schemes, information bits are conveyed through indexing of transmission entities such as antennas, subcarriers, times slots, precoders, subarrays, and radio frequency (RF) mirrors. Index modulation schemes are attractive for their advantages such as good performance, high rates, and hardware simplicity. This paper focuses on index modulation schemes in which multiple transmission entities, namely, {\em antennas}, {\em time slots}, and {\em RF mirrors}, are indexed {\em simultaneously}. Recognizing that such multidimensional index modulation schemes encourage sparsity in their transmit signal vectors, we propose efficient signal detection schemes that use compressive sensing based reconstruction algorithms. Results show that, for a given rate, improved performance is achieved when the number of indexed transmission entities is increased. We also explore indexing opportunities in {\em load modulation}, which is a modulation scheme that offers power efficiency and reduced RF hardware complexity advantages in multiantenna systems. Results show that indexing space and time in load modulated multiantenna systems can achieve improved performance. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03346;Joint Precoding and RRH selection for User-centric Green MIMO C-RAN; Cunhua Pan,  Huiling Zhu,  Nathan J. Gomes,  Jiangzhou Wang;  This paper jointly optimizes the precoding matrices and the set of active remote radio heads (RRHs) to minimize the network power consumption (NPC) for a user-centric cloud radio access network (C-RAN), where both the RRHs and users have multiple antennas and each user is served by its nearby RRHs. Both users' rate requirements and per-RRH power constraints are considered. Due to these conflicting constraints, this optimization problem may be infeasible. In this paper, we propose to solve this problem in two stages. In Stage I, a low-complexity user selection algorithm is proposed to find the largest subset of feasible users. In Stage II, a low-complexity algorithm is proposed to solve the optimization problem with the users selected from Stage I. Specifically, the re-weighted $l_1$-norm minimization method is used to transform the original problem with non-smooth objective function into a series of weighted power minimization (WPM) problems, each of which can be solved by the weighted minimum mean square error (WMMSE) method. The solution obtained by the WMMSE method is proved to satisfy the Karush-Kuhn-Tucker (KKT) conditions of the WPM problem. Moreover, a low-complexity algorithm based on Newton's method and the gradient descent method is developed to update the precoder matrices in each iteration of the WMMSE method. Simulation results demonstrate the rapid convergence of the proposed algorithms and the benefits of equipping multiple antennas at the user side. Moreover, the proposed algorithm is shown to achieve near-optimal performance in terms of NPC. ;Information Theory (cs.IT)
https://arxiv.org/abs/1702.03372;The Connectivity of Millimeter-Wave Networks in Urban Environments  Modeled Using Random Lattices; Kaifeng Han,  Kaibin Huang,  Ying Cui,  Yueping Wu;  Millimeter-wave (mmWave) communication opens up tens of giga-hertz (GHz) spectrum in the mmWave band for use by next-generation wireless systems, thereby solving the problem of spectrum scarcity. Maintaining connectivity stands out to be a key design challenge for mmWave networks deployed in urban regions due to the blockage effect characterizing mmWave propagation. Specifically, mmWave signals can be blocked by buildings and other large urban objects. In this paper, we set out to investigate the blockage effect on the connectivity of mmWave networks in a Manhattan-type urban region modeled using a random regular lattice while base stations (BSs) are Poisson distributed in the plane. In particular, we analyze the connectivity probability that a typical user is within the transmission range of a BS and connected by a line-of-sight. Using random lattice and stochastic geometry theories, different lower bounds on the connectivity probability are derived as functions of the buildings' size and probability of a lattice cell being occupied by a building as well as BS density and transmission range. The asymptotic connectivity probability is also derived for cases of dense buildings. Last, the results are extended to heterogeneous networks. Our study yields closed-form relations between the parameters of the building process and the BS process, providing useful guidelines for practical mmWave network deployment. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00092;Interlinked Cycles for Index Coding: Generalizing Cycles and Cliques; Chandra Thapa,  Lawrence Ong,  Sarah J. Johnson;  We consider a graphical approach to index coding. While cycles have been shown to provide coding gain, only disjoint cycles and cliques (a specific type of overlapping cycles) have been exploited in existing literature. In this paper, we define a more general form of overlapping cycles, called the interlinked-cycle (IC) structure, that generalizes cycles and cliques. We propose a scheme, called the interlinked-cycle-cover (ICC) scheme, that leverages IC structures in digraphs to construct scalar linear index codes. We characterize a class of infinitely many digraphs where our proposed scheme is optimal over all linear and non-linear index codes. Consequently, for this class of digraphs, we indirectly prove that scalar linear index codes are optimal. Furthermore, we show that the ICC scheme can outperform all existing graph-based schemes (including partial-clique-cover and fractional-local-chromatic number schemes), and a random-coding scheme (namely, composite coding) for certain graphs. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00133;Asymptotic Analysis of Random Lattices in High Dimensions; Rongrong Qian,  Yuan Qi;  This paper presents the asymptotic analysis of random lattices in high dimensions to clarify the distance properties of the considered lattices. These properties not only indicate the asymptotic value for the distance between any pair of lattice points in high-dimension random lattices, but also describe the convergence behavior of how the asymptotic value approaches the exact distance. The asymptotic analysis further prompts new insights into the asymptotic behavior of sphere-decoding complexity and the pairwise error probability (PEP) with maximum-likelihood (ML) detector for a large number of antennas. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00154;Broadcast Repair for Wireless Distributed Storage Systems; Ping Hu,  Chi Wan Sung,  Terence H. Chan;  In wireless distributed storage systems, storage nodes are connected by wireless channels, which are broadcast in nature. This paper exploits this unique feature to design an efficient repair mechanism, called broadcast repair, for wireless distributed storage systems with multiple-node failures. Since wireless channels are typically bandwidth limited, we advocate a new measure on repair performance called repair-transmission bandwidth, which measures the average number of packets transmitted by helper nodes per failed node. The fundamental tradeoff between storage amount and repair-transmission bandwidth is obtained. It is shown that broadcast repair outperforms cooperative repair, which is the basic repair method for wired distributed storage systems with multiple-node failures, in terms of storage efficiency and repair-transmission bandwidth, thus yielding a better tradeoff curve. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00160;Design and Analysis Framework for Sparse FIR Channel Shortening; Abubakr O. Al-Abbasi,  Ridha Hamila,  Waheed U. Bajwa,  Naofal Al-Dhahir;  A major performance and complexity limitation in broadband communications is the long channel delay spread which results in a highly-frequency-selective channel frequency response. Channel shortening equalizers (CSEs) are used to ensure that the cascade of a long channel impulse response (CIR) and the CSE is approximately equivalent to a target impulse response (TIR) with much shorter delay spread. In this paper, we propose a general framework that transforms the problems of design of sparse CSE and TIR finite impulse response (FIR) filters into the problem of sparsest-approximation of a vector in different dictionaries. In addition, we compare several choices of sparsifying dictionaries under this framework. Furthermore, the worst-case coherence of these dictionaries, which determines their sparsifying effectiveness, are analytically and/or numerically evaluated. Finally, the usefulness of the proposed framework for the design of sparse CSE and TIR filters is validated through numerical experiments. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00169;Energy Efficient Transmission for Multicast Services in MISO Distributed  Antenna Systems; Hong Ren,  Nan Liu,  Cunhua Pan;  This paper aims to solve the energy efficiency (EE) maximization problem for multicast services in a multiple-input single-output (MISO) distributed antenna system (DAS). A novel iterative algorithm is proposed, which consists of solving two subproblems iteratively: the power allocation problem and the beam direction updating problem. The former subproblem can be equivalently transformed into a one-dimension quasi-concave problem that is solved by the golden search method. The latter problem can be efficiently solved by the existing method. Simulation results show that the proposed algorithm achieves significant EE performance gains over the existing rate maximization method. In addition, when the backhaul power consumption is low, the EE performance of the DAS is better than that of the centralized antenna system (CAS). ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00203;Harvesting the (Self-)Interference in Heterogeneous Full-Duplex Networks  For Joint Rate-Energy Optimization; Ali Kariminezhad,  Aydin Sezgin;  Wireless nodes in future communication systems are expected to overcome three barriers when compared to their transitional counterparts, namely to support significantly higher data rates, have long-lasting energy supplies and remain fully operational in interference-limited heterogeneous networks. This could be achieved by providing three promising features, which are radio frequency (RF) energy harvesting, improper Gaussian signaling and operating in full-duplex communication mode, i.e., transmit and receive at the same time within the same frequency band. In this paper, we consider these aspects jointly in a multi-antenna heterogeneous two-tier-network. Thus, the users in the femto-cell are sharing the scarce resources with the cellular users in the macro-cell and have to cope with the interference from the macro-cell base station as well as the transmitter noise and residual self-interference (RSI) due to imperfect full-duplex operation. Interestingly enough, while these impairments are detrimental from the achievable rate perspective, they are beneficial from the energy harvesting aspect as they carry RF energy. In this paper, we consider this natural trade-off jointly and propose appropriate optimization problems for beamforming and optimal resource allocation. Various receiver structures are employed for both information detection (ID) and energy harvesting (EH) capabilities. The paper aims at characterizing the trade-off between the achievable rates and harvested energies. Rate and energy maximization problems are thoroughly investigated. Finally, the numerical illustrations demonstrate the impact of the energy harvesting on the achievable rate performance. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00244;Caching Incentive Design in Wireless D2D Networks: A Stackelberg Game  Approach; Zhuoqun Chen,  Yangyang Liu,  Bo Zhou,  Meixia Tao;  Caching in wireless device-to-device (D2D) networks can be utilized to offload data traffic during peak times. However, the design of incentive mechanisms is challenging due to the heterogeneous preference and selfish nature of user terminals (UTs). In this paper, we propose an incentive mechanism in which the base station (BS) rewards those UTs that share contents with others using D2D communication. We study the cost minimization problem for the BS and the utility maximization problem for each UT. In particular, the BS determines the rewarding policy to minimize his total cost, while each UT aims to maximize his utility by choosing his caching policy. We formulate the conflict among UTs and the tension between the BS and the UTs as a Stackelberg game. We show the existence of the equilibrium and propose an iterative gradient algorithm (IGA) to obtain the Stackelberg Equilibrium. Extensive simulations are carried out to evaluate the performance of the proposed caching scheme and comparisons are drawn with several baseline caching schemes with no incentives. Numerical results show that the caching scheme under our incentive mechanism outperforms other schemes in terms of the BS serving cost and the utilities of the UTs. ;"Information Theory (cs.IT); Computer Science and Game Theory (cs.GT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.00273;Component Based Modeling of Ultrasound Signals; Yael Yankelevsky,  Zvi Friedman,  Arie Feuer;  This work proposes a component based model for the raw ultrasound signals acquired by the transducer elements. Based on this approach, before undergoing the standard digital processing chain, every sampled raw signal is first decomposed into a smooth background signal and a strong reflectors component. The decomposition allows for a suited processing scheme to be adjusted for each component individually. We demonstrate the potential benefit of this approach in image enhancement by suppressing side lobe artifacts, and in improvement of digital data compression. Applying our proposed processing schemes to real cardiac ultrasound data, we show that by separating the two components and compressing them individually, over twenty-fold reduction of the data size is achieved while retaining the image contents. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00302;MIMO-NOMA Design for Small Packet Transmission in the Internet of Things; Z. Ding,  L. Dai,  H. V. Poor;  A feature of the Internet of Things (IoT) is that some users in the system need to be served quickly for small packet transmission. To address this requirement, a new multiple-input multiple-output non-orthogonal multiple access (MIMO-NOMA) scheme is designed in this paper, where one user is served with its quality of service (QoS) requirement strictly met, and the other user is served opportunistically by using the NOMA concept. The novelty of this new scheme is that it confronts the challenge that most existing MIMO-NOMA schemes rely on the assumption that users' channel conditions are different, a strong assumption which may not be valid in practice. The developed precoding and detection strategies can effectively create a significant difference between the users' effective channel gains, and therefore the potential of NOMA can be realized even if the users' original channel conditions are similar. Analytical and numerical results are provided to demonstrate the performance of the proposed MIMO-NOMA scheme. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00587;A Theorem on Multi-Objective Optimization Approach for Bit Allocation of  Scalable Coding; Wen-Liang Hwang;  In the current work, we have formulated the optimal bit-allocation problem for a scalable codec of images or videos as a constrained vector-valued optimization problem and demonstrated that there can be many optimal solutions, called Pareto optimal points. In practice, the Pareto points are derived via the weighted sum scalarization approach. An important question which arises is whether all the Pareto optimal points can be derived using the scalarization approach? The present paper provides a sufficient condition on the rate-distortion function of each resolution of a scalable codec to address the above question. The result indicated that if the rate-distortion function of each resolution is strictly decreasing and convex and the Pareto points form a continuous curve, then all the optimal Pareto points can be derived by using the scalarization method. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00600;Decentralized Detection in Energy Harvesting Wireless Sensor Networks; Alla Tarighati,  James Gross,  Joakim Jalden;  We consider a decentralized hypothesis testing problem in which several peripheral energy harvesting sensors are arranged in parallel. Each sensor makes a noisy observation of a time varying phenomenon, and sends a message about the present hypothesis towards a fusion center at each time instance t. The fusion center, using the aggregate of the received messages during the time instance t, makes a decision about the state of the present hypothesis. We assume that each sensor is an energy harvesting device and is capable of harvesting all the energy it needs to communicate from its environment. Our contribution is to formulate and analyze the decentralized detection problem when the energy harvesting sensors are allowed to form a long term energy usage policy. Our analysis is based on a queuing-theoretic model for the battery. Then, by using numerical simulations, we show how the resulting performance differs from the energy unconstrained case. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00644;A Novel Interleaving Scheme for Polar Codes; Ya Meng,  Liping Li,  Yanjun Hu;  It's known that the bit errors of polar codes with successive cancellation (SC) decoding are coupled. We call the coupled information bits the correlated bits. In this paper, concatenation schemes are studied for polar codes (as inner codes) and LDPC codes (as outer codes). In a conventional concatenation scheme, to achieve a better BER performance, one can divide all $N_l$ bits in a LDPC block into $N_l$ polar blocks to completely de-correlate the possible coupled errors. In this paper, we propose a novel interleaving scheme between a LDPC code and a polar code which breaks the correlation of the errors among the correlated bits. This interleaving scheme still keeps the simple SC decoding of polar codes while achieves a comparable BER performance at a much smaller delay compared with a $N_l$-block delay scheme. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00648;Superimposed Pilots are Superior for Mitigating Pilot Contamination in  Massive MIMO; Karthik Upadhya,  Sergiy A. Vorobyov,  Mikko Vehkapera;  In this paper, superimposed pilots are introduced as an alternative to time-multiplexed pilot and data symbols for mitigating pilot contamination in massive multiple-input multiple-output (MIMO) systems. We propose a non-iterative scheme for uplink channel estimation based on superimposed pilots and derive an expression for the uplink signal-to-interference-plus-noise ratio (SINR) at the output of a matched filter employing this channel estimate. Based on this expression, we observe that power control is essential when superimposed pilots are employed. Moreover, the quality of the channel estimate can be improved by reducing the interference that results from transmitting data alongside the pilots, and an intuitive iterative data-aided scheme that reduces this component of interference is also proposed. Approximate expressions for the uplink SINR are provided for the iterative data-aided method as well. In addition, we show that a hybrid system with users utilizing both time-multiplexed and superimposed pilots is superior to an optimally designed system that employs only time-multiplexed pilots, even when the non-iterative channel estimate is used to build the detector and precoder. We also describe a simple approach to implement this hybrid system by minimizing the overall inter and intra-cell interference. Numerical simulations demonstrating the performance of the proposed channel estimation schemes and the superiority of the hybrid system are also provided. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.00671;Distributed Spectral Efficiency Maximization in Full-Duplex Cellular  Networks; Jose Mairton B. da Silva Jr,  Yuzhe Xu,  Gabor Fodor,  Carlo Fischione;  Three-node full-duplex is a promising new transmission mode between a full-duplex capable wireless node and two other wireless nodes that use half-duplex transmission and reception respectively. Although three-node full-duplex transmissions can increase the spectral efficiency without requiring full-duplex capability of user devices, inter-node interference - in addition to the inherent self-interference - can severely degrade the performance. Therefore, as methods that provide effective self-interference mitigation evolve, the management of inter-node interference is becoming increasingly important. This paper considers a cellular system in which a full-duplex capable base station serves a set of half-duplex capable users. As the spectral efficiencies achieved by the uplink and downlink transmissions are inherently intertwined, the objective is to device channel assignment and power control algorithms that maximize the weighted sum of the uplink-downlink transmissions. To this end a distributed auction based channel assignment algorithm is proposed, in which the scheduled uplink users and the base station jointly determine the set of downlink users for full-duplex transmission. Realistic system simulations indicate that the spectral efficiency can be up to 89% better than using the traditional half-duplex mode. Furthermore, when the self-interference cancelling level is high, the impact of the user-to-user interference is severe unless properly managed. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.00762;On self-dual double circulant codes; Adel Alahmadi,  Funda Özdemir,  Patrick Solé;  Self-dual double circulant codes of odd dimension are shown to be dihedral in even characteristic and consta-dihedral in odd characteristic. Exact counting formulae are derived for them and used to show they contain families of codes with relative distance satisfying a modified Gilbert-Varshamov bound. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01080;Spectrum Pooling in MmWave Networks: Opportunities, Challenges, and  Enablers; Federico Boccardi,  Hossein Shokri-Ghadikolaei,  Gabor Fodor,  Elza Erkip,  Carlo Fischione,  Marios Kountouris,  Petar Popovski,  and Michele Zorzi;  Motivated by the intrinsic characteristics of mmWave technologies, we discuss the possibility of an authorization regime that allows spectrum sharing between multiple operators, also referred to as spectrum pooling. In particular, considering user rate as the performance measure, we assess the benefit of coordination among the networks of different operators, study the impact of beamforming both at the base stations and at the user terminals, and analyze the pooling performance at different frequency carriers. We also discuss the enabling spectrum mechanisms, architectures, and protocols required to make spectrum pooling work in real networks. Our initial results show that, from a technical perspective, spectrum pooling at mmWave has the potential for a more efficient spectrum use than a traditional exclusive spectrum allocation to a single operator. However, further studies are needed in order to reach a thorough understanding of this matter, and we hope that this paper will help stimulate further research in this area. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI); Systems and Control (cs.SY)"
https://arxiv.org/abs/1603.01115;Optimization of Energy-Constrained Wireless Powered Communication  Networks with Heterogeneous Nodes; Mohamed A. Abd-Elmagid,  Tamer ElBatt,  Karim G. Seddik;  In this paper, we study wireless networks where nodes have two energy sources, namely a battery and radio frequency (RF) energy harvesting circuitry. We formulate two optimization problems with different objective functions, namely maximizing the sum throughput and maximizing the minimum throughput, for enhanced fairness. Furthermore, we show the generality of the proposed system model through characterizing the conditions under which the two formulated optimization problems can be reduced to the corresponding problems of different known wireless networks, namely, conventional wireless networks (battery-powered) and wireless powered communications networks (WPCNs) with only RF energy harvesting nodes. In addition, we introduce WPCNs with two types of nodes, with and without RF energy harvesting capability, in which the nodes without RF energy harvesting are utilized to enhance the sum throughput, even beyond WPCNs with all energy harvesting nodes. We establish the convexity of all formulated problems which opens room for efficient solution using standard techniques. Our numerical results show that the two types of wireless networks, namely WPCNs with only RF energy harvesting nodes and conventional wireless networks, are considered, respectively, as lower and upper bounds on the performance of the generalized problem setting in terms of the maximum sum throughput and the maxmin throughput. Moreover, the results reveal new insights and throughput-fairness trade-offs unique to our new problem setting. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01213;Optimal Rebuilding of Multiple Erasures in MDS Codes; Zhiying Wang,  Itzhak Tamo,  Jehoshua Bruck;  MDS array codes are widely used in storage systems due to their computationally efficient encoding and decoding procedures. An MDS code with $r$ redundancy nodes can correct any $r$ node erasures by accessing all the remaining information in the surviving nodes. However, in practice, $e$ erasures is a more likely failure event, for $1\le e<r$. Hence, a natural question is how much information do we need to access in order to rebuild $e$ storage nodes? We define the rebuilding ratio as the fraction of remaining information accessed during the rebuilding of $e$ erasures. In our previous work we constructed MDS codes, called zigzag codes, that achieve the optimal rebuilding ratio of $1/r$ for the rebuilding of any systematic node when $e=1$, however, all the information needs to be accessed for the rebuilding of the parity node erasure. The (normalized) repair bandwidth is defined as the fraction of information transmitted from the remaining nodes during the rebuilding process. For codes that are not necessarily MDS, Dimakis et al. proposed the regenerating codes framework where any $r$ erasures can be corrected by accessing some of the remaining information, and any $e=1$ erasure can be rebuilt from some subsets of surviving nodes with optimal repair bandwidth. In this work, we study 3 questions on rebuilding of codes: (i) We show a fundamental trade-off between the storage size of the node and the repair bandwidth similar to the regenerating codes framework, and show that zigzag codes achieve the optimal rebuilding ratio of $e/r$ for MDS codes, for any $1\le e\le r$. (ii) We construct systematic codes that achieve optimal rebuilding ratio of $1/r$, for any systematic or parity node erasure. (iii) We present error correction algorithms for zigzag codes, and in particular demonstrate how these codes can be corrected beyond their minimum Hamming distances. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01217;Rate Splitting for MIMO Wireless Networks: A Promising PHY-Layer  Strategy for LTE Evolution; Bruno Clerckx,  Hamdi Joudeh,  Chenxi Hao,  Mingbo Dai,  Borzoo Rassouli;  MIMO processing plays a central part towards the recent increase in spectral and energy efficiencies of wireless networks. MIMO has grown beyond the original point-to-point channel and nowadays refers to a diverse range of centralized and distributed deployments. The fundamental bottleneck towards enormous spectral and energy efficiency benefits in multiuser MIMO networks lies in a huge demand for accurate channel state information at the transmitter (CSIT). This has become increasingly difficult to satisfy due to the increasing number of antennas and access points in next generation wireless networks relying on dense heterogeneous networks and transmitters equipped with a large number of antennas. CSIT inaccuracy results in a multi-user interference problem that is the primary bottleneck of MIMO wireless networks. Looking backward, the problem has been to strive to apply techniques designed for perfect CSIT to scenarios with imperfect CSIT. In this paper, we depart from this conventional approach and introduce the readers to a promising strategy based on rate-splitting. Rate-splitting relies on the transmission of common and private messages and is shown to provide significant benefits in terms of spectral and energy efficiencies, reliability and CSI feedback overhead reduction over conventional strategies used in LTE-A and exclusively relying on private message transmissions. Open problems, impact on standard specifications and operational challenges are also discussed. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.01340;OFDM demodulation using virtual time reversal processing in underwater  acoustic communication; Yanling Yin,  Songzuo Liu,  Gang Qiao,  Yue Yang;  The extremely long underwater channel delay spread causes severe inter-symbol interference (ISI) for underwater acoustic communications. Passive time reversal processing (PTRP) can effectively reduce the channel time dispersion in a simple way via convolving the received packet with a time reversed probe signal. However the probe signal itself may introduce extra noise and interference (self-correlation of the probe signal). In this paper, we propose a virtual time reversal processing (VTRP) for single input single output (SISO) Orthogonal Frequency Division Multiplexing (OFDM) systems. It convolves the received packet with the reversed estimated channel, instead of the probe signal to reduce the interference. Two sparse channel estimation methods, matching pursuit (MP), and basis pursuit de-noising (BPDN), are adopted to estimate the channel impulse response (CIR). We compare the performance of VTRP with the PTRP and without any time reversal processing through MATLAB simulations and the pool experiments. The results reveal that VTRP has outstanding performance over time-invariant channels. ;"Information Theory (cs.IT); Sound (cs.SD)"
https://arxiv.org/abs/1603.01393;Inter-User Interference Coordination in Full-Duplex Systems Based on  Geographical Context Information; Melissa Duarte,  Afef Feki,  Stefan Valentin;  We propose a coordination scheme to minimize the interference between users in a cellular network with full-duplex base stations and half-duplex user devices. Our scheme exploits signal attenuation from obstacles between the users by (i) extracting spatially isolated regions from a radio map and (ii) assigning simultaneous co-channel uplink and downlink transmissions to users in these regions such that inter-user interference is minimized. While adding low computational complexity and insignificant signaling overhead to existing deployments, evaluating our solution with real coverage data shows impressive gains compared to conventional half-duplex and full-duplex operation. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01399;Sampling approach to sparse approximation problem: determining degrees  of freedom by simulated annealing; Tomoyuki Obuchi,  Yoshiyuki Kabashima;  The approximation of a high-dimensional vector by a small combination of column vectors selected from a fixed matrix has been actively debated in several different disciplines. In this paper, a sampling approach based on the Monte Carlo method is presented as an efficient solver for such problems. Especially, the use of simulated annealing (SA), a metaheuristic optimization algorithm, for determining degrees of freedom (the number of used columns) by cross validation is focused on and tested. Test on a synthetic model indicates that our SA-based approach can find a nearly optimal solution for the approximation problem and, when combined with the CV framework, it can optimize the generalization ability. Its utility is also confirmed by application to a real-world supernova data set. ;"Information Theory (cs.IT); Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Methodology (stat.ME)"
https://arxiv.org/abs/1603.01420;Capacity Results for the Multicast Cognitive Interference Channel; Meryem Benammar,  Pablo Piantanida,  Shlomo Shamai (Shitz);  The capacity region of the Multicast Cognitive Interference Channel (CIFC) is investigated. This channel consists of two independent transmitters that wish to multicast two different messages, each of them to a different set of users. In addition, one of the transmitters --commonly referred to as the cognitive transmitter-- has prior non-causal knowledge of both messages to be transmitted. This scenario combines difficulties and challenges arising in the Interference Channel, the Broadcast Channel and multicasting communications. Our aim concerns the derivation of optimal interference mitigation techniques in such a challenging communication setup. We investigate to this end the multi-primary CIFC and its dual multi-secondary CIFC under various interference regimes as an attempt to build a thorough understanding for the more general setting. It is shown that, for some regimes, well-known coding techniques for the conventional CIFC remain still optimal in the presence of multicasting. While in other regimes, evolved encoding and/or decoding strategies are crucial. A careful use of these coding schemes and new outer bounding techniques allows us to characterize the capacity region for several classes of discrete memoryless and Gaussian channels in different interference regimes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01468;Edge Coloring and Stopping Sets Analysis in Product Codes with MDS  components; Fanny Jardel,  Joseph J. Boutros;  We consider non-binary product codes with MDS components and their iterative row-column algebraic decoding on the erasure channel. Both independent and block erasures are considered in this paper. A compact graph representation is introduced on which we define double-diversity edge colorings via the rootcheck concept. An upper bound of the number of decoding iterations is given as a function of the graph size and the color palette size $M$. Stopping sets are defined in the context of MDS components and a relationship is established with the graph representation. A full characterization of these stopping sets is given up to a size $(d_1+1)(d_2+1)$, where $d_1$ and $d_2$ are the minimum Hamming distances of the column and row MDS components respectively. Then, we propose a differential evolution edge coloring algorithm that produces colorings with a large population of minimal rootcheck order symbols. The complexity of this algorithm per iteration is $o(M^{\aleph})$, for a given differential evolution parameter $\aleph$, where $M^{\aleph}$ itself is small with respect to the huge cardinality of the coloring ensemble. The performance of MDS-based product codes with and without double-diversity coloring is analyzed in presence of both block and independent erasures. In the latter case, ML and iterative decoding are proven to coincide at small channel erasure probability. Furthermore, numerical results show excellent performance in presence of unequal erasure probability due to double-diversity colorings. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01472;Minimax Design and Order Estimation of FIR Filters for Extending the  Bandwidth of ADCs; Yinan Wang,  Hakan Johansson,  Hui Xu,  Jietao Diao;  The bandwidth of the sampling systems, especially for time-interleaved analog-to-digital converters, needs to be extended along with the rapid increase of the sampling rate. A digitally assisted technique becomes a feasible approach to extend the analog bandwidth, as it is impractical to implement the extension in analog circuits. This paper derives accurate order estimation formulas for the bandwidth extension filter, which is designed in the minimax sense with the ripple constraints as the design criteria. The derived filter order estimation is significant in evaluating the computational complexity from the viewpoint of the top-level system design. Moreover, with the proposed order estimates, one can conveniently obtain the minimal order that satisfies the given ripple constraints, which contributes to reducing the design time. Both the performance of the extension filter and its order estimation are illustrated and demonstrated through simulation examples. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01507;A Novel Sufficient Condition for Generalized Orthogonal Matching Pursuit; Jinming Wen,  Zhengchun Zhou,  Dongfang Li,  Xiaohu Tang;  Generalized orthogonal matching pursuit (gOMP), also called orthogonal multi-matching pursuit, is an extension of OMP in the sense that $N\geq1$ indices are identified per iteration. In this paper, we show that if the restricted isometry constant (RIC) $\delta_{NK+1}$ of a sensing matrix $\A$ satisfies $\delta_{NK+1} < 1/\sqrt {K/N+1}$, then under a condition on the signal-to-noise ratio, gOMP identifies at least one index in the support of any $K$-sparse signal $\x$ from $\y=\A\x+\v$ at each iteration, where $\v$ is a noise vector. Surprisingly, this condition does not require $N\leq K$ which is needed in Wang, \textit{et al} 2012 and Liu, \textit{et al} 2012. Thus, $N$ can have more choices. When $N=1$, it reduces to be a sufficient condition for OMP, which is less restrictive than that proposed in Wang 2015. Moreover, in the noise-free case, it is a sufficient condition for accurately recovering $\x$ in $K$ iterations which is less restrictive than the best known one. In particular, it reduces to the sharp condition proposed in Mo 2015 when $N=1$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01566;Identifiability of an X-rank decomposition of polynomial maps; Pierre Comon,  Yang Qi,  Konstantin Usevich;  In this paper, we study a polynomial decomposition model that arises in problems of system identification, signal processing and machine learning. We show that this decomposition is a special case of the X-rank decomposition --- a powerful novel concept in algebraic geometry that generalizes the tensor CP decomposition. We prove new results on generic/maximal rank and on identifiability of a particular polynomial decomposition model. In the paper, we try to make results and basic tools accessible for general audience (assuming no knowledge of algebraic geometry or its prerequisites). ;"Information Theory (cs.IT); Numerical Analysis (math.NA); Machine Learning (stat.ML)"
https://arxiv.org/abs/1603.01592;Phase Retrieval of Real-Valued Signals in a Shift-Invariant Space; Yang Chen,  Cheng Cheng,  Qiyu Sun,  Haichao Wang;  Phase retrieval arises in various fields of science and engineering and it is well studied in a finite-dimensional setting. In this paper, we consider an infinite-dimensional phase retrieval problem to reconstruct real-valued signals living in a shift-invariant space from its phaseless samples taken either on the whole line or on a set with finite sampling rate. We find the equivalence between nonseparability of signals in a linear space and its phase retrievability with phaseless samples taken on the whole line. For a spline signal of order $N$, we show that it can be well approximated, up to a sign, from its noisy phaseless samples taken on a set with sampling rate $2N-1$. We propose an algorithm to reconstruct nonseparable signals in a shift-invariant space generated by a compactly supported continuous function. The proposed algorithm is robust against bounded sampling noise and it could be implemented in a distributed manner. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01634;Low Complexity Hybrid Precoding and Channel Estimation Based on  Hierarchical Multi-Beam Search for Millimeter-Wave MIMO Systems; Zhenyu Xiao,  Pengfei Xia,  Xiang-Gen Xia;  In millimeter-wave (mmWave) MIMO systems, while a hybrid digital/analog precoding structure offers the potential to increase the achievable rate, it also faces the challenge of the need of a low-complexity design. In specific, the hybrid precoding may require matrix operations with a scale of antenna size, which is generally large in mmWave communication. Moreover, the channel estimation is also rather time consuming due to the large number of antennas at both Tx/Rx sides. In this paper, a low-complexity hybrid precoding and channel estimation approach is proposed. In the channel estimation phase, a hierarchical multi-beam search scheme is proposed to fast acquire $N_{\rm{S}}$ (the number of streams) multipath components (MPCs)/clusters with the highest powers. In the hybrid precoding phase, the analog and digital precodings are decoupled. The analog precoding is designed to steer along the $N_{\rm{S}}$ acquired MPCs/clusters at both Tx/Rx sides, shaping an equivalent $N_{\rm{S}}\times N_{\rm{S}}$ baseband channel, while the digital precoding performs operations in the baseband with the reduced-scale channel. Performance evaluations show that, compared with a state-of-the-art scheme, while achieving a close or even better performance when the number of radio-frequency (RF) chains or streams is small, both the computational complexity of the hybrid precoding and the time complexity of the channel estimation are greatly reduced. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01651;Degrees of Freedom of the MIMO 2x2 Interference Network with General  Message Sets; Yao Wang,  Mahesh K. Varanasi;  We establish the DoF region for the MIMO 2x2 interference network with a general message set, consisting of nine messages, one for each pair of a subset of transmitters at which that message is known and a subset of receivers where that message is desired. An outer bound on the general nine-message network is obtained and then it is shown to be tight, establishing the DoF region for the most general antenna setting wherein all four nodes have an arbitrary number of antennas each. The DoF-optimal scheme is applicable to the MIMO 2x2 network with constant channel coefficients, and hence, a fortiori, to time/frequency varying channel scenarios. In particular, a linear precoding scheme is proposed that can achieve all the DoF tuples in the DoF region. In it, the precise roles played by transmit zero-forcing, interference alignment, random beamforming, symbol extensions and asymmetric complex signaling are delineated. For instance, we identify a class of antenna settings in which ACS is required to achieve the fractional-valued corner points. Evidently, the DoF regions of all previously unknown cases of the 2x2 interference network with a subset of the nine-messages are established as special cases of the general result of this paper. In particular, the DoF region of the well-known four-message (and even three-message) MIMO X channel is established. This problem had remained open despite previous studies which had found inner and outer bounds that were not tight in general. Hence, the DoF regions of all special cases obtained from the general DoF region of the nine-message 2x2 interference network of this work that include at least three of the four X channel messages are new, among many others. Our work sheds light on how the same physical 2x2 network could be used by a suitable choice of message sets to take most advantage of the channel resource in a flexible and efficient manner. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01659;Queue-Aware Energy-Efficient Joint Remote Radio Head Activation and  Beamforming in Cloud Radio Access Networks; Jian Li,  Jingxian Wu,  Mugen Peng,  Ping Zhang;  In this paper, we study the stochastic optimization of cloud radio access networks (C-RANs) by joint remote radio head (RRH) activation and beamforming in the downlink. Unlike most previous works that only consider a static optimization framework with full traffic buffers, we formulate a dynamic optimization problem by explicitly considering the effects of random traffic arrivals and time-varying channel fading. The stochastic formulation can quantify the tradeoff between power consumption and queuing delay. Leveraging on the Lyapunov optimization technique, the stochastic optimization problem can be transformed into a per-slot penalized weighted sum rate maximization problem, which is shown to be non-deterministic polynomial-time hard. Based on the equivalence between the penalized weighted sum rate maximization problem and the penalized weighted minimum mean square error (WMMSE) problem, the group sparse beamforming optimization based WMMSE algorithm and the relaxed integer programming based WMMSE algorithm are proposed to efficiently obtain the joint RRH activation and beamforming policy. Both algorithms can converge to a stationary solution with low-complexity and can be implemented in a parallel manner, thus they are highly scalable to large-scale C-RANs. In addition, these two proposed algorithms provide a flexible and efficient means to adjust the power-delay tradeoff on demand. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01675;Capacity of Systems with Queue-Length Dependent Service Quality; Avhishek Chatterjee,  Daewon Seo,  Lav R. Varshney;  We study the information-theoretic limit of reliable information processing by a server with queue-length dependent quality of service. We define the capacity for such a system as the number of bits reliably processed per unit time, and characterize it in terms of queuing system parameters. We also characterize the distributions of the arrival and service processes that maximize and minimize the capacity of such systems in a discrete-time setting. For arrival processes with at most one arrival per time slot, we observed a minimum around the memoryless distribution. We also studied the case of multiple arrivals per time slot, and observed that burstiness in arrival has adverse effects on the system. The problem is theoretically motivated by an effort to incorporate the notion of reliability in queueing systems, and is applicable in the contexts of crowdsourcing, multimedia communication, and stream computing. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01694;Intracell Interference Characterization and Cluster Inference for D2D  Communication; Hafiz Attaul Mustafa,  Muhammad Zeeshan Shakir,  Ali Riza Ekti,  Muhammad Ali Imran,  Rahim Tafazolli;  The homogeneous poisson point process (PPP) is widely used to model temporal, spatial or both topologies of base stations (BSs) and mobile terminals (MTs). However, negative spatial correlation in BSs, due to strategical deployments, and positive spatial correlations in MTs, due to homophilic relations, cannot be captured by homogeneous spatial PPP (SPPP). In this paper, we assume doubly stochastic poisson process, a generalization of homogeneous PPP, with intensity measure as another stochastic process. To this end, we assume Permanental Cox Process (PCP) to capture positive spatial correlation in MTs. We consider product density to derive closed-form approximation (CFA) of spatial summary statistics. We propose Euler Characteristic (EC) based novel approach to approximate intractable random intensity measure and subsequently derive nearest neighbor distribution function. We further propose the threshold and spatial extent of excursion set of chi-square random field as interference control parameters to select different cluster sizes for device-to-device (D2D) communication. The spatial extent of clusters is controlled by nearest neighbor distribution function which is incorporated into Laplace functional of SPPP to analyze the effect of D2D interfering clusters on average coverage probability of cellular user. The CFA and empirical results are in good agreement and its comparison with SPPP clearly shows spatial correlation between D2D nodes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01698;Coverage gain and Device-to-Device user Density: Stochastic Geometry  Modeling and Analysis; Hafiz Attaul Mustafa,  Muhammad Zeeshan Shakir,  Muhammad Ali Imran,  Ali Imran,  Rahim Tafazolli;  Device-to-device (D2D) communication has huge potential for capacity and coverage enhancements for next generation cellular networks. The number of potential nodes for D2D communication is an important parameter that directly impacts the system capacity. In this paper, we derive analytic expression for average coverage probability of cellular user and corresponding number of potential D2D users. In this context, mature framework of stochastic geometry and Poisson point process has been used. The retention probability has been incorporated in Laplace functional to capture reduced path-loss and shortest distance criterion based D2D pairing. The numerical results show a close match between analytic expression and simulation setup. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01729;Low-Rank Matrix Completion for Topological Interference Management by  Riemannian Pursuit; Yuanming Shi,  Jun Zhang,  Khaled B. Letaief;  In this paper, we present a flexible low-rank matrix completion (LRMC) approach for topological interference management (TIM) in the partially connected K-user interference channel. No channel state information (CSI) is required at the transmitters except the network topology information. The previous attempt on the TIM problem is mainly based on its equivalence to the index coding problem, but so far only a few index coding problems have been solved. In contrast, in this paper, we present an algorithmic approach to investigate the achievable degrees-of-freedom (DoFs) by recasting the TIM problem as an LRMC problem. Unfortunately, the resulting LRMC problem is known to be NP-hard, and the main contribution of this paper is to propose a Riemannian pursuit (RP) framework to detect the rank of the matrix to be recovered by iteratively increasing the rank. This algorithm solves a sequence of fixed-rank matrix completion problems. To address the convergence issues in the existing fixed-rank optimization methods, the quotient manifold geometry of the search space of fixed-rank matrices is exploited via Riemannian optimization. By further exploiting the structure of the low-rank matrix varieties, i.e., the closure of the set of fixed- rank matrices, we develop an efficient rank increasing strategy to find good initial points in the procedure of rank pursuit. Simulation results demonstrate that the proposed RP algorithm achieves a faster convergence rate and higher achievable DoFs for the TIM problem compared with the state-of-the-art methods. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01817;Proof of Threshold Saturation for Spatially Coupled Sparse Superposition  Codes; Jean Barbier,  Mohamad Dia,  Nicolas Macris;  Recently, a new class of codes, called sparse superposition or sparse regression codes, has been proposed for communication over the AWGN channel. It has been proven that they achieve capacity using power allocation and various forms of iterative decoding. Empirical evidence has also strongly suggested that the codes achieve capacity when spatial coupling and approximate message passing decoding are used, without need of power allocation. In this note we prove that state evolution (which tracks message passing) indeed saturates the potential threshold of the underlying code ensemble, which approaches in a proper limit the optimal threshold. Our proof uses ideas developed in the theory of low-density parity-check codes and compressive sensing. ;"Information Theory (cs.IT); Disordered Systems and Neural Networks (cond-mat.dis-nn)"
https://arxiv.org/abs/1603.01819;Type Based Sign Modulation and its Application for ISI mitigation in  Molecular Communication; Reza Mosayebi,  Amin Gohari,  Mahtab Mirmohseni,  Masoumeh Nasiri Kenari;  An important challenge in design of modulation schemes for molecular communication is positivity of the transmission signal (only a positive concentration of molecules can be released in the environment). This restriction makes handling of the InterSymbol Interference (ISI) a challenge for molecular communication. Previous works have proposed use of chemical reactions to remove molecules from the environment, and to effectively simulate negative signals. However, the differential equation describing a diffusion-reaction process is non-linear. This precludes the possibility of using Fourier transform tools. In this paper, a solution for simulating negative signals based on the diffusion-reaction channel model is proposed. While the proposed solution does not exploit the full degrees of freedom available for signaling in a diffusion-reaction process, but its end-to-end system is a linear channel and amenable to Fourier transform analysis. Based on our solution, a modulation scheme and a precoder are introduced and shown to have a significant reduction in error probability compared to previous modulation schemes such as CSK and MCSK. The effect of various imperfections (such as quantization error) on the communication system performance are studied. ;"Information Theory (cs.IT); Emerging Technologies (cs.ET)"
https://arxiv.org/abs/1603.01869;Physical Layer Security for Massive MIMO Systems Impaired by Phase Noise; Jun Zhu,  Robert Schober,  Vijay K. Bhargava;  In this paper, we investigate the impact of phase noise on the secrecy performance of downlink massive MIMO systems in the presence of a passive multiple-antenna eavesdropper. Thereby, for the base station (BS) and the legitimate users, the effect of multiplicative phase noise is taken into account, whereas the eavesdropper is assumed to employ ideal hardware. We derive a lower bound for the ergodic secrecy rate of a given user when matched filter data precoding and artificial noise transmission are employed at the BS. Based on the derived analytical expression, we investigate the impact of the various system parameters on the secrecy rate. Our analytical and simulation results reveal that distributively deployed local oscillators (LOs) can achieve a better performance than one common LO for all BS antennas as long as a sufficient amount of power is assigned for data transmission. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01921;Optimal Geographic Caching in Finite Wireless Networks; Mehrnaz Afshang,  Harpreet S. Dhillon;  Cache-enabled device-to-device (D2D) networks turn memory of the devices at the network edge, such as smart phones and tablets, into bandwidth by enabling asynchronous content sharing directly between proximate devices. Limited storage capacity of the mobile devices necessitates the determination of optimal set of contents to be cached on each device. In order to study the problem of optimal cache placement, we model the locations of devices in a finite region (e.g., coffee shop, sports bar, library) as a uniform binomial point process (BPP). For this setup, we first develop a generic framework to analyze the coverage probability of the target receiver (target-Rx) when the requested content is available at the $k^{th}$ closest device to it. Using this coverage probability result, we evaluate optimal caching probability of the popular content to maximize the total hit probability. Our analysis concretely demonstrates that optimal caching probability strongly depends on the number of simultaneously active devices in the network. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.01926;Millimeter Wave MIMO Channel Estimation using Overlapped Beam Patterns  and Rate Adaptation; Matthew Kokshoorn,  He Chen,  Peng Wang,  Yonghui Li,  Branka Vucetic;  This paper is concerned with the channel estimation problem in Millimeter wave (mmWave) wireless systems with large antenna arrays. By exploiting the inherent sparse nature of the mmWave channel, we first propose a fast channel estimation (FCE) algorithm based on a novel overlapped beam pattern design, which can increase the amount of information carried by each channel measurement and thus reduce the required channel estimation time compared to the existing non-overlapped designs. We develop a maximum likelihood (ML) estimator to optimally extract the path information from the channel measurements. Then, we propose a novel rate-adaptive channel estimation (RACE) algorithm, which can dynamically adjust the number of channel measurements based on the expected probability of estimation error (PEE). The performance of both proposed algorithms is analyzed. For the FCE algorithm, an approximate closed-form expression for the PEE is derived. For the RACE algorithm, a lower bound for the minimum signal energy-to-noise ratio required for a given number of channel measurements is developed based on the Shannon-Hartley theorem. Simulation results show that the FCE algorithm significantly reduces the number of channel estimation measurements compared to the existing algorithms using non-overlapped beam patterns. By adopting the RACE algorithm, we can achieve up to a 6dB gain in signal energy-to-noise ratio for the same PEE compared to the existing algorithms. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01943;Partially Block Markov Superposition Transmission of Gaussian Source  with Nested Lattice Codes; Shancheng Zhao,  Xiao Ma;  This paper studies the transmission of Gaussian sources through additive white Gaussian noise (AWGN) channels in bandwidth expansion regime, i.e., the channel bandwidth is greater than the source bandwidth. To mitigate the error propagation phenomenon of conventional digital transmission schemes, we propose in this paper a new capacity-approaching joint source channel coding (JSCC) scheme based on partially block Markov superposition transmission (BMST) of nested lattice codes. In the proposed scheme, first, the Gaussian source sequence is discretized by a lattice-based quantizer, resulting in a sequence of lattice points. Second, these lattice points are encoded by a short systematic group code. Third, the coded sequence is partitioned into blocks of equal length and then transmitted in the BMST manner. Main characteristics of the proposed JSCC scheme include: 1) Entropy coding is not used explicitly. 2) Only parity-check sequence is superimposed, hence, termed partially BMST (PBMST). This is different from the original BMST. To show the superior performance of the proposed scheme, we present extensive simulation results which show that the proposed scheme performs within 1.0 dB of the Shannon limits. Hence, the proposed scheme provides an attractive candidate for transmission of Gaussian sources. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.01991;A Desired PAR-Achieving Precoder Design for Multi-User MIMO OFDM based  on Concentration of Measure; Hyun-Su Cha,  Dong Ku Kim;  For multi-user multiple-input and multiple-output (MIMO) wireless communications in orthogonal frequency di- vision multiplexing systems, we propose a MIMO precoding scheme providing a desired peak-to-average power ratio (PAR) at the minimum cost that is defined as received SNR degradation. By taking advantage of the concentration of measure, we formulate a convex problem with constraint on the desired PAR. Consequently, the proposed scheme almost exactly achieves the desired PAR on average, and asymptotically attains the desired PAR at the 0.001 point of its complementary cumulative distribution function, as the number of subcarriers increases. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02000;Identifying Randomly Activated Users via Sign-Compute-Resolve on Graphs; Cedomir Stefanovic,  Dejan Vukobratovic,  Jasper Goseling,  Petar Popovski;  In this paper we treat the problem of identification of a subset of active users in a set of a large number of potentially active users. The users from the subset are activated randomly, such that the access point (AP) does not know the subset or its size a priori. The active users are contending to report their activity to the AP over a multiple access channel. We devise a contention algorithm that assumes a combination of physical-layer network coding and K-out-of-N signature coding, allowing for multiple detection of up to K users at the access point. In addition, we rely on the principles of coded slotted ALOHA (CSA) and use of successive interference cancellation to enable subsequent resolution of the collisions that originally featured more than K users. The objective is to identify the subset of active users such that the target performance, e.g., probability of active user resolution and/or throughput is reached, which implies that the duration of the contention period is also not known a priori. In contrast to standard CSA approaches, in the proposed algorithm each user, active or not, has a predefined schedule of slots in which it sends its signature. We analyze the performance of the proposed algorithm both in the asymptotic and non-asymptotic settings. We also derive an estimator that, based on the observation of collision multiplicities, estimates how many users are active and thereby enables tuning of the length of the contention period. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02018;Linear Codes over Galois Ring $GR(p^2,r)$ Related to Gauss sums; Aixian Zhang,  Jin Li,  Keqin Feng;  Linear codes over finite rings become one of hot topics in coding theory after Hommons et al.([4], 1994) discovered that several remarkable nonlinear binary codes with some linear-like properties are the images of Gray map of linear codes over $Z_4$. In this paper we consider two series of linear codes $C(G)$ and $\widetilde{C}(G)$ over Galois ring $R=GR(p^2,r)$, where $G$ is a subgroup of $R^{(s)^*}$ and $R^{(s)}=GR(p^2,rs)$. We present a general formula on $N_\beta(a)$ in terms of Gauss sums on $R^{(s)}$ for each $a\in R$, where $N_\beta(a)$ is the number of a-component of the codeword $c_\beta\in C(G) (\beta\in R^{(s)})$ (Theorem 3.1). We have determined the complete Hamming weight distribution of $C(G)$ and the minimum Hamming distance of $\widetilde{C}(G)$ for some special G (Theorem 3.3 and 3.4). We show a general formula on homogeneous weight of codewords in $C(G)$ and $\widetilde{C}(G)$ (Theorem 4.5) for the special $G$ given in Theorem 3.4. Finally we obtained series of nonlinear codes over $\mathbb{F}_{q} \ (q=p^r)$ with two Hamming distance by using Gray map (Corollary 4.6). ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02034;"Comments on ""Overdemodulation for High-Performance Receivers with  Low-Resolution ADC"""; Tristan Afortiori;  This submission has been withdrawn by arXiv administrators due to misrepresentation of authorship. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02106;Carrier Phase Estimation in Dispersion-Unmanaged Optical Transmission  Systems; Tianhua Xu,  Polina Bayvel,  Tiegen Liu,  Yimo Zhang,  Gunnar Jacobsen,  Jie Li,  Sergei Popov;  The study on carrier phase estimation (CPE) approaches, involving a one-tap normalized least-mean-square (NLMS) algorithm, a block-wise average algorithm, and a Viterbi-Viterbi algorithm has been carried out in the long-haul high-capacity dispersion-unmanaged coherent optical systems. The close-form expressions and analytical predictions for bit-error-rate behaviors in these CPE methods have been analyzed by considering both the laser phase noise and the equalization enhanced phase noise. It is found that the Viterbi-Viterbi algorithm outperforms the one-tap NLMS and the block-wise average algorithms for a small phase noise variance (or effective phase noise variance), while the three CPE methods converge to a similar performance for a large phase noise variance (or effective phase noise variance). In addition, the differences between the three CPE approaches become smaller for higher-level modulation formats. ;"Information Theory (cs.IT); Classical Physics (physics.class-ph); Optics (physics.optics)"
https://arxiv.org/abs/1603.02182;Wireless Information and Power Transfer in Full-Duplex Communication  Systems; Alexander A. Okandeji,  Muhammad R. A. Khandaker,  Kai-Kit Wong;  This paper considers the problem of maximizing the sum-rate for simultaneous wireless information and power transfer (SWIPT) in a full-duplex bi-directional communication system subject to energy harvesting and transmit power constraints at both nodes. We investigate the optimum design of the receive power splitters and transmit powers for SWIPT in full-duplex mode. Exploiting rate-split method, an iterative algorithm is derived to solve the non-convex problem. The effectiveness of the proposed algorithm is justified through numerical simulations. ;"Information Theory (cs.IT); Emerging Technologies (cs.ET)"
https://arxiv.org/abs/1603.02344;Optimal Link Adaptation for Multicarrier Communication Systems; Ebrahim Bedeer;  Link adaptation is the terminology used to describe techniques that improve multicarrier communication systems performance by dynamically adapting the transmission parameters, i.e., transmit power and number of bits per subcarrier, to the changing quality of the wireless link. The research literature has focused on single objective optimization techniques to optimize the multicarrier communication systems performance, e.g., maximizing the throughput/capacity or minimizing the transmit power subject to a set of constraints. In this dissertation, we adopt a novel optimization concept, namely multiobjective optimization, where our objective is to simultaneously optimize the conflicting and incommensurable throughput and power objectives. More specifically, in some of the following Chapters, we propose novel algorithms that jointly maximize the multicarrier system throughput and minimize its total transmit power subject to quality-of-service, total transmit power, and maximum allocated bits per subcarrier constraints. The proposed algorithms require prior knowledge about the importance of the competing objective functions in terms of pre-determined weighting coefficients, or they can adapt the weighting coefficients during the solution process while meeting the constraints, in order to reduce the computational complexity. Simulation results show significant performance gains in terms of the achieved throughput and transmit power when compared to single optimization approaches, at the cost of no additional complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02365;On the Polar Code Encoding in Fading Channels; Rui Deng,  Liping Li,  Yanjun Hu;  Besides the determined construction of polar codes in BEC channels, different construction techniques have been proposed for AWGN channels. The current state-of-the-art algorithm starts with a design-SNR (or an operating SNR) and then processing is carried out to approximate each individual bit channel. However, as found in this paper, for fading channels, an operating SNR can not be directly used in approximating the bit channels. To achieve a better BER performance, the input SNR for the polar code construction in fadding channels is derived. A selection of the design-SNR for both the AWGN and the fading channels from an information theoretical point of view is studied. Also presented in this paper is the study of sacrificing a small data rate to gain orders of magnitude increase in the BER performance. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02366;Local Partial Clique Covers for Index Coding; Abhishek Agarwal,  Arya Mazumdar;  Index coding, or broadcasting with side information, is a network coding problem of most fundamental importance. In this problem, given a directed graph, each vertex represents a user with a need of information, and the neighborhood of each vertex represents the side information availability to that user. The aim is to find an encoding to minimum number of bits (optimal rate) that, when broadcasted, will be sufficient to the need of every user. Not only the optimal rate is intractable, but it is also very hard to characterize with some other well-studied graph parameter or with a simpler formulation, such as a linear program. Recently there have been a series of works that address this question and provide explicit schemes for index coding as the optimal value of a linear program with rate given by well-studied properties such as local chromatic number or partial clique-covering number. There has been a recent attempt to combine these existing notions of local chromatic number and partial clique covering into a unified notion denoted as the local partial clique cover (Arbabjolfaei and Kim, 2014). We present a generalized novel upper-bound (encoding scheme) - in the form of the minimum value of a linear program - for optimal index coding. Our bound also combines the notions of local chromatic number and partial clique covering into a new definition of the local partial clique cover, which outperforms both the previous bounds, as well as beats the previous attempt to combination. Further, we look at the upper bound derived recently by Thapa et al., 2015, and extend their $n$-$\mathsf{GIC}$ (Generalized Interlinked Cycle) construction to $(k,n)$-$\mathsf{GIC}$ graphs, which are a generalization of $k$-partial cliques. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02388;Efficient Optimal Joint Channel Estimation and Data Detection for  Massive MIMO Systems; Haider Ali Jasim Alshamary,  Weiyu Xu;  In this paper, we propose an efficient optimal joint channel estimation and data detection algorithm for massive MIMO wireless systems. Our algorithm is optimal in terms of the generalized likelihood ratio test (GLRT). For massive MIMO systems, we show that the expected complexity of our algorithm grows polynomially in the channel coherence time. Simulation results demonstrate significant performance gains of our algorithm compared with suboptimal non-coherent detection algorithms. To the best of our knowledge, this is the first algorithm which efficiently achieves GLRT-optimal non-coherent detections for massive MIMO systems with general constellations. ;"Information Theory (cs.IT); Optimization and Control (math.OC)"
https://arxiv.org/abs/1603.02491;Effective Capacity in Broadcast Channels with Arbitrary Inputs; Marwan Hammouda,  Sami Akin,  Jürgen Peissig;  We consider a broadcast scenario where one transmitter communicates with two receivers under quality-of-service constraints. The transmitter initially employs superposition coding strategies with arbitrarily distributed signals and sends data to both receivers. Regarding the channel state conditions, the receivers perform successive interference cancellation to decode their own data. We express the effective capacity region that provides the maximum allowable sustainable data arrival rate region at the transmitter buffer or buffers. Given an average transmission power limit, we provide a two-step approach to obtain the optimal power allocation policies that maximize the effective capacity region. Then, we characterize the optimal decoding regions at the receivers in the space spanned by the channel fading power values. We finally substantiate our results with numerical presentations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02558;Multidimensional factorization through helical mapping; Francesca Raimondi,  Pierre Comon,  Olivier Michel,  Umberto Spagnolini;  This paper proposes a new perspective on the problem of multidimensional spectral factorization, through helical mapping: $d$-dimensional ($d$D) data arrays are vectorized, processed by $1$D cepstral analysis and then remapped onto the original space. Partial differential equations (PDEs) are the basic framework to describe the evolution of physical phenomena. We observe that the minimum phase helical solution asymptotically converges to the $d$D semi-causal solution, and allows to decouple the two solutions arising from PDEs describing physical systems. We prove this equivalence in the theoretical framework of cepstral analysis, and we also illustrate the validity of helical factorization through a $2$D wave propagation example and a $3$D application to helioseismology. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02651;Resource Sharing in 5G mmWave Cellular Networks; Mattia Rebato,  Marco Mezzavilla,  Sundeep Rangan,  Michele Zorzi;  In this paper, we discuss resource sharing, a key dimension in mmWave network design in which spectrum, access and/or network infrastructure resources can be shared by multiple operators. It is argued that this sharing paradigm will be essential to fully exploit the tremendous amounts of bandwidth and the large number of antenna degrees of freedom available in these bands, and to provide statistical multiplexing to accommodate the highly variable nature of the traffic. In this paper, we investigate and compare various sharing configurations in order to capture the enhanced potential of mmWave communications. Our results reflect both the technical and the economical aspects of the various sharing paradigms. We deliver a number of key insights, corroborated by detailed simulations, which include an analysis of the effects of the distinctive propagation characteristics of the mmWave channel, along with a rigorous multi-antenna characterization. Key findings of this study include (i) the strong dependence of the comparative results on channel propagation and antenna characteristics, and therefore the need to accurately model them, and (ii) the desirability of a full spectrum and infrastructure sharing configuration, which may result in increased user rate as well as in economical advantages for both service provider. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.02701;Transport Layer Performance in 5G mmWave Cellular; Menglei Zhang,  Marco Mezzavilla,  Russell Ford,  Sundeep Rangan,  Shivendra Panwar,  Evangelos Mellios,  Di Kong,  Andrew Nix,  Michele Zorzi;  The millimeter wave (mmWave) bands are likely to play a significant role in next generation cellular systems due to the possibility of very high throughput thanks to the availability of massive bandwidth and high-dimensional antennas. Especially in Non-Line-of-Sight conditions, significant variations in the received RF power can occur as a result of the scattering from nearby building and terrain surfaces. Scattering objects come and go as the user moves through the local environment. At the higher end of the mmWave band, rough surface scatter generates cluster-based small-scale fading, where signal levels can vary by more than 20 dB over just a few wavelengths. This high level of channel variability may present significant challenges for congestion control. Using our recently developed end-to-end mmWave ns3-based framework, this paper presents the first performance evaluation of TCP congestion control in next-generation mmWave networks. Importantly, the framework can incorporate detailed models of the mmWave channel, beam- forming and tracking algorithms, and builds on statistical channel models derived from real measurements in New York City, as well as detailed ray traces. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02734;Codebook Design for Millimeter-Wave Channel Estimation with Hybrid  Precoding Structure; Zhenyu Xiao,  Pengfei Xia,  Xiang-Gen Xia;  In this paper, we study hierarchical codebook design for channel estimation in millimeter-wave (mmWave) communications with a hybrid precoding structure. Due to the limited saturation power of mmWave power amplifier (PA), we take the per-antenna power constraint (PAPC) into consideration. We first propose a metric, i.e., generalized detection probability (GDP), to evaluate the quality of \emph{an arbitrary codeword}. This metric not only enables an optimization approach for mmWave codebook design, but also can be used to compare the performance of two different codewords/codebooks. To the best of our knowledge, GDP is the first metric particularly for mmWave codebook design for channel estimation. We then propose an approach to design a hierarchical codebook exploiting BeaM Widening with Multi-RF-chain Sub-array technique (BMW-MS). To obtain crucial parameters of BMW-MS, we provide two solutions, namely a low-complexity search (LCS) solution to optimize the GDP metric and a closed-form (CF) solution to pursue a flat beam pattern. Performance comparisons show that BMW-MS/LCS and BMW-MS/CF achieve very close performances, and they outperform the existing alternatives under the PAPC. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02780;A Novel Design of Linear Phase Non-uniform Digital Filter Banks; Sakthivel V,  Elizabeth Elias;  In many applications such as wireless communications and subband adaptive filtering, we need to design non-uniform filter banks (NUFB), which may lead to better performances and reduced hardware complexity when compared to uniform filter bank. NUFB satisfying linear phase property for all the constituent filters, are desirable in applications such as speech and image processing and in communication. This paper proposes a novel design of non-uniform modified discrete fourier transform filter bank (MDFT FB). Here, each non-uniform channel is obtained by merging the nearby channels of a uniform MDFT FB. The reported works of non-uniform cosine modulated filter banks (CMFBs) do not satisfy linear phase property for all the constituent filters. In this work, we introduce the design of a non-uniform MDFT FB which satisfies linear phase property for all the constituent filters. The proposed design of the non-uniform MDFT FB is checked utilizing the alias cancellation among the channels, distortion and flatness condition of the channels. A condition is derived to find the channels when merged with adjacent channels, will cause aliasing in M channels. In the design and implementation of the proposed non-uniform MDFT FB, the structure of the uniform MDFT filter bank is preserved and hence all the advantages of MDFT FB over the DFT filter bank, are guaranteed. Hence without increasing the design complexity, the non-uniform MDFT FB is designed. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02863;LDA Lattices Without Dithering Achieve Capacity on the Gaussian Channel; Nicola di Pietro,  Gilles Zémor,  Joseph J. Boutros;  This paper deals with Low-Density Construction-A (LDA) lattices, which are obtained via Construction A from non-binary Low-Density Parity-Check codes. More precisely, a proof is provided that Voronoi constellations of LDA lattices achieve the capacity of the AWGN channel under lattice encoding and decoding. This is obtained after showing the same result for more general Construction-A lattice constellations. The theoretical analysis is carried out in a way that allows to describe how the prime number underlying Construction A behaves as a function of the lattice dimension. Moreover, no dithering is required in the transmission scheme, simplifying some previous solutions of the problem. Remarkably, capacity is achievable with LDA lattice codes whose parity-check matrices have constant row and column Hamming weights. Some expansion properties of random bipartite graphs constitute an extremely important tool for dealing with sparse matrices and allow to find a lower bound of the minimum Euclidean distance of LDA lattices in our ensemble. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.02895;Performance Analysis of Multi-Hop Underwater Wireless Optical  Communication Systems (Extended Version); Mohammad Vahid Jamali,  Ata Chizari,  Jawad A. Salehi;  In this paper, we evaluate the end-to-end bit error rate (BER) of point-to-point underwater wireless optical communication (UWOC) systems with multi-hop transmission. To do so, we analytically derive the BER expression of a single-hop UWOC link as the building block for end-to-end BER evaluation. We also apply photon-counting method to evaluate the system BER in the presence of shot noise. Moreover, we use Gauss-Hermite quadrature formula to obtain the closed-form solutions for the system BER in the case of log-normal underwater fading channels. Our analytical treatment involves all the impairing effects of the underwater optical channel, namely absorption, scattering and fading. Numerical results demonstrate that multi-hop transmission by alleviating the aforementioned impairing effects of the channel, can significantly improve the system performance and extend the viable end-to-end communication distance. For example, dual-hop transmission in $22.5$ m and $45$ m coastal water links can provide $17.5$ dB and $39$ dB performance enhancement at the BER of $10^{-6}$, respectively. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03133;Energy-Efficient Packet Scheduling with Finite Blocklength Codes:  Convexity Analysis and Efficient Algorithms; Shengfeng Xu,  Tsung-Hui Chang,  Shih-Chun Lin,  Chao Shen,  Gang Zhu;  This paper considers an energy-efficient packet scheduling problem over quasi-static block fading channels. The goal is to minimize the total energy for transmitting a sequence of data packets under the first-in-first-out rule and strict delay constraints. Conventionally, such design problem is studied under the assumption that the packet transmission rate can be characterized by the classical Shannon capacity formula, which, however, may provide inaccurate energy consumption estimation, especially when the code blocklength is finite. In this paper, we formulate a new energy-efficient packet scheduling problem by adopting a recently developed channel capacity formula for finite blocklength codes. The newly formulated problem is fundamentally more challenging to solve than the traditional one because the transmission energy function under the new channel capacity formula neither can be expressed in closed form nor possesses desirable monotonicity and convexity in general. We analyze conditions on the code blocklength for which the transmission energy function is monotonic and convex. Based on these properties, we develop efficient offline packet scheduling algorithms as well as a rolling-window based online algorithm for real-time packet scheduling. Simulation results demonstrate not only the efficacy of the proposed algorithms but also the fact that the traditional design using the Shannon capacity formula can considerably underestimate the transmission energy for reliable communications. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03152;Noisy Index Coding with PSK and QAM; Anjana A. Mahesh,  B. Sundar Rajan;"  Noisy index coding problems over AWGN channel are considered. For a given index coding problem and a chosen scalar linear index code of length $N$, we propose to transmit the $N$ index coded bits as a single signal from a $2^N$- PSK constellation. By transmitting the index coded bits in this way, there is an $N/2$ - fold reduction in the bandwidth consumed. Also, receivers with side information satisfying certain conditions get coding gain relative to a receiver with no side information. This coding gain is due to proper utilization of their side information and hence is called ""PSK side information coding gain (PSK-SICG)"". A necessary and sufficient condition for a receiver to get PSK-SICG is presented. An algorithm to map the index coded bits to PSK signal set such that the PSK-SICG obtained is maximized for the receiver with maximum side information is given. We go on to show that instead of transmitting the $N$ index coded bits as a signal from $2^N$- PSK, we can as well transmit them as a signal from $2^N$- QAM and all the results including the necessary and sufficient condition to get coding gain holds. We prove that sending the index coded bits as a QAM signal is better than sending them as a PSK signal when the receivers see an effective signal set of eight points or more. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.03248;On Energy Cooperation in Energy Harvesting Underlay Cognitive Radio  Network; Kalpant Pathak,  Adrish Banerjee;  In this paper, we consider an energy harvesting cognitive radio network (EH-CRN), where a primary and a secondary user coexist in underlay mode. Both the transmitters have energy harvesting capability and are equipped with finite capacity battery to store the harvested energy. In addition, the secondary user (SU) has an independent energy transfer unit such that it can transfer some portion of it's harvested energy to the primary user (PU). We obtain an optimal transmit power and energy transfer policy for single-slot and a suboptimal policy for multi-slot scenario maximizing the number of bits transmitted by SU under the primary sum-rate constraint in an offline setting. For both cases, the effect of energy cooperation on the system performance is studied and it is observed that energy cooperation results in higher SU throughput. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03330;Filter Banks on Discrete Abelian Groups; Antonio Garcia Garcia,  Miguel Angel Hernandez-Medina,  Gerardo Perez-Villalon;  In this work we provide polyphase, modulation, and frame theoretical analyses of a filter bank on a discrete abelian group. Thus, multidimensional or cyclic filter banks as well as filter banks for signals in $\ell^2(\mathbb{Z}^d\times \mathbb{Z}_s)$ or $\ell^2(\mathbb{Z}_r \times \mathbb{Z}_s)$ spaces are studied in a unified way. We obtain perfect reconstruction conditions and the corresponding frame bounds. ;"Information Theory (cs.IT); Functional Analysis (math.FA)"
https://arxiv.org/abs/1603.03357;Cognitive Green Radio for Energy-Aware Communications; Malek Naoues,  Quentin Bodinier,  Jacques Palicot;  In 5G networks, the number of connected devices, data rate and data volume per area, as well as the variety of QoS requirements, will attain unprecedented scales. The achievement of these goals will rely on new technologies and disruptive changes in network architecture and node design. Energy efficiency is believed to play a key role in complementing the 5G technologies and optimizing their deployment, dynamic configuration and management [1]. Within the framework of green communications and networks, especially for next-generation green cellular radio access networks, the GREAT (Green Cognitive Radio for Energy-Aware wireless communication Technologies evolution) initiative, a CominLabs Excellence Center (Laboratoire d'Excellence) and Universit\'e Europ\'eenne de Bretagne (UEB)project, has mainly addressed the fundamental issues of energy efficiency from various perspectives and angles, leveraging on cognitive techniques, at networking level as well as at thephysical layer level. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.03389;On the Effects of Battery Imperfections in an Energy Harvesting Device; Alessandro Biason,  Michele Zorzi;  Energy Harvesting allows the devices in a Wireless Sensor Network to recharge their batteries through environmental energy sources. While in the literature the main focus is on devices with ideal batteries, in reality several inefficiencies have to be considered to correctly design the operating regimes of an Energy Harvesting Device (EHD). In this work we describe how the throughput optimization problem changes under \emph{real battery} constraints in an EHD. In particular, we consider imperfect knowledge of the state of charge of the battery and storage inefficiencies, \emph{i.e.}, part of the harvested energy is wasted in the battery recharging process. We formulate the problem as a Markov Decision Process, basing our model on some realistic observations about transmission, consumption and harvesting power. We find the performance upper bound with a real battery and numerically discuss the novelty introduced by the real battery effects. We show that using the \emph{old} policies obtained without considering the real battery effects is strongly sub-optimal and may even result in zero throughput. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03448;Optimized Sensor Collaboration for Estimation of Temporally Correlated  Parameters; Sijia Liu,  Swarnendu Kar,  Makan Fardad,  Pramod K. Varshney;  In this paper, we aim to design the optimal sensor collaboration strategy for the estimation of time-varying parameters, where collaboration refers to the act of sharing measurements with neighboring sensors prior to transmission to a fusion center. We begin by addressing the sensor collaboration problem for the estimation of uncorrelated parameters. We show that the resulting collaboration problem can be transformed into a special nonconvex optimization problem, where a difference of convex functions carries all the nonconvexity. This specific problem structure enables the use of a convex-concave procedure to obtain a near-optimal solution. When the parameters of interest are temporally correlated, a penalized version of the convex-concave procedure becomes well suited for designing the optimal collaboration scheme. In order to improve computational efficiency, we further propose a fast algorithm that scales gracefully with problem size via the alternating direction method of multipliers. Numerical results are provided to demonstrate the effectiveness of our approach and the impact of parameter correlation and temporal dynamics of sensor networks on estimation performance. ;"Information Theory (cs.IT); Applications (stat.AP)"
https://arxiv.org/abs/1603.03464;Recovery of signals under the high order RIP condition via prior support  information; Wengu Chen,  Yaling Li;  In this paper we study the recovery conditions of weighted $l_{1}$ minimization for signal reconstruction from incomplete linear measurements when partial prior support information is available. We obtain that a high order RIP condition can guarantee stable and robust recovery of signals in bounded $l_{2}$ and Dantzig selector noise settings. Meanwhile, we not only prove that the sufficient recovery condition of weighted $l_{1}$ minimization method is weaker than that of standard $l_{1}$ minimization method, but also prove that weighted $l_{1}$ minimization method provides better upper bounds on the reconstruction error in terms of the measurement noise and the compressibility of the signal, provided that the accuracy of prior support estimate is at least $50\%$. Furthermore, the condition is proved sharp. ;"Information Theory (cs.IT); Classical Analysis and ODEs (math.CA); Functional Analysis (math.FA)"
https://arxiv.org/abs/1603.03465;Recovery of signals under the condition on RIC and ROC via prior support  information; Wengu Chen,  Yaling Li;  In this paper, the sufficient condition in terms of the RIC and ROC for the stable and robust recovery of signals in both noiseless and noisy settings was established via weighted $l_{1}$ minimization when there is partial prior information on support of signals. An improved performance guarantee has been derived. We can obtain a less restricted sufficient condition for signal reconstruction and a tighter recovery error bound under some conditions via weighted $l_{1}$ minimization. When prior support estimate is at least $50\%$ accurate, the sufficient condition is weaker than the analogous condition by standard $l_{1}$ minimization method, meanwhile the reconstruction error upper bound is provably to be smaller under additional conditions. Furthermore, the sufficient condition is also proved sharp. ;"Information Theory (cs.IT); Classical Analysis and ODEs (math.CA); Functional Analysis (math.FA)"
https://arxiv.org/abs/1603.03520;On Euclidean and Hermitian Self-Dual Cyclic Codes over  $\mathbb{F}_{2^r}$; Odessa D. Consorte,  Lilibeth D. Valdez;  Cyclic and self-dual codes are important classes of codes in coding theory. Jia, Ling and Xing \cite{Jia} as well as Kai and Zhu \cite{Kai} proved that Euclidean self-dual cyclic codes of length $n$ over $\mathbb{F}_q$ exist if and only if $n$ is even and $q=2^r$, where $r$ is any positive integer. For $n$ and $q$ even, there always exists an $[n, \frac{n}{2}]$ self-dual cyclic code with generator polynomial $x^{\frac{n}{2}}+1$ called the \textit{trivial self-dual cyclic code}. In this paper we prove the existence of nontrivial self-dual cyclic codes of length $n=2^\nu \cdot \bar{n}$, where $\bar{n}$ is odd, over $\mathbb{F}_{2^r}$ in terms of the existence of a nontrivial splitting $(Z, X_0, X_1)$ of $\mathbb{Z}_{\bar{n}}$ by $\mu_{-1}$, where $Z, X_0,X_1$ are unions of $2^r$-cyclotomic cosets mod $\bar{n}.$ We also express the formula for the number of cyclic self-dual codes over $\mathbb{F}_{2^r}$ for each $n$ and $r$ in terms of the number of $2^r$-cyclotomic cosets in $X_0$ (or in $X_1$). We also look at Hermitian self-dual cyclic codes and show properties which are analogous to those of Euclidean self-dual cyclic codes. That is, the existence of nontrivial Hermitian self-dual codes over $\mathbb{F}_{2^{2 \ell}}$ based on the existence of a nontrivial splitting $(Z, X_0, X_1)$ of $\mathbb{Z}_{\bar{n}}$ by $\mu_{-2^\ell}$, where $Z, X_0,X_1$ are unions of $2^{2 \ell}$-cyclotomic cosets mod $\bar{n}.$ We also determine the lengths at which nontrivial Hermitian self-dual cyclic codes exist and the formula for the number of Hermitian self-dual cyclic codes for each $n$. ;"Information Theory (cs.IT); Number Theory (math.NT)"
https://arxiv.org/abs/1603.03551;The three primary colors of mobile systems; Hui Liu,  Zhiyong Chen,  Liang Qian;"  In this paper, we present the notion of ""mobile 3C systems in which the ""Communications"", ""Computing"", and ""Caching"" (i.e., 3C) make up the three primary resources/funcationalties, akin to the three primary colors, for a mobile system. We argue that in future mobile networks, the roles of computing and caching are as intrinsic and essential as communications, and only the collective usage of these three primary resources can support the sustainable growth of mobile systems. By defining the 3C resources in their canonical forms, we reveal the important fact that ""caching"" affects the mobile system performance by introducing non-causality into the system, whereas ""computing"" achieves capacity gains by performing logical operations across mobile system entities. Many existing capacity-enhancing techniques such as coded multicast, collaborative transmissions, and proactive content pushing can be cast into the native 3C framework for analytical tractability. We further illustrate the mobile 3C concepts with practical examples, including a system on broadcast-unicast convergence for massive media content delivery. The mobile 3C design paradigm opens up new possibilities as well as key research problems bearing academic and practice significance. ";"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1603.03600;Artificial-Noise Aided Secure Transmission in Large Scale Spectrum  Sharing Networks; Yansha Deng,  Lifeng Wang,  Syed Ali Raza Zaidi,  Jinhong Yuan,  Maged Elkashlan;  We investigate beamforming and artificial noise generation at the secondary transmitters to establish secure transmission in large scale spectrum sharing networks,where multiple non-colluding eavesdroppers attempt to intercept the secondary transmission. We develop a comprehensive analytical framework to accurately assess the secrecy performance under the primary users' quality of service constraint. Our aim is to characterize the impact of beamforming and artificial noise generation on this complex large scale network. We first derive exact expressions for the average secrecy rate and the secrecy outage probability.We then derive an easy-to-evaluate asymptotic average secrecy rate and asymptotic secrecy outage probability when the number of antennas at the secondary transmitter goes to infinity. Our results show that the equal power allocation between the useful signal and artificial noise is not always the best strategy to achieve maximum average secrecy rate in large scale spectrum sharing networks. Another interesting observation is that the advantage of beamforming and artificial noise generation over beamforming on the average secrecy rate is lost when the aggregate interference from the primary and secondary transmitters is strong, such that it overtakes the effect of the generated artificial noise. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03695;Energy Harvesting Communication System with SOC-Dependent Energy Storage  Losses; Alessandro Biason,  Michele Zorzi;  The popularity of Energy Harvesting Devices (EHDs) has grown in the past few years, thanks to their capability of prolonging the network lifetime. In reality, EHDs are affected by several inefficiencies, e.g., energy leakage, battery degradation or storage losses. In this work we consider an energy harvesting transmitter with storage inefficiencies. In particular, we assume that when new energy has to be stored in the battery, part of this is wasted and the losses depend upon the current state of charge of the device. This is a practical realistic assumption, e.g., for a capacitor, that changes the structure of the optimal transmission policy. We analyze the throughput maximization problem with a dynamic programming approach and prove that, given the battery status and the channel gain, the optimal transmission policy is deterministic. We derive numerical results for the energy losses in a capacitor and show the presence of a \emph{loop effect} that degrades the system performance if the optimal policy is not considered. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03697;Subsampling for Graph Power Spectrum Estimation; Sundeep Prabhakar Chepuri,  Geert Leus;  In this paper we focus on subsampling stationary random processes that reside on the vertices of undirected graphs. Second-order stationary graph signals are obtained by filtering white noise and they admit a well-defined power spectrum. Estimating the graph power spectrum forms a central component of stationary graph signal processing and related inference tasks. We show that by sampling a significantly smaller subset of vertices and using simple least squares, we can reconstruct the power spectrum of the graph signal from the subsampled observations, without any spectral priors. In addition, a near-optimal greedy algorithm is developed to design the subsampling scheme. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.03898;On the Capacity and Performance of Generalized Spatial Modulation; T. Lakshmi Narasimhan,  A. Chockalingam;  Generalized spatial modulation (GSM) uses $N$ antenna elements but fewer radio frequency (RF) chains ($R$) at the transmitter. Spatial modulation and spatial multiplexing are special cases of GSM with $R=1$ and $R=N$, respectively. In GSM, apart from conveying information bits through $R$ modulation symbols, information bits are also conveyed through the indices of the $R$ active transmit antennas. In this paper, we derive lower and upper bounds on the the capacity of a ($N,M,R$)-GSM MIMO system, where $M$ is the number of receive antennas. Further, we propose a computationally efficient GSM encoding (i.e., bits-to-signal mapping) method and a message passing based low-complexity detection algorithm suited for large-scale GSM-MIMO systems. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04020;Statistical Distribution of Intensity Fluctuations for Underwater  Wireless Optical Channels in the Presence of Air Bubbles; Mohammad Vahid Jamali,  Pirazh Khorramshahi,  Arvin Tashakori,  Ata Chizari,  Shadi Shahsavari,  Sajjad AbdollahRamezani,  Masoome Fazelian,  Sima Bahrani,  Jawad A. Salehi;  In this paper, we experimentally investigate the statistical distribution of intensity fluctuations for underwater wireless optical channels under different channel conditions, namely fresh and salty underwater channels with and without air bubbles. To do so, we first measure the received optical signal with a large number of samples. Based on the normalized acquired data the channel coherence time and the fluctuations probability density function (PDF) are obtained for different channel scenarios. Our experimental results show that salt attenuates the received signal while air bubbles mainly introduce severe intensity fluctuations. Moreover, we observe that log-normal distribution precisely fits the acquired data PDF for scintillation index ($\sigma^2_I$) values less than $0.1$, while Gamma-Gamma and K distributions aptly predict the intensity fluctuations for $\sigma^2_I>1$. Since neither of these distributions are capable of predicting the received irradiance for $0.1<\sigma^2_I<1$, we propose a combination of an exponential and a log-normal distributions to perfectly describe the acquired data PDF for such regimes of scintillation index. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04055;Construction of cyclic DNA codes over the Ring $\Z_4[u]/\langle u^2-1  \rangle $ Based on the deletion distance; Sukhamoy Pattanayak,  Abhay Kumar Singh;  In this paper, we develop the theory for constructing DNA cyclic codes of odd length over $R=\Z_4[u]/\langle u^2-1 \rangle$ based on the deletion distance. Firstly, we relate DNA pairs with a special 16 elements of ring $R$. Cyclic codes of odd length over $R$ satisfy the reverse constraint and the reverse-complement constraint are discussed in this paper. We also study the $GC$-content of these codes and their deletion distance. The paper concludes with some examples of cyclic DNA codes with $GC$-content and their respective deletion distance. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04079;Indoor 5G 3GPP-like Channel Models for Office and Shopping Mall  Environments; Katsuyuki Haneda,  Lei Tian,  Henrik Asplund,  Jian Li,  Yi Wang,  David Steer,  Clara Li,  Tommaso Balercia,  Sunguk Lee,  YoungSuk Kim,  Amitava Ghosh,  Timothy Thomas,  Takehiro Nakamura,  Yuichi Kakishima,  Tetsuro Imai,  Haralabos Papadopoulas,  Theodore S. Rappaport,  George R. MacCartney Jr.,  Mathew K. Samimi,  Shu Sun,  Ozge Koymen,  Sooyoung Hur,  Jeongho Park,  Charlie Zhang,  Evangelos Mellios,  Andreas F. Molisch,  Saeed S. Ghassamzadah,  Arun Ghosh;  Future mobile communications systems are likely to be very different to those of today with new service innovations driven by increasing data traffic demand, increasing processing power of smart devices and new innovative applications. To meet these service demands the telecommunications industry is converging on a common set of 5G requirements which includes network speeds as high as 10 Gbps, cell edge rate greater than 100 Mbps, and latency of less than 1 msec. To reach these 5G requirements the industry is looking at new spectrum bands in the range up to 100 GHz where there is spectrum availability for wide bandwidth channels. For the development of new 5G systems to operate in bands up to 100 GHz there is a need for accurate radio propagation models which are not addressed by existing channel models developed for bands below 6 GHz. This paper presents a preliminary overview of the 5G channel models for bands up to 100 GHz in indoor offices and shopping malls, derived from extensive measurements across a multitude of bands. These studies have found some extensibility of the existing 3GPP models to the higher frequency bands up to 100 GHz. The measurements indicate that the smaller wavelengths introduce an increased sensitivity of the propagation models to the scale of the environment and show some frequency dependence of the path loss as well as increased occurrence of blockage. Further, the penetration loss is highly dependent on the material and tends to increase with frequency. The small-scale characteristics of the channel such as delay spread and angular spread and the multipath richness is somewhat similar over the frequency range, which is encouraging for extending the existing 3GPP models to the wider frequency range. Further work will be carried out to complete these models, but this paper presents the first steps for an initial basis for the model development. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04142;Turbo-Equalization Using Partial Gaussian Approximation; Chuanzong Zhang,  Zhongyong Wang,  Carles Navarro Manchón,  Peng Sun,  Qinghua Guo,  Bernard Henri Fleury;  This paper deals with turbo-equalization for coded data transmission over intersymbol interference (ISI) channels. We propose a message-passing algorithm that uses the expectation-propagation rule to convert messages passed from the demodulator-decoder to the equalizer and computes messages returned by the equalizer by using a partial Gaussian approximation (PGA). Results from Monte Carlo simulations show that this approach leads to a significant performance improvement compared to state-of-the-art turbo-equalizers and allows for trading performance with complexity. We exploit the specific structure of the ISI channel model to significantly reduce the complexity of the PGA compared to that considered in the initial paper proposing the method. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04163;A BP-MF-EP Based Iterative Receiver for Joint Phase Noise Estimation,  Equalization and Decoding; Wei Wang,  Zhongyong Wang,  Chuanzong Zhang,  Qinghua Guo,  Peng Sun,  Xingye Wang;  In this work, with combined belief propagation (BP), mean field (MF) and expectation propagation (EP), an iterative receiver is designed for joint phase noise (PN) estimation, equalization and decoding in a coded communication system. The presence of the PN results in a nonlinear observation model. Conventionally, the nonlinear model is directly linearized by using the first-order Taylor approximation, e.g., in the state-of-the-art soft-input extended Kalman smoothing approach (soft-in EKS). In this work, MF is used to handle the factor due to the nonlinear model, and a second-order Taylor approximation is used to achieve Gaussian approximation to the MF messages, which is crucial to the low-complexity implementation of the receiver with BP and EP. It turns out that our approximation is more effective than the direct linearization in the soft-in EKS with similar complexity, leading to significant performance improvement as demonstrated by simulation results. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04172;Optimal Estimation via Nonanticipative Rate Distortion Function and  Applications to Time-Varying Gauss-Markov Processes; Photios A. Stavrou,  Themistoklis Charalambous,  Charalambos D. Charalambous,  Sergey Loyka;  In this paper, we develop {finite-time horizon} causal filters using the nonanticipative rate distortion theory. We apply the {developed} theory to {design optimal filters for} time-varying multidimensional Gauss-Markov processes, subject to a mean square error fidelity constraint. We show that such filters are equivalent to the design of an optimal \texttt{\{encoder, channel, decoder\}}, which ensures that the error satisfies {a} fidelity constraint. Moreover, we derive a universal lower bound on the mean square error of any estimator of time-varying multidimensional Gauss-Markov processes in terms of conditional mutual information. Unlike classical Kalman filters, the filter developed is characterized by a reverse-waterfilling algorithm, which ensures {that} the fidelity constraint is satisfied. The theoretical results are demonstrated via illustrative examples. ;"Information Theory (cs.IT); Dynamical Systems (math.DS); Optimization and Control (math.OC)"
https://arxiv.org/abs/1603.04174;On Nyquist-Shannon Theorem with one-sided half of sampling sequence; Nikolai Dokuchaev;  The classical sampling Nyquist-Shannon-Kotelnikov theorem states that a band-limited continuous time function can be uniquely recovered without error from a infinite two-sided sampling series taken with a sufficient frequency. This short note shows that the function can be recovered from any one-sided semi-infinite half of any oversampling series, with the same boundary for admissible frequencies as in the classical theorem. ;"Information Theory (cs.IT); Spectral Theory (math.SP)"
https://arxiv.org/abs/1603.04290;Secrecy Sum Rate Maximization in Non-Orthogonal Multiple Access; Yi Zhang,  Hui-Ming Wang,  Qian Yang,  Zhiguo Ding;  Non-orthogonal multiple access (NOMA) has been recognized as a promising technique for providing high data rates in 5G systems. This letter is to study physical layer security in a single-input single-output (SISO) NOMA system consisting of a transmitter, multiple legitimate users and an eavesdropper. The aim of this letter is to maximize the secrecy sum rate (SSR) of the NOMA system subject to the users' quality of service (QoS) requirements. We firstly identify the feasible region of the transmit power for satisfying all users' QoS requirements. Then we derive the closed-form expression of an optimal power allocation policy that maximizes the SSR. Numerical results are provided to show a significant SSR improvement by NOMA compared with conventional orthogonal multiple access (OMA). ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04341;Wireless Content Caching for Small Cell and D2D Networks; Maria Gregori,  Jesús Gómez-Vilardebó,  Javier Matamoros,  Deniz Gündüz;  The fifth generation wireless networks must provide fast and reliable connectivity while coping with the ongoing traffic growth. It is of paramount importance that the required resources, such as energy and bandwidth, do not scale with traffic. While the aggregate network traffic is growing at an unprecedented rate, users tend to request the same popular contents at different time instants. Therefore, caching the most popular contents at the network edge is a promising solution to reduce the traffic and the energy consumption over the backhaul links. In this paper, two scenarios are considered, where caching is performed either at a small base station, or directly at the user terminals, which communicate using \ac{D2D} communications. In both scenarios, joint design of the transmission and caching policies is studied when the user demands are known in advance. This joint design offers two different caching gains, namely, the \textit{pre-downloading} and \textit{local caching gains}. It is shown that the finite cache capacity limits the attainable gains, and creates an inherent tradeoff between the two types of gains. In this context, a continuous time optimization problem is formulated to determine the optimal transmission and caching policies that minimize a generic cost function, such as energy, bandwidth, or throughput. The jointly optimal solution is obtained by demonstrating that caching files at a constant rate is optimal, which allows to reformulate the problem as a finite-dimensional convex program. The numerical results show that the proposed joint transmission and caching policy dramatically reduces the total cost, which is particularised to the total energy consumption at the \ac{MBS}, as well as to the total economical cost for the service provider, when users demand economical incentives for delivering content to other users over the D2D links. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04389;Linear and Nonlinear Frequency-Division Multiplexing; Mansoor I. Yousefi,  Xianhe Yangzhang;"  Two signal multiplexing strategies for multi-user optical fiber communication are considered: Wavelength-division multiplexing (WDM) and nonlinear frequency-division multiplexing (NFDM), based on the nonlinear Fourier transform (NFT). The inverse NFT is implemented using an approach that is dual of the forward NFT and does not require solving integral equations. In contrast to prior work where NFDM is applied to single-user channels or combined with WDM, in this paper users' signals are multiplexed in the nonlinear Fourier domain. Furthermore, each user now sends a sequence of symbols. NFDM orthogonalizes the nonlinear Schr\""odinger equation in a generalized frequency and a generalized time. Thus all degrees-of-freedom are (deterministically) independent. As an example, a data rate of 10.5 bits per complex degree-of-freedom is achieved in a 15-user NFDM with $60$ GHz overall bandwidth at average input power $\mathcal P=-0.33$ dBm. Data rate in a comparable 15-user WDM with the same bandwidth and power is 5.26 bits per complex degree-of-freedom. The ratio of the spectral efficiency of NFDM and WDM is 2.23, taking into account bandwidth and time duration of signals at channel input and output. Data rates are plotted as a function of the average input power, indicating that the NFDM rate increases monotonically with transmit power, in contrast to the WDM rate which characteristically vanishes as transmit power is increased more than an optimal value. Thus, as a result of the nonlinear multiplexing of users' signals, NFDM spectral efficiencies higher than the corresponding WDM spectral efficiencies are demonstrated at high input powers. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.04404;Investigation of Prediction Accuracy, Sensitivity, and Parameter  Stability of Large-Scale Propagation Path Loss Models for 5G Wireless  Communications; Shu Sun,  Theodore S. Rappaport,  Timothy A. Thomas,  Amitava Ghosh,  Huan C. Nguyen,  Istvan Z. Kovacs,  Ignacio Rodriguez,  Ozge Koymen,  Andrzej Partyka;  This paper compares three candidate large-scale propagation path loss models for use over the entire microwave and millimeter-wave (mmWave) radio spectrum: the alpha-beta-gamma (ABG) model, the close-in (CI) free space reference distance model, and the CI model with a frequency-weighted path loss exponent (CIF). Each of these models have been recently studied for use in standards bodies such as 3GPP, and for use in the design of fifth generation (5G) wireless systems in urban macrocell, urban microcell, and indoor office and shopping mall scenarios. Here we compare the accuracy and sensitivity of these models using measured data from 30 propagation measurement datasets from 2 GHz to 73 GHz over distances ranging from 4 m to 1238 m. A series of sensitivity analyses of the three models show that the physically-based two-parameter CI model and three-parameter CIF model offer computational simplicity, have very similar goodness of fit (i.e., the shadow fading standard deviation), exhibit more stable model parameter behavior across frequencies and distances, and yield smaller prediction error in sensitivity testing across distances and frequencies, when compared to the four-parameter ABG model. Results show the CI model with a 1 m close-in reference distance is suitable for outdoor environments, while the CIF model is more appropriate for indoor modeling. The CI and CIF models are easily implemented in existing 3GPP models by making a very subtle modification -- by replacing a floating non-physically based constant with a frequency-dependent constant that represents free space path loss in the first meter of propagation. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04564;On Reliability Function Of BSC: Expanding The Region, Where It Is Known  Exactly; Marat V. Burnashev;"  The region of rates (""straight-line""), where the BSC reliability function is known exactly, is expanded. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.04574;Caching in Wireless Small Cell Networks: A Storage-Bandwidth Tradeoff; Syed Tamoor-ul-Hassan,  Mehdi Bennis,  Pedro H. J. Nardelli,  Matti Latva-Aho;  Caching contents at the network edge is an efficient mean for offloading traffic, reducing latency and improving users' quality-of-experience. In this letter, we focus on aspects of storage-bandwidth tradeoffs in which small cell base stations are distributed according to a homogeneous Poisson point process and cache contents according to a given content popularity distribution, subject to storage constraints. We provide a closed-form expression of the cache-miss probability, defined as the probability of not satisfying users' requests over a given coverage area, as a function of signal-to-interference ratio, cache size, base stations density and content popularity. In particular, it is shown that for a given minimum cache size, the popularity based caching strategy achieves lower outage probability for a given base station density compared to uniform caching. Furthermore, we show that popularity based caching attains better performance in terms of cache-miss probability for the same amount of spectrum. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04591;Threshold Saturation of Spatially Coupled Sparse Superposition Codes for  All Memoryless Channels; Jean Barbier,  Mohamad Dia,  Nicolas Macris;"  We recently proved threshold saturation for spatially coupled sparse superposition codes on the additive white Gaussian noise channel. Here we generalize our analysis to a much broader setting. We show for any memoryless channel that spatial coupling allows generalized approximate message-passing (GAMP) decoding to reach the potential (or Bayes optimal) threshold of the code ensemble. Moreover in the large input alphabet size limit: i) the GAMP algorithmic threshold of the underlying (or uncoupled) code ensemble is simply expressed as a Fisher information; ii) the potential threshold tends to Shannon's capacity. Although we focus on coding for sake of coherence with our previous results, the framework and methods are very general and hold for a wide class of generalized estimation problems with random linear mixing. ";"Information Theory (cs.IT); Disordered Systems and Neural Networks (cond-mat.dis-nn)"
https://arxiv.org/abs/1603.04660;Energy Costs for Traffic Offloading by Cache-enabled D2D Communications; Binqiang Chen,  Chenyang Yang;  Device-to-Device (D2D) communications can offload the traffic and boost the throughput of cellular networks. By caching files at users, content delivery traffic can be offloaded via D2D links, if a helper user are willing to send the cached file to the user who requests the file. Yet it is unclear how much energy needs to be consumed at a helper user to support the traffic offloading. In this paper, we strive to find the minimal energy consumption required at a helper user to maximize the amount of offloaded traffic. To this end, we introduce a user-centric proactive caching policy that can control the energy cost for a helper user to convey a file, and then optimize the caching policy to maximize the offloaded traffic. To reduce the energy during transmission, we optimize the transmit power to minimize the energy consumed by a helper to send a file. We analyze the relationship between traffic offloading and energy cost with the optimized caching policy and transmit power by numerical and simulation results, which demonstrate that a significant amount of traffic can be offloaded with affordable energy costs. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04664;Cooperative Device-to-Device Communications With Caching; Binqiang Chen,  Chenyang Yang,  Gang Wang;  Device-to-Device (D2D) communications can increase the throughput of cellular networks significantly, where the interference among D2D links should be properly managed. In this paper, we propose an opportunistic cooperative D2D transmission strategy by exploiting the caching capability at the users to deal with the interference among D2D links. To increase the cooperative opportunity and improve spatial reuse gain, we divide the D2D users into clusters and cache different popular files at the users within a cluster, and then find the optimal cluster size. To maximize the network throughput, we assign different frequency bands to cooperative and non-cooperative D2D links and optimize the bandwidth partition. Simulation results demonstrate that the proposed strategy can provide 500%-600% throughput gain over existing cache-enabled D2D communications when the popularity distribution is skewed, and can provide 40%-80% gain even when the popularity distribution is uniform. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04726;The SPURS Algorithm for Resampling an Irregularly Sampled Signal onto a  Cartesian Grid; Amir Kiperwas,  Daniel Rosenfeld,  Yonina C. Eldar;  We present an algorithm for resampling a function from its values on a non-Cartesian grid onto a Cartesian grid. This problem arises in many applications such as MRI, CT, radio astronomy and geophysics. Our algorithm, termed SParse Uniform ReSampling (SPURS), employs methods from modern sampling theory to achieve a small approximation error while maintaining low computational cost. The given non-Cartesian samples are projected onto a selected intermediate subspace, spanned by integer translations of a compactly supported kernel function. This produces a sparse system of equations describing the relation between the nonuniformly spaced samples and a vector of coefficients representing the projection of the signal onto the chosen subspace. This sparse system of equations can be solved efficiently using available sparse equation solvers. The result is then projected onto the subspace in which the sampled signal is known to reside. The second projection is implemented efficiently using a digital linear shift invariant (LSI) filter and produces uniformly spaced values of the signal on a Cartesian grid. The method can be iterated to improve the reconstruction results. We then apply SPURS to reconstruction of MRI data from nonuniformly spaced k-space samples. Simulations demonstrate that SPURS outperforms other reconstruction methods while maintaining a similar computational complexity over a range of sampling densities and trajectories as well as various input SNR levels. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04812;Modulation-Specific Multiuser Transmit Precoding and User Selection for  BPSK Signalling; Majid Bavand,  Steven D. Blostein;  Motivated by challenges to existing multiuser transmission methods in a low signal to noise ratio (SNR) regime, and emergence of massive numbers of low data rate ehealth and internet of things (IoT) devices, in this paper we show that it is beneficial to incorporate knowledge of modulation type into multiuser transmit precoder design. Particularly, we propose a transmit precoding (beamforming) specific to BPSK modulation, which has maximum power efficiency and capacity in poor channel conditions. To be more specific, in a multiuser scenario, an objective function is formulated based on the weighted sum of error probabilities of BPSK modulated users. Convex optimization is used to transform and solve this ill-behaved non-convex minimum probability of error (MPE) precoding problem. Numerical results confirm significant performance improvement. We then develop a low-complexity user selection algorithm for MPE precoding. Based on line packing principles in Grassmannian manifolds, the number of supported users is able to exceed the number of transmit antennas, and hence the proposed approach is able to support more simultaneous users compared with existing multiuser transmit precoding methods. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.04822;Centralized Repair of Multiple Node Failures with Applications to  Communication Efficient Secret Sharing; Ankit Singh Rawat,  O. Ozan Koyluoglu,  Sriram Vishwanath;  This paper considers a distributed storage system, where multiple storage nodes can be reconstructed simultaneously at a centralized location. This centralized multi-node repair (CMR) model is a generalization of regenerating codes that allow for bandwidth-efficient repair of a single failed node. This work focuses on the trade-off between the amount of data stored and repair bandwidth in this CMR model. In particular, repair bandwidth bounds are derived for the minimum storage multi-node repair (MSMR) and the minimum bandwidth multi-node repair (MBMR) operating points. The tightness of these bounds are analyzed via code constructions. The MSMR point is characterized through codes achieving this point under functional repair for general set of CMR parameters, as well as with codes enabling exact repair for certain CMR parameters. The MBMR point, on the other hand, is characterized with exact repair codes for all CMR parameters for systems that satisfy a certain entropy accumulation property. Finally, the model proposed here is utilized for the secret sharing problem, where the codes for the multi-node repair problem is used to construct communication efficient secret sharing schemes with the property of bandwidth efficient share repair. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05063;Quasi-cyclic subcodes of cyclic codes; Jean-Claude Belfiore,  Cem Güneri,  Buket Özkaya;  We completely characterize possible indices of quasi-cyclic subcodes in a cyclic code for a very broad class of cyclic codes. We present enumeration results for quasi-cyclic subcodes of a fixed index and show that the problem of enumeration is equivalent to enumeration of certain vector subspaces in finite fields. In particular, we present enumeration results for quasi-cyclic subcodes of the simplex code and duals of certain BCH codes. Our results are based on the trace representation of cyclic codes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05132;On Optimal Policies in Full-Duplex Wireless Powered Communication  Networks; Mohamed A. Abd-Elmagid,  Alessandro Biason,  Tamer ElBatt,  Karim G. Seddik,  Michele Zorzi;  The optimal resource allocation scheme in a full-duplex Wireless Powered Communication Network (WPCN) composed of one Access Point (AP) and two wireless devices is analyzed and derived. AP operates in a full-duplex mode and is able to broadcast wireless energy signals in downlink and receive information data in uplink simultaneously. On the other hand, each wireless device is assumed to be equipped with Radio-Frequency (RF) energy harvesting circuitry which gathers the energy sent by AP and stores it in a finite capacity battery. The harvested energy is then used for performing uplink data transmission tasks. In the literature, the main focus so far has been on slot-oriented optimization. In this context, all the harvested RF energy in a given slot is also consumed in the same slot. However, this approach leads to sub-optimal solutions because it does not take into account the Channel State Information (CSI) variations over future slots. Differently from most of the prior works, in this paper we focus on the long-term weighted throughput maximization problem. This approach significantly increases the complexity of the optimization problem since it requires to consider both CSI variations over future slots and the evolution of the batteries when deciding the optimal resource allocation. We formulate the problem using the Markov Decision Process (MDP) theory and show how to solve it. Our numerical results emphasize the superiority of our proposed full-duplex WPCN compared to the half-duplex WPCN and reveal interesting insights about the effects of perfect as well as imperfect self-interference cancellation techniques on the network performance. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05238;A Universal Coding Scheme for Remote Generation of Continuous Random  Variables; Cheuk Ting Li,  Abbas El Gamal;  We consider a setup in which Alice selects a pdf $f$ from a set of prescribed pdfs $\mathscr{P}$ and sends a prefix-free codeword $W$ to Bob in order to allow him to generate a single instance of the random variable $X\sim f$. We describe a universal coding scheme for this setup and establish an upper bound on the expected codeword length when the pdf $f$ is bounded, orthogonally concave (which includes quasiconcave pdf), and has a finite first absolute moment. A dyadic decomposition scheme is used to express the pdf as a mixture of uniform pdfs over hypercubes. Alice randomly selects a hypercube according to its weight, encodes its position and size into $W$, and sends it to Bob who generates $X$ uniformly over the hypercube. Compared to previous results on channel simulation, our coding scheme applies to any continuous distribution and does not require two-way communication or shared randomness. We apply our coding scheme to classical simulation of quantum entanglement and obtain a better bound on the average codeword length than previously known. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05269;Mbps Experimental Acoustic Through-Tissue Communications: MEAT-COMMS; Andrew Singer,  Michael Oelze,  Anthony Podkowa;  Methods for digital, phase-coherent acoustic communication date to at least the work of Stojanjovic, et al [20], and the added robustness afforded by improved phase tracking and compensation of Johnson, et al [21]. This work explores the use of such methods for communications through tissue for potential biomedical applications, using the tremendous bandwidth available in commercial medical ultrasound transducers. While long-range ocean acoustic experiments have been at rates of under 100kbps, typically on the order of 1- 10kbps, data rates in excess of 120Mb/s have been achieved over cm-scale distances in ultrasonic testbeds [19]. This paper describes experimental transmission of digital communication signals through samples of real pork tissue and beef liver, achieving data rates of 20-30Mbps, demonstrating the possibility of real-time video-rate data transmission through tissue for inbody ultrasonic communications with implanted medical devices. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05273;Fast Low-Complexity Decoders for Low-Rate Polar Codes; Pascal Giard,  Alexios Balatsoukas-Stimming,  Gabi Sarkis,  Claude Thibeault,  Warren J. Gross;  Polar codes are capacity-achieving error-correcting codes with an explicit construction that can be decoded with low-complexity algorithms. In this work, we show how the state-of-the-art low-complexity decoding algorithm can be improved to better accommodate low-rate codes. More constituent codes are recognized in the updated algorithm and dedicated hardware is added to efficiently decode these new constituent codes. We also alter the polar code construction to further decrease the latency and increase the throughput with little to no noticeable effect on error-correction performance. Rate-flexible decoders for polar codes of length 1024 and 2048 are implemented on FPGA. Over the previous work, they are shown to have from 22% to 28% lower latency and 26% to 34% greater throughput when decoding low-rate codes. On 65 nm ASIC CMOS technology, the proposed decoder for a (1024, 512) polar code is shown to compare favorably against the state-of-the-art ASIC decoders. With a clock frequency of 400 MHz and a supply voltage of 0.8 V, it has a latency of 0.41 $\mu$s and an area efficiency of 1.8 Gbps/mm$^2$ for an energy efficiency of 77 pJ/info. bit. At 600 MHz with a supply of 1 V, the latency is reduced to 0.27 $\mu$s and the area efficiency increased to 2.7 Gbps/mm$^2$ at 115 pJ/info. bit. ;"Information Theory (cs.IT); Hardware Architecture (cs.AR)"
https://arxiv.org/abs/1603.05274;New Sufficient Conditions for Multiple-Access Channel with Correlated  Sources; Mohsen Heidari,  Farhad Shirani,  S. Sandeep Pradhan;  The problem of three-user Multiple-Access Channel (MAC) with correlated sources is investigated. An extension to the Cover-El Gamal-Salehi (CES) scheme is introduced. We use a combination of this scheme with linear codes and propose a new coding strategy. We derive new sufficient conditions to transmit correlated sources reliably. We consider an example of three-user MAC with binary inputs. Using this example, we show strict improvements over the CES scheme. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05358;Self-Interference Cancellation Using Time-Domain Phase Noise Estimation  in OFDM Full-Duplex Systems; Heba Shehata,  Tamer Khattab;  In full-duplex systems, oscillator phase noise (PN) problem is considered the bottleneck challenge that may face the self-interference cancellation (SIC) stage especially when orthogonal frequency division multiplexing (OFDM) transmission scheme is deployed. Phase noise degrades the SIC performance significantly, if not mitigated before or during the SIC technique. The presence of the oscillator phase noise has different impacts on the transmitted data symbol like common phase error (CPE) and inter-carrier interference (ICI). However, phase noise can be estimated and mitigated digitally in either time or frequency domain. Through this work, we propose a novel and simple time domain self-interference (SI) phase noise estimation and mitigation technique. The proposed algorithm is inspired from Wiener filtering in time domain. Simulation results show that the proposed algorithm has a superior performance than the already-existing time-domain or frequency domain PN mitigation solutions with a noticeable reduction in the computational complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05365;A Relation Between Network Computation and Functional Index Coding  Problems; Anindya Gupta,  B. Sundar Rajan;  In contrast to the network coding problem wherein the sinks in a network demand subsets of the source messages, in a network computation problem the sinks demand functions of the source messages. Similarly, in the functional index coding problem, the side information and demands of the clients include disjoint sets of functions of the information messages held by the transmitter instead of disjoint subsets of the messages, as is the case in the conventional index coding problem. It is known that any network coding problem can be transformed into an index coding problem and vice versa. In this work, we establish a similar relationship between network computation problems and a class of functional index coding problems, viz., those in which only the demands of the clients include functions of messages. We show that any network computation problem can be converted into a functional index coding problem wherein some clients demand functions of messages and vice versa. We prove that a solution for a network computation problem exists if and only if a functional index code (of a specific length determined by the network computation problem) for a suitably constructed functional index coding problem exists. And, that a functional index coding problem admits a solution of a specified length if and only if a suitably constructed network computation problem admits a solution. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05368;A Survey on High-Speed Railway Communications: A Radio Resource  Management Perspective; Shengfeng Xu,  Gang Zhu,  Bo Ai,  Zhangdui Zhong;  High-speed railway (HSR) communications will become a key feature supported by intelligent transportation communication systems. The increasing demand for HSR communications leads to significant attention on the study of radio resource management (RRM), which enables efficient resource utilization and improved system performance. RRM design is a challenging problem due to heterogenous quality of service (QoS) requirements and dynamic characteristics of HSR wireless communications. The objective of this paper is to provide an overview on the key issues that arise in the RRM design for HSR wireless communications. A detailed description of HSR communication systems is first presented, followed by an introduction on HSR channel models and characteristics, which are vital to the cross-layer RRM design. Then we provide a literature survey on state-of-the-art RRM schemes for HSR wireless communications, with an in-depth discussion on various RRM aspects including admission control, mobility management, power control and resource allocation. Finally, this paper outlines the current challenges and open issues in the area of RRM design for HSR wireless communications. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05399;Strong Secrecy in Pairwise Key Agreement over a Generalized Multiple  Access Channel; Somayeh Salimi,  Matthieu Bloch,  Frederic Gabry,  Mikael Skoglund,  Panos Papadimitratos;"  This paper considers the problem of pairwise key agreement without public communication between three users connected through a generalized multiple access channel (MAC). While two users control the channel inputs, all three users observe noisy outputs from the channel and each pair of users wishes to agree on a secret key hidden from the remaining user. We first develop a ""pre-generated"" key-agreement scheme based on secrecy codes for the generalized MAC, in which the channel is only used to distribute pre-generated secret keys. We then extend this scheme to include an additional layer of rate-limited secret-key generation by treating the observed channel outputs as induced sources. We characterize inner and outer bounds on the strong secret-key capacity region for both schemes. For a special case of the ""pre-generated"" scheme, we obtain an exact characterization. We also illustrate with some binary examples that exploiting the generalized nature of the generalized MAC may lead to significantly larger key-agreement rates. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.05410;Multidimensional Sparse Recovery for MIMO Channel Parameter Estimation; Christian Steffens,  Yang Yang,  Marius Pesavento;  Multipath propagation is a common phenomenon in wireless communication. Knowledge of propagation path parameters such as complex channel gain, propagation delay or angle-of-arrival provides valuable information on the user position and facilitates channel response estimation. A major challenge in channel parameter estimation lies in its multidimensional nature, which leads to large-scale estimation problems which are difficult to solve. Current approaches of sparse recovery for multidimensional parameter estimation aim at simultaneously estimating all channel parameters by solving one large-scale estimation problem. In contrast to that we propose a sparse recovery method which relies on decomposing the multidimensional problem into successive one-dimensional parameter estimation problems, which are much easier to solve and less sensitive to off-grid effects, while providing proper parameter pairing. Our proposed decomposition relies on convex optimization in terms of nuclear norm minimization and we present an efficient implementation in terms of the recently developed STELA algorithm. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05540;Conferencing in Wyner's Asymmetric Interference Network: Effect of  Number of Rounds; Michèle Wigger,  Roy Timo,  Shlomo Shamai (Shitz);"  Our goal is to study the effect of the number of conferencing rounds on the capacity of large interference networks. We do this at hand of the per-user multiplexing gain (MG) of Wyner's soft-handoff model with dedicated conferencing links between neighbouring transmitters and receivers. We present upper and lower bounds on the per-user MG of this network, which depend on the capacities of the transmitter- and receiver-conferencing links and on the number of allowed conferencing rounds. The bounds are tight when: the prelogs of the conferencing links are small or high; there is only transmitter conferencing or only receiver conferencing; or some symmetry conditions between transmitter-conferencing and receiver-conferencing hold. We also determine the per-user MG of the network when the number of conferencing rounds is unlimited. Our results show that for small conferencing prelogs around 1/6, a single conferencing round suffices to attain the maximum per-user MG when the number of conferencing rounds is unconstrained. In contrast, when the prelogs are large, then every additional conferencing round increases the maximum per-user MG. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.05576;Extracting Wyner's Common Information Using Polar Codes and Polar  Lattices; Jinwen Shi,  Ling Liu,  Cong Ling;"  Explicit constructions of polar codes and polar lattices for both lossless and lossy Gray-Wyner problems are studied. Polar codes are employed to extract Wyner's common information of doubly symmetric binary source; polar lattices are then extended to extract that of a pair of Gaussian sources or multiple Gaussian sources. With regard to the discrete sources, the entire best-known region of the lossless Gray-Wyner problem are achieved by specifying the test channels to construct polar codes without time-sharing. As a result, we are able to give an interpretation that the Wyner's common information remains the same to the lossy case when the distortion is small [1]. Finally, the entire best-known lossy Gray-Wyner region for discrete sources can also be achieved using polar codes. With regard to the Gaussian sources, the best-known lossy Gray-Wyner region for bivariate Gaussian sources with a specific covariance matrix [1] can be achieved by using polar lattices. Moreover, we prove that extracting Wyner's common information of a pair of Gaussian sources is equivalent to implementing the lossy compression for a single Gaussian source, which implies that the common information can be extracted by a polar lattice for quantization. Furthermore, we extend this result to the case of multiple Gaussian sources. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.05584;On the Multiplexing Gain of Discrete-Time MIMO Phase Noise Channels; Sheng Yang,  Shlomo Shamai (Shitz);  The capacity of a point-to-point discrete-time multi-input-multiple-output (MIMO) channel with phase uncertainty (MIMO phase noise channel) is still open. As a matter of fact, even the pre-log (multiplexing gain) of the capacity in the high signal-to-noise ratio (SNR) regime is unknown in general. We make some progresses in this direction for two classes of such channels. With phase noise on the individual paths of the channel (model A), we show that the multiplexing gain is 1/2, which implies that the capacity does not scale with the channel dimension at high SNR. With phase noise at both the input and output of the channel (model B), the multiplexing gain is upper-bounded by 1/2 min{nt,(nr-2)^+ + 1}, and lower-bounded by 1/2 min{nt, floor((nr+1)/2)}, where nt and nr are the number of transmit and receive antennas, respectively. The multiplexing gain is enhanced to 1/2 min{nt,nr} without receive phase noise, and to 1/2 min{2nt-1,nr} without transmit phase noise. In all the cases of model B, the multiplexing gain scales linearly with min{nt,nr}. Our main results rely on the derivation of non-trivial upper and lower bounds on the capacity of such channels. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05680;Semidefinite Relaxation and Approximation Analysis of a Beamformed  Alamouti Scheme for Relay Beamforming Networks; Sissi Xiaoxiao Wu,  Anthony Man-Cho So,  Jiaxian Pan,  Wing-Kin Ma;  In this paper, we study the amplify-and-forward (AF) schemes in two-hop one-way relay networks. In particular, we consider the multigroup multicast transmission between long-distance users. Given that perfect channel state information is perceived, our goal is to design the AF process so that the max-min-fair (MMF) signal-to-interference-plus-noise ratio (SINR) is optimized subject to generalized power constraints. We propose a rank-two beamformed Alamouti (BFA) AF scheme and formulate the corresponding AF design problem as a \emph{two-variable} fractional quadratically-constrained quadratic program (QCQP), which is further tackled by the semidefinite relaxation (SDR) technique. We analyze the approximation quality of two-variable fractional SDRs under the Gaussian randomization algorithm. These results are fundamentally new and reveal that the proposed BFA AF scheme can outperform the traditional BF AF scheme, especially when there are many users in the system or many generalized power constraints in the problem formulation. From a practical perspective, the BFA AF scheme offers two degrees of freedom (DoFs) in beamformer design, as opposed to the one DoF offered by the BF AF scheme, to improve the receivers' SINR. In the latter part of this paper, we demonstrate how this extra DoF leads to provable performance gains by considering two special cases of multicasting, where the AF process is shown to employ a special structure. The numerical simulations further validate that the proposed BFA AF scheme outperforms the BF AF scheme and works well for large-scale relay systems. ;Information Theory (cs.IT)
https://arxiv.org/abs/1603.05736;Construction of polar codes for arbitrary discrete memoryless channels; Talha Cihad Gulcu,  Min Ye,  Alexander Barg;"  It is known that polar codes can be efficiently constructed for binary-input channels. At the same time, existing algorithms for general input alphabets are less practical because of high complexity. We address the construction problem for the general case, and analyze an algorithm that is based on successive reduction of the output alphabet size of the subchannels in each recursion step. For this procedure we estimate the approximation error as $O(\mu^{-1/(q-1)}),$ where $\mu$ is the ""quantization parameter,"" i.e., the maximum size of the subchannel output alphabet allowed by the algorithm. The complexity of the code construction scales as $O(N\mu^4),$ where $N$ is the length of the code. We also show that if the polarizing operation relies on modulo-$q$ addition, it is possible to merge subsets of output symbols without any loss in subchannel capacity. Performing this procedure before each approximation step results in a further speed-up of the code construction, and the resulting codes have smaller gap to capacity. We show that a similar acceleration can be attained for polar codes over finite field alphabets. Experimentation shows that the suggested construction algorithms can be used to construct long polar codes for alphabets of size $q=16$ and more with acceptable loss of the code rate for a variety of polarizing transforms. ";Information Theory (cs.IT)
https://arxiv.org/abs/1603.05823;Optimal Throughput for Covert Communication Over a Classical-Quantum  Channel; Ligong Wang;"  This paper considers the problem of communication over a memoryless classical-quantum wiretap channel subject to the constraint that the eavesdropper on the channel should not be able to learn whether the legitimate parties are using the channel to communicate or not. Specifically, the relative entropy between the output quantum states at the eavesdropper when a codeword is transmitted and when no input is provided must be sufficiently small. Extending earlier works, this paper proves the ""square-root law"" for a broad class of classical-quantum channels: the maximum amount of information that can be reliably and covertly transmitted over $n$ uses of such a channel scales like $\sqrt{n}$. The scaling constant is also determined. ";"Information Theory (cs.IT); Quantum Physics (quant-ph)"
https://arxiv.org/abs/1605.00019;Sharp Bounds Between Two Rényi Entropies of Distinct Positive Orders; Yuta Sakai,  Ken-ichi Iwata;  Many axiomatic definitions of entropy, such as the R\'enyi entropy, of a random variable are closely related to the $\ell_{\alpha}$-norm of its probability distribution. This study considers probability distributions on finite sets, and examines the sharp bounds of the $\ell_{\beta}$-norm with a fixed $\ell_{\alpha}$-norm, $\alpha \neq \beta$, for $n$-dimensional probability vectors with an integer $n \ge 2$. From the results, we derive the sharp bounds of the R\'enyi entropy of positive order $\beta$ with a fixed R\'enyi entropy of another positive order $\alpha$. As applications, we investigate sharp bounds of Ariomoto's mutual information of order $\alpha$ and Gallager's random coding exponents for uniformly focusing channels under the uniform input distribution. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00020;Locally Repairable Regenerating Code Constructions; Imad Ahmad,  Chih-Chun Wang;  In this work, we give locally repairable regenerating code (LRRC) [1]-[3], [5], [6] constructions that can protect the file size promised by the graph analysis of the modified family helper selection (MFHS) scheme [1] at the minimum-bandwidth-regenerating (MBR) point. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00113;Improving practical sensitivity of energy optimized wake-up receivers:  proof of concept in 65nm CMOS; Nafiseh Seyed Mazloum,  Joachim Neves Rodrigues,  Oskar Andersson,  Anders Nejdel,  Ove Edfors;  We present a high performance low-power digital base-band architecture, specially designed for an energy optimized duty-cycled wake-up receiver scheme. Based on a careful wake-up beacon design, a structured wake-up beacon detection technique leads to an architecture that compensates for the implementation loss of a low-power wake-up receiver front-end at low energy and area costs. Design parameters are selected by energy optimization and the architecture is easily scalable to support various network sizes. Fabricated in 65nm CMOS, the digital base-band consumes 0.9uW (V_DD=0.37V) in sub-threshold operation at 250kbps, with appropriate 97% wake-up beacon detection and 0.04% false alarm probabilities. The circuit is fully functional at a minimum V_DD of 0.23V at f_max=5kHz and 0.018uW power consumption. Based on these results we show that our digital base-band can be used as a companion to compensate for front-end implementation losses resulting from the limited wake-up receiver power budget at a negligible cost. This implies an improvement of the practical sensitivity of the wake-up receiver, compared to what is traditionally reported. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00194;Distributed Detection Fusion via Monte Carlo Importance Sampling; Hang Rao,  Xiaojing Shen,  Yunmin Zhu,  Jianxin Pan;  Distributed detection fusion with high-dimension conditionally dependent observations is known to be a challenging problem. When a fusion rule is fixed, this paper attempts to make progress on this problem for the large sensor networks by proposing a new Monte Carlo framework. Through the Monte Carlo importance sampling, we derive a necessary condition for optimal sensor decision rules in the sense of minimizing the approximated Bayesian cost function. Then, a Gauss-Seidel/person-by-person optimization algorithm can be obtained to search the optimal sensor decision rules. It is proved that the discretized algorithm is finitely convergent. The complexity of the new algorithm is $O(LN)$ compared with $O(LN^L)$ of the previous algorithm where $L$ is the number of sensors and $N$ is a constant. Thus, the proposed methods allows us to design the large sensor networks with general high-dimension dependent observations. Furthermore, an interesting result is that, for the fixed AND or OR fusion rules, we can analytically derive the optimal solution in the sense of minimizing the approximated Bayesian cost function. In general, the solution of the Gauss-Seidel algorithm is only local optimal. However, in the new framework, we can prove that the solution of Gauss-Seidel algorithm is same as the analytically optimal solution in the case of the AND or OR fusion rule. The typical examples with dependent observations and large number of sensors are examined under this new framework. The results of numerical examples demonstrate the effectiveness of the new algorithm. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00203;Fundamental Tradeoff between Storage and Latency in Cache-Aided Wireless  Interference Networks; Fan Xu,  Meixia Tao,  Kangqi Liu;  This paper studies the fundamental tradeoff between storage and latency in a general wireless interference network with caches equipped at all transmitters and receivers. The tradeoff is characterized by an information-theoretic metric, \emph{normalized delivery time} (NDT), which is the worst-case delivery time of the actual traffic load at a transmission rate specified by degrees of freedom (DoF) of a given channel. We obtain both an achievable upper bound and a theoretical lower bound of the minimum NDT for any number of transmitters, any number of receivers, and any feasible cache size tuple. We show that the achievable NDT is exactly optimal in certain cache size regions, and is within a bounded multiplicative gap to the theoretical lower bound in other regions. In the achievability analysis, we first propose a novel cooperative transmitter/receiver coded caching strategy. It offers the freedom to adjust file splitting ratios for NDT minimization. We then propose a delivery strategy which transforms the considered interference network into a new class of cooperative X-multicast channels. It leverages local caching gain, coded multicasting gain, and transmitter cooperation gain (via interference alignment and interference neutralization) opportunistically. Finally, the achievable NDT is obtained by solving a linear programming problem. This study reveals that with caching at both transmitter and receiver sides, the network can benefit simultaneously from traffic load reduction and transmission rate enhancement, thereby effectively reducing the content delivery latency. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00204;Energy-Distortion Tradeoff for the Gaussian Broadcast Channel with  Feedback; Yonathan Murin,  Yonatan Kaspi,  Ron Dabora,  Deniz Gunduz;  This work focuses on the minimum transmission energy required for communicating a pair of correlated Gaussian sources over a two-user Gaussian broadcast channel with noiseless and causal channel output feedback (GBCF). We study the fundamental limit on the required transmission energy for broadcasting a pair of source samples, such that each source can be reconstructed at its respective receiver to within a target distortion, when the source-channel bandwidth ratio is not restricted. We derive a lower bound and three distinct upper bounds on the minimum required energy. For the upper bounds we analyze three transmission schemes: Two schemes are based on separate source-channel coding, and apply coding over multiple samples of source pairs. The third scheme is based on joint source-channel coding obtained by extending the Ozarow-Leung (OL) transmission scheme, which applies uncoded linear transmission. Numerical simulations show that despite its simplicity, the energy-distortion tradeoff of the OL-based scheme is close to that of the better separation-based scheme, which indicates that the OL scheme is attractive for energy-efficient source transmission over GBCFs. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00205;Gains of Restricted Secondary Licensing in Millimeter Wave Cellular  Systems; Abhishek K. Gupta,  Ahmed Alkhateeb,  Jeffrey G. Andrews,  Robert W. Heath, Jr;  Sharing the spectrum among multiple operators seems promising in millimeter wave (mmWave) systems. One explanation is the highly directional transmission in mmWave, which reduces the interference caused by one network on the other networks sharing the same resources. In this paper, we model a mmWave cellular system where an operator that primarily owns an exclusive-use license of a certain band can sell a restricted secondary license of the same band to another operator. This secondary network has a restriction on the maximum interference it can cause to the original network. Using stochastic geometry, we derive expressions for the coverage and rate of both networks, and establish the feasibility of secondary licensing in licensed mmWave bands. To explain economic trade-offs, we consider a revenue-pricing model for both operators in the presence of a central licensing authority. Our results show that the original operator and central network authority can benefit from secondary licensing when the maximum interference threshold is properly adjusted. This means that the original operator and central licensing authority have an incentive to permit a secondary network to restrictively share the spectrum. Our results also illustrate that the spectrum sharing gains increase with narrow beams and when the network densifies. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00211;On Optimal Offline Time Sharing Policy for Energy Harvesting Underlay  Cognitive Radio; Kalpant Pathak,  Adrish Banerjee;  RF energy harvesting can be used to power communication devices so that perpetual operation of such devices can be ensured. We consider a RF energy harvesting underlay cognitive radio system operating in slotted fashion. The primary user (PU) is equipped with a reliable power source and transmits with a constant power in all the slots. However, the secondary user (SU) harvests energy from primary's transmission and simultaneously transmits it's own data such that interference at the primary receiver (PR) remains below an acceptable threshold. At the secondary transmitter (ST), each time slot is divided into two phases: energy harvesting (EH) phase and information transfer (IT) phase. We formulated the problem of maximizing the achievable secondary sum rate under primary receiver's protection criteria as a convex optimization problem and obtained the optimal time sharing between EH and IT phase, and optimal secondary transmit power under offline setting. The optimal offline scheme is then compared with an online myopic policy, where the optimal time sharing between EH and IT phase, and optimal secondary transmit power are obtained based on instantaneous channel gains only. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00317;Performance of LDPC Decoders with Missing Connections; Linjia Chang,  Avhishek Chatterjee,  Lav R. Varshney;  Due to process variation in nanoscale manufacturing, there may be permanently missing connections in information processing hardware. Due to timing errors in circuits, there may be missed messages in intra-chip communications, equivalent to transiently missing connections. In this work, we investigate the performance of message-passing LDPC decoders in the presence of missing connections. We prove concentration and convergence theorems that validate the use of density evolution performance analysis. Arbitrarily small error probability is not possible with missing connections, but we find suitably defined decoding thresholds for communication systems with binary erasure channels under peeling decoding, as well as binary symmetric channels under Gallager A and B decoding. We see that decoding is robust to missing wires, as decoding thresholds degrade smoothly. Moreover, there is a stochastic facilitation effect in Gallager B decoders with missing connections. We also compare the decoding sensitivity with respect to channel noise and missing wiring. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00319;Edge Caching for Coverage and Capacity-aided Heterogeneous Networks; Ejder Baştuğ,  Mehdi Bennis,  Marios Kountouris,  Mérouane Debbah;  A two-tier heterogeneous cellular network (HCN) with intra-tier and inter-tier dependence is studied. The macro cell deployment follows a Poisson point process (PPP) and two different clustered point processes are used to model the cache-enabled small cells. Under this model, we derive approximate expressions in terms of finite integrals for the average delivery rate considering inter-tier and intra-tier dependence. On top of the fact that cache size drastically improves the performance of small cells in terms of average delivery rate, we show that rate splitting of limited-backhaul induces non-linear performance variations, and therefore has to be adjusted for rate fairness among users of different tiers. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00322;Adaptive Modulation in Network-coded Two-way Relay Channel: A  Supermodular Game Approach; Ni Ding,  Parastoo Sadeghi,  Rodney A. Kennedy;  We study the adaptive modulation (AM) problem in a network-coded two-way relay channel (NC-TWRC), where each of the two users controls its own bit rate in the $m$-ary quadrature amplitude modulation ($m$-QAM) to minimize the transmission error rate and enhance the spectral efficiency. We show that there exists a strategic complementarity, one user tends to transmit while the other decides to do so in order to enhance the overall spectral efficiency, which is beyond the scope of the conventional single-agent AM scheduling method. We propose a two-player game model parameterized by the signal-to-noise ratios (SNRs) of two user-to-user channels and prove that it is a supermodular game where there always exist the extremal pure strategy Nash equilibria (PSNEs), the largest and smallest PSNEs. We show by simulation results that the extremal PSNEs incur a similar bit error rate (BER) as the conventional single-agent AM scheme, but significantly improve the spectral efficiency in the NC-TWRC system. The study also reveals the Pareto order of the extremal PSNEs: The largest and smallest PSNEs are Pareto worst and best PSNEs, respectively. Finally, we derive the sufficient conditions for the extremal PSNEs to be symmetric and monotonic in channel SNRs. We also discuss how to utilize the symmetry and monotonicity to relieve the complexity in the PSNE learning process. ;"Information Theory (cs.IT); Systems and Control (cs.SY); Optimization and Control (math.OC)"
https://arxiv.org/abs/1605.00390;A New NOMA Approach for Fair Power Allocation; Jose Armando Oviedo,  Hamid R. Sadjadpour;  A non-orthogonal multiple access (NOMA) approach to user signal power allocation called Fair-NOMA is introduced. Fair-NOMA is the application of NOMA in such a way that two mobile users have the opportunity to always achieve at least the information capacity they can achieve by using orthogonal multiple access (OMA), regardless of the user selection criteria, making it suitable for implementation using any current or future scheduling paradigms. Given this condition, the bounds of the power allocation coefficients are derived as functions of the channel gains of the two mobile users. The NOMA power allocation is analyzed for two scheduled users that are selected randomly with i.i.d. channel gains. The capacity improvements made by each user and the sum capacity improvement are derived. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00414;On sampling theorem with sparse decimated samples: exploring branching  spectrum degeneracy; Nikolai Dokuchaev;  The paper investigates possibility of recovery of sequences from their decimated subsequences. It is shown that this recoverability is associated with certain spectrum degeneracy of a new kind, and that a sequences of a general kind can be approximated by sequences featuring this degeneracy. This is applied to sparse sampling of continuous time band-limited functions. The paper shows that these functions allow an arbitrarily close approximation by functions that can be recovered from sparse equidistant samples with sampling distance larger than the distance defined by the critical Nyquist rate for the underlying function. This allows to bypass, in a certain sense, the restriction on the sampling rate defined by the Nyquist rate. ;"Information Theory (cs.IT); Statistics Theory (math.ST)"
https://arxiv.org/abs/1605.00419;Well-Rounded Lattices for Reliability and Security in Rayleigh Fading  SISO Channels; Oliver Wilhelm Gnilke,  Ha Thanh Nguyen Tran,  Alex Karrila,  Camilla Hollanti;  For many wiretap channel models asymptotically optimal coding schemes are known, but less effort has been put into actual realizations of wiretap codes for practical parameters. Bounds on the mutual information and error probability when using coset coding on a Rayleigh fading channel were recently established by Oggier and Belfiore, and the results in this paper build on their work. However, instead of using their ultimate inverse norm sum approximation, a more precise expression for the eavesdropper's probability of correct decision is used in order to determine a general class of good coset codes. The code constructions are based on well-rounded lattices arising from simple geometric criteria. In addition to new coset codes and simulation results, novel number-theoretic results on well-rounded ideal lattices are presented. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00462;Sharper Upper Bounds for Unbalanced Uniquely Decodable Code Pairs; Per Austrin,  Petteri Kaski,  Mikko Koivisto,  Jesper Nederlof;  Two sets $A, B \subseteq \{0, 1\}^n$ form a Uniquely Decodable Code Pair (UDCP) if every pair $a \in A$, $b \in B$ yields a distinct sum $a+b$, where the addition is over $\mathbb{Z}^n$. We show that every UDCP $A, B$, with $|A| = 2^{(1-\epsilon)n}$ and $|B| = 2^{\beta n}$, satisfies $\beta \leq 0.4228 +\sqrt{\epsilon}$. For sufficiently small $\epsilon$, this bound significantly improves previous bounds by Urbanke and Li~[Information Theory Workshop '98] and Ordentlich and Shayevitz~[2014, arXiv:1412.8415], which upper bound $\beta$ by $0.4921$ and $0.4798$, respectively, as $\epsilon$ approaches $0$. ;"Information Theory (cs.IT); Discrete Mathematics (cs.DM)"
https://arxiv.org/abs/1605.00508;Towards an Appropriate Beamforming Scheme for Initial Cell Discovery in  mmW 5G Cellular Networks; Waqas bin Abbas,  Michele Zorzi;  Beamforming is an essential requirement to combat high pathloss and to improve signal-to-noise ratio during initial cell discovery in future millimeter wave cellular networks. The choice of an appropriate beamforming is directly coupled with its energy consumption. The energy consumption is even of more concern at a battery limited mobile station (MS). In this work, we provide an energy consumption based comparison of different beamforming schemes while considering both a low power and a high power analog-to-digital converter (ADC) for a millimeter wave based receiver at the MS. We analyze both context information (CI) (GPS positioning based) and non context information based schemes, and show that analog beamforming with CI (where mobile station's positioning information is already available) can result in a lower energy consumption, while in all other scenarios digital beamforming has a lower energy consumption than analog and hybrid beamforming. We also show that under certain scenarios recently proposed phase shifters network architecture can result in a lower energy consumption than other beamforming schemes. Moreover, we show that the energy consumption trend among different beamforming schemes is valid irrespective of the number of ADC bits. Finally, we propose a new signaling structure which utilizes a relatively higher frequency sub-carrier for primary synchronization signals compared to other signaling, which allows a further reduction in initial cell search delay and energy consumption of the MS. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1605.00626;Pixelated VLC-backscattering for Self-charging Indoor IoT Devices; Sihua Shao,  Abdallah Khreishah,  Hany Elgala;  Visible light communication (VLC) backscatter has been proposed as a wireless access option for Internet of Things (IoT). However, the throughput of the state-of-the-art VLC backscatter is limited by simple single-carrier pulsed modulation scheme, such as on-off keying (OOK). In this paper, a novel pixelated VLC backscatter is proposed and implemented to overcome the channel capacity limitation. In particular, multiple smaller VLC backscatters, switching on or off, are integrated to generate multi-level signals, which enables the usage of more advanced modulation schemes than OOK. Based on experimental results, rate adaptation at different communication distances can be employed to enhance the achievable data rate. Compared to OOK, the data rate can be tripled when 8-PAM is used at 2 meters. In general, $n$-fold throughput enhancement is realized by utilizing $n$ smaller VLC backscatters while incurring negligible additional energy using the same device space as that of a single large backscatter. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1605.00635;The Capacity of Robust Private Information Retrieval with Colluding  Databases; Hua Sun,  Syed A. Jafar;  Private information retrieval (PIR) is the problem of retrieving as efficiently as possible, one out of $K$ messages from $N$ non-communicating replicated databases (each holds all $K$ messages) while keeping the identity of the desired message index a secret from each individual database. The information theoretic capacity of PIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. $T$-private PIR is a generalization of PIR to include the requirement that even if any $T$ of the $N$ databases collude, the identity of the retrieved message remains completely unknown to them. Robust PIR is another generalization that refers to the scenario where we have $M \geq N$ databases, out of which any $M - N$ may fail to respond. For $K$ messages and $M\geq N$ databases out of which at least some $N$ must respond, we show that the capacity of $T$-private and Robust PIR is $\left(1+T/N+T^2/N^2+\cdots+T^{K-1}/N^{K-1}\right)^{-1}$. The result includes as special cases the capacity of PIR without robustness ($M=N$) or $T$-privacy constraints ($T=1$). ;"Information Theory (cs.IT); Cryptography and Security (cs.CR); Information Retrieval (cs.IR)"
https://arxiv.org/abs/1605.00668;Hybrid Architectures with Few-Bit ADC Receivers: Achievable Rates and  Energy-Rate Tradeoffs; Jianhua Mo,  Ahmed Alkhateeb,  Shadi Abu-Surra,  Robert W. Heath Jr;  Hybrid analog/digital architectures and receivers with low-resolution analog-to-digital converters (ADCs) are two low power solutions for wireless systems with large antenna arrays, such as millimeter wave and massive MIMO systems. Most prior work represents two extreme cases in which either a small number of RF chains with full-resolution ADCs, or low resolution ADC with a number of RF chains equal to the number of antennas is assumed. In this paper, a generalized hybrid architecture with a small number of RF chains and finite number of ADC bits is proposed. For this architecture, achievable rates with channel inversion and SVD based transmission methods are derived. Results show that the achievable rate is comparable to that obtained by full-precision ADC receivers at low and medium SNRs. A trade-off between the achievable rate and power consumption for different numbers of bits and RF chains is devised. This enables us to draw some conclusions on the number of ADC bits needed to maximize the system energy efficiency. Numerical simulations show that coarse ADC quantization is optimal under various system configurations. This means that hybrid combining with coarse quantization achieves better energy-rate trade-off compared to both hybrid combining with full-resolutions ADCs and 1-bit ADC combining. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00693;The Generalized Degrees of Freedom Region of the MIMO Z-Interference  Channel with Delayed CSIT; Kaniska Mohanty,  Mahesh K. Varanasi;  The generalized degrees of freedom (GDoF) region of the multiple-input multiple-output (MIMO) Gaussian Z-interference channel with an arbitrary number of antennas at each node is established under the assumption of delayed channel state information at transmitters (CSIT). The GDoF region is parameterized by $\alpha$, which links the interference-to-noise ratio (INR) to the signal-to-noise ratio (SNR) via $INR=SNR^{\alpha}$. A new outer bound for the GDoF region is established by maximizing a bound on the weighted sum-rate of the two users, which in turn is obtained by using a combination of genie-aided side-information and an extremal inequality. The maximum weighted sum-rate in the high SNR regime is shown to occur when the transmission covariance matrix of the interfering transmitter has full rank. An achievability scheme based on block-Markov encoding and backward decoding is developed which uses interference quantization and digital multicasting to take advantage of the channel statistics of the cross-link, and the scheme is separately shown to be GDoF-optimal in both the weak ($\alpha\leq1$) and strong ($\alpha>1$) interference regimes. This is the first complete characterization of the GDoF region of any interference network with delayed CSIT, as well as the first such GDoF characterization of a MIMO network with delayed CSIT and arbitrary number of antennas at each node. For all antenna tuples, the GDoF region is shown to be equal to or larger than the degrees of freedom (DoF) region over the entire range of $\alpha$, which leads to a V-shaped maximum sum-GDoF as a function of $\alpha$, with the minimum occurring at $\alpha=1$. The delayed CSIT GDoF region and the sum-DoF are compared with their counterparts under perfect CSIT, thereby characterizing all antenna tuples and ranges of $\alpha$ for which delayed CSIT is sufficient to achieve the perfect CSIT GDoF region or sum-DoF. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00695;Cyclone Codes; Christian Schindelhauer,  Andreas Jakoby,  Sven Köhler;  We introduce Cyclone codes which are rateless erasure resilient codes. They combine Pair codes with Luby Transform (LT) codes by computing a code symbol from a random set of data symbols using bitwise XOR and cyclic shift operations. The number of data symbols is chosen according to the Robust Soliton distribution. XOR and cyclic shift operations establish a unitary commutative ring if data symbols have a length of $p-1$ bits, for some prime number $p$. We consider the graph given by code symbols combining two data symbols. If $n/2$ such random pairs are given for $n$ data symbols, then a giant component appears, which can be resolved in linear time. We can extend Cyclone codes to data symbols of arbitrary even length, provided the Goldbach conjecture holds. Applying results for this giant component, it follows that Cyclone codes have the same encoding and decoding time complexity as LT codes, while the overhead is upper-bounded by those of LT codes. Simulations indicate that Cyclone codes significantly decreases the overhead of extra coding symbols. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00705;Robust measurement-based buffer overflow probability estimators for QoS  provisioning and traffic anomaly prediction applicationm; Spyridon Vassilaras,  Ioannis Ch. Paschalidis;  Suitable estimators for a class of Large Deviation approximations of rare event probabilities based on sample realizations of random processes have been proposed in our earlier work. These estimators are expressed as non-linear multi-dimensional optimization problems of a special structure. In this paper, we develop an algorithm to solve these optimization problems very efficiently based on their characteristic structure. After discussing the nature of the objective function and constraint set and their peculiarities, we provide a formal proof that the developed algorithm is guaranteed to always converge. The existence of efficient and provably convergent algorithms for solving these problems is a prerequisite for using the proposed estimators in real time problems such as call admission control, adaptive modulation and coding with QoS constraints, and traffic anomaly detection in high data rate communication networks. ;"Information Theory (cs.IT); Optimization and Control (math.OC)"
https://arxiv.org/abs/1605.00724;An Effective Limited Feedback Scheme for FD-MIMO Based on Noncoherent  Detection and Kronecker Product Codebook; Lisi Jiang,  Juling Zeng;  The low complexity quantization of channel state information (CSI) and the utilization of vertical freedom of three dimension (3D) channels are two critical issues in the limited feedback design of the \emph{full dimension multi-input-multi-output} (FD-MIMO) systems. In this paper, we propose an effective limited feedback scheme. We first employ Kronecker product based codebook (KPC) to explore the vertical freedom of 3D channels, extending the limited feedback from two dimension (2D) to 3D. Fruthermore, we use noncoherent sequence detection (NCSD) to quantify the CSI which includes both the vertical and horizontal channel information. This quantization method exploits the duality between codebook searching and NCSD to transform the CSI quntization on KPC to two parallel NCSD. The complexity is reduced from exponential to linear with the number of antennas. We also show the proposed scheme does not affect the diversity gain of the system by demonstrating the full diversity order. Monte Carlo simulation results show that the proposed scheme provides at least 1.2dB coding gain compared with traditional 2D limited feedback schemes. Moreover, the proposed scheme outperforms other FD/3D CSI quantization schemes by 0.8dB coding gain with moderate complexity when the channel is highly spatially correlated. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00738;Performance of Multilevel Flash Memories with Different Binary  Labelings: A Multi-User Perspective; Pengfei Huang,  Paul H. Siegel,  Eitan Yaakobi;  In this work, we study the performance of different decoding schemes for multilevel flash memories where each page in every block is encoded independently. We focus on the multi-level cell (MLC) flash memory, which is modeled as a two-user multiple access channel suffering from asymmetric noise. The uniform rate regions and sum rates of Treating Interference as Noise (TIN) decoding and Successive Cancelation (SC) decoding are investigated for a Program/Erase (P/E) cycling model and a data retention model. We examine the effect of different binary labelings of the cell levels, as well as the impact of further quantization of the memory output (i.e., additional read thresholds). Finally, we extend our analysis to the three-level cell (TLC) flash memory. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00760;Fast Detection of Orthogonal Space-Time Block Codes with Unknown Channel; Xiaowen Tian,  Ming Li,  Guangyu Ti,  Wenfei Liu;  This letter investigates the problem of blind detection of orthogonal space-time block codes (OSTBC) over a quasi-static flat multiple-input multiple-output (MIMO) Rayleigh fading channel. We first introduce a core iterative least-squares (ILS) algorithm to blindly detect OSTBC signals without the knowledge of channel state information (SCI) at the receiver. This ILS algorithm has low computational complexity but may converge to local optimum which offers unreliable detection result. Then, in order to improve the detection performance, we propose an enhanced ILS (E-ILS) approach which is based on statistical analysis of repeated independent ILS procedures on received data. Extensive simulation studies prove the efficiency of the proposed E-ILS algorithm with blind detection performance approaching the optimal maximum-likelihood detector with known CSI. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00769;Delay Analysis and Optimization in Cache-enabled Multi-Cell Cooperative  Networks; Yaping Sun,  Zhiyong Chen,  Hui Liu;  Caching at the base stations (BSs) has been widely adopted to reduce the delivery delay and alleviate the backhaul traffic between BSs and the core network. In this paper, we consider a collaborative content caching scheme among BSs in cache-enabled multi-cell cooperative networks, where the requested contents can be obtained from the associated BS, the other collaborative BSs or the core network. Novelly, we model the stochastic request traffic and derive a closed form expression for the average delay per request based on multi-class processor sharing queuing theory. We then formulate a cooperative caching optimization problem of minimizing the average delay under the finite cache size constraint at BSs and show it to be at least NP-complete. Furthermore, we prove it equivalent to the maximization of a monotone submodular function subject to matroid constraints, allowing us to adopt the common greedy algorithm with 1/2 performance guarantee. A heuristic greedy caching strategy is also developed, achieving a better performance than the conventional greedy solution. Simulation results verify the accuracy of the analytical results and demonstrate the performance gains obtained by our proposed caching scheme. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00802;Queuing Approaches to Principal-Agent Communication under Information  Overload; Aseem Sharma,  Krishna Jagannathan,  Lav R. Varshney;  In the information overload regime, human communication tasks such as responding to email are well-modeled as priority queues, where priority is determined by a mix of intrinsic motivation and extrinsic motivation corresponding to the task's importance to the sender. We view priority queuing from a principal-agent perspective, and characterize the effect of priority-misalignment and information asymmetry between task senders and task receivers in both single-agent and multi-agent settings. In the single-agent setting, we find that discipline can override misalignment. Although variation in human interests leads to performance loss in the single-agent setting, the same variability is useful to the principal with optimal routing of tasks, if the principal has suitable information about agents' priorities. Our approach starts to quantitatively address the effect of human dynamics in routine communication tasks. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00873;Queueing Stability and CSI Probing of a TDD Wireless Network with  Interference Alignment; Matha Deghel,  Mohamad Assaad,  Mérouane Debbah,  Anthony Ephremides;  This paper characterizes the performance of interference alignment (IA) technique taking into account the dynamic traffic pattern and the probing/feedback cost. We consider a time-division duplex (TDD) system where transmitters acquire their channel state information (CSI) by decoding the pilot sequences sent by the receivers. Since global CSI knowledge is required for IA, the transmitters have also to exchange their estimated CSIs over a backhaul of limited capacity (i.e. imperfect case). Under this setting, we characterize in this paper the stability region of the system under both the imperfect and perfect (i.e. unlimited backhaul) cases, then we examine the gap between these two resulting regions. Further, under each case, we provide a centralized probing algorithm (policy) that achieves the max stability region. These stability regions and scheduling policies are given for the symmetric system where all the path loss coefficients are equal to each other, as well as for the general system. For the symmetric system, we compare the stability region of IA with the one achieved by a time division multiple access (TDMA) system where each transmitter applies a simple singular value decomposition technique (SVD). We then propose a scheduling policy that consists in switching between these two techniques, leading the system, under some conditions, to achieve a bigger stability region. Under the general system, the adopted scheduling policy is of a high computational complexity for moderate number of pairs, consequently we propose an approximate policy that has a reduced complexity but that achieves only a fraction of the system stability region. A characterization of this fraction is provided. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00904;Random Access in Uplink Massive MIMO Systems: How to exploit  asynchronicity and excess antennas; Luca Sanguinetti,  Antonio A. D'Amico,  Michele Morelli,  Merouane Debbah;  Massive MIMO systems, where the base stations are equipped with hundreds of antennas, are an attractive way to handle the rapid growth of data traffic. As the number of users increases, the initial access and handover in contemporary networks will be flooded by user collisions. In this work, we propose a random access procedure that resolves collisions and also performs timing, channel, and power estimation by simply utilizing the large number of antennas envisioned in massive MIMO systems and the inherent timing misalignments of uplink signals during network access and handover. Numerical results are used to validate the performance of the proposed solution under different settings. It turns out that the proposed solution can detect all collisions with a probability higher than 90%, at the same time providing reliable timing and channel estimates. Moreover, numerical results demonstrate that it is robust to overloaded situations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00912;Lossless Linear Analog Compression; Giovanni Alberti,  Helmut Bölcskei,  Camillo De Lellis,  Günther Koliander,  Erwin Riegler;  We establish the fundamental limits of lossless linear analog compression by considering the recovery of random vectors ${\boldsymbol{\mathsf{x}}}\in{\mathbb R}^m$ from the noiseless linear measurements ${\boldsymbol{\mathsf{y}}}=\boldsymbol{A}{\boldsymbol{\mathsf{x}}}$ with measurement matrix $\boldsymbol{A}\in{\mathbb R}^{n\times m}$. Specifically, for a random vector ${\boldsymbol{\mathsf{x}}}\in{\mathbb R}^m$ of arbitrary distribution we show that ${\boldsymbol{\mathsf{x}}}$ can be recovered with zero error probability from $n>\inf\underline{\operatorname{dim}}_\mathrm{MB}(U)$ linear measurements, where $\underline{\operatorname{dim}}_\mathrm{MB}(\cdot)$ denotes the lower modified Minkowski dimension and the infimum is over all sets $U\subseteq{\mathbb R}^{m}$ with $\mathbb{P}[{\boldsymbol{\mathsf{x}}}\in U]=1$. This achievability statement holds for Lebesgue almost all measurement matrices $\boldsymbol{A}$. We then show that $s$-rectifiable random vectors---a stochastic generalization of $s$-sparse vectors---can be recovered with zero error probability from $n>s$ linear measurements. From classical compressed sensing theory we would expect $n\geq s$ to be necessary for successful recovery of ${\boldsymbol{\mathsf{x}}}$. Surprisingly, certain classes of $s$-rectifiable random vectors can be recovered from fewer than $s$ measurements. Imposing an additional regularity condition on the distribution of $s$-rectifiable random vectors ${\boldsymbol{\mathsf{x}}}$, we do get the expected converse result of $s$ measurements being necessary. The resulting class of random vectors appears to be new and will be referred to as $s$-analytic random vectors. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00973;Inexact Alternating Optimization for Phase Retrieval In the Presence of  Outliers; Cheng Qian,  Xiao Fu,  Nicholas D. Sidiropoulos,  Lei Huang,  Junhao Xie;  Phase retrieval has been mainly considered in the presence of Gaussian noise. However, the performance of the algorithms proposed under the Gaussian noise model severely degrades when grossly corrupted data, i.e., outliers, exist. This paper investigates techniques for phase retrieval in the presence of heavy-tailed noise -- which is considered a better model for situations where outliers exist. An $\ell_p$-norm ($0<p<2$) based estimator is proposed for fending against such noise, and two-block inexact alternating optimization is proposed as the algorithmic framework to tackle the resulting optimization problem. Two specific algorithms are devised by exploring different local approximations within this framework. Interestingly, the core conditional minimization steps can be interpreted as iteratively reweighted least squares and gradient descent. Convergence properties of the algorithms are discussed, and the Cram\'er-Rao bound (CRB) is derived. Simulations demonstrate that the proposed algorithms approach the CRB and outperform state-of-the-art algorithms in heavy-tailed noise. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00975;Breaking the Limits -- Redefining the Instantaneous Frequency; Pushpendra Singh;  The Carson and Fry (1937) introduced the concept of variable frequency as a generalization of the constant frequency. The instantaneous frequency (IF) is the time derivative of the instantaneous phase and it is well-defined only when this derivative is positive. If this derivative is negative, the IF creates problem because it does not provide any physical significance. This study proposes a mathematical solution and eliminate this problem by redefining the IF such that it is valid for all monocomponent and multicomponent signals which can be nonlinear and nonstationary in nature. This is achieved by using the property of the multivalued inverse tangent function. The efforts and understanding of all the methods based on the IF would improve significantly by using this proposed definition of the IF. We also demonstrate that the decomposition of a signal, using zero-phase filtering based on the well established Fourier and filter theory, into a set of desired frequency bands with proposed IF produces accurate time-frequency-energy (TFE) distribution that reveals true nature of signal. Simulation results demonstrate the efficacy of the proposed IF that makes zero-phase filter based decomposition most powerful, for the TFE analysis of a signal, as compared to other existing methods in the literature. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.00979;Gaussian Two-Way Channels With Discrete Inputs and Quantized Outputs; Ershad Banijamali;  In this paper, Gaussian two-way channel with uniform output quantization is studied. For Gaussian inputs, the optimum uniform finite-level quantizer is determined numerically for different values of Signal-to-Noise Ratio (SNR). The two-way channel with constellation-based transmitters is then investigated. A formulation for the so-called Shannon achievable region of this channel is developed and numerical computations of this region are presented for particular constellations. It is shown that if one transmitter utilizes a rotated version of the constellation used at the other transmitter, the Shannon achievable region can be enlarged ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01033;Universal Multiparty Data Exchange and Secret Key Agreement; Himanshu Tyagi,  Shun Watanabe;  Multiple parties observing correlated data seek to recover each other's data and attain omniscience. To that end, they communicate interactively over a noiseless broadcast channel - each bit transmitted over this channel is received by all the parties. We give a universal interactive communication protocol, termed the recursive data exchange protocol (RDE), which attains omniscience for any sequence of data observed by the parties and provide an individual sequence guarantee of performance. As a by-product, for observations of length $n$, we show the universal rate optimality of RDE up to an $\mathcal{O}\left(n^{-\frac 12}\sqrt{\log n}\right)$ term in a generative setting where the data sequence is independent and identically distributed (in time). Furthermore, drawing on the duality between omniscience and secret key agreement due to Csiszar and Narayan, we obtain a universal protocol for generating a multiparty secret key of rate at most $\mathcal{O}\left(n^{-\frac 12}\sqrt{\log n}\right)$ less than the maximum rate possible. A key feature of RDE is its recursive structure whereby when a subset $A$ of parties recover each-other's data, the rates appear as if the parties have been executing the protocol in an alternative model where the parties in $A$ are collocated. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01081;On the Co-existence of TD-LTE and Radar over 3.5 GHz Band: An  Experimental Study; Jeffrey H. Reed,  Andrew W. Clegg,  Aditya V. Padaki,  Taeyoung Yang,  Randall Nealy,  Carl Dietrich,  Christopher R. Anderson,  D. Michael Mearns;  This paper presents a pioneering study based on a series of experiments on the operation of commercial Time-Division Long-Term Evolution (TD-LTE) systems in the presence of pulsed interfering signals in the 3550-3650 MHz band. TD-LTE operations were carried out in channels overlapping and adjacent to the high power SPN-43 radar with various frequency offsets between the two systems to evaluate the susceptibility of LTE to a high power interfering signal. Our results demonstrate that LTE communication using low antenna heights was not adversely affected by the pulsed interfering signal operating on adjacent frequencies irrespective of the distance of interfering transmitter. Performance was degraded only for very close distances (1-2 km) of overlapping frequencies of interfering transmitter. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1605.01105;Communication Cost for Updating Linear Functions when Message Updates  are Sparse: Connections to Maximally Recoverable Codes; N. Prakash,  Muriel Medard;  We consider a communication problem in which an update of the source message needs to be conveyed to one or more distant receivers that are interested in maintaining specific linear functions of the source message. The setting is one in which the updates are sparse in nature, and where neither the source nor the receiver(s) is aware of the exact {\em difference vector}, but only know the amount of sparsity that is present in the difference-vector. Under this setting, we are interested in devising linear encoding and decoding schemes that minimize the communication cost involved. We show that the optimal solution to this problem is closely related to the notion of maximally recoverable codes (MRCs), which were originally introduced in the context of coding for storage systems. In the context of storage, MRCs guarantee optimal erasure protection when the system is partially constrained to have local parity relations among the storage nodes. In our problem, we show that optimal solutions exist if and only if MRCs of certain kind (identified by the desired linear functions) exist. We consider point-to-point and broadcast versions of the problem, and identify connections to MRCs under both these settings. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01110;On the Delay of Geographical Caching Methods in Two-Tiered Heterogeneous  Networks; Ejder Baştuğ,  Marios Kountouris,  Mehdi Bennis,  Mérouane Debbah;  We consider a hierarchical network that consists of mobile users, a two-tiered cellular network (namely small cells and macro cells) and central routers, each of which follows a Poisson point process (PPP). In this scenario, small cells with limited-capacity backhaul are able to cache content under a given set of randomized caching policies and storage constraints. Moreover, we consider three different content popularity models, namely fixed content popularity, distance-dependent and load-dependent, in order to model the spatio-temporal behavior of users' content request patterns. We derive expressions for the average delay of users assuming perfect knowledge of content popularity distributions and randomized caching policies. Although the trend of the average delay for all three content popularity models is essentially identical, our results show that the overall performance of cached-enabled heterogeneous networks can be substantially improved, especially under the load-dependent content popularity model. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01120;Information Sources on a Bratteli diagram; John C. Kieffer;  A Bratteli diagram is a type of graph in which the vertices are split into finite subsets occupying an infinite sequence of levels, starting with a bottom level and moving to successively higher levels along edges connecting consecutive levels. An information source on a Bratteli diagram consists of a sequence of PMFs on the vertex sets at each level that are compatible under edge transport. By imposing a regularity condition on the Bratteli diagram, we obtain various results for its information sources including ergodic and entropy rate decomposition theorems, a Shannon-Mcmillan-Breiman theorem, and lossless and lossy source coding theorems. Proof methodology exploits the Vershik transformation on the path space of a Bratteli diagram. Some results for finite alphabet stationary sequential information sources are seen to be a special case of the results of this paper. ;"Information Theory (cs.IT); Dynamical Systems (math.DS)"
https://arxiv.org/abs/1605.01160;Successive Interference Cancellation in Bipolar Ad Hoc Networks with  SWIPT; Constantinos Psomas,  Ioannis Krikidis;  Successive interference cancellation (SIC) is based on the idea that some interfering signals may be strong enough to decode in order to be removed from the aggregate received signal and thus boost performance. In this letter, we study the SIC technique from a simultaneous wireless information and power transfer (SWIPT) standpoint. We consider a bipolar ad hoc network and evaluate the impact of SIC on the SWIPT performance for the power splitting technique. Theoretical and numerical results show that our proposed approach can achieve significant energy gains and under certain scenarios the average harvested energy converges to its upper bound. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01178;Optimal Degrees of Freedom Region for the Asymmetric MIMO Y Channel; Kangqi Liu,  Xiaojun Yuan,  Meixia Tao;  This letter studies the optimal degrees of freedom (DoF) region for the asymmetric three-user MIMO Y channel with antenna configuration $(M_1,M_2,M_3,N)$, where $M_i$ is the number of antennas at user $i$ and $N$ is the number of antennas at the relay node. The converse is proved by using the cut-set theorem and the genie-message approach. To prove the achievability, we divide the DoF tuples in the outer bound into two cases. For each case, we show that the DoF tuples are achievable by collectively utilizing antenna deactivation, pairwise signal alignment and cyclic signal alignment techniques. This work not only offers a complete characterization of DoF region for the considered channel model, but also provides a new and elegant achievability proof. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01182;On empirical cumulant generating functions of code lengths for  individual sequences; Neri Merhav;  We consider the problem of lossless compression of individual sequences using finite-state (FS) machines, from the perspective of the best achievable empirical cumulant generating function (CGF) of the code length, i.e., the normalized logarithm of the empirical average of the exponentiated code length. Since the probabilistic CGF is minimized in terms of the R\'enyi entropy of the source, one of the motivations of this study is to derive an individual-sequence analogue of the R\'enyi entropy, in the same way that the FS compressibility is the individual-sequence counterpart of the Shannon entropy. We consider the CGF of the code-length both from the perspective of fixed-to-variable (F-V) length coding and the perspective of variable-to-variable (V-V) length coding, where the latter turns out to yield a better result, that coincides with the FS compressibility. We also extend our results to compression with side information, available at both the encoder and decoder. In this case, the V-V version no longer coincides with the FS compressibility, but results in a different complexity measure. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01184;Optimal DoF Region for the Asymmetric Two-Pair MIMO Two-Way Relay  Channel; Kangqi Liu,  Meixia Tao,  Xiaojun Yuan;  In this paper, we study the optimal degrees of freedom (DoF) region for the two-pair MIMO two-way relay channel (TWRC) with asymmetric antenna setting, where two pairs of users exchange information with the help of a common relay. Each user $i$ is equipped with $M_i$ antennas, for $i=1,2,3,4$, and the relay is equipped with $N$ antennas. First, we derive an outer bound of the DoF region by using the cut-set theorem and the genie-message approach. Then, we propose a new transmission scheme to achieve the outer bound of the DoF region. Due to the asymmetric data exchange, where the two users in each pair can communicate a different number of data streams, we not only need to form the network-coded symbols but also need to process the additional asymmetric data streams at the relay. This is realized through the joint design of relay compression matrix and source precoding matrices. After obtaining the optimal DoF region, we study the optimal sum DoF by solving a linear programming problem. From the optimal DoF region of this channel, we show that in the asymmetric antenna setting, some antennas at certain source nodes are redundant and cannot contribute to enlarge the DoF region. We also show that there is no loss of optimality in terms of the sum DoF by enforcing symmetric data exchange, where the two users in each pair are restricted to communicate the same number of data streams. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01191;Waveform Optimization for Large-Scale Multi-Antenna Multi-Sine Wireless  Power Transfer; Yang Huang,  Bruno Clerckx;  Wireless power transfer (WPT) is expected to be a technology reshaping the landscape of low-power applications such as the Internet of Things, machine-to-machine communications and radio frequency identification networks. Although there has been some progress towards multi-antenna multi-sine WPT design, the large-scale design of WPT, reminiscent of massive multiple-input multiple-output (MIMO) in communications, remains an open problem. Considering the nonlinear rectifier model, a multiuser waveform optimization algorithm is derived based on successive convex approximation (SCA). A lower-complexity algorithm is derived based on asymptotic analysis and sequential approximation (SA). It is shown that the difference between the average output voltage achieved by the two algorithms can be negligible provided the number of antennas is large enough. The performance gain of the nonlinear model based design over the linear model based design can be large, in the presence of a large number of tones. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01211;An Upper Bound for the Capacity of Amplitude-Constrained Scalar AWGN  Channel; Borazon Rassouli,  Bruno Clerckx;  This paper slightly improves the upper bound in Thangaraj et al. for the capacity of the amplitude-constrained scalar AWGN channel. This improvement makes the upper bound within 0.002 bits of the capacity for $\frac{E_b}{N_0}\leq 2.5$ dB. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01233;Info-Clustering: A Mathematical Theory for Data Clustering; Chung Chan,  Ali Al-Bashabsheh,  Qiaoqiao Zhou,  Tarik Kaced,  Tie Liu;  We formulate an info-clustering paradigm based on a multivariate information measure, called multivariate mutual information, that naturally extends Shannon's mutual information between two random variables to the multivariate case involving more than two random variables. With proper model reductions, we show that the paradigm can be applied to study the human genome and connectome in a more meaningful way than the conventional algorithmic approach. Not only can info-clustering provide justifications and refinements to some existing techniques, but it also inspires new computationally feasible solutions. ;"Information Theory (cs.IT); Genomics (q-bio.GN); Neurons and Cognition (q-bio.NC)"
https://arxiv.org/abs/1605.01330;On the capacity of the binary adversarial wiretap channel; Carol Wang;  New bounds on the semantic secrecy capacity of the binary adversarial wiretap channel are established . Against an adversary which reads a $\rho_r$ fraction of the transmitted codeword and modifies a $\rho_w$ fraction of the codeword, we show an achievable rate of $1-h(\rho_w)-\rho_r$, where $h(\cdot)$ is the binary entropy function. We also give an upper bound which is nearly matching when $\rho_r$ is small. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01331;Linear Network Coding Capacity Region of The Smart Repeater with  Broadcast Erasure Channels; Jaemin Han,  Chih-Chun Wang;"  This work considers the smart repeater network where a single source $s$ wants to send two independent packet streams to destinations $\{d_1,d_2\}$ with the help of relay $r$. The transmission from $s$ or $r$ is modeled by packet erasure channels: For each time slot, a packet transmitted by $s$ may be received, with some probabilities, by a random subset of $\{d_1,d_2,r\}$; and those transmitted by $r$ will be received by a random subset of $\{d_1,d_2\}$. Interference is avoided by allowing at most one of $\{s,r\}$ to transmit in each time slot. One example of this model is any cellular network that supports two cell-edge users when a relay in the middle uses the same downlink resources for throughput/safety enhancement. In this setting, we study the capacity region of $(R_1,R_2)$ when allowing linear network coding (LNC). The proposed LNC inner bound introduces more advanced packing-mixing operations other than the previously well-known butterfly-style XOR operation on overheard packets of two co-existing flows. A new LNC outer bound is derived by exploring the inherent algebraic structure of the LNC problem. Numerical results show that, with more than 85% of the experiments, the relative sum-rate gap between the proposed outer and inner bounds is smaller than 0.08% under the strong-relaying setting and 0.04% under arbitrary distributions, thus effectively bracketing the LNC capacity of the smart repeater problem. ";Information Theory (cs.IT)
https://arxiv.org/abs/1605.01348;Private Coded Caching; Vaishakh Ravindrakumar,  Parthasarathi Panda,  Nikhil Karamchandani,  Vinod Prabhakaran;  Recent work by Maddah-Ali and Niesen introduced coded caching which demonstrated the benefits of joint design of storage and transmission policies in content delivery networks. They studied a setup where a server communicates with a set of users, each equipped with a local cache, over a shared error-free link and proposed an order-optimal caching and delivery scheme. In this paper, we introduce the problem of secretive coded caching where we impose the additional constraint that a user should not be able to learn anything, from either the content stored in its cache or the server transmissions, about a file it did not request. We propose a feasible scheme for this setting and demonstrate its order-optimality with respect to information-theoretic lower bounds. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01424;Coded Caching for Networks with the Resolvability Property; Li Tang,  Aditya Ramamoorthy;  Coded caching is a recently proposed technique for dealing with large scale content distribution over the Internet. As in conventional caching, it leverages the presence of local caches at the end users. However, it considers coding in the caches and/or coded transmission from the central server and demonstrates that huge savings in transmission rate are possible when the server and the end users are connected via a single shared link. In this work, we consider a more general topology where there is a layer of relay nodes between the server and the users, e.g., combination networks studied in network coding are an instance of these networks. We propose novel schemes for a class of such networks that satisfy a so-called resolvability property and demonstrate that the performance of our scheme is strictly better than previously proposed schemes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01434;Performance Comparison of CP-OFDM and OQAM-OFDM Based WiFi Systems; Martin Fuhrwerk,  Christoph Thein,  Lars Häring;  In this contribution, a direct comparison of the Offset-QAM-OFDM (OQAM-OFDM) and the Cyclic Prefix OFDM (CP-OFDM) scheme is given for an 802.11a based system. Therefore, the chosen algorithms and choices of design are described and evaluated as a whole system in terms of bit and frame error rate (BER/FER) performance as well as spectral efficiency and complexity in the presence of multipath propagation for different modulation orders. The results show that the OQAM-OFDM scheme exhibits similar BER and FER performance at a 24% higher spectral efficiency and achievable throughput at the cost of an up to five times increased computational complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01436;Sampling Requirements for Stable Autoregressive Estimation; Abbas Kazemipour,  Sina Miran,  Piya Pal,  Behtash Babadi,  Min Wu;  We consider the problem of estimating the parameters of a linear univariate autoregressive model with sub-Gaussian innovations from a limited sequence of consecutive observations. Assuming that the parameters are compressible, we analyze the performance of the $\ell_1$-regularized least squares as well as a greedy estimator of the parameters and characterize the sampling trade-offs required for stable recovery in the non-asymptotic regime. In particular, we show that for a fixed sparsity level, stable recovery of AR parameters is possible when the number of samples scale sub-linearly with the AR order. Our results improve over existing sampling complexity requirements in AR estimation using the LASSO, when the sparsity level scales faster than the square root of the model order. We further derive sufficient conditions on the sparsity level that guarantee the minimax optimality of the $\ell_1$-regularized least squares estimate. Applying these techniques to simulated data as well as real-world datasets from crude oil prices and traffic speed data confirm our predicted theoretical performance gains in terms of estimation accuracy and model selection. ;"Information Theory (cs.IT); Discrete Mathematics (cs.DM); Optimization and Control (math.OC); Methodology (stat.ME); Machine Learning (stat.ML)"
https://arxiv.org/abs/1605.01473;Topological Interference Management with Reconfigurable Antennas; Heecheol Yang,  Navid Naderializadeh,  Amir Salman Avestimehr,  Jungwoo Lee;  We study the symmetric degrees-of-freedom (DoF) of partially connected interference networks under linear coding strategies at transmitters without channel state information beyond topology. We assume that the receivers are equipped with reconfigurable antennas that can switch among their preset modes. In such a network setting, we characterize the class of network topologies in which half linear symmetric DoF is achievable. Moreover, we derive a general upper bound on the linear symmetric DoF for arbitrary network topologies. We also show that this upper bound is tight if the transmitters have at most two co-interferers. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01501;Constant Envelope Pilot-Based Low-Complexity CFO Estimation in Massive  MU-MIMO Systems; Sudarshan Mukherjee,  Saif Khan Mohammed;  In this paper we consider a constant envelope pilot signal based carrier frequency offset (CFO) estimation in massive multiple-input multiple-output (MIMO) systems. The proposed algorithm performs spatial averaging on the periodogram of the received pilots across the base station (BS) antennas. Our study reveals that the proposed algorithm has complexity only linear in $M$ (the number of BS antennas). Further our analysis and numerical simulations also reveal that with fixed number of users and a fixed pilot length, the minimum required transmit pilot power decreases as $\frac{1}{\sqrt{M}}$ with increasing $M$, while maintaining a fixed desired mean squared error (MSE) of CFO estimation. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01549;Reduced Switching Connectivity for Large Scale Antenna Selection; Adrian Garcia-Rodriguez,  Christos Masouros,  Pawel Rulikowski;  In this paper, we explore reduced-connectivity radio frequency (RF) switching networks for reducing the analog hardware complexity and switching power losses in antenna selection (AS) systems. In particular, we analyze different hardware architectures for implementing the RF switching matrices required in AS designs with a reduced number of RF chains. We explicitly show that fully-flexible switching matrices, which facilitate the selection of any possible subset of antennas and attain the maximum theoretical sum rates of AS, present numerous drawbacks such as the introduction of significant insertion losses, particularly pronounced in massive multiple-input multiple-output (MIMO) systems. Since these disadvantages make fully-flexible switching suboptimal in the energy efficiency sense, we further consider partially-connected switching networks as an alternative switching architecture with reduced hardware complexity, which we characterize in this work. In this context, we also analyze the impact of reduced switching connectivity on the analog hardware and digital signal processing of AS schemes that rely on channel power information. Overall, the analytical and simulation results shown in this paper demonstrate that partially-connected switching maximizes the energy efficiency of massive MIMO systems for a reduced number of RF chains, while fully-flexible switching offers sub-optimal energy efficiency benefits due to its significant switching power losses. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01557;On the Aloha throughput-fairness tradeoff; Nan Xie,  Steven Weber;  A well-known inner bound of the stability region of the slotted Aloha protocol on the collision channel with n users assumes worst-case service rates (all user queues non-empty). Using this inner bound as a feasible set of achievable rates, a characterization of the throughput--fairness tradeoff over this set is obtained, where throughput is defined as the sum of the individual user rates, and two definitions of fairness are considered: the Jain-Chiu-Hawe function and the sum-user alpha-fair (isoelastic) utility function. This characterization is obtained using both an equality constraint and an inequality constraint on the throughput, and properties of the optimal controls, the optimal rates, and the fairness as a function of the target throughput are established. A key fact used in all theorems is the observation that all contention probability vectors that extremize the fairness functions take at most two non-zero values. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI); Performance (cs.PF)"
https://arxiv.org/abs/1605.01641;Achievable Sum DoF of the K-User MIMO Interference Channel with Delayed  CSIT; Chenxi Hao,  Bruno Clerckx;  This paper considers a $K$-user multiple-input-multiple-output (MIMO) interference channel (IC) where 1) the channel state information obtained by the transmitters (CSIT) is completely outdated, and 2) the number of transmit antennas at each transmitter, i.e., $M$, is greater than the number of receive antennas at each user, i.e., $N$. The usefulness of the delayed CSIT was firstly identified in a $K$-phase Retrospective Interference Alignment (RIA) scheme proposed by Maddah-Ali et al for the Multiple-Input-Single-Output Broadcast Channel, but the extension to the MIMO IC is a non-trivial step as each transmitter only has the message intended for the corresponding user. Recently, Abdoli et al focused on a Single-Input-Single-Output IC and solved such bottleneck by inventing a $K$-phase RIA with distributed overheard interference retransmission. In this paper, we propose two $K$-phase RIA schemes suitable for the MIMO IC by generalizing and integrating some key features of both Abdoli's and Maddah-Ali's works. The two schemes jointly yield the best known sum Degrees-of-Freedom (DoF) performance so far. For the case $\frac{M}{N}{\geq}K$, the achieved sum DoF is asymptotically given by $\frac{64}{15}N$ when $K{\to}\infty$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01668;A Layered Caching Architecture for the Interference Channel; Jad Hachem,  Urs Niesen,  Suhas Diggavi;  Recent work has studied the benefits of caching in the interference channel, particularly by placing caches at the transmitters. In this paper, we study the two-user Gaussian interference channel in which caches are placed at both the transmitters and the receivers. We propose a separation strategy that divides the physical and network layers. While a natural separation approach might be to abstract the physical layer into several independent bit pipes at the network layer, we argue that this is inefficient. Instead, the separation approach we propose exposes interacting bit pipes at the network layer, so that the receivers observe related (yet not identical) quantities. We find the optimal strategy within this layered architecture, and we compute the degrees-of-freedom it achieves. Finally, we show that separation is optimal in regimes where the receiver caches are large. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01690;Fog-Aided Wireless Networks for Content Delivery: Fundamental Latency  Trade-Offs; Avik Sengupta,  Ravi Tandon,  Osvaldo Simeone;  A fog-aided wireless network architecture is studied in which edge-nodes (ENs), such as base stations, are connected to a cloud processor via dedicated fronthaul links, while also being endowed with caches. Cloud processing enables the centralized implementation of cooperative transmission strategies at the ENs, albeit at the cost of an increased latency due to fronthaul transfer. In contrast, the proactive caching of popular content at the ENs allows for the low-latency delivery of the cached files, but with generally limited opportunities for cooperative transmission among the ENs. The interplay between cloud processing and edge caching is addressed from an information-theoretic viewpoint by investigating the fundamental limits of a high Signal-to-Noise-Ratio (SNR) metric, termed normalized delivery time (NDT), which captures the worst-case coding latency for delivering any requested content to the users. The NDT is defined under the assumptions of either serial or pipelined fronthaul-edge transmission, and is studied as a function of fronthaul and cache capacity constraints. Placement and delivery strategies across both fronthaul and wireless, or edge, segments are proposed with the aim of minimizing the NDT. Information-theoretic lower bounds on the NDT are also derived. Achievability arguments and lower bounds are leveraged to characterize the minimal NDT in a number of important special cases, including systems with no caching capabilities, as well as to prove that the proposed schemes achieve optimality within a constant multiplicative factor of 2 for all values of the problem parameters. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1605.01696;A Many Antenna High Rate Wireless System; Philip Gossett,  Jeremy Thorpe,  Bob Nuckolls,  Brett Coon,  Dan McCloskey,  David Chang,  Greg Steuck,  Paul Rodman,  Sasha Levitskiy,  Yuan Yuan;  We describe a TDD MIMO wireless system designed to operate at high bandwidth and low SNR. Signals are transmitted as a direct sequence. In the uplink (Multiple Access Channel), signal detection is done by a space-time whitening filter followed by a matched filter. In the downlink (Broadcast Channel), precoding is done by the transpose of these filters. We further describe an implementation of this system that uses an array of 32 antennas to communicate with 32 single-antenna clients simultaneously on the same frequencies between 512-608 and 614-698 MHz. At close range, all 32 links achieve the full PHY data rate, both uplink and downlink, with less than 1\% Block Error Rate on each link. The total system rate is 3.8 Gb/s. The system spectral efficiency is 21.7 b/s/Hz for both uplink and downlink. We close with some projections to the not-to-distant future. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01829;Downlink Transmission of Short Packets: Framing and Control Information  Revisited; Kasper Fløe Trillingsgaard,  Petar Popovski;  Cellular wireless systems rely on frame-based transmissions. The frame design is conventionally based on heuristics, consisting of a frame header and a data part. The frame header contains control information that provides pointers to the messages within the data part. In this paper, we revisit the principles of frame design and show the impact of the new design in scenarios that feature short data packets which are central to various 5G and Internet of Things applications. We treat framing for downlink transmission in an AWGN broadcast channel with K users, where the sizes of the messages to the users are random variables. Using approximations from finite blocklength information theory, we establish a framework in which a message to a given user is not necessarily encoded as a single packet, but may be grouped with the messages to other users and benefit from the improved efficiency of longer codes. This requires changes in the way control information is sent, and it requires that the users need to spend power decoding other messages, thereby increasing the average power consumption. We show that the common heuristic design is only one point on a curve that represents the trade-off between latency and power consumption. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01834;Arbitrarily Varying Networks: Capacity-achieving Computationally  Efficient Codes; Peida Tian,  Sidharth Jaggi,  Mayank Bakshi,  Oliver Kosut;"  We consider the problem of communication over a network containing a hidden and malicious adversary that can control a subset of network resources, and aims to disrupt communications. We focus on omniscient node-based adversaries, i.e., the adversaries can control a subset of nodes, and know the message, network code and packets on all links. Characterizing information-theoretically optimal communication rates as a function of network parameters and bounds on the adversarially controlled network is in general open, even for unicast (single source, single destination) problems. In this work we characterize the information-theoretically optimal randomized capacity of such problems, i.e., under the assumption that the source node shares (an asymptotically negligible amount of) independent common randomness with each network node a priori (for instance, as part of network design). We propose a novel computationally-efficient communication scheme whose rate matches a natural information-theoretically ""erasure outer bound"" on the optimal rate. Our schemes require no prior knowledge of network topology, and can be implemented in a distributed manner as an overlay on top of classical distributed linear network coding. ";Information Theory (cs.IT)
https://arxiv.org/abs/1605.01848;On the Performance of Mobile Visible Light Communications; Yang Hong,  Lian-Kuan Chen;  We experimentally characterize the performance of mobile VLC and propose using OCT precoding to combat mobility-induced performance degradation. Results show that for approximate 300-Mb/s mobile VLC transmission, OCT precoding outperforms adaptive-loaded DMT and offers significant packet loss rate reduction. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01861;Incremental and Decremental Secret Key Agreement; Chung Chan,  Ali Al-Bashabsheh,  Qiaoqiao Zhou;  We study the rate of change of the multivariate mutual information among a set of random variables when some common randomness is added to or removed from a subset. This is formulated more precisely as two new multiterminal secret key agreement problems which ask how one can increase the secrecy capacity efficiently by adding common randomness to a small subset of users, and how one can simplify the source model by removing redundant common randomness that does not contribute to the secrecy capacity. The combinatorial structure has been clarified along with some meaningful open problems. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01867;Statistical mechanics analysis of thresholding 1-bit compressed sensing; Yingying Xu,  Yoshiyuki Kabashima;  The one-bit compressed sensing framework aims to reconstruct a sparse signal by only using the sign information of its linear measurements. To compensate for the loss of scale information, past studies in the area have proposed recovering the signal by imposing an additional constraint on the L2-norm of the signal. Recently, an alternative strategy that captures scale information by introducing a threshold parameter to the quantization process was advanced. In this paper, we analyze the typical behavior of the thresholding 1-bit compressed sensing utilizing the replica method of statistical mechanics, so as to gain an insight for properly setting the threshold value. Our result shows that, fixing the threshold at a constant value yields better performance than varying it randomly when the constant is optimally tuned, statistically. Unfortunately, the optimal threshold value depends on the statistical properties of the target signal, which may not be known in advance. In order to handle this inconvenience, we develop a heuristic that adaptively tunes the threshold parameter based on the frequency of positive (or negative) values in the binary outputs. Numerical experiments show that the heuristic exhibits satisfactory performance while incurring low computational cost. ;"Information Theory (cs.IT); Data Analysis, Statistics and Probability (physics.data-an)"
https://arxiv.org/abs/1605.01869;Lower Bound on the Redundancy of PIR Codes; Sankeerth Rao,  Alexander Vardy;  We prove that the redundancy of a $k$-server PIR code of dimension $s$ is $\Omega(\sqrt{s})$ for all $k \ge 3$. This coincides with a known upper bound of $O(\sqrt{s})$ on the redundancy of PIR codes. Moreover, for $k=3$ and $k = 4$, we determine the lowest possible redundancy of $k$-server PIR codes exactly. Similar results were proved independently by Mary Wootters using a different method. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01880;Privacy-Constrained Remote Source Coding; Kittipong Kittichokechai,  Giuseppe Caire;"  We consider the problem of revealing/sharing data in an efficient and secure way via a compact representation. The representation should ensure reliable reconstruction of the desired features/attributes while still preserve privacy of the secret parts of the data. The problem is formulated as a remote lossy source coding with a privacy constraint where the remote source consists of public and secret parts. Inner and outer bounds for the optimal tradeoff region of compression rate, distortion, and privacy leakage rate are given and shown to coincide for some special cases. When specializing the distortion measure to a logarithmic loss function, the resulting rate-distortion-leakage tradeoff for the case of identical side information forms an optimization problem which corresponds to the ""secure"" version of the so-called information bottleneck. ";Information Theory (cs.IT)
https://arxiv.org/abs/1605.01930;Context Information Based Initial Cell Search for Millimeter Wave 5G  Cellular Networks; Waqas Bin Abbas,  Michele Zorzi;  Millimeter wave (mmWave) communication is envisioned as a cornerstone to fulfill the data rate requirements for fifth generation (5G) cellular networks. In mmWave communication, beamforming is considered as a key technology to combat the high path-loss, and unlike in conventional microwave communication, beamforming may be necessary even during initial access/cell search. Among the proposed beamforming schemes for initial cell search, analog beamforming is a power efficient approach but suffers from its inherent search delay during initial access. In this work, we argue that analog beamforming can still be a viable choice when context information about mmWave base stations (BS) is available at the mobile station (MS). We then study how the performance of analog beamforming degrades in case of angular errors in the available context information. Finally, we present an analog beamforming receiver architecture that uses multiple arrays of Phase Shifters and a single RF chain to combat the effect of angular errors, showing that it can achieve the same performance as hybrid beamforming. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1605.01941;Partial DNA Assembly: A Rate-Distortion Perspective; Ilan Shomorony,  Govinda M. Kamath,  Fei Xia,  Thomas A. Courtade,  David N. Tse;"  Earlier formulations of the DNA assembly problem were all in the context of perfect assembly; i.e., given a set of reads from a long genome sequence, is it possible to perfectly reconstruct the original sequence? In practice, however, it is very often the case that the read data is not sufficiently rich to permit unambiguous reconstruction of the original sequence. While a natural generalization of the perfect assembly formulation to these cases would be to consider a rate-distortion framework, partial assemblies are usually represented in terms of an assembly graph, making the definition of a distortion measure challenging. In this work, we introduce a distortion function for assembly graphs that can be understood as the logarithm of the number of Eulerian cycles in the assembly graph, each of which correspond to a candidate assembly that could have generated the observed reads. We also introduce an algorithm for the construction of an assembly graph and analyze its performance on real genomes. ";"Information Theory (cs.IT); Genomics (q-bio.GN)"
https://arxiv.org/abs/1605.01993;Coded Caching for a Large Number Of Users; Mohammad Mohammadi Amiri,  Qianqian Yang,  Deniz Gunduz;  Information theoretic analysis of a coded caching system is considered, in which a server with a database of N equal-size files, each F bits long, serves K users. Each user is assumed to have a local cache that can store M files, i.e., capacity of MF bits. Proactive caching to user terminals is considered, in which the caches are filled by the server in advance during the placement phase, without knowing the user requests. Each user requests a single file, and all the requests are satisfied simultaneously through a shared error-free link during the delivery phase. First, centralized coded caching is studied assuming both the number and the identity of the active users in the delivery phase are known by the server during the placement phase. A novel group-based centralized coded caching (GBC) scheme is proposed for a cache capacity of M = N/K. It is shown that this scheme achieves a smaller delivery rate than all the known schemes in the literature. The improvement is then extended to a wider range of cache capacities through memory-sharing between the proposed scheme and other known schemes in the literature. Next, the proposed centralized coded caching idea is exploited in the decentralized setting, in which the identities of the users that participate in the delivery phase are assumed to be unknown during the placement phase. It is shown that the proposed decentralized caching scheme also achieves a delivery rate smaller than the state-of-the-art. Numerical simulations are also presented to corroborate our theoretical results. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.01997;Near-Optimal Finite-Length Scaling for Polar Codes over Large Alphabets; Henry D. Pfister,  Rüdiger Urbanke;  For any prime power $q$, Mori and Tanaka introduced a family of $q$-ary polar codes based on $q$ by $q$ Reed-Solomon polarization kernels. For transmission over a $q$-ary erasure channel, they also derived a closed-form recursion for the erasure probability of each effective channel. In this paper, we use that expression to analyze the finite-length scaling of these codes on $q$-ary erasure channel with erasure probability $\epsilon\in(0,1)$. Our primary result is that, for any $\gamma>0$ and $\delta>0$, there is a $q_{0}$ such that, for all $q\geq q_{0}$, the fraction of effective channels with erasure rate at most $N^{-\gamma}$ is at least $1-\epsilon-O(N^{-1/2+\delta})$, where $N=q^{n}$ is the blocklength. Since this fraction cannot be larger than $1-\epsilon-O(N^{-1/2})$, this establishes near-optimal finite-length scaling for this family of codes. Our approach can be seen as an extension of a similar analysis for binary polar codes by Hassani, Alishahi, and Urbanke. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02055;Secrecy Rate Maximization for MISO Multicasting SWIPT System with Power  Splitting Scheme; Miao Zhang,  Kanapathippillai Cumanan,  Alister Burr;  This paper considers transmit covariance matrix design for secrecy rate maximization problem in a multiple-input single-output (MISO) multicasting simultaneous wireless information and power transfer (SWIPT) system. In order to enhance the performance of the system, artificial noise (AN) is added to the transmit signal in the design for the following purposes: to reduce the received signal-to-noise ratio (SNR) at the eavesdroppers and increase the harvested energy. We assume that all the channel-state-information (CSI) is perfectly known at the transmitter and all legitimate users are capable of simultaneously receiving information and harvesting energy. In addition, all the eavesdroppers are passive and they can harvest energy only when they are not intercepting or eavesdropping the messages intended for the legitimate users. The original secrecy rate maximization problem is not convex in terms of transmit and artificial covariance matrices as well as the power splitting (PS) ratio. In order to circumvent this non-convexity issue, we exploit the \emph{Charnes-Cooper} Transformation and semidefinite relaxation (SDR) to convert this original problem into a convex one. However, this convex problem does not always yield the rank-one transmit and AN covariance matrices to obtain the solution of the original problem. Therefore, we analyze the optimal conditions and utilize a Gaussian randomization (GR) method to construct the rank-one solutions from the non-rank one results. Simulation results have been provided to demonstrate the performance of the proposed transmit covariance matrices design for MISO multicasting SWIPT system. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02147;Unified Error Rates Analysis of MIMO Space-Time Block Codes over  Generalized Shadowed κ-μ and η-μ Fading and AWGGN; Ehab Salahat,  Ali Hakam;  This paper presents a novel unified performance analysis of Space-Time Block Codes (STBCs) operating in the Multiple Input Multiple Output (MIMO) network and subjected to generalized shadowed fading and noise scenarios. Specifically, we derive novel, simple and accurate average bit error rates (ABER) expressions for coherent modulation schemes in the generalized {\eta}-{\mu} and shadowed {\kappa}-{\mu} fading channels. The noise in the network is assumed to be modeled by the additive white generalized Gaussian noise (AWGGN), which encompasses the Laplacian and the Gaussian noise environments as special cases. The result obviates the need to re-derive the error rates for MIMO STBC systems under many multipath fading and noise models, while avoiding computationally-expensive expressions. Published results from the literature as well as numerical simulations corroborate the accuracy of our derived generalized expressions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02152;Maximal Ratio Combining Diversity Analysis of Underwater Acoustic  Communications Subject to $κ-μ$ Shadowed Fading Channels; Ehab Salahat,  Ali Hakam;  In this paper, a novel unified analytical expression for average bit error rates (ABER) and average channel capacity (ACC) is presented for the ${\kappa}-{\mu}$ shadowed fading model. This new shadowed fading model has shown to be suitable for underwater wireless channel modeling for the measurements conducted by the Naval Research Laboratory, and is not so well covered in the public literature. Deploying the Maximal Ratio Combining (MRC) receiver, a new simple analytical expression for the probability density function (PDF) of the receiver output signal to noise ratio is presented. Based on this new PDF, the novel unified ABER and ACC expression derived. To further generalize the error rate analysis, the additive white generalized Gaussian noise model is assumed that models the different noise environments. The new unified expression is accurate, simple and generic, and is suitable for MRC analysis in this generalized shadowed fading and noise environment. Numerical techniques and published results from the technical literature corroborate the generality and accuracy of our analysis under the different test scenarios. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02175;Asymptotics of Input-Constrained Erasure Channel Capacity; Yonglong Li,  Guangyue Han;"  In this paper, we examine an input-constrained erasure channel and we characterize the asymptotics of its capacity when the erasure rate is low. More specifically, for a general memoryless erasure channel with its input supported on an irreducible finite-type constraint, we derive partial asymptotics of its capacity, using some series expansion type formulas of its mutual information rate; and for a binary erasure channel with its first-order Markovian input supported on the $(1, \infty)$-RLL constraint, based on the concavity of its mutual information rate with respect to some parameterization of the input, we numerically evaluate its first-order Markov capacity and further derive its full asymptotics. The asymptotics obtained in this paper, when compared with the recently derived feedback capacity for a binary erasure channel with the same input constraint, enable us to draw the conclusion that feedback may increase the capacity of an input-constrained channel, even if the channel is memoryless. ";Information Theory (cs.IT)
https://arxiv.org/abs/1605.02213;Online Learning and Optimization of Markov Jump Affine Models; Sevi Baltaoglu,  Lang Tong,  Qing Zhao;  The problem of online learning and optimization of unknown Markov jump affine models is considered. An online learning policy, referred to as Markovian simultaneous perturbations stochastic approximation (MSPSA), is proposed for two different optimization objectives: (i) the quadratic cost minimization of the regulation problem and (ii) the revenue (profit) maximization problem. It is shown that the regret of MSPSA grows at the order of the square root of the learning horizon. Furthermore, by the use of van Trees inequality, it is shown that the regret of any policy grows no slower than that of MSPSA, making MSPSA an order optimal learning policy. In addition, it is also shown that the MSPSA policy converges to the optimal control input almost surely as well as in the mean square sense. Simulation results are presented to illustrate the regret growth rate of MSPSA and to show that MSPSA can offer significant gain over the greedy certainty equivalent approach. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02233;On the Capacity of the Beta-Binomial Channel Model for Multi-Level Cell  Flash Memories; Veeresh Taranalli,  Hironori Uchikawa,  Paul H. Siegel;  The beta-binomial (BBM) channel model was recently proposed to model the overdispersed statistics of empirically observed bit errors in multi-level cell (MLC) flash memories. In this paper, we study the capacity of the BBM channel model for MLC flash memories. Using the compound channel approach, we first show that the BBM channel model capacity is zero. However, through empirical observation, this appears to be a very pessimistic estimate of the flash memory channel capacity. We propose a refined channel model called the truncated-support beta-binomial (TS-BBM) channel model and derive its capacity. Using empirical error statistics from 1X-nm and 2Y-nm MLC flash memories, we numerically estimate the TS-BBM channel model capacity as a function of the program/erase (P/E) cycling stress. The capacity of the 2-TS-BBM channel model provides an upper bound on the coding rates for the flash memory chip assuming a single binary error correction code is used. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02238;Latency Analysis of Systems with Multiple Interfaces for Ultra-Reliable  M2M Communication; Jimmy J. Nielsen,  Petar Popovski;  One of the ways to satisfy the requirements of ultra-reliable low latency communication for mission critical Machine-type Communications (MTC) applications is to integrate multiple communication interfaces. In order to estimate the performance in terms of latency and reliability of such an integrated communication system, we propose an analysis framework that combines traditional reliability models with technology-specific latency probability distributions. In our proposed model we demonstrate how failure correlation between technologies can be taken into account. We show for the considered scenario with fiber and different cellular technologies how up to 5-nines reliability can be achieved and how packet splitting can be used to reduce latency substantially while keeping 4-nines reliability. The model has been validated through simulation. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1605.02268;Rate-Distortion Bounds on Bayes Risk in Supervised Learning; Matthew Nokleby,  Ahmad Beirami,  Robert Calderbank;  An information-theoretic framework is presented for estimating the number of labeled samples needed to train a classifier in a parametric Bayesian setting. Ideas from rate-distortion theory are used to derive bounds on the average $L_1$ or $L_\infty$ distance between the learned classifier and the true maximum a posteriori classifier---which are well-established surrogates for the excess classification error due to imperfect learning---in terms of the differential entropy of the posterior distribution, the Fisher information of the parametric family, and the number of training samples available. The maximum {\em a posteriori} classifier is viewed as a random source, labeled training data are viewed as a finite-rate encoding of the source, and the $L_1$ or $L_\infty$ Bayes risk is viewed as the average distortion. The result is a complementary framework to the well-known probably approximately correct (PAC) framework. PAC bounds characterize worst-case learning performance of a family of classifiers whose complexity is captured by the Vapnik-Chervonenkis (VC) dimension. The rate-distortion framework, on the other hand, characterizes the average-case performance of a family of data distributions in terms of a quantity called the interpolation dimension, which represents the complexity of the family of data distributions. The resulting bounds do not suffer from the pessimism typical of the PAC framework, particularly when the training set is small. The framework also naturally accommodates multi-class settings. Furthermore, Monte Carlo methods provide accurate estimates of the bounds even for complicated distributions. The effectiveness of this framework is demonstrated in both a binary and multi-class Gaussian setting. ;"Information Theory (cs.IT); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1605.02281;Nonhomogeneous distributions and optimal quantizers for Sierpiński  carpets; Mrinal Kanti Roychowdhury;  The purpose of quantization of a probability distribution is to estimate the probability by a discrete probability with finite support. In this paper, a nonhomogeneous probability measure $P$ on $\mathbb R^2$ which has support the Sierpi\'nski carpet generated by a set of four contractive similarity mappings with equal similarity ratios has been considered . For this probability measure, the optimal sets of $n$-means and the $n$th quantization errors are investigated for all $n\geq 2$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1605.02290;New Constructions of SD and MR Codes over Small Finite Fields; Guangda Hu,  Sergey Yekhanin;  Data storage applications require erasure-correcting codes with prescribed sets of dependencies between data symbols and redundant symbols. The most common arrangement is to have $k$ data symbols and $h$ redundant symbols (that each depends on all data symbols) be partitioned into a number of disjoint groups, where for each group one allocates an additional (local) redundant symbol storing the parity of all symbols in the group. A code as above is maximally recoverable, if it corrects all erasure patterns that are information theoretically correctable given the dependency constraints. A slightly weaker guarantee is provided by SD codes. One key consideration in the design of MR and SD codes is the size of the finite field underlying the code as using small finite fields facilitates encoding and decoding operations. In this paper we present new explicit constructions of SD and MR codes over small finite fields. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00124;Caching Placement in Stochastic Wireless Caching Helper Networks:  Channel Selection Diversity via Caching; Seong Ho Chae,  Wan Choi;  Content delivery success in wireless caching helper networks depends mainly on cache-based channel selection diversity and network interference. For given channel fading and network geometry, both channel selection diversity and network interference dynamically vary according to what and how the caching helpers cache at their finite storage space. We study probabilistic content placement (or caching placement) to desirably control cache-based channel selection diversity and network interference in a stochastic wireless caching helper network, with sophisticated considerations of wireless fading channels, interactions among multiple users such as interference and loads at caching helpers, and arbitrary memory size. Using stochastic geometry, we derive optimal caching probabilities in closed form to maximize the average success probability of content delivery and propose an efficient algorithm to find the solution in a noise-limited network. In an interference-limited network, based on a lower bound of the average success probability of content delivery, we find near-optimal caching probabilities in closed form to control the channel selection diversity and the network interference. We numerically verify that the proposed content placement is superior to other comparable content placement strategies. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00127;On the Capacity of an Elemental Two-Way Two-Tier Network; Dennis Michaelis,  Aydin Sezgin,  Eduard Jorswieck;  A basic setup of a two-tier network, where two mobile users exchange messages with a multi-antenna macrocell basestation, is studied from a rate perspective subject to beamforming and power constraints. The communication is facilitated by two femtocell basestations which act as relays as there is no direct link between the macrocell basestation and the mobile users. We propose a scheme based on physical-layer network coding and compute-and-forward combined with a novel approach that solves the problem of beamformer design and power allocation. We also show that the optimal beamformers are always a convex combination of the channels between the macro- and femtocell basestations. We then establish the cut-set bound of the setup to show that the presented scheme almost achieves the capacity of the setup numerically. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00134;Constructions of Good Entanglement-Assisted Quantum Error Correcting  Codes; Kenza Guenda,  Somphong Jitman,  T. Aaron Gulliver;  Entanglement-assisted quantum error correcting codes (EAQECCs) are a simple and fundamental class of codes. They allow for the construction of quantum codes from classical codes by relaxing the duality condition and using pre-shared entanglement between the sender and receiver. However, in general it is not easy to determine the number of shared pairs required to construct an EAQECC. In this paper, we show that this number is related to the hull of the classical code. Using this fact, we give methods to construct EAQECCs requiring desirable amount of entanglement. This leads to design families of EAQECCs with good error performance. Moreover, we construct maximal entanglement EAQECCs from LCD codes. Finally, we prove the existence of asymptotically good EAQECCs in the odd characteristic case. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00397;Duplication-Correcting Codes for Data Storage in the DNA of Living  Organisms; Siddharth Jain,  Farzad Farnoud,  Moshe Schwartz,  Jehoshua Bruck;  The ability to store data in the DNA of a living organism has applications in a variety of areas including synthetic biology and watermarking of patented genetically-modified organisms. Data stored in this medium is subject to errors arising from various mutations, such as point mutations, indels, and tandem duplication, which need to be corrected to maintain data integrity. In this paper, we provide error-correcting codes for errors caused by tandem duplications, which create a copy of a block of the sequence and insert it in a tandem manner, i.e., next to the original. In particular, we present two families of codes for correcting errors due to tandem-duplications of a fixed length, the first family can correct any number of errors while the second corrects a bounded number of errors. We also study codes for correcting tandem duplications of length up to a given constant $k$, where we are primarily focused on the cases of $k=2,3$. Finally, we provide a full classification of the sets of lengths allowed in tandem duplication that result in a unique root for all sequences. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00478;Uplink and Downlink Rate Analysis of a Full-Duplex C-RAN with Radio  Remote Head Association; Mohammadali Mohammadi,  Himal A. Suraweera,  Chintha Tellambura;  We characterize the uplink (UL) and downlink (DL) rates of a full-duplex cloud radio access network (C-RAN) with all participate and single best remote radio head (RRH) association schemes. Specifically, multi-antenna equipped RRHs distributed according to a Poisson point process is assumed. The UL and DL sum rate of the single best RRH association scheme is maximized using receive and transmit beamformer designs at the UL and DL RRHs, respectively. In the case of the single best strategy, we study both optimum and sub-optimum schemes based on maximum ratio combining/maximal ratio transmission (MRC/MRT) and zero-forcing/MRT (ZF/MRT) processing. Numerical results show that significant performance improvements can be achieved by using the full-duplex mode as compared to the half-duplex mode. Moreover, the choice of the beamforming design and the RRH association scheme have a major influence on the achievable full-duplex gains. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00531;Fast and Robust Compressive Phase Retrieval with Sparse-Graph Codes; Dong Yin,  Kangwook Lee,  Ramtin Pedarsani,  Kannan Ramchandran;  In this paper, we tackle the compressive phase retrieval problem in the presence of noise. The noisy compressive phase retrieval problem is to recover a $K$-sparse complex signal $s \in \mathbb{C}^n$, from a set of $m$ noisy quadratic measurements: $ y_i=| a_i^H s |^2+w_i$, where $a_i^H\in\mathbb{C}^n$ is the $i$th row of the measurement matrix $A\in\mathbb{C}^{m\times n}$, and $w_i$ is the additive noise to the $i$th measurement. We consider the regime where $K=\beta n^\delta$, with constants $\beta>0$ and $\delta\in(0,1)$. We use the architecture of PhaseCode algorithm, and robustify it using two schemes: the almost-linear scheme and the sublinear scheme. We prove that with high probability, the almost-linear scheme recovers $s$ with sample complexity $\Theta(K \log(n))$ and computational complexity $\Theta(n \log(n))$, and the sublinear scheme recovers $s$ with sample complexity $\Theta(K\log^3(n))$ and computational complexity $\Theta(K\log^3(n))$. To the best of our knowledge, this is the first scheme that achieves sublinear computational complexity for compressive phase retrieval problem. Finally, we provide simulation results that support our theoretical contributions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00623;Spectrally-Precoded OFDM for 5G Wideband Operation in Fragmented  sub-6GHz Spectrum; Renaud-Alexandre Pitaval,  Branislav M. Popović,  Medhat Mohamad,  Rickard Nilsson,  Jaap van de Beek;  We consider spectrally-precoded OFDM waveforms for 5G wideband transmission in sub-6GHz band. In this densely packed spectrum, a low out-of-band (OOB) waveform is a critical 5G component to achieve the promised high spectral efficiency. By precoding data symbols before OFDM modulation, it is possible to achieve extremely low out-of-band emission with very sharp spectrum transition enabling an efficient and flexible usage of frequency resources. Spectrally-precoded OFDM shows promising results for reaching 5G targets in high-data rate enhanced mobile broadband and ultra-reliable low-latency communications use cases. Spectral precoding is particularly efficient for wideband transmission enabling short-time transmission, which will often require flexible fragmented spectrum usage. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00668;Unified Scalable Equivalent Formulations for Schatten Quasi-Norms; Fanhua Shang,  Yuanyuan Liu,  James Cheng;  The Schatten quasi-norm can be used to bridge the gap between the nuclear norm and rank function, and is the tighter approximation to matrix rank. However, most existing Schatten quasi-norm minimization (SQNM) algorithms, as well as for nuclear norm minimization, are too slow or even impractical for large-scale problems, due to the SVD or EVD of the whole matrix in each iteration. In this paper, we rigorously prove that for any p, p1, p2>0 satisfying 1/p=1/p1+1/p2, the Schatten-p quasi-norm of any matrix is equivalent to minimizing the product of the Schatten-p1 norm (or quasi-norm) and Schatten-p2 norm (or quasi-norm) of its two factor matrices. Then we present and prove the equivalence relationship between the product formula of the Schatten quasi-norm and its weighted sum formula for the two cases of p1 and p2: p1=p2 and p1\neq p2. In particular, when p>1/2, there is an equivalence between the Schatten-p quasi-norm of any matrix and the Schatten-2p norms of its two factor matrices, where the widely used equivalent formulation of the nuclear norm can be viewed as a special case. That is, various SQNM problems with p>1/2 can be transformed into the one only involving smooth, convex norms of two factor matrices, which can lead to simpler and more efficient algorithms than conventional methods. We further extend the theoretical results of two factor matrices to the cases of three and more factor matrices, from which we can see that for any 0<p<1, the Schatten-p quasi-norm of any matrix is the minimization of the mean of the Schatten-(p3+1)p norms of all factor matrices, where p3 denotes the largest integer not exceeding 1/p. In other words, for any 0<p<1, the SQNM problem can be transformed into an optimization problem only involving the smooth, convex norms of multiple factor matrices. ;"Information Theory (cs.IT); Optimization and Control (math.OC); Machine Learning (stat.ML)"
https://arxiv.org/abs/1606.00682;Constrained Phase Noise Estimation in OFDM Using Scattered Pilots  Without Decision Feedback; Pramod Mathecken,  Taneli Riihonen,  Stefan Werner,  Risto Wichman;  In this paper, we consider an OFDM radio link corrupted by oscillator phase noise in the receiver, namely the problem of estimating and compensating for the impairment. To lessen the computational burden and delay incurred onto the receiver, we estimate phase noise using only scattered pilot subcarriers, i.e., no tentative symbol decisions are used in obtaining and improving the phase noise estimate. In particular, the phase noise estimation problem is posed as an unconstrained optimization problem whose minimizer suffers from the so-called amplitude and phase estimation error. These errors arise due to receiver noise, estimation from limited scattered pilot subcarriers and estimation using a dimensionality reduction model. It is empirically shown that, at high signal-to-noise-ratios, the phase estimation error is small. To reduce the amplitude estimation error, we restrict the minimizer to be drawn from the so-called phase noise geometry set when minimizing the cost function. The resulting optimization problem is a non-convex program. However, using the S-procedure for quadratic equalities, we show that the optimal solution can be obtained by solving the convex dual problem. We also consider a less complex heuristic scheme that achieves the same objective of restricting the minimizer to the phase noise geometry set. Through simulations, we demonstrate improved coded bit-error-rate and phase noise estimation error performance when enforcing the phase noise geometry. For example, at high signal-to-noise-ratios, the probability density function of the phase noise estimation error exhibits thinner tails which results in lower bit-error-rate. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00737;Hardware Decoders for Polar Codes: An Overview; Pascal Giard,  Gabi Sarkis,  Alexios Balatsoukas-Stimming,  YouZhe Fan,  Chi-ying Tsui,  Andreas Burg,  Claude Thibeault,  Warren J. Gross;  Polar codes are an exciting new class of error correcting codes that achieve the symmetric capacity of memoryless channels. Many decoding algorithms were developed and implemented, addressing various application requirements: from error-correction performance rivaling that of LDPC codes to very high throughput or low-complexity decoders. In this work, we review the state of the art in polar decoders implementing the successive-cancellation, belief propagation, and list decoding algorithms, illustrating their advantages. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00755;Performance Prediction of Nonbinary Forward Error Correction in Optical  Transmission Experiments; Laurent Schmalen,  Alex Alvarado,  Rafael Rios-Müller;  In this paper, we compare different metrics to predict the error rate of optical systems based on nonbinary forward error correction (FEC). It is shown that the correct metric to predict the performance of coded modulation based on nonbinary FEC is the mutual information. The accuracy of the prediction is verified in a detailed example with multiple constellation formats, FEC overheads in both simulations and optical transmission experiments over a recirculating loop. It is shown that the employed FEC codes must be universal if performance prediction based on thresholds is used. A tutorial introduction into the computation of the threshold from optical transmission measurements is also given. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00757;A note on reductions between compressed sensing guarantees; Tom Morgan,  Jelani Nelson;  In compressed sensing, one wishes to acquire an approximately sparse high-dimensional signal $x\in\mathbb{R}^n$ via $m\ll n$ noisy linear measurements, then later approximately recover $x$ given only those measurement outcomes. Various guarantees have been studied in terms of the notion of approximation in recovery, and some isolated folklore results are known stating that some forms of recovery are stronger than others, via black-box reductions. In this note we provide a general theorem concerning the hierarchy of strengths of various recovery guarantees. As a corollary of this theorem, by reducing from well-known results in the compressed sensing literature, we obtain an efficient $\ell_p/\ell_p$ scheme for any $0<p<1$ with the fewest number of measurements currently known amongst efficient schemes, improving recent bounds of [SomaY16]. ;"Information Theory (cs.IT); Data Structures and Algorithms (cs.DS)"
https://arxiv.org/abs/1606.00815;On self-dual double negacirculant codes; Adel Alahmadi,  Hatoon Shohaib,  Patrick Solé;  Double negacirculant (DN) codes are the analogues in odd characteristic of double circulant codes. Self-dual DN codes of odd dimension are shown to be consta-dihedral. Exact counting formulae are derived for DN codes. The special class of length a power of two is studied by means of Dickson polynomials, and is shown to contain families of codes with relative distances satisfying a modified Gilbert-Varshamov bound. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00901;Sparse Signal Recovery using Generalized Approximate Message Passing  with Built-in Parameter Estimation; Shuai Huang,  Trac D. Tran;  The generalized approximate message passing (GAMP) algorithm under the Bayesian setting shows advantage in recovering under-sampled sparse signals from corrupted observations. Compared to conventional convex optimization methods, it has a much lower complexity and is computationally tractable. In the GAMP framework, the sparse signal and the observation are viewed to be generated according to some pre-specified probability distributions in the input and output channels. However, the parameters of the distributions are usually unknown in practice. In this paper, we propose an extended GAMP algorithm with built-in parameter estimation (PE-GAMP) and present its empirical convergence analysis. PE-GAMP treats the parameters as unknown random variables with simple priors and jointly estimates them with the sparse signals. Compared with Expectation Maximization (EM) based parameter estimation methods, the proposed PE-GAMP could draw information from the prior distributions of the parameters to perform parameter estimation. It is also more robust and much simpler, which enables us to consider more complex signal distributions apart from the usual Bernoulli-Gaussian (BGm) mixture distribution. Specifically, the formulations of Bernoulli-Exponential mixture (BEm) distribution and Laplace distribution are given in this paper. Simulated noiseless sparse signal recovery experiments demonstrate that the performance of the proposed PE-GAMP matches the oracle GAMP algorithm. When noise is present, both the simulated experiments and the real image recovery experiments show that PE-GAMP is still able to maintain its robustness and outperform EM based parameter estimation method when the sampling ratio is small. Additionally, using the BEm formulation of the PE-GAMP, we can successfully perform non-negative sparse coding of local image patches and provide useful features for the image classification task. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00933;Multipair Massive MIMO Relaying with Pilot-Data Transmission Overlay; Leyuan Pan,  Yongyu Dai,  Wei Xu,  Xiaodai Dong;  We propose a pilot-data transmission overlay scheme for multipair massive multiple-input multiple-output (MIMO) relaying systems employing either half- or full-duplex (HD or FD) communications at the relay station (RS). In the proposed scheme, pilots are transmitted in partial overlap with data to decrease the channel estimation overhead. The RS can detect the source data with minimal destination pilot interference by exploiting the asymptotic orthogonality of massive MIMO channels. Then pilot-data interference can be effectively suppressed with assistance of the detected source data in the destination channel estimation. Due to the transmission overlay, the effective data period is extended, hence improving system throughput. Both theoretical and simulation results confirm that the proposed pilot-data overlay scheme outperforms the conventional separate pilot-data design in the limited coherence time interval scenario. Moreover, asymptotic analyses at high and low SNR regions demonstrate the superiority of the proposed scheme regardless of the coherence interval length. Because of simultaneous transmission, the proper allocation of source data transmission and relay data forwarding power can further improve the system performance. Hence a power allocation problem is formulated and a successive convex approximation approach is proposed to solve the non-convex optimization problem with the FD pilot-data transmission overlay. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00952;Delay Optimal Scheduling of Arbitrarily Bursty Traffic over Multi-State  Time-Varying Channels; Meng Wang,  Juan Liu,  Wei Chen;  In this paper, we study joint queue-aware and channel-aware scheduling of arbitrarily bursty traffic over multi-state time-varying channels, where the bursty packet arrival in the network layer, the backlogged queue in the data link layer, and the power adaptive transmission with fixed modulation in the physical layer are jointly considered from a cross-layer perspective. To achieve minimum queueing delay given a power constraint, a probabilistic cross-layer scheduling policy is proposed, and characterized by a Markov chain model. To describe the delay-power tradeoff, we formulate a non-linear optimization problem, which however is very challenging to solve. To handle with this issue, we convert the optimization problem into an equivalent Linear Programming (LP) problem, which allows us to obtain the optimal threshold-based scheduling policy with an optimal threshold imposed on the queue length in accordance with each channel state. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.00963;Optimal quantizers for probability distributions on nonhomogeneous  R-triangles; Mrinal Kanti Roychowdhury;  Quantization of a probability distribution refers to the idea of estimating a given probability by a discrete probability supported by a finite set. In this paper, we have considered a Borel probability measure $P$ on $\mathbb R^2$ which has support the R-triangle generated by a set of three contractive similarity mappings on $\mathbb R^2$. For this probability measure, the optimal sets of $n$-means and the $n$th quantization error are determined for all $n\geq 2$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01040;Soft McEliece: MDPC code-based McEliece cryptosystems with very compact  keys through real-valued intentional errors; Marco Baldi,  Paolo Santini,  Franco Chiaraluce;  We propose to use real-valued errors instead of classical bit flipping intentional errors in the McEliece cryptosystem based on moderate-density parity-check (MDPC) codes. This allows to exploit the error correcting capability of these codes to the utmost, by using soft-decision iterative decoding algorithms instead of hard-decision bit flipping decoders. However, soft reliability values resulting from the use of real-valued noise can also be exploited by attackers. We devise new attack procedures aimed at this, and compute the relevant work factors and security levels. We show that, for a fixed security level, these new systems achieve the shortest public key sizes ever reached, with a reduction up to 25% with respect to previous proposals. ;"Information Theory (cs.IT); Cryptography and Security (cs.CR)"
https://arxiv.org/abs/1606.01190;Distributed stochastic optimization via matrix exponential learning; Panayotis Mertikopoulos,  E. Veronica Belmega,  Romain Negrel,  Luca Sanguinetti;  In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect and/or obsolete. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. We also derive an explicit linear bound for the algorithm's convergence speed, which remains valid under measurement errors and uncertainty of arbitrarily high variance. To validate our theoretical analysis, we test the algorithm in realistic multi-carrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. ;"Information Theory (cs.IT); Learning (cs.LG); Optimization and Control (math.OC)"
https://arxiv.org/abs/1606.01295;Weighted $\ell_1$-Minimization for Sparse Recovery under Arbitrary Prior  Information; Deanna Needell,  Rayan Saab,  Tina Woolf;  Weighted $\ell_1$-minimization has been studied as a technique for the reconstruction of a sparse signal from compressively sampled measurements when prior information about the signal, in the form of a support estimate, is available. In this work, we study the recovery conditions and the associated recovery guarantees of weighted $\ell_1$-minimization when arbitrarily many distinct weights are permitted. For example, such a setup might be used when one has multiple estimates for the support of a signal, and these estimates have varying degrees of accuracy. Our analysis yields an extension to existing works that assume only a single support estimate set upon which a constant weight is applied. We include numerical experiments, with both synthetic signals and real video data, that demonstrate the benefits of allowing non-uniform weights in the reconstruction procedure. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01314;Optimal Storage Allocation for Wireless Cloud Caching Systems with a  Limited Sum Storage Capacity; Bi Hong,  Wan Choi;  In wireless cloud storage systems, the recovery failure probability depends on not only wireless channel conditions but also storage size of each distributed storage node. For an efficient utilization of limited storage capacity and the performance characterization of allocation strategies, we asymptotically analyze the recovery failure probability of a wireless cloud storage system with a sum storage capacity constraint for both high SNR regime and low SNR regime. Then, we find the optimal storage allocation strategy across distributed storage nodes in terms of the asymptotic recovery failure probability. Our analysis reveals that the maximal symmetric allocation is optimal for high SNR regime and the minimal allocation (with $\lfloor T\rfloor$ complete storage nodes and an incomplete storage node) is optimal for low SNR regime, where $T$ is the sum storage capacity. Based on the numerical investigation, we also show that in intermediate SNR regime, a balance allocation between the minimal allocation and the maximal symmetric allocation would not be required if we select one between them according to SNR. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01374;Cut-Set Bound Is Loose for Gaussian Relay Networks; Xiugang Wu,  Ayfer Ozgur;  The cut-set bound developed by Cover and El Gamal in 1979 has since remained the best known upper bound on the capacity of the Gaussian relay channel. We develop a new upper bound on the capacity of the Gaussian primitive relay channel which is tighter than the cut-set bound. Our proof is based on typicality arguments and concentration of Gaussian measure. Combined with a simple tensorization argument proposed by Courtade and Ozgur in 2015, our result also implies that the current capacity approximations for Gaussian relay networks, which have linear gap to the cut-set bound in the number of nodes, are order-optimal and leads to a lower bound on the pre-constant. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01379;Refined Composite Multiscale Dispersion Entropy and its Application to  Biomedical Signals; Hamed Azami,  Mostafa Rostaghi,  Daniel Abasolo,  Javier Escudero;  Multiscale entropy (MSE) is a widely-used tool to analyze biomedical signals. It was proposed to overcome the deficiencies of conventional entropy methods when quantifying the complexity of time series. However, MSE is undefined for very short signals and slow for real-time applications because of the use of sample entropy (SampEn). To overcome these shortcomings, we introduce multiscale dispersion entropy (DisEn - MDE) as a very fast and powerful method to quantify the complexity of signals. MDE is based on our recently developed DisEn, which has a computation cost of O(N), compared with O(N2) for SampEn. We also propose the refined composite MDE (RCMDE) to improve the stability of MDE. We evaluate MDE, RCMDE, and refined composite MSE (RCMSE) on synthetic signals and find that these methods have similar behaviors but the MDE and RCMDE are significantly faster than MSE and RCMSE, respectively. The results also illustrate that RCMDE is more stable than MDE for short and noisy signals, which are common in biomedical applications. To evaluate the proposed methods on real signals, we employ three biomedical datasets, including focal and non-focal electroencephalograms (EEGs), blood pressure recordings in Fantasia database, and resting-state EEGs activity in Alzheimer's disease (AD). The results again demonstrate a similar behavior of RCMSE, MDE and RCMDE, although the RCMDE and MDE are significantly faster and lead to larger differences between physiological conditions known to alter the complexity of the physiological recordings. To sum up, MDE and RCMDE are expected to be useful for the analysis of physiological signals thanks to their ability to distinguish different types of dynamics. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01416;Online Power Control Optimization for Wireless Transmission with Energy  Harvesting and Storage; Fatemeh Amirnavaei,  Min Dong;  We consider wireless transmission over fading channel powered by energy harvesting and storage devices. Assuming a finite battery storage capacity, we design an online power control strategy aiming at maximizing the long-term time-averaged transmission rate under battery operational constraints for energy harvesting. We first formulate the stochastic optimization problem, and then develop techniques to transform this problem and employ techniques from Lyapunov optimization to design the online power control solution. In particular, we propose an approach to handle unbounded channel fade which cannot by directly dealt with by Lyapunov framework. Our proposed algorithm determines the transmission power based only on the current energy state of the battery and channel fade conditions,without requiring any knowledge of the statistics of energy arrivals and fading channels. Our online power control solution is a three-stage closed-form solution depending on the battery energy level. It not only provides strategic energy conservation through the battery energy control, but also reveals an opportunistic transmission style based on fading condition, both of which improve the long-term time-averaged transmission rate. We further characterize the performance bound of our proposed algorithm to the optimal solution with a general fading distribution. Simulation results demonstrate a significant performance gain of our proposed online algorithm over alternative online approaches. ;"Information Theory (cs.IT); Systems and Control (cs.SY)"
https://arxiv.org/abs/1606.01557;An Energy-Efficient Compressive Sensing Framework Incorporating Online  Dictionary Learning for Long-term Wireless Health Monitoring; Kai Xu,  Yixing Li,  Fengbo Ren;  Wireless body area network (WBAN) is emerging in the mobile healthcare area to replace the traditional wire-connected monitoring devices. As wireless data transmission dominates power cost of sensor nodes, it is beneficial to reduce the data size without much information loss. Compressive sensing (CS) is a perfect candidate to achieve this goal compared to existing compression techniques. In this paper, we proposed a general framework that utilize CS and online dictionary learning (ODL) together. The learned dictionary carries individual characteristics of the original signal, under which the signal has an even sparser representation compared to pre-determined dictionaries. As a consequence, the compression ratio is effectively improved by 2-4x comparing to prior works. Besides, the proposed framework offloads pre-processing from sensor nodes to the server node prior to dictionary learning, providing further reduction in hardware costs. As it is data driven, the proposed framework has the potential to be used with a wide range of physiological signals. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01567;Fast and Provable Algorithms for Spectrally Sparse Signal Reconstruction  via Low-Rank Hankel Matrix Completion; Jian-Feng Cai,  Tianming Wang,  Ke Wei;  A spectrally sparse signal of order $r$ is a mixture of $r$ damped or undamped complex sinusoids. This paper investigates the problem of reconstructing spectrally sparse signals from a random subset of $n$ regular time domain samples, which can be reformulated as a low rank Hankel matrix completion problem. We introduce an iterative hard thresholding (IHT) algorithm and a fast iterative hard thresholding (FIHT) algorithm for efficient reconstruction of spectrally sparse signals via low rank Hankel matrix completion. Theoretical recovery guarantees have been established for FIHT, showing that $O(r^2\log^2(n))$ number of samples are sufficient for exact recovery with high probability. Empirical performance comparisons establish significant computational advantages for IHT and FIHT. In particular, numerical simulations on $3$D arrays demonstrate the capability of FIHT on handling large and high-dimensional real data. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01592;Proof of tightness of Varshamov - Gilbert bound for binary codes; Vladimir Blinovsky;  We prove tightness of right logarithmic asymptotic of Varshamov- Gilbert bound for linear binary codes We find general asymptotic coding bound for linear codes ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01599;Effect of Densification on Cellular Network Performance with Bounded  Pathloss Model; Junyu Liu,  Min Sheng,  Lei Liu,  Jiandong Li;  In this paper, we investigate how network densification influences the performance of downlink cellular network in terms of coverage probability (CP) and area spectral efficiency (ASE). Instead of the simplified unbounded pathloss model (UPM), we apply a more realistic bounded pathloss model (BPM) to model the decay of signal power caused by pathloss. It is shown that network densification indeed degrades CP when the base station (BS) density $\lambda$ is sufficiently large. This is inconsistent with the result derived using UPM that CP is independent of $\lambda$. Moreover, we shed light on the impact of ultra-dense deployment of BSs on the ASE scaling law. Specifically, it is proved that the cellular network ASE scales with rate $\lambda e^{-\kappa\lambda}$, i.e., first increases with $\lambda$ and then diminishes to be zero as $\lambda$ goes to infinity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01660;Cutsize Distributions of Balanced Hypergraph Bipartitions for Random  Hypergraphs; Takayuki Nozaki;  In a previous work, we presented a parallel encoding algorithm for low-density parity-check (LDPC) codes by partitioning hypergraph representation for the LDPC codes. The aim of this research is to analyze the processing time of this encoding algorithm. This paper clarifies that the processing time of the encoding algorithm depends on the minimum cutsize of balanced hypergraph partitions. Moreover, this paper gives the typical minimum cutsize and cutsize distribution for balanced hypergraph bipartitions of random hypergraphs defined from a regular LDPC ensemble. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01689;Information Rates of Next-Generation Long-Haul Optical Fiber Systems  Using Coded Modulation; Gabriele Liga,  Alex Alvarado,  Erik Agrell,  Polina Bayvel;  A comprehensive study of the coded performance of long-haul spectrally-efficient WDM optical fiber transmission systems with different coded modulation decoding structures is presented. Achievable information rates are derived for three different square QAM formats and the optimal format is identified as a function of distance and specific decoder implementation. The four cases analyzed combine hard-decision (HD) or soft-decision (SD) decoding together with either a bit-wise or a symbol-wise demapper, the last two suitable for binary and nonbinary codes, respectively. The information rates achievable for each scheme are calculated based on the mismatched decoder principle. These quantities represent true indicators of the coded performance of the system for specific decoder implementations and when the modulation format and its input distribution are fixed. In combination with the structure of the decoder, two different receiver-side equalization strategies are also analyzed: electronic dispersion compensation and digital backpropagation. We show that, somewhat unexpectedly, schemes based on nonbinary HD codes can achieve information rates comparable to SD decoders and that, when SD is used, switching from a symbol-wise to a bit-wise decoder results in a negligible penalty. Conversely, from an information-theoretic standpoint, HD binary decoders are shown to be unsuitable for spectrally-efficient, long-haul systems. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01745;Computing the generator polynomials of  $\mathbb{Z}_2\mathbb{Z}_4$-additive cyclic codes; Joaquim Borges Ayats,  Cristina Fernández-Córdoba,  Roger Ten-Valls;  A ${\mathbb{Z}}_2{\mathbb{Z}}_4$-additive code ${\cal C}\subseteq{\mathbb{Z}}_2^\alpha\times{\mathbb{Z}}_4^\beta$ is called cyclic if the set of coordinates can be partitioned into two subsets, the set of ${\mathbb{Z}}_2$ and the set of ${\mathbb{Z}}_4$ coordinates, such that any simultaneous cyclic shift of the coordinates of both subsets leaves invariant the code. These codes can be identified as submodules of the $\mathbb{Z}_4[x]$-module $\mathbb{Z}_2[x]/(x^\alpha-1)\times\mathbb{Z}_4[x]/(x^\beta-1)$. Any $\mathbb{Z}_2\mathbb{Z}_4$-additive cyclic code ${\cal C}$ is of the form $\langle (b(x)\mid{ 0}), (\ell(x) \mid f(x)h(x) +2f(x)) \rangle$ for some $b(x), \ell(x)\in\mathbb{Z}_2[x]/(x^\alpha-1)$ and $f(x),h(x)\in {\mathbb{Z}}_4[x]/(x^\beta-1)$. A new algorithm is presented to compute the generator polynomials for ${\mathbb{Z}}_2{\mathbb{Z}}_4$-additive cyclic codes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01750;On the Degrees of Freedom of MIMO X Networks with Non-Cooperation  Transmitters; Tengda Ying,  Wenjiang Feng,  Weifeng Su,  Weiheng Jiang;  Due to limited backhaul/feedback link capacity and channel state information (CSI) feedback delay, obtaining global and instantaneous channel state information at the transmitter (CSIT) is a main obstacle in practice. In this paper, novel transmission schemes are proposed for a class of interference networks that can achieve new trade-off regions between the sum of degrees of freedom (sum-DoF) and CSI feedback delay with distributed and temperately-delayed CSIT. More specifically, a distributed space-time interference alignment (STIA) scheme is proposed for the two-user multiple-input multiple-output (MIMO) X channel via a novel precoding method called Cyclic Zero-padding. The achieved sum-DoFs herein for certain antenna configurations are greater than the best known sum-DoFs in literature with delayed CSIT. Furthermore, we propose a distributed retrospective interference alignment (RIA) scheme that achieves more than 1 sum-DoF for the K-user single-input single-output (SISO) X network. Finally, we extend the distributed STIA to the MxN user multiple-input single-output (MISO) X network where each transmitter has N-1 antennas and each receiver has a single antenna, yielding the same sum-DoF as that in the global and instantaneous CSIT case. The discussion and the result of the MISO X network can be extended to the MIMO case due to spatial scale invariance property. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01759;Performance Analysis of $L$-Branch Scan-and-Wait Combining (SWC) over  Arbitrarily Correlated Nakagami-$m$ Fading Channels; George C. Alexandropoulos,  P. Takis Mathiopoulos,  Pingzhi Fan;  The performance of $L$-branch scan-and-wait combining (SWC) reception systems over arbitrarily correlated and not necessarily identically distributed Nakagami-$m$ fading channels is analyzed and evaluated. Firstly, a fast convergent infinite series representation for the SWC output signal-noise ratio (SNR) is presented. This expression is used to obtain analytical expressions in the form of infinite series for the average error probability performance of various modulation schemes for integer values of $m$ as well as the average number of paths estimation and average waiting time (AWT) of $L$-branch SWC receivers for arbitrary values of $m$. The numerically obtained results have shown that the performance expressions converge very fast to their exact analytical values. It was found that the convergence speed depends on the correlation and operating SNR values as well as the Nakagami $m$-parameter. In addition to the analytical results, complementary computer simulated performance evaluation results have been obtained by means of Monte Carlo error counting techniques. The match between these two sets of results has verified the accuracy of the proposed mathematical analysis. Furthermore, it is revealed that, at the expense of a negligible AWT, the average error probability performance of SWC receivers is always superior to that of switched-and-examine combining receivers and in certain cases to that of maximal-ratio combining receivers. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01768;Classical - Quantum Arbitrarily Varying Wiretap Channel: Common  Randomness Assisted Code and Continuity; Holger Boche,  Minglai Cai,  Christian Deppe,  Janis Nötzel;  We determine the secrecy capacities under common randomness assisted coding of arbitrarily varying classical-quantum wiretap channels.Furthermore, we determine the secrecy capacity of a mixed channel model which is compound from the sender to the legal receiver and varies arbitrarily from the sender to the eavesdropper. As an application we examine when the secrecy capacity is a continuous function of the system parameters and show that resources, i.e., having access to a perfect copy of the outcome of a random experiment. are helpful for channel stability. ;"Information Theory (cs.IT); Quantum Physics (quant-ph)"
https://arxiv.org/abs/1606.01799;Modular non-repeating codes for DNA storage; Ian Holmes;"  We describe a strategy for constructing codes for DNA-based information storage by serial composition of weighted finite-state transducers. The resulting state machines can integrate correction of substitution errors; synchronization by interleaving watermark and periodic marker signals; conversion from binary to ternary, quaternary or mixed-radix sequences via an efficient block code; encoding into a DNA sequence that avoids homopolymer, dinucleotide, or trinucleotide runs and other short local repeats; and detection/correction of errors (including local duplications, burst deletions, and substitutions) that are characteristic of DNA sequencing technologies. We present software implementing these codes, available at github.com/ihh/dnastore, with simulation results demonstrating that the generated DNA is free of short repeats and can be accurately decoded even in the presence of substitutions, short duplications and deletions. ";Information Theory (cs.IT)
https://arxiv.org/abs/1606.01800;Finite Sample Analysis of Approximate Message Passing Algorithms; Cynthia Rush,  Ramji Venkataramanan;  This paper analyzes the performance of Approximate Message Passing (AMP) algorithms in the regime where the problem dimension is large but finite. We consider the setting of high-dimensional regression, where the goal is to estimate a high-dimensional vector $\beta_0$ from a noisy measurement $y=A \beta_0 + w$. AMP is a low-complexity, scalable algorithm for this problem. Under suitable assumptions on the measurement matrix $A$, AMP has the attractive feature that its performance can be accurately characterized in the large system limit by a simple scalar iteration called state evolution. Previous proofs of the validity of state evolution have all been asymptotic convergence results. In this paper, we derive a concentration inequality for AMP with i.i.d.\ Gaussian measurement matrices with finite size $n \times N$. The result shows that the probability of deviation from the state evolution prediction falls exponentially in $n$. This provides theoretical support for empirical findings that have demonstrated excellent agreement of AMP performance with state evolution predictions for moderately large dimensions. The concentration inequality also indicates that the number of AMP iterations $t$ can grow no faster than order $\frac{\log n}{\log \log n}$ for the performance to be close to the state evolution predictions with high probability. ;"Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)"
https://arxiv.org/abs/1606.01840;Temporal Correlation of Interference in Bounded Mobile Ad Hoc Networks  with Blockage; Konstantinos Koufos,  Carl P. Dettmann;  In mobile wireless networks with blockage, different users, and/or a single user at different time slots, may be blocked by some common obstacles. Therefore the temporal correlation of interference does not depend only on the user displacement law but also on the spatial correlation introduced by the obstacles. In this letter, we show that in mobile networks with a high density of users, blockage increases the temporal correlation of interference, while in sparse networks blockage has the opposite effect. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01872;A Data-Driven Compressive Sensing Framework for Long-Term Health  Monitoring; Kai Xu,  Yuhao Wang,  Yixing Li,  Fengbo Ren;  Compressive sensing (CS) is a promising technology for realizing energy-efficient wireless sensors for long-term health monitoring. In this paper, we propose a data-driven CS framework that learns signal characteristics and individual variability from patients' data to significantly enhance CS performance and noise resilience. This is accomplished by a co-training approach that optimizes both the sensing matrix and dictionary towards improved restricted isometry property (RIP) and signal sparsity, respectively. Experimental results upon ECG signals show that our framework is able to achieve better reconstruction quality with up to 80% higher compression ratio (CP) than conventional frameworks based on random sensing matrices and overcomplete bases. In addition, our framework shows great noise resilience capability, which tolerates up to 40dB higher noise energy at a CP of 9 times. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01941;Intra-Slot Interference Cancellation for Collision Resolution in  Irregular Repetition Slotted ALOHA; G. Interdonato,  S. Pfletschinger,  F. Vazquez-Gallego,  J. Alonso-Zarate,  G. Araniti;  ALOHA-type protocols became a popular solution for distributed and uncoordinated multiple random access in wireless networks. However, such distributed operation of the Medium Access Control (MAC) layer leads to sub-optimal utilization of the shared channel. One of the reasons is the occurrence of collisions when more than one packet is transmitted at the same time. These packets cannot be decoded and retransmissions are necessary. However, it has been recently shown that it is possible to apply signal processing techniques with these collided packets so that useful information can be decoded. This was recently proposed in the Irregular Repetition Slotted ALOHA (IRSA), achieving a throughput $T \simeq 0.97$ for very large MAC frame lengths as long as the number of active users is smaller than the number of slots per frame. In this paper, we extend the operation of IRSA with i) an iterative physical layer decoding processing that exploits the capture effect and ii) a Successive Interference Cancellation (SIC) processing at the slot-level, named intra-slot SIC, to decode more than one colliding packet per slot. We evaluate the performance of the proposed scheme, referred to as Extended IRSA (E-IRSA), in terms of throughput and channel capacity. Computer-based simulation results show that E-IRSA protocol allows to reach the maximum theoretical achievable throughput even in scenarios where the number of active users is higher than the number of slots per frame. Results also show that E-IRSA protocol significantly improves the performance even for small MAC frame lengths used in practical scenarios. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01943;Optimizing Point-to-Multipoint Transmissions in High Speed Packet Access  Networks; G. Araniti,  V. Scordamaglia,  A. Molinaro,  A. Iera,  G. Interdonato,  F. Spanò;  In this paper an innovative Radio Resource Management (RRM) algorithm is proposed with the purpose of increasing High Speed Packet Access (HSPA) performances, in terms of system capacity and service quality, when the Multimedia Broadcast Multicast Services (MBMS) is supplied. The proposed RRM algorithm exploits channel quality indications to set up point-to-multipoint connections to subgroups of multicast users and to select the proper modulation and coding schemes on the downlink. The number of subgroups is determined through an optimization technique that also takes into account the user satisfaction. An exhaustive simulation campaign is conducted to compare the proposed algorithm with the most promising approaches in the literature. Comparisons aim to assess the capability of the proposed RRM algorithm to efficiently manage group oriented services by providing an increment in terms of user satisfaction. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.01962;Efficient Deployment of Multiple Unmanned Aerial Vehicles for Optimal  Wireless Coverage; Mohammad Mozaffari,  Walid Saad,  Mehdi Bennis,  Merouane Debbah;  In this paper, the efficient deployment of multiple unmanned aerial vehicles (UAVs) with directional antennas acting as wireless base stations that provide coverage for ground users is analyzed. First, the downlink coverage probability for UAVs as a function of the altitude and the antenna gain is derived. Next, using circle packing theory, the three-dimensional locations of the UAVs is determined in a way that the total coverage area is maximized while maximizing the coverage lifetime of the UAVs. Our results show that, in order to mitigate interference, the altitude of the UAVs must be properly adjusted based on the beamwidth of the directional antenna as well as coverage requirements. Furthermore, the minimum number of UAVs needed to guarantee a target coverage probability for a given geographical area is determined. Numerical results evaluate the various tradeoffs involved in various UAV deployment scenarios. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.01985;Adaptation is Useless for Two Discrete Additive-Noise Two-Way Channels; Lin Song,  Fady Alajaji,  Tamas Linder;  In two-way channels, each user transmits and receives at the same time. This allows each encoder to interactively adapt the current input to its own message and all previously received signals. Such coding approach can introduce correlation between inputs of different users, since all the users' outputs are correlated by the nature of the channel. However, for some channels, such adaptation in the coding scheme and its induced correlation among users are useless in the sense that they do not help enlarge the capacity region with respect to the standard coding method (where each user encodes only based on its own message). In this paper, it is shown that adaptation is not helpful for enlarging the capacity region of two classes of two-way discrete channels: the modulo additive-noise channel with memory and the multiple access/degraded broadcast channel. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02033;User Cooperation for Enhanced Throughput Fairness in Wireless Powered  Communication Networks; Mingquan Zhong,  Suzhi Bi,  Xiaohui Lin;  This paper studies a novel user cooperation method in a wireless powered communication network (WPCN), where a pair of distributed terminal users first harvest wireless energy broadcasted by one energy node (EN) and then use the harvested energy to transmit information cooperatively to a destination node (DN). In particular, the two cooperating users exchange their independent information with each other to form a virtual antenna array and transmit jointly to the DN. By allowing each user to allocate part of its harvested energy to transmit the other's information, the proposed cooperation can effectively mitigate the user unfairness problem in WPCNs, where a user may suffer from very low data rate due to the poor energy harvesting performance and high data transmission consumptions. We derive the maximum common throughput achieved by the cooperation scheme through optimizing the time allocation on wireless energy transfer, user message exchange, and joint information transmissions. Through comparing with some representative benchmark schemes, our results demonstrate the effectiveness of the proposed user cooperation in enhancing the throughput performance under different setups. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.02080;Random Access Protocols for Massive MIMO; Elisabeth de Carvalho,  Emil Björnson,  Jesper H. Sørensen,  Petar Popovski,  Erik G. Larsson;  5G wireless networks are expected to support new services with stringent requirements on data rates, latency and reliability. One novel feature is the ability to serve a dense crowd of devices, calling for radically new ways of accessing the network. This is the case in machine-type communications, but also in urban environments and hotspots. In those use cases, the high number of devices and the relatively short channel coherence interval do not allow per-device allocation of orthogonal pilot sequences. This article motivates the need for random access by the devices to pilot sequences used for channel estimation, and shows that Massive MIMO is a main enabler to achieve fast access with high data rates, and delay-tolerant access with different data rate levels. Three pilot access protocols along with data transmission protocols are described, fulfilling different requirements of 5G services. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.02087;Continuous Transmission of Spatially-Coupled LDPC Code Chains; Pablo M. Olmos,  David G. M. Mitchell,  Dmitri Truhachev,  Daniel J. Costello Jr;  We propose a novel encoding/transmission scheme called continuous chain (CC) transmission that is able to improve the finite-length performance of a system using spatially-coupled low-density parity-check (SC-LDPC) codes. In CC transmission, instead of transmitting a sequence of independent codewords from a terminated SC-LDPC code chain, we connect multiple chains in a layered format, where encoding, transmission, and decoding are now performed in a continuous fashion. The connections between chains are created at specific points, chosen to improve the finite-length performance of the code structure under iterative decoding. We describe the design of CC schemes for different SC-LDPC code ensembles constructed from protographs: a (J,K)-regular SC-LDPC code chain, a spatially-coupled repeat-accumulate (SC-RA) code, and a spatially-coupled accumulate-repeat-jagged-accumulate (SC- ARJA) code. In all cases, significant performance improvements are reported and, in addition, it is shown that using CC transmission only requires a small increase in decoding complexity and decoding delay with respect to a system employing a single SC-LDPC code chain for transmission. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02143;Trends and Challenges in Wireless Channel Modeling for an Evolving Radio  Access; Paul Ferrand,  Mustapha Amara,  Maxime Guillaud,  Stefan Valentin;  With the advent of 5G, standardization and research are currently defining the next generation of the radio access. Considering the high constraints imposed by the future standards, disruptive technologies such as Massive MIMO and mmWave are being proposed. At the heart of this process are wireless channel models that now need to cover a massive increase in design parameters, a large variety of frequency bands, and heterogeneous deployments. This tutorial describes how channel models address this new level of complexity and which tools the community prepares to efficiently but accurately capture the upcoming changes in radio access design. We analyze the main drivers behind these new modeling tools, the challenges they pose, and survey the current approaches to overcome them. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.02213;Energy-Aware Relay Selection and Power Allocation for Multiple-User  Cooperative Networks; Sabyasachi Gupta,  Ranjan Bose;  This paper investigates the relay assignment and power allocation problem for two different network power management policies: group lifetime maximization (GLM) and minimum weighted total power (MWTP), with the aim of lifetime maximization in symbol error rate (SER) constrained multipleuser cooperative network. With optimal power allocation solution obtained for each policy, we show that the optimal relay assignment can be obtained using bottleneck matching (BM) algorithm and minimum weighted matching (MWM) algorithm for GLM and MWTP policies, respectively. Since relay assignment with BM algorithm is not power efficient, we propose a novel minimum bottleneck matching (MBM) algorithm to solve the relay assignment problem optimally for GLM policy. To further reduce the complexity of the relay assignment, we propose suboptimal relay selection (SRS) algorithm which has linear complexity in number of source and relay nodes. Simulation results demonstrate that the proposed relay selection and power allocation strategies based on GLM policy have better network lifetime performance over the strategies based on MWTP policy. Compared to the MBM and SRS algorithm, relay assignment based on BM algorithm for GLM policy has inferior network lifetime performance at low update interval. We show that relay assignment based on MBM algorithm achieves maximum network lifetime performance and relay assignment with SRS algorithm has performance very close to it. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02337;Random Access in C-RAN for User Activity Detection with Limited-Capacity  Fronthaul; Zoran Utkovski,  Osvaldo Simeone,  Tamara Dimitrova,  Petar Popovski;  Cloud-Radio Access Network (C-RAN) is characterized by a hierarchical structure in which the baseband processing functionalities of remote radio heads (RRHs) are implemented by means of cloud computing at a Central Unit (CU). A key limitation of C-RANs is given by the capacity constraints of the fronthaul links connecting RRHs to the CU. In this letter, the impact of this architectural constraint is investigated for the fundamental functions of random access and active User Equipment (UE) identification in the presence of a potentially massive number of UEs. In particular, the standard C-RAN approach based on quantize-and-forward and centralized detection is compared to a scheme based on an alternative CU-RRH functional split that enables local detection. Both techniques leverage Bayesian sparse detection. Numerical results illustrate the relative merits of the two schemes as a function of the system parameters. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.02348;No Downlink Pilots are Needed in TDD Massive MIMO; Hien Quoc Ngo,  Erik G. Larsson;  We consider the Massive Multiple-Input Multiple-Output (MIMO) downlink with maximum-ratio and zero-forcing processing and time-division duplex (TDD) operation. To decode, the terminals must know their instantaneous effective channel gain. Conventionally, it is assumed that by virtue of channel hardening, this instantaneous gain is close to its average and hence that terminals can rely on knowledge of that average (also known as statistical channel information). However, in some propagation environments, such as keyhole channels, channel hardening does not hold. We propose a blind algorithm to estimate the effective channel gain at each user, that does not require any downlink pilots. We derive a capacity lower bound of each user for our proposed scheme, applicable to any propagation channel. Compared to the case of no downlink pilots (relying on channel hardening), and compared to training-based estimation using downlink pilots, our blind algorithm performs significantly better. The difference is especially pronounced in environments that do not offer channel hardening. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02371;Energy Efficiency in Multicast Multihop D2D Networks; Zicheng Xia,  Jiawei Yan,  Yuan Liu;  As the demand of mobile devices (MDs) for data services is explosively increasing, traditional offloading in the cellular networks is facing the contradiction of energy efficiency and quality of service. Device-to-device (D2D) communication is considered as an effective solution. This work investigates a scenario where the MDs have the same demand for common content and they cooperate to deliver it using multicast multihop relaying. We focus on the problem of total power minimization by grouping the MDs in multihop D2D networks, while maintaining the minimum rate requirement of each MD. As the problem is shown to be NP-complete and the optimal solution can not be found efficiently, two greedy algorithms are proposed to solve this problem in polynomial time. Simulation results demonstrate that lots of power can be saved in the content delivery situation using multihop D2D communication, and the proposed algorithms are suitable for different situations with different advantages. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.02379;Energy-Efficient Transmission Design in Non-Orthogonal Multiple Access; Yi Zhang,  Hui-Ming Wang,  Tong-Xing Zheng,  Qian Yang;  Non-orthogonal multiple access (NOMA) is considered as a promising technology for improving the spectral efficiency (SE) in 5G. In this correspondence, we study the benefit of NOMA in enhancing energy efficiency (EE) for a multi-user downlink transmission, where the EE is defined as the ratio of the achievable sum rate of the users to the total power consumption. Our goal is to maximize the EE subject to a minimum required data rate for each user, which leads to a non-convex fractional programming problem. To solve it, we first establish the feasible range of the transmitting power that is able to support each user's data rate requirement. Then, we propose an EE-optimal power allocation strategy that maximizes the EE. Our numerical results show that NOMA has superior EE performance in comparison with conventional orthogonal multiple access (OMA). ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02433;Training Design and Two-stage Channel Estimation for Correlated Two-way  MIMO Relay Systems; Huiming Chen;  This paper addresses the training signal design for the channel estimation in two-way multiple-input-and-multipleoutput (MIMO) relay systems, where the channels are correlated. We first derive the backward channel estimator with the optimal training signal sent by the relay node. Given the estimated backward channels and the probabilistic knowledge of the estimation error, we mainly focus on the forward channel estimation and the related training signal design. We further propose a novel training signal. The design criterion is to minimize the relaxation of the total mean square error (MSE) of the forward channel estimators, which is conditioned on the estimated backward channels. Finally, the numerical results show that the proposed training signal can improve the MSE performance. ;"Information Theory (cs.IT); Numerical Analysis (cs.NA)"
https://arxiv.org/abs/1606.02463;(Almost) Practical Tree Codes; Anatoly Khina,  Wael Halbawi,  Babak Hassibi;  We consider the problem of stabilizing an unstable plant driven by bounded noise over a digital noisy communication link, a scenario at the heart of networked control. To stabilize such a plant, one needs real-time encoding and decoding with an error probability profile that decays exponentially with the decoding delay. The works of Schulman and Sahai over the past two decades have developed the notions of tree codes and anytime capacity, and provided the theoretical framework for studying such problems. Nonetheless, there has been little practical progress in this area due to the absence of explicit constructions of tree codes with efficient encoding and decoding algorithms. Recently, linear time-invariant tree codes were proposed to achieve the desired result under maximum-likelihood decoding. In this work, we take one more step towards practicality, by showing that these codes can be efficiently decoded using sequential decoding algorithms, up to some loss in performance (and with some practical complexity caveats). We supplement our theoretical results with numerical simulations that demonstrate the effectiveness of the decoder in a control system setting. ;"Information Theory (cs.IT); Systems and Control (cs.SY)"
https://arxiv.org/abs/1606.02679;Learning Power Spectrum Maps from Quantized Power Measurements; Daniel Romero,  Seung-Jun Kim,  Georgios B. Giannakis,  Roberto Lopez-Valcarce;  Power spectral density (PSD) maps providing the distribution of RF power across space and frequency are constructed using power measurements collected by a network of low-cost sensors. By introducing linear compression and quantization to a small number of bits, sensor measurements can be communicated to the fusion center with minimal bandwidth requirements. Strengths of data- and model-driven approaches are combined to develop estimators capable of incorporating multiple forms of spectral and propagation prior information while fitting the rapid variations of shadow fading across space. To this end, novel nonparametric and semiparametric formulations are investigated. It is shown that PSD maps can be obtained using support vector machine-type solvers. In addition to batch approaches, an online algorithm attuned to real-time operation is developed. Numerical tests assess the performance of the novel algorithms. ;"Information Theory (cs.IT); Learning (cs.LG); Functional Analysis (math.FA); Machine Learning (stat.ML)"
https://arxiv.org/abs/1606.02763;On Matched Metric and Channel Problem; Artur Poplawski;  The sufficient condition for partial function from the cartesian square of the finite set to the reals to be compatible with some metric on this set is given. It is then shown, that when afforementioned set and function are respectively a space of binary words of length n and probalities of receiving some word after sending the other word through Binary Assymetric Channel the condition is satisfied so the required metrics exist. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02809;On Uplink User Capacity for Massive MIMO Cellular Networks; Anand Sivamalai,  Jamie S. Evans;  Under the conditions where performance in a massive MIMO network is limited by pilot contamination, the reverse link signal-to-interference ratio (SIR) exhibits different distributions when using different pilot allocation schemes. By utilising different sets of orthogonal pilot sequences, as opposed to reused sequences amongst adjacent cells, the resulting SIR distribution is more favourable with respect to maximising the number of users on the network while maintaining a given quality of service (QoS) for all users. This paper provides a simple expression for uplink user capacity on such networks and presents uplink user capacity figures for both pilot allocation schemes for a selection of quality of service targets. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02828;Spatial modeling and analysis of cellular networks using the Ginibre  point process: A tutorial; Naoto Miyoshi,  Tomoyuki Shirai;  Spatial stochastic models have been much used for performance analysis of wireless communication networks. This is due to the fact that the performance of wireless networks depends on the spatial configuration of wireless nodes and the irregularity of node locations in a real wireless network can be captured by a spatial point process. Most works on such spatial stochastic models of wireless networks have adopted homogeneous Poisson point processes as the models of wireless node locations. While this adoption makes the models analytically tractable, it assumes that the wireless nodes are located independently of each other and their spatial correlation is ignored. Recently, the authors have proposed to adopt the Ginibre point process---one of the determinantal point processes---as the deployment models of base stations (BSs) in cellular networks. The determinantal point processes constitute a class of repulsive point processes and have been attracting attention due to their mathematically interesting properties and efficient simulation methods. In this tutorial, we provide a brief guide to the Ginibre point process and its variant, $\alpha$-Ginibre point process, as the models of BS deployments in cellular networks and show some existing results on the performance analysis of cellular network models with $\alpha$-Ginibre deployed BSs. The authors hope the readers to use such point processes as a tool for analyzing various problems arising in future cellular networks. ;"Information Theory (cs.IT); Probability (math.PR)"
https://arxiv.org/abs/1606.02849;Time Optimal Spectrum Sensing; Garimella Rama Murthy,  Rhishi Pratap Singh,  Samdarshi Abhijeet,  Sachin Chaudhary;  Spectrum sensing is a fundamental operation in cognitive radio environment. It gives information about spectrum availability by scanning the bands. Usually a fixed amount of time is given to scan individual bands. Most of the times, historical information about the traffic in the spectrum bands is not used. But this information gives the idea, how busy a specific band is. Therefore, instead of scanning a band for a fixed amount of time, more time can be given to less occupied bands and less time to heavily occupied ones. In this paper we have formulated the time assignment problem as integer linear programming and source coding problems. The time assignment problem is solved using the associated stochastic optimization problem. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02866;Cache-enabled Device-to-Device Communications: Offloading Gain and  Energy Cost; Binqiang Chen,  Chenyang Yang,  Andreas F. Molisch;  By caching files at users, content delivery traffic can be offloaded via device-to-device (D2D) links if a helper user is willing to transmit the cached file to the user who requests the file. In practice, the user device has limited battery capacity, and may terminate the D2D connection when its battery has little energy left. Thus, taking the battery consumption allowed by the helper users to support D2D into account introduces a reduction in the possible amount of offloading. In this paper, we investigate the relationship between offloading gain of the system and energy cost of each helper user. To this end, we introduce a user-centric protocol to control the energy cost for a helper user to transmit the file. Then, we optimize the proactive caching policy to maximize the offloading opportunity, and optimize the transmit power at each helper to maximize the offloading probability. Finally, we evaluate the overall amount of traffic offloaded to D2D links and evaluate the average energy consumption at each helper, with the optimized caching policy and transmit power. Simulations show that a significant amount of traffic can be offloaded even when the energy cost is kept low. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.02867;High Throughput Opportunistic Cooperative Device-to-Device  Communications With Caching; Binqiang Chen,  Chenyang Yang,  Gang Wang;  To achieve the potential in providing high throughput for cellular networks by device-to-device (D2D) communications, the interference among D2D links should be carefully managed. In this paper, we propose an opportunistic cooperation strategy for D2D transmission by exploiting the caching capability at the users to control the interference among D2D links. We consider overlay inband D2D, divide the D2D users into clusters, and assign different frequency bands to cooperative and non-cooperative D2D links. To provide high opportunity for cooperative transmission, we introduce a caching policy. To maximize the network throughput, we jointly optimize the cluster size and bandwidth allocation, where the closed-form expression of the bandwidth allocation factor is obtained. Simulation results demonstrate that the proposed strategy can provide 400%-500% throughput gain over traditional D2D communications when the content popularity distribution is skewed, and can provide 60%-80% gain even when the content popularity distribution is uniform. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03000;On Projected Stochastic Gradient Descent Algorithm with Weighted  Averaging for Least Squares Regression; Kobi Cohen,  Angelia Nedic,  R. Srikant;  The problem of least squares regression of a $d$-dimensional unknown parameter is considered. A stochastic gradient descent based algorithm with weighted iterate-averaging that uses a single pass over the data is studied and its convergence rate is analyzed. We first consider a bounded constraint set of the unknown parameter. Under some standard regularity assumptions, we provide an explicit $O(1/k)$ upper bound on the convergence rate, depending on the variance (due to the additive noise in the measurements) and the size of the constraint set. We show that the variance term dominates the error and decreases with rate $1/k$, while the term which is related to the size of the constraint set decreases with rate $\log k/k^2$. We then compare the asymptotic ratio $\rho$ between the convergence rate of the proposed scheme and the empirical risk minimizer (ERM) as the number of iterations approaches infinity. We show that $\rho\leq 4$ under some mild conditions for all $d\geq 1$. We further improve the upper bound by showing that $\rho\leq 4/3$ for the case of $d=1$ and unbounded parameter set. Simulation results demonstrate strong performance of the algorithm as compared to existing methods, and coincide with $\rho\leq 4/3$ even for large $d$ in practice. ;"Information Theory (cs.IT); Learning (cs.LG)"
https://arxiv.org/abs/1606.03055;Optimizing quantization for Lasso recovery; Xiaoyi Gu,  Shenyinying Tu,  Hao-Jun Michael Shi,  Mindy Case,  Deanna Needell,  Yaniv Plan;  This letter is focused on quantized Compressed Sensing, assuming that Lasso is used for signal estimation. Leveraging recent work, we provide a framework to optimize the quantization function and show that the recovered signal converges to the actual signal at a quadratic rate as a function of the quantization level. We show that when the number of observations is high, this method of quantization gives a significantly better recovery rate than standard Lloyd-Max quantization. We support our theoretical analysis with numerical simulations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03150;Performance Analysis of ZF Receivers with Imperfect CSI for Uplink  Massive MIMO Systems; Van-Dinh Nguyen,  Oh-Soon Shin;  We consider the uplink of massive multipleinput multiple-output systems in a multicell environment. Since the base station (BS) estimates the channel state information (CSI) using the pilot signals transmitted from the users, each BS will have imperfect CSI in practice. Assuming zero-forcing method to eliminate the multi-user interference, we derive the exact analytical expressions for the probability density function (PDF) of the signal-to-interference-plus-noise ratio (SINR), the corresponding achievable rate, the outage probability, and the symbol error rate (SER) when the BS has imperfect CSI. An upper bound of the SER is also derived for an arbitrary number of antennas at the BS. Moreover, we derive the upper bound of the achievable rate for the case where the number of antennas at the BS goes to infinity, and the analysis is verified by presenting numerical results. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03175;Degrees of Freedom of Cache-Aided Wireless Interference Networks; Jad Hachem,  Urs Niesen,  Suhas Diggavi;  We study the role of caches in wireless interference networks. We focus on content caching and delivery across a Gaussian interference network, where both transmitters and receivers are equipped with caches. We provide a constant-factor approximation of the system's degrees of freedom (DoF), for arbitrary number of transmitters, number of receivers, content library size, receiver cache size, and transmitter cache size (as long as the transmitters combined can store the entire content library among them). We demonstrate approximate optimality with respect to information-theoretic bounds that do not impose any restrictions on the caching and delivery strategies. Our characterization reveals three key insights. First, the approximate DoF is achieved using a strategy that separates the physical and network layers. This separation architecture is thus approximately optimal. Second, we show that increasing transmitter cache memory beyond what is needed to exactly store the entire library between all transmitters does not provide more than a constant-factor benefit to the DoF. A consequence is that transmit zero-forcing is not needed for approximate optimality. Third, we derive an interesting trade-off between the receiver memory and the number of transmitters needed for approximately maximal performance. In particular, if each receiver can store a constant fraction of the content library, then only a constant number of transmitters are needed. Solving the caching problem required formulating and solving a new communication problem, the symmetric multiple multicast X-channel, for which we provide an exact DoF characterization. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03196;Phase Retrieval via Incremental Truncated Wirtinger Flow; Ritesh Kolte,  Ayfer Özgür;  In the phase retrieval problem, an unknown vector is to be recovered given quadratic measurements. This problem has received considerable attention in recent times. In this paper, we present an algorithm to solve a nonconvex formulation of the phase retrieval problem, that we call $\textit{Incremental Truncated Wirtinger Flow}$. Given random Gaussian sensing vectors, we prove that it converges linearly to the solution, with an optimal sample complexity. We also provide stability guarantees of the algorithm under noisy measurements. Performance and comparisons with existing algorithms are illustrated via numerical experiments on simulated and real data, with both random and structured sensing vectors. ;"Information Theory (cs.IT); Learning (cs.LG)"
https://arxiv.org/abs/1606.03202;A Low-Complexity Transceiver Design in Sparse Multipath Massive MIMO  Channels; Yuehua Yu,  Peng Wang,  He Chen,  Yonghui Li,  Branka Vucetic;  In this letter, we develop a low-complexity transceiver design, referred to as semi-random beam pairing (SRBP), for sparse multipath massive MIMO channels. By exploring a sparse representation of the MIMO channel in the virtual angular domain, we generate a set of transmit-receive beam pairs in a semi-random way to support the simultaneous transmission of multiple data streams. These data streams can be easily separated at the receiver via a successive interference cancelation (SIC) technique, and the power allocation among them are optimized based on the classical waterfilling principle. The achieved degree of freedom (DoF) and capacity of the proposed approach are analyzed. Simulation results show that, compared to the conventional singular value decomposition (SVD)-based method, the proposed transceiver design can achieve near-optimal DoF and capacity with a significantly lower computational complexity. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03242;On Frame Asynchronous Coded Slotted ALOHA: Asymptotic, Finite Length,  and Delay Analysis; Erik Sandgren,  Alexandre Graell i Amat,  Fredrik Brännström;  We consider a frame asynchronous coded slotted ALOHA (FA-CSA) system for uncoordinated multiple access, where users join the system on a slot-by-slot basis according to a Poisson random process and, in contrast to standard frame synchronous CSA (FS-CSA), users are not frame-synchronized. We analyze the performance of FA-CSA in terms of packet loss rate and delay. In particular, we derive the (approximate) density evolution that characterizes the asymptotic performance of FA-CSA when the frame length goes to infinity. We show that, if the receiver can monitor the system before anyone starts transmitting, a boundary effect similar to that of spatially-coupled codes occurs, which greatly improves the iterative decoding threshold. Furthermore, we derive tight approximations of the error floor (EF) for the finite frame length regime, based on the probability of occurrence of the most frequent stopping sets. We show that, in general, FA-CSA provides better performance in both the EF and waterfall regions as compared to FS-CSA. Moreover, FA-CSA exhibits better delay properties than FS-CSA. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03380;Low-Complexity MIMO Precoding for Finite-Alphabet Signals; Yongpeng Wu,  Chao-Kai Wen,  Derrick Wing Kwan Ng,  Robert Schober,  Angel Lozano;  This paper investigates the design of precoders for single-user multiple-input multiple-output (MIMO) channels, and in particular for finite-alphabet signals. Based on an asymptotic expression for the mutual information of channels exhibiting line-of-sight components and rather general antenna correlations, precoding structures that decompose the general channel into a set of parallel subchannel pairs are proposed. Then, a low-complexity iterative algorithm is devised to maximize the sum mutual information of all pairs. The proposed algorithm significantly reduces the computational load of existing approaches with only minimal loss in performance. The complexity savings increase with the number of transmit antennas and with the cardinality of the signal alphabet, making it possible to support values thereof that were unmanageable with existing solutions. Most importantly, the proposed solution does not require instantaneous channel state information (CSI) at the transmitter, but only statistical CSI. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03472;Super-Resolution From Binary Measurements With Unknown Threshold; Subhadip Mukherjee,  Anjany Kumar Sekuboyina,  Chandra Sekhar Seelamantula;  We address the problem of super-resolution of point sources from binary measurements, where random projections of the blurred measurement of the actual signal are encoded using only the sign information. The threshold used for binary quantization is not known to the decoder. We develop an algorithm that solves convex programs iteratively and achieves signal recovery. The proposed algorithm, which we refer to as the binary super-resolution (BSR) algorithm, recovers point sources with reasonable accuracy, albeit up to a scale factor. We show through simulations that the BSR algorithm is successful in recovering the locations and the amplitudes of the point sources, even in the presence of significant amount of blurring. We also propose a framework for handling noisy measurements and demonstrate that BSR gives a reliable reconstruction (correspondingly, reconstruction signal-to-noise ratio (SNR) of about 22 dB) for a measurement SNR of 15 dB. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03639;Sparse Spectrum Sensing in Infrastructure-less Cognitive Radio Networks  via Binary Consensus Algorithms; Mohamed Seif,  Tamer Elbatt,  Karim G. Seddik;"  Compressive Sensing has been utilized in Cognitive Radio Networks (CRNs) to exploit the sparse nature of the occupation of the primary users. Also, distributed spectrum sensing has been proposed to tackle the wireless channel problems, like node or link failures, rather than the common (centralized approach) for spectrum sensing. In this paper, we propose a distributed spectrum sensing framework based on consensus algorithms where SU nodes exchange their binary decisions to take global decisions without a fusion center to coordinate the sensing process. Each SU will share its decision with its neighbors, and at every new iteration each SU will take a new decision based on its current decision and the decisions it receives from its neighbors; in the next iteration, each SU will share its new decision with its neighbors. We show via simulations that the detection performance can tend to the performance of majority rule Fusion Center based CRNs. ";Information Theory (cs.IT)
https://arxiv.org/abs/1606.03665;Resource Allocation and Fairness in Wireless Powered Cooperative  Cognitive Radio Networks; Sanket S. Kalamkar,  Jeya Pradha Jeyaraj,  Adrish Banerjee,  Ketan Rajawat;  We integrate a wireless powered communication network with a cooperative cognitive radio network, where multiple secondary users (SUs) powered wirelessly by a hybrid access point (HAP) help a primary user relay the data. As a reward for the cooperation, the secondary network gains the spectrum access where SUs transmit to HAP using time division multiple access. To maximize the sum-throughput of SUs, we present a secondary sum-throughput optimal resource allocation (STORA) scheme. Under the constraint of meeting target primary rate, the STORA scheme chooses the optimal set of relaying SUs and jointly performs the time and energy allocation for SUs. Specifically, by exploiting the structure of the optimal solution, we find the order in which SUs are prioritized to relay primary data. Since the STORA scheme focuses on the sum-throughput, it becomes inconsiderate towards individual SU throughput, resulting in low fairness. To enhance fairness, we investigate three resource allocation schemes, which are (i) equal time allocation, (ii) minimum throughput maximization, and (iii) proportional time allocation. Simulation results reveal the trade-off between sum-throughput and fairness. The minimum throughput maximization scheme is the fairest one as each SU gets the same throughput, but yields the least SU sum-throughput. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.03668;Spatial and Social Paradigms for Interference and Coverage Analysis in  Underlay D2D Network; Hafiz Attaul Mustafa,  Muhammad Zeeshan Shakir,  Muhammad Ali Imran,  Rahim Tafazolli;  The homogeneous Poisson point process (PPP) is widely used to model spatial distribution of base stations and mobile terminals. The same process can be used to model underlay device-to-device (D2D) network, however, neglecting homophilic relation for D2D pairing presents underestimated system insights. In this paper, we model both spatial and social distributions of interfering D2D nodes as proximity based independently marked homogeneous Poisson point process. The proximity considers physical distance between D2D nodes whereas social relationship is modeled as Zipf based marks. We apply these two paradigms to analyze the effect of interference on coverage probability of distance-proportional power-controlled cellular user. Effectively, we apply two type of functional mappings (physical distance, social marks) to Laplace functional of PPP. The resulting coverage probability has no closed-form expression, however for a subset of social marks, the mark summation converges to digamma and polygamma functions. This subset constitutes the upper and lower bounds on coverage probability. We present numerical evaluation of these bounds on coverage probability by varying number of different parameters. The results show that by imparting simple power control on cellular user, ultra-dense underlay D2D network can be realized without compromising the coverage probability of cellular user. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03695;Nearest Neighbour Distance Distribution in Hard-Core Point Processes; Akram Al-Hourani,  Robin J. Evans,  Sithamparanathan Kandeepan;  In this paper we present an analytic framework for formulating the statistical distribution of the nearest neighbour distance in hard-core point processes. We apply this framework to Mat\'{e}rn hard-core point process (MHC) to derive the cumulative distribution function of the contact distance in three cases. The first case is between a point in an MHC process and its nearest neighbour from the same process. The second case is between a point in an independent Poisson point process and the nearest neighbour from an MHC process. The third case is between a point in the complement of an MHC process and its sibling MHC process. We test the analytic results against Monte-Carlo simulations to verify their consistency. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03752;Location Based Performance Model for Indoor mmWave Wearable  Communication; Kiran Venugopal,  Robert W. Heath Jr;  Simultaneous use of high-end wearable wireless devices like smart glasses is challenging in a dense indoor environment due to the high nature of interference. In this scenario, the millimeter wave (mmWave) band offers promising potential for achieving gigabits per second throughput. Here we propose a novel system model for analyzing system performance of mmWave based communication among wearables. The proposed model accounts for the non-isotropy of the indoor environment and the effects of reflections that are predominant for indoor mmWave signals. The effect of human body blockages are modeled and the system performance is shown to hugely vary depending on the user location, body orientation and the density of the network. Closed form expressions for spatially averaged signal to interference plus noise ratio distribution are also derived as a function of the location and orientation of a reference user. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03768;New Permutation Trinomials From Niho Exponents over Finite Fields with  Even Characteristic; Nian Li,  Tor Helleseth;  In this paper, a class of permutation trinomials of Niho type over finite fields with even characteristic is further investigated. New permutation trinomials from Niho exponents are obtained from linear fractional polynomials over finite fields, and it is shown that the presented results are the generalizations of some earlier works. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03851;Wireless Information Surveillance via Proactive Eavesdropping with  Spoofing Relay; Yong Zeng,  Rui Zhang;  Wireless information surveillance, by which suspicious wireless communications are closely monitored by legitimate agencies, is an integral part of national security. To enhance the information surveillance capability, we propose in this paper a new proactive eavesdropping approach via a spoofing relay, where the legitimate monitor operates in a full-duplex manner with simultaneous eavesdropping and spoofing relaying to vary the source transmission rate in favor of the eavesdropping performance. To this end, a power splitting receiver is proposed, where the signal received at each antenna of the legitimate monitor is split into two parts for information eavesdropping and spoofing relaying, respectively. We formulate an optimization problem to maximize the achievable eavesdropping rate by jointly optimizing the power splitting ratios and relay beamforming matrix at the multi-antenna monitor. Depending on the suspicious and eavesdropping channel conditions, the optimal solution corresponds to three possible spoofing relay strategies, namely \emph{constructive relaying}, \emph{jamming}, and \emph{simultaneous jamming and destructive relaying}. Numerical results show that the proposed technique significantly improves the eavesdropping rate of the legitimate monitor as compared to the existing passive eavesdropping and jamming-based eavesdropping schemes. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.03893;Massive Machine-type Communications in 5G: Physical and MAC-layer  solutions; Carsten Bockelmann,  Nuno Pratas,  Hosein Nikopour,  Kelvin Au,  Tommy Svensson,  Cedomir Stefanovic,  Petar Popovski,  Armin Dekorsy;"  Machine-type communications (MTC) are expected to play an essential role within future 5G systems. In the FP7 project METIS, MTC has been further classified into ""massive Machine-Type Communication"" (mMTC) and ""ultra-reliable Machine-Type Communication"" (uMTC). While mMTC is about wireless connectivity to tens of billions of machine-type terminals, uMTC is about availability, low latency, and high reliability. The main challenge in mMTC is scalable and efficient connectivity for a massive number of devices sending very short packets, which is not done adequately in cellular systems designed for human-type communications. Furthermore, mMTC solutions need to enable wide area coverage and deep indoor penetration while having low cost and being energy efficient. In this article, we introduce the physical (PHY) and medium access control (MAC) layer solutions developed within METIS to address this challenge. ";"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.03956;Inferring Sparsity: Compressed Sensing using Generalized Restricted  Boltzmann Machines; Eric W. Tramel,  Andre Manoel,  Francesco Caltagirone,  Marylou Gabrié,  Florent Krzakala;  In this work, we consider compressed sensing reconstruction from $M$ measurements of $K$-sparse structured signals which do not possess a writable correlation model. Assuming that a generative statistical model, such as a Boltzmann machine, can be trained in an unsupervised manner on example signals, we demonstrate how this signal model can be used within a Bayesian framework of signal reconstruction. By deriving a message-passing inference for general distribution restricted Boltzmann machines, we are able to integrate these inferred signal models into approximate message passing for compressed sensing reconstruction. Finally, we show for the MNIST dataset that this approach can be very effective, even for $M < K$. ;"Information Theory (cs.IT); Disordered Systems and Neural Networks (cond-mat.dis-nn); Learning (cs.LG); Machine Learning (stat.ML)"
https://arxiv.org/abs/1606.03971;Effect of Retransmissions on Optimal Caching in Cache-enabled Small Cell  Networks; Shankar Krishnan,  Mehrnaz Afshang,  Harpreet S. Dhillon;  Caching popular content in the storage of small cells is being considered as an efficient technique to complement limited backhaul of small cells in ultra-dense heterogeneous cellular networks. Limited storage capacity of the small cells renders it important to determine the optimal set of files (cache) to be placed on each small cell. In contrast to prior works on optimal caching, in this work we study the effect of retransmissions on the optimal cache placement policy for both static and mobile user scenarios. With the popularity of files modeled as a Zipf distribution and a maximum n transmissions, i.e., n-1 retransmissions, allowed to receive each file, we determine the optimal caching probability of the files that maximizes the hit probability. Our closed-form optimal solutions concretely demonstrate that the optimal caching probabilities are very sensitive to the number of retransmissions. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.03986;DDoS Attacks with Randomized Traffic Innovation: Botnet Identification  Challenges and Strategies; Vincenzo Matta,  Mario Di Mauro,  Maurizio Longo;"  Distributed Denial-of-Service (DDoS) attacks are usually launched through the $botnet$, an ""army"" of compromised nodes hidden in the network. Inferential tools for DDoS mitigation should accordingly enable an early and reliable discrimination of the normal users from the compromised ones. Unfortunately, the recent emergence of attacks performed at the application layer has multiplied the number of possibilities that a botnet can exploit to conceal its malicious activities. New challenges arise, which cannot be addressed by simply borrowing the tools that have been successfully applied so far to earlier DDoS paradigms. In this work, we offer basically three contributions: $i)$ we introduce an abstract model for the aforementioned class of attacks, where the botnet emulates normal traffic by continually learning admissible patterns from the environment; $ii)$ we devise an inference algorithm that is shown to provide a consistent (i.e., converging to the true solution as time progresses) estimate of the botnet possibly hidden in the network; and $iii)$ we verify the validity of the proposed inferential strategy over $real$ network traces. ";"Information Theory (cs.IT); Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.04011;Dynamic chromatic dispersion equalization in coherent optical fiber  networks using least-mean-square algorithm; Tianhua Xu,  Gunnar Jacobsen,  Jie Li,  Sergei Popov;  In optical transport networks, signal lightpaths between two terminal nodes can be different due to current network conditions. Thus the transmission distance and accumulated dispersion in the lightpath cannot be predicted. Therefore, the adaptive compensation of dynamic dispersion is necessary in such networks to enable a flexible routing and switching. In this paper, we present a detailed analysis on the adaptive dispersion compensation using the least-mean-square (LMS) algorithms in coherent optical communication networks. It is found that the variable-step-size LMS equalizer can achieve the same performance with a lower complexity, compared to the traditional LMS algorithm. ;"Information Theory (cs.IT); Optics (physics.optics)"
https://arxiv.org/abs/1606.04022;Joint Channel Estimation and Training Signal Design for Two-way MIMO  Relay Systems; Huiming Chen,  Xiaohan Zhong;  In this paper, a two-stage channel estimation scheme for two-way MIMO relay systems with a single relay antenna is proposed. The backward channel is estimated by using linear minimum mean square estimator (LMMSE) at the first stage, where the optimal training signal is designed. We then mainly focus on the forward channel estimation by using singular value decomposition (SVD) based maximum likelihood method, and the related training signal is proposed. We note that the forward channel estimator is nonlinear and by analyzing the asymptotic Bayesian Cramer-rao Lower Bound (BCRLB), we seek BCRLB as the criterion for training signal design. Finally, the numerical results show that the proposed training signal can improve the MSE performance. ;"Information Theory (cs.IT); Numerical Analysis (cs.NA)"
https://arxiv.org/abs/1606.04073;On Probabilistic Shaping of Quadrature Amplitude Modulation for the  Nonlinear Fiber Channel; Tobias Fehenberger,  Alex Alvarado,  Georg Böcherer,  Norbert Hanik;  Different aspects of probabilistic shaping for a multi-span optical communication system are studied. First, a numerical analysis of the additive white Gaussian noise (AWGN) channel investigates the effect of using a small number of input probability mass functions (PMFs) for a range of signal-to-noise ratios (SNRs), instead of optimizing the constellation shaping for each SNR. It is shown that if a small penalty of at most 0.1 dB SNR to the full shaping gain is acceptable, just two shaped PMFs are required per quadrature amplitude modulation (QAM) over a large SNR range. For a multi-span wavelength division multiplexing (WDM) optical fiber system with 64QAM input, it is shown that just one PMF is required to achieve large gains over uniform input for distances from 1,400 km to 3,000 km. Using recently developed theoretical models that extend the Gaussian noise (GN) model and full-field split-step simulations, we illustrate the ramifications of probabilistic shaping on the effective SNR after fiber propagation. Our results show that, for a fixed average optical launch power, a shaping gain is obtained for the noise contributions from fiber amplifiers and modulation-independent nonlinear interference (NLI), whereas shaping simultaneously causes a penalty as it leads to an increased NLI. However, this nonlinear shaping loss is found to have a relatively minor impact, and optimizing the shaped PMF with a modulation-dependent GN model confirms that the PMF found for AWGN is also a good choice for a multi-span fiber system. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04142;Mutual information for symmetric rank-one matrix estimation: A proof of  the replica formula; Jean Barbier,  Mohamad Dia,  Nicolas Macris,  Florent Krzakala,  Thibault Lesieur,  Lenka Zdeborova;  Factorizing low-rank matrices has many applications in machine learning and statistics. For probabilistic models in the Bayes optimal setting, a general expression for the mutual information has been proposed using heuristic statistical physics computations, and proven in few specific cases. Here, we show how to rigorously prove the conjectured formula for the symmetric rank-one case. This allows to express the minimal mean-square-error and to characterize the detectability phase transitions in a large set of estimation problems ranging from community detection to sparse PCA. We also show that for a large set of parameters, an iterative algorithm called approximate message-passing is Bayes optimal. There exists, however, a gap between what currently known polynomial algorithms can do and what is expected information theoretically. Additionally, the proof technique has an interest of its own and exploits three essential ingredients: the interpolation method introduced in statistical physics by Guerra, the analysis of the approximate message-passing algorithm and the theory of spatial coupling and threshold saturation in coding. Our approach is generic and applicable to other open problems in statistical estimation where heuristic statistical physics predictions are available. ;"Information Theory (cs.IT); Disordered Systems and Neural Networks (cond-mat.dis-nn); Learning (cs.LG); Mathematical Physics (math-ph)"
https://arxiv.org/abs/1606.04191;Path-Following Algorithms for Beamforming and Signal Splitting in RF  Energy Harvesting Networks; Ali A. Nasir,  Hoang D. Tuan,  Duy T. Ngo,  Salman Durrani,  Dong In Kim;  We consider the joint design of transmit beamforming and receive signal-splitting ratios in the downlink of a wireless network with simultaneous radio-frequency (RF) information and energy transfer. Under constraints on the signal-to-interference-plus-noise ratio (SINR) at each user and the total transmit power at the base station, the design objective is to maximize either the sum harvested energy or the minimum harvested energy. We develop a computationally efficient path-following method to solve these challenging nonconvex optimization problems. We mathematically show that the proposed algorithms iteratively progress and converge to locally optimal solutions. Simulation results further show that these locally optimal solutions are the same as the globally optimal solutions for the considered practical network settings. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04198;Cloud Radio Access meets Heterogeneous Small Cell Networks: A Cognitive  Hierarchy Perspective; Nof Abuzainab,  Walid Saad;  In this paper, the problem of distributed power allocation is considered for the downlink of a cloud radio access network (CRAN) that is coexisting with a heterogeneous network. In this multi-tier system, the heterogeneous network base stations (BSs) as well as the CRAN remote radio heads seek to choose their optimal power to maximize their users' rates. The problem is formulated as a noncooperative game in which the players are the CRAN's cloud and the BSs. Given the difference of capabilities between the CRAN and the various BSs, the game is cast within the framework of cognitive hierarchy theory. In this framework, players are organized in a hierarchy in such a way that a player can choose its strategy while considering players of only similar or lower hierarchies. Using such a hierarchical design, one can reduce the interference caused by the CRAN and high-powered base stations on low-powered BSs. For this game, the properties of the Nash equilibrium and the cognitive hierarchy equilibrium are analyzed. Simulation results show that the proposed cognitive hierarchy model yields significant performance gains, in terms of the total rate, reaching up to twice the rate achieved by a classical noncooperative game's Nash equilibrium. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04202;Improved Approximation of Storage-Rate Tradeoff for Caching with  Multiple Demands; Avik Sengupta,  Ravi Tandon;"  Caching at the network edge has emerged as a viable solution for alleviating the severe capacity crunch in modern content centric wireless networks by leveraging network load-balancing in the form of localized content storage and delivery. In this work, we consider a cache-aided network where the cache storage phase is assisted by a central server and users can demand multiple files at each transmission interval. To service these demands, we consider two delivery models - $(1)$ centralized content delivery where user demands at each transmission interval are serviced by the central server via multicast transmissions; and $(2)$ device-to-device (D2D) assisted distributed delivery where users multicast to each other in order to service file demands. For such cache-aided networks, we present new results on the fundamental cache storage vs. transmission rate tradeoff. Specifically, we develop a new technique for characterizing information theoretic lower bounds on the storage-rate tradeoff and show that the new lower bounds are strictly tighter than cut-set bounds from literature. Furthermore, using the new lower bounds, we establish the optimal storage-rate tradeoff to within a constant multiplicative gap. We show that, for multiple demands per user, achievable schemes based on repetition of schemes for single demands are order-optimal under both delivery models. ";"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.04322;Modeling and Analysis of SCMA Enhanced D2D and Cellular Hybrid Network; Junyu Liu,  Min Sheng,  Lei Liu,  Yan Shi,  Jiandong Li;  Sparse code multiple access (SCMA) has been recently proposed for the future wireless networks, which allows non-orthogonal spectrum resource sharing and enables system overloading. In this paper, we apply SCMA into device-to-device (D2D) communication and cellular hybrid network, targeting at using the overload feature of SCMA to support massive device connectivity and expand network capacity. Particularly, we develop a stochastic geometry based framework to model and analyze SCMA, considering underlaid and overlaid mode. Based on the results, we analytically compare SCMA with orthogonal frequency-division multiple access (OFDMA) using area spectral efficiency (ASE) and quantify closed-form ASE gain of SCMA over OFDMA. Notably, it is shown that system ASE can be significantly improved using SCMA and the ASE gain scales linearly with the SCMA codeword dimension. Besides, we endow D2D users with an activated probability to balance cross-tier interference in the underlaid mode and derive the optimal activated probability. Meanwhile, we study resource allocation in the overlaid mode and obtain the optimal codebook allocation rule. It is interestingly found that the optimal SCMA codebook allocation rule is independent of cellular network parameters when cellular users are densely deployed. The results are helpful in the implementation of SCMA in the hybrid system. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04405;Fundamentals of Modeling Finite Wireless Networks using Binomial Point  Process; Mehrnaz Afshang,  Harpreet S. Dhillon;  Modeling the locations of nodes as a uniform binomial point process (BPP), we present a generic mathematical framework to characterize the performance of an arbitrarily-located reference receiver in a finite wireless network. Different from most of the prior works where the serving transmitter (TX) node is located at the fixed distance from the reference receiver, we consider two general TX-selection policies: i) uniform TX-selection: the serving node is chosen uniformly at random amongst transmitting nodes, and ii) k-closest TX-selection: the serving node is the k-th closest node out of transmitting nodes to the reference receiver. The key intermediate step in our analysis is the derivation of a new set of distance distributions that lead not only to the tractable analysis of coverage probability but also enable the analyses of wide range of classical and currently trending problems in wireless networks. Using this new set of distance distributions, we first investigate the diversity loss due to SIR correlation in a finite network. We then obtain the optimal number of links that can be simultaneously activated to maximize network spectral efficiency. Finally, we evaluate optimal caching probability to maximize the total hit probability in cache-enabled finite networks. ;"Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)"
https://arxiv.org/abs/1606.04432;Decentralized Simultaneous Information and Energy Transmission in K-User  Multiple Access Channels; Selma Belhadj Amor,  Samir M. Perlaza,  H. Vincent Poor;"  In this paper, the fundamental limits of decentralized simultaneous information and energy transmission in the $K$-user Gaussian multiple access channel (G-MAC), with an arbitrary $K \geqslant 2$ and one non-colocated energy harvester (EH), are fully characterized. The objective of the transmitters is twofold. First, they aim to reliably communicate their message indices to the receiver; and second, to harvest energy at the EH at a rate not less than a minimum rate requirement $b$. The information rates $R_1,\dots,R_K$, in bits per channel use, are measured at the receiver and the energy rate $B$ is measured at an EH. Stability is considered in the sense of an $\eta$-Nash equilibrium ($\eta$-NE), with $\eta > 0$. The main result is a full characterization of the $\eta$-NE information-energy region, i.e., the set of information-energy rate tuples $(R_1,\dots,R_K,B)$ that are achievable and stable in the G-MAC when: $(a)$ all the transmitters autonomously and independently tune their own transmit configurations seeking to maximize their own information transmission rates $R_1,\dots, R_K$; and $(b)$ all the transmitters jointly guarantee an energy transmission rate $B$ at the EH, such that $B \geqslant b$. Therefore, any rate tuple outside the $\eta$-NE region is not stable as there always exists at least one transmitter able to increase by at least $\eta$ bits per channel use its own information transmission rate by updating its own transmit configuration. ";Information Theory (cs.IT)
https://arxiv.org/abs/1606.04458;Secure Compute-and-Forward Transmission With Artificial Noise and  Full-Duplex Devices; Stefano Tomasin;"  We consider a wiretap channel with an eavesdropper (Eve) and an honest but curious relay (Ray). Ray and the destination (Bob) are full-duplex (FD) devices. Since we aim at not revealing information on the secret message to the relay, we consider the scaled compute-and-forward (SCF) where scaled lattice coding is used in the transmission by both the source (Alice) and Bob in order to allow Ray to decode only a linear combination of the two messages. At the same time Ray transmits artificial noise (AN) to confuse Eve. When Ray relays the decoded linear combination, Alice and Bob are transmitting AN against Eve. This can be a 5G cellular communication scenario where a mobile terminal (MT) aims at transmitting a secret message to a FD base station (BS), with the assistance of a network FD relay. With respect to existing literature the innovations of this paper are: a) Bob and Ray are FD devices; b) Alice, Ray and Bob transmit also AN; and c) the channel to Eve is not known to Alice, Bob and Ray. For this scenario we derive bounds on both the secrecy outage probability under Rayleigh fading conditions of the channels to Eve, and the achievable secrecy-outage rates. ";Information Theory (cs.IT)
https://arxiv.org/abs/1606.04467;Outer Bounds on the Storage-Repair Bandwidth Tradeoff of Exact-Repair  Regenerating Codes; Birenjith Sasidharan,  N. Prakash,  M. Nikhil Krishnan,  Myna Vajha,  Kaushik Senthoor,  P. Vijay Kumar;  In this paper, three outer bounds on the normalized storage-repair bandwidth (S-RB) tradeoff of regenerating codes having parameter set $\{(n,k,d),(\alpha,\beta)\}$ under the exact-repair (ER) setting are presented. The first outer bound is applicable for every parameter set $(n,k,d)$ and in conjunction with a code construction known as {\em improved layered codes}, it characterizes the normalized ER tradeoff for the case $(n,k=3,d=n-1)$. It establishes a non-vanishing gap between the ER and functional-repair (FR) tradeoffs for every $(n,k,d)$. The second bound is an improvement upon an existing bound due to Mohajer et al. and is tighter than the first bound, in a regime away from the Minimum Storage Regeneraing (MSR) point. The third bound is for the case of $k=d$, under the linear setting. This outer bound matches with the achievable region of {\em layered codes} thereby characterizing the normalized ER tradeoff of linear ER codes when $k=d=n-1$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04476;Downlink Performance of Superimposed Pilots in Massive MIMO systems; Karthik Upadhya,  Sergiy A. Vorobyov,  Mikko Vehkapera;  In this paper, we investigate the downlink signal-to-interference plus noise ratio (SINR) performance of a massive multiple-input multiple-output (MIMO) system that employs superimposed pilots for channel estimation. The mean-squared error (MSE) of the channel estimate is compared with the Bayesian Cram\'{e}r-Rao lower bound that is derived for the system, and the former is shown to diminish with increasing number of antennas at the base station (BS). The component of downlink (DL) interference that results from transmitting data alongside pilots in the uplink (UL) is also shown to decrease at a rate proportional to the square root of the number of antennas at the BS. Furthermore, we show that staggered pilots are a particular case of superimposed pilots and therefore, offer higher downlink throughput while retaining the UL spectral and energy efficiency of time-multiplexed pilots. We also extend the framework for designing a hybrid system, consisting of users that transmit either time-multiplexed or superimposed pilots, to minimize both the UL and DL interference. The improved MSE and DL SINR performances of the channel estimator based on superimposed pilots are demonstrated by means of simulations. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04488;Directional Modulation via Symbol-Level Precoding: A Way to Enhance  Security; Ashkan Kalantari,  Mojtaba Soltanalian,  Sina Maleki,  Symeon Chatzinotas,  Björn Ottersten;  Wireless communication provides a wide coverage at the cost of exposing information to unintended users. As an information-theoretic paradigm, secrecy rate derives bounds for secure transmission when the channel to the eavesdropper is known. However, such bounds are shown to be restrictive in practice and may require exploitation of specialized coding schemes. In this paper, we employ the concept of directional modulation and follow a signal processing approach to enhance the security of multi-user MIMO communication systems when a multi-antenna eavesdropper is present. Enhancing the security is accomplished by increasing the symbol error rate at the eavesdropper. Unlike the information-theoretic secrecy rate paradigm, we assume that the legitimate transmitter is not aware of its channel to the eavesdropper, which is a more realistic assumption. We examine the applicability of MIMO receiving algorithms at the eavesdropper. Using the channel knowledge and the intended symbols for the users, we design security enhancing symbol-level precoders for different transmitter and eavesdropper antenna configurations. We transform each design problem to a linearly constrained quadratic program and propose two solutions, namely the iterative algorithm and one based on non-negative least squares, at each scenario for a computationally-efficient modulation. Simulation results verify the analysis and show that the designed precoders outperform the benchmark scheme in terms of both power efficiency and security enhancement. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04601;Cyclic codes over $\mathbb{Z}_4[u]/\langle u^k\rangle$ of odd length; Cao Yuan,  Li Qingguo;  Let $R=\mathbb{Z}_{4}[u]/\langle u^k\rangle=\mathbb{Z}_{4}+u\mathbb{Z}_{4}+\ldots+u^{k-1}\mathbb{Z}_{4}$ ($u^k=0$) where $k\in \mathbb{Z}^{+}$ satisfies $k\geq 2$. For any odd positive integer $n$, it is known that cyclic codes over $R$ of length $n$ are identified with ideals of the ring $R[x]/\langle x^{n}-1\rangle$. In this paper, an explicit representation for each cyclic code over $R$ of length $n$ is provided and a formula to count the number of codewords in each code is given. Then a formula to calculate the number of cyclic codes over $R$ of length $n$ is obtained. Precisely, the dual code of each cyclic code and self-dual cyclic codes over $R$ of length $n$ are investigated. When $k=4$, some optimal quasi-cyclic codes over $\mathbb{Z}_{4}$ of length $28$ and index $4$ are obtained from cyclic codes over $R=\mathbb{Z}_{4} [u]/\langle u^4\rangle$. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04639;Wireless Information and Power Transfer Design for Energy Cooperation  Distributed Antenna Systems; Fangchao Yuan,  Shi Jin,  Kai-Kit Wong,  Hongbo Zhu;  Distributed antenna systems (DAS) have been widely implemented in state-of-the-art cellular communication systems to cover dead spots. Recent studies have also indicated that DAS have advantages in wireless energy transfer (WET). In this paper, we study simultaneous wireless information and power transfer (SWIPT) for a multiple-input single-output (MISO) DAS in the downlink which consists of arbitrarily distributed remote antenna units (RAUs). In order to save the energy cost, we adopt energy cooperation of energy harvesting (EH) and two-way energy flows to let the RAUs trade their harvested energy through the smart grid network. Under individual EH constraints, per-RAU power constraints and various smart grid considerations, we investigate a power management strategy that determines how to utilize the stochastically spatially distributed harvested energy at the RAUs and how to trade the energy with the smart grid simultaneously to supply maximum wireless information transfer (WIT) with a minimum WET constraint for a receiver adopting power splitting (PS). Our analysis shows that the optimal design can be achieved in two steps. The first step is to maximize a new objective that can simultaneously maximize both WET and WIT, considering both the smart grid profitable and smart grid neutral cases. For the grid-profitable case, we derive the optimal full power strategy and provide a closed-form result to see under what condition this strategy is used. On the other hand, for the grid-neutral case, we illustrate that the optimal power policy has a double-threshold structure and present an optimal allocation strategy. The second step is then to solve the whole problem by obtaining the splitting power ratio based on the minimum WET constraint. Simulation results are provided to evaluate the performance under various settings and characterize the double-threshold structure. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04661;Throughput Maximization for Decode-and-Forward Relay Channels with  Non-Ideal Circuit Power; Hengjing Liang,  Chuan Huang,  Zhi Chen,  Shaoqian Li;  This paper studies the throughput maximization problem for a three-node relay channel with non-ideal circuit power. In particular, the relay operates in a half-duplex manner, and the decode-and-forward (DF) relaying scheme is adopted. Considering the extra power consumption by the circuits, the optimal power allocation to maximize the throughput of the considered system over an infinite time horizon is investigated. First, two special scenarios, i.e., the direct link transmission (only use the direct link to transmit) and the relay assisted transmission (the source and the relay transmit with equal probability), are studied, and the corresponding optimal power allocations are obtained. By transforming two non-convex problems into quasiconcave ones, the closed-form solutions show that the source and the relay transmit with certain probability, which is determined by the average power budgets, circuit power consumptions, and channel gains. Next, based on the above results, the optimal power allocation for both the cases with and without direct link is derived, which is shown to be a mixed transmission scheme between the direct link transmission and the relay assisted transmission. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04678;Strong Converse Theorems for Multimessage Networks with Tight Cut-Set  Bound; Silas L. Fong,  Vincent Y. F. Tan;"  This paper considers a multimessage network where each node may send a message to any other node in the network. Under the discrete memoryless model, we prove the strong converse theorem for any network with tight cut-set bound, i.e., whose cut-set bound is achievable. Our result implies that for any network with tight cut-set bound and any fixed rate vector that resides outside the capacity region, the average error probabilities of any sequence of length-$n$ codes operated at the rate vector must tend to $1$ as $n$ grows. The proof is based on the method of types. The proof techniques are inspired by the work of Csisz\'{a}r and K\""{o}rner in 1982 which fully characterized the reliability function of any discrete memoryless channel (DMC) with feedback for rates above capacity. In addition, we generalize the strong converse theorem to the Gaussian model where each node is subject to a peak power constraint. Important consequences of our results are new strong converses for the Gaussian multiple access channel (MAC) with feedback and the following relay channels under both models: The degraded relay channel (RC), the RC with orthogonal sender components, and the general RC with feedback. ";Information Theory (cs.IT)
https://arxiv.org/abs/1606.04749;Network Densification in 5G: From the Short-Range Communications  Perspective; Junyu Liu,  Min Sheng,  Lei Liu,  Jiandong Li;  Besides advanced telecommunications techniques, the most prominent evolution of wireless networks is the densification of network deployment. In particular, the increasing access points/users density and reduced cell size significantly enhance spatial reuse, thereby improving network capacity. Nevertheless, does network ultra-densification and over-deployment always boost the performance of wireless networks? Since the distance from transmitters to receivers is greatly reduced in dense networks, signal is more likely to be propagated from long- to short-range region. Without considering short-range propagation features, conventional understanding of the impact of network densification becomes doubtful. With this regard, it is imperative to reconsider the pros and cons brought by network densification. In this article, we first discuss the short-range propagation features in densely deployed network and verify through experimental results the validity of the proposed short-range propagation model. Considering short-range propagation, we further explore the fundamental impact of network densification on network capacity, aided by which a concrete interpretation of ultra-densification is presented from the network capacity perspective. Meanwhile, as short-range propagation makes interference more complicated and difficult to handle, we discuss possible approaches to further enhance network capacity in ultra-dense wireless networks. Moreover, key challenges are presented to suggest future directions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04760;Adapting to unknown noise level in sparse deconvolution; Claire Boyer,  Yohann De Castro,  Joseph Salmon;  In this paper, we study sparse spike deconvolution over the space of complex-valued measures when the input measure is a finite sum of Dirac masses. We introduce a modified version of the Beurling Lasso (BLasso), a semi-definite program that we refer to as the Concomitant Beurling Lasso (CBLasso). This new procedure estimates the target measure and the unknown noise level simultaneously. Contrary to previous estimators in the literature, theory holds for a tuning parameter that depends only on the sample size, so that it can be used for unknown noise level problems. Consistent noise level estimation is standardly proved. As for Radon measure estimation, theoretical guarantees match the previous state-of-the-art results in Super-Resolution regarding minimax prediction and localization. The proofs are based on a bound on the noise level given by a new tail estimate of the supremum of a stationary non-Gaussian process through the Rice method. ;"Information Theory (cs.IT); Optimization and Control (math.OC); Statistics Theory (math.ST)"
https://arxiv.org/abs/1606.04761;Probabilistic Interpretation for Correntropy with Complex Data; João P. F. Guimarães,  Aluisio I. R. Fontes,  Joilson B. A. Rego,  Allan de M. Martins;  Recent studies have demonstrated that correntropy is an efficient tool for analyzing higher-order statistical moments in nonGaussian noise environments. Although it has been used with complex data, some adaptations were then necessary without deriving a generic form so that similarities between complex random variables can be aggregated. This paper presents a novel probabilistic interpretation for correntropy using complex-valued data called complex correntropy. An analytical recursive solution for the maximum complex correntropy criterion (MCCC) is introduced as based on the fixedpoint solution. This technique is applied to a simple system identification case study, as the results demonstrate prominent advantages regarding the proposed cost function if compared to the complex recursive least squares (RLS) algorithm. By using such probabilistic interpretation, correntropy can be applied to solve several problems involving complex data in a more straightforward way. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04794;A Convex Relaxation Approach to Higher-Order Statistical Approaches to  Signal Recovery; Huy-Dung Han,  Zhi Ding,  Muhammad Zia;  In this work, we investigate an efficient numerical approach for solving higher order statistical methods for blind and semi-blind signal recovery from non-ideal channels. We develop numerical algorithms based on convex optimization relaxation for minimization of higher order statistical cost functions. The new formulation through convex relaxation overcomes the local convergence problem of existing gradient descent based algorithms and applies to several well-known cost functions for effective blind signal recovery including blind equalization and blind source separation in both single-input-single-output (SISO) and multi-input-multi-output (MIMO) systems. We also propose a fourth order pilot based cost function that benefits from this approach. The simulation results demonstrate that our approach is suitable for short-length packet data transmission using only a few pilot symbols. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04861;A necessary and sufficient condition for minimum phase and implications  for phase retrieval; Antonio Mecozzi;  We give a necessary and sufficient condition for a function $E(t)$ being of minimum phase, and hence for its phase being univocally determined by its intensity $|E(t)|^2$. This condition is based on the knowledge of $E(t)$ alone and not of its analytic continuation in the complex plane, thus greatly simplifying its practical applicability. We apply these results to find the class of all band-limited signals that correspond to distinct receiver states when the detector is sensitive to the field intensity only and insensitive to the field phase, and discuss the performance of a recently proposed transmission scheme able to linearly detect all distinguishable states. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.04933;Rapid, Robust, and Reliable Blind Deconvolution via Nonconvex  Optimization; Xiaodong Li,  Shuyang Ling,  Thomas Strohmer,  Ke Wei;  We study the question of reconstructing two signals $f$ and $g$ from their convolution $y = f\ast g$. This problem, known as {\em blind deconvolution}, pervades many areas of science and technology, including astronomy, medical imaging, optics, and wireless communications. A key challenge of this intricate non-convex optimization problem is that it might exhibit many local minima. We present an efficient numerical algorithm that is guaranteed to recover the exact solution, when the number of measurements is (up to log-factors) slightly larger than the information-theoretical minimum, and under reasonable conditions on $f$ and $g$. The proposed regularized gradient descent algorithm converges at a geometric rate and is provably robust in the presence of noise. To the best of our knowledge, our algorithm is the first blind deconvolution algorithm that is numerically efficient, robust against noise, and comes with rigorous recovery guarantees under certain subspace conditions. Moreover, numerical experiments do not only provide empirical verification of our theory, but they also demonstrate that our method yields excellent performance even in situations beyond our theoretical framework. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.05019;On a class of left metacyclic codes; Cao Yonglin,  Cao Yuan,  Fu Fang-Wei,  Gao Jian;  Let $G_{(m,3,r)}=\langle x,y\mid x^m=1, y^3=1,yx=x^ry\rangle$ be a metacyclic group of order $3m$, where ${\rm gcd}(m,r)=1$, $1<r<m$ and $r^3\equiv 1$ (mod $m$). Then left ideals of the group algebra $\mathbb{F}_q[G_{(m,3,r)}]$ are called left metacyclic codes over $\mathbb{F}_q$ of length $3m$, and abbreviated as left $G_{(m,3,r)}$-codes. A system theory for left $G_{(m,3,r)}$-codes is developed for the case of ${\rm gcd}(m,q)=1$ and $r\equiv q^\epsilon$ for some positive integer $\epsilon$, only using finite field theory and basic theory of cyclic codes and skew cyclic codes. The fact that any left $G_{(m,3,r)}$-code is a direct sum of concatenated codes with inner codes ${\cal A}_i$ and outer codes $C_i$ is proved, where ${\cal A}_i$ is a minimal cyclic code over $\mathbb{F}_q$ of length $m$ and $C_i$ is a skew cyclic code of length $3$ over an extension field of $\mathbb{F}_q$. Then an explicit expression for each outer code in any concatenated code is provided. Moreover, the dual code of each left $G_{(m,3,r)}$-code is given and self-orthogonal left $G_{(m,3,r)}$-codes are determined. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.05025;Large Antenna Analysis of Multi-Cell Full-Duplex Networks; Jingwen Bai,  Ashutosh Sabharwal;  We study a multi-cell multi-user MIMO full-duplex network, where each base station (BS) has multiple antennas with full-duplex capability supporting single-antenna users with either full-duplex or half-duplex radios. We characterize the up- and downlink ergodic achievable rates for the case of linear precoders and receivers. The rate analysis includes practical constraints such as imperfect self- interference cancellation, channel estimation error, training overhead and pilot contamination. We show that the 2X gain of full-duplex over half-duplex system remains in the asymptotic regime where the number of BS antennas grows infinitely large. We numerically evaluate the finite SNR and antenna performance, which reveals that full-duplex networks can use significantly fewer antennas to achieve spectral efficiency gain over the half-duplex counterparts. In addition, the overall full-duplex gains can be achieved under realistic 3GPP multi-cell network settings despite the increased interference introduced in the full-duplex networks. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.05043;Performance Analysis of Target Parameters Estimation Using Multiple  Widely Separated Antenna Arrays; Peter Khomchuk,  Igal Bilik,  Rick S. Blum;  Target parameter estimation performance is investigated for a radar employing a set of widely separated transmitting and receiving antenna arrays. Cases with multiple extended targets are considered under two signal model assumptions: stochastic and deterministic. The general expressions for the corresponding Cramer-Rao lower bound (CRLB) and the asymptotic properties of the maximum-likelihood (ML) estimator are derived for a radar with $M_t$ arrays of $L_t$ transmitting elements and $M_r$ arrays of $L_r$ receiving elements for both types of signal models. It is shown that for an infinitely large product $M_tM_r$, and a finite $L_r$, the ML estimator is consistent and efficient under the stochastic model, while the deterministic model requires $M_tM_r$ to be finite and $L_r$ to be infinitely large in order to guarantee consistency and efficiency. Monte Carlo simulations further investigate the estimation performance of the proposed radar configuration in practical scenarios with finite $M_tM_r$ and $L_r$, and a fixed total number of available receiving antenna elements, $M_r L_r$. The numerical results demonstrate that grouping receiving elements into properly sized arrays reduces the mean squared error (MSE) and decreases the threshold SNR. In the numerical examples considered, the preferred configurations employ $M_t M_r > 1$. In fact, when $M_t M_r$ becomes too small, due to the loss of the geometric gain, the estimation performance becomes strongly dependent on the particular scenario and can degrade significantly, while the CRLB may become a poor prediction of the MSE even for high SNR. This suggests it may be advantageous to employ approaches where neither $M_tM_r$ nor $L_r$ are too small. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.05057;Accumulate then Forward: An Opportunistic Relaying Protocol for  Wireless-Powered Cooperative Communications; Ziyi Li,  He Chen,  Yifan Gu,  Yonghui Li,  Branka Vucetic;"  This paper investigates a wireless-powered cooperative communication network consisting of a source, a destination and a multi-antenna decode-and-forward relay. We consider the relay as a wireless-powered node that has no external power supply; but it is equipped with an energy harvesting (EH) unit and a rechargeable battery such that it can harvest and accumulate energy from radio-frequency signals broadcast by the source. By fully incorporating the EH feature of the relay, we develop an opportunistic relaying protocol, termed accumulate-then-forward (ATF), for the considered WPCCN. We then adopt the discrete Markov chain to model the dynamic charging and discharging behaviors of the relay battery. Based on this, we derive a closed-form expression for the exact outage probability of the proposed ATF protocol. Numerical results show that the ATF scheme can outperform the direct transmission one, especially when the amount of energy consumed by relay for information forwarding is optimized. ";Information Theory (cs.IT)
https://arxiv.org/abs/1606.05127;On the Calculation of the Incomplete MGF with Applications to Wireless  Communications; F.J. Lopez-Martinez,  J.M. Romero-Jerez,  J.F. Paris;  The incomplete moment generating function (IMGF) has paramount relevance in communication theory, since it appears in a plethora of scenarios when analyzing the performance of communication systems. We here present a general method for calculating the IMGF of any arbitrary fading distribution. Then, we provide exact closed-form expressions for the IMGF of the very general {\kappa}-{\mu} shadowed fading model, which includes the popular {\kappa}-{\mu}, {\eta}-{\mu}, Rician shadowed and other classical models as particular cases. We illustrate the practical applicability of this result by analyzing several scenarios of interest in wireless communications: (1) Physical layer security in the presence of an eavesdropper, (2) Outage probability analysis with interference and background noise, (3) Channel capacity with side information at the transmitter and the receiver, and (4) Average bit-error rate with adaptive modulation, when the fading on the desired link can be modeled by any of the aforementioned distributions. ;Information Theory (cs.IT)
https://arxiv.org/abs/1606.05135;Distributed Beam Scheduling for Multi-RAT Coexistence in mm-Wave 5G  Networks; Maziar Nekovee,  Yinan Qi,  Yue Wang;  Millimetre-wave communication (licensed or unlicensed) is envisaged to be an important part of the fifth generation (5G) multi-RAT ecosystem. In this paper, we consider the spectrum bands shared by 5G cellular base stations and some existing networks, such as WiGig. Sharing the same band among such multiple radio access technologies (RATs) is very challenging due to the lack of centralized coordination and demands novel and efficient interference mitigation and coexistence mechanisms to reduce the mutual interference. To address this important challenge, we propose in this paper a novel multi-RAT coexistence mechanism where neighbouring 5G and WiGig base stations, each serving their own associated UEs, schedule their beam configurations in a distributed manner such that their own utility function, e.g. spectral efficiency, is maximized. We formulate the problem as a combinatorial optimization problem and show via simulations that our proposed distributed algorithms yield a comparable spectral efficiency for the entire networks as that using an exhaustive search, which requires global coordination among coexisting RATs and also has a much higher algorithmic complexity. ;Information Theory (cs.IT)
